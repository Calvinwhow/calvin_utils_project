{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P(S,A, W_S={'strawb': 0.5, 'blueb': 0.25, 'cin': 0.25}):\n",
    "    '''\n",
    "    basic function to calculate probability of selecting from sample S if it belongs to the population A. \n",
    "    P(simultaneous_events) = p(1)*p(2)*p(3)\n",
    "    '''\n",
    "    # W_S is the prevalence within the distribution, normalized.\n",
    "    \n",
    "    if set(A).issubset(set(S)):\n",
    "        if W_S is not None:\n",
    "            return len(A)/len(S)\n",
    "        else:\n",
    "            return len(A)/len(S)\n",
    "    else:\n",
    "        return 0\n",
    "A= set(['strawb'])\n",
    "S = set(['strawb','blueb','cin'])\n",
    "P(S,A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install preliz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy pymc3 arviz matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Expected counts for 3:2:1 ratio\n",
    "expected_counts = np.array([1, 1, 1])\n",
    "# Dirichlet prior parameters based on expected counts\n",
    "alpha = expected_counts\n",
    "\n",
    "# Observed synthetic stroke counts for 3 brain regions\n",
    "stroke_counts = np.array([90, 50, 40])\n",
    "total_strokes = np.sum(stroke_counts)\n",
    "num_regions = len(stroke_counts)\n",
    "\n",
    "with pm.Model() as model:\n",
    "    # Dirichlet prior (theta)\n",
    "    theta = pm.Dirichlet('theta', a=alpha)\n",
    "    \n",
    "    # Likelihood (y|theta)\n",
    "    y = pm.Multinomial('y', n=total_strokes, p=theta, observed=stroke_counts)\n",
    "    \n",
    "    # p(y) is undefined here as it is calculated during pm.Model's call. \n",
    "    # Use the defined model to fine-tune the posterior P(theta | y) via pm.sample\n",
    "    trace = pm.sample(2000, tune=1000, return_inferencedata=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the statistical properties of the posterior\n",
    "# hdi (highest density interval) interval is the 94% probability that the true value is actually within that interval (the 94% credibility interval)\n",
    "# credible interval widens based on the inerse sample size of the observed values, NOT the model. \n",
    "summary = az.summary(trace, kind='stats')\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the posteriors\n",
    "az.plot_trace(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimlab_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
