{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify where you want to save your results to\n",
    "out_dir = '/Users/cu135/Partners HealthCare Dropbox/Calvin Howard/studies/atrophy_seeds_2023/Figures/supplement_parametric_regression_to_adascog'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your CSV file containing NIFTI paths\n",
    "input_csv_path = '/Users/cu135/Partners HealthCare Dropbox/Calvin Howard/studies/cognition_2023/metadata/master_list_proper_subjects.xlsx'\n",
    "sheet = 'master_list_proper_subjects' # 'master_list_proper_subjects'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.permutation_analysis_utils.statsmodels_palm import CalvinStatsmodelsPalm\n",
    "# Instantiate the PalmPrepararation class\n",
    "cal_palm = CalvinStatsmodelsPalm(input_csv_path=input_csv_path, output_dir=out_dir, sheet=sheet)\n",
    "# Call the process_nifti_paths method\n",
    "data_df = cal_palm.read_and_display_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 01 - Preprocess Your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handle NANs**\n",
    "- Set drop_nans=True is you would like to remove NaNs from data\n",
    "- Provide a column name or a list of column names to remove NaNs from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject', 'Age', 'Hippocampus_GM_Vol', 'Parahippocampal_Gyrus_GM_Vol',\n",
       "       'Entorhinal_Cortex_GM_Vol', 'Normalized_Percent_Cognitive_Improvement',\n",
       "       'Z_Scored_Percent_Cognitive_Improvement_By_Origin_Group',\n",
       "       'Z_Scored_Percent_Cognitive_Improvement',\n",
       "       'Percent_Cognitive_Improvement',\n",
       "       'Z_Scored_Subiculum_T_By_Origin_Group_',\n",
       "       'Z_Scored_Subiculum_Connectivity_T', 'Subiculum_Connectivity_T_Redone',\n",
       "       'Subiculum_Connectivity_T', 'Amnesia_Lesion_T_Map', 'Memory_Network_T',\n",
       "       'Z_Scored_Memory_Network_R', 'Memory_Network_R',\n",
       "       'Subiculum_Grey_Matter', 'Subiculum_White_Matter', 'Subiculum_CSF',\n",
       "       'Subiculum_Total', 'Standardized_Age',\n",
       "       'Standardized_Percent_Improvement',\n",
       "       'Standardized_Subiculum_Connectivity',\n",
       "       'Standardized_Subiculum_Grey_Matter',\n",
       "       'Standardized_Subiculum_White_Matter', 'Standardized_Subiculum_CSF',\n",
       "       'Standardized_Subiculum_Total', 'Disease', 'Cohort', 'City',\n",
       "       'Inclusion_Cohort', 'Categorical_Age_Group', 'Age_Group',\n",
       "       'Age_And_Disease', 'Age_Disease_and_Cohort', 'Age_Disease_Cohort_Stim',\n",
       "       'Age_And_Stim', 'Subiculum_Group_By_Z_Score_Sign',\n",
       "       'Subiculum_Group_By_Inflection_Point', 'Subiculum_Group_By_24',\n",
       "       'Cognitive_Outcome', 'StimMatch', 'StimMatch24', 'Cognitive_Baseline',\n",
       "       'Cognitive_Score_1_Yr', 'MinMaxNorm_Cog_Score_1_Yr',\n",
       "       'Abs_Cognitive_Improve', 'IMPROVE_OR_STABLE', 'DECLINE_OR_STABLE',\n",
       "       'IMPROVE', 'DECLINE', 'Cognitive_Improve',\n",
       "       'Z_Scored_Cognitive_Baseline',\n",
       "       'Z_Scored_Cognitive_Baseline__Lower_is_Better_',\n",
       "       'Min_Max_Normalized_Baseline', 'MinMaxNormBaseline_Higher_is_Better',\n",
       "       'ROI_to_Alz_Max', 'ROI_to_PD_Max', 'Standardzied_AD_Max',\n",
       "       'Standardized_PD_Max'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['Age', 'Z_Scored_Percent_Cognitive_Improvement', 'Hippocampus_GM_Vol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>Age</th>\n",
       "      <th>Hippocampus_GM_Vol</th>\n",
       "      <th>Parahippocampal_Gyrus_GM_Vol</th>\n",
       "      <th>Entorhinal_Cortex_GM_Vol</th>\n",
       "      <th>Normalized_Percent_Cognitive_Improvement</th>\n",
       "      <th>Z_Scored_Percent_Cognitive_Improvement_By_Origin_Group</th>\n",
       "      <th>Z_Scored_Percent_Cognitive_Improvement</th>\n",
       "      <th>Percent_Cognitive_Improvement</th>\n",
       "      <th>Z_Scored_Subiculum_T_By_Origin_Group_</th>\n",
       "      <th>...</th>\n",
       "      <th>DECLINE</th>\n",
       "      <th>Cognitive_Improve</th>\n",
       "      <th>Z_Scored_Cognitive_Baseline</th>\n",
       "      <th>Z_Scored_Cognitive_Baseline__Lower_is_Better_</th>\n",
       "      <th>Min_Max_Normalized_Baseline</th>\n",
       "      <th>MinMaxNormBaseline_Higher_is_Better</th>\n",
       "      <th>ROI_to_Alz_Max</th>\n",
       "      <th>ROI_to_PD_Max</th>\n",
       "      <th>Standardzied_AD_Max</th>\n",
       "      <th>Standardized_PD_Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>62.0</td>\n",
       "      <td>5.8883</td>\n",
       "      <td>4.5970</td>\n",
       "      <td>2.4587</td>\n",
       "      <td>-0.392857</td>\n",
       "      <td>0.314066</td>\n",
       "      <td>0.314066</td>\n",
       "      <td>-21.428571</td>\n",
       "      <td>-1.282630</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1.518764</td>\n",
       "      <td>-1.518764</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.280</td>\n",
       "      <td>12.222658</td>\n",
       "      <td>14.493929</td>\n",
       "      <td>-1.714513</td>\n",
       "      <td>-1.227368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>77.0</td>\n",
       "      <td>3.7634</td>\n",
       "      <td>3.9036</td>\n",
       "      <td>2.2905</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.013999</td>\n",
       "      <td>0.013999</td>\n",
       "      <td>-36.363636</td>\n",
       "      <td>-1.760917</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.465551</td>\n",
       "      <td>-0.465551</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.520</td>\n",
       "      <td>14.020048</td>\n",
       "      <td>15.257338</td>\n",
       "      <td>-1.155843</td>\n",
       "      <td>-1.022243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>76.0</td>\n",
       "      <td>4.8575</td>\n",
       "      <td>4.8177</td>\n",
       "      <td>3.1596</td>\n",
       "      <td>-1.447368</td>\n",
       "      <td>-0.841572</td>\n",
       "      <td>-0.841572</td>\n",
       "      <td>-78.947368</td>\n",
       "      <td>-0.595369</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.061056</td>\n",
       "      <td>0.061056</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.640</td>\n",
       "      <td>15.118727</td>\n",
       "      <td>17.376384</td>\n",
       "      <td>-0.814348</td>\n",
       "      <td>-0.452865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4.8569</td>\n",
       "      <td>4.8655</td>\n",
       "      <td>2.6641</td>\n",
       "      <td>-2.372549</td>\n",
       "      <td>-1.855477</td>\n",
       "      <td>-1.855477</td>\n",
       "      <td>-129.411765</td>\n",
       "      <td>-0.945206</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.412127</td>\n",
       "      <td>0.412127</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.720</td>\n",
       "      <td>13.112424</td>\n",
       "      <td>15.287916</td>\n",
       "      <td>-1.437954</td>\n",
       "      <td>-1.014027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.9636</td>\n",
       "      <td>4.8434</td>\n",
       "      <td>3.3463</td>\n",
       "      <td>-0.192982</td>\n",
       "      <td>0.533109</td>\n",
       "      <td>0.533109</td>\n",
       "      <td>-10.526316</td>\n",
       "      <td>-1.151973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.061056</td>\n",
       "      <td>0.061056</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.640</td>\n",
       "      <td>15.086568</td>\n",
       "      <td>12.951426</td>\n",
       "      <td>-0.824344</td>\n",
       "      <td>-1.641831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>30</td>\n",
       "      <td>58.0</td>\n",
       "      <td>7.1449</td>\n",
       "      <td>6.5446</td>\n",
       "      <td>3.8850</td>\n",
       "      <td>-0.638889</td>\n",
       "      <td>0.106772</td>\n",
       "      <td>0.106772</td>\n",
       "      <td>-1.388889</td>\n",
       "      <td>-0.590767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1.114522</td>\n",
       "      <td>1.114522</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>13.873339</td>\n",
       "      <td>15.685024</td>\n",
       "      <td>-0.347959</td>\n",
       "      <td>-0.150172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>31</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0478</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.086636</td>\n",
       "      <td>1.086636</td>\n",
       "      <td>1.449275</td>\n",
       "      <td>-1.065220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-1.345113</td>\n",
       "      <td>-1.345113</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.250</td>\n",
       "      <td>10.930371</td>\n",
       "      <td>11.599140</td>\n",
       "      <td>-0.855211</td>\n",
       "      <td>-0.712879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>33</td>\n",
       "      <td>60.0</td>\n",
       "      <td>8.5035</td>\n",
       "      <td>7.4388</td>\n",
       "      <td>4.5143</td>\n",
       "      <td>-0.643357</td>\n",
       "      <td>0.103418</td>\n",
       "      <td>0.103418</td>\n",
       "      <td>-1.398601</td>\n",
       "      <td>-1.108473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.704583</td>\n",
       "      <td>0.704583</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>6.780175</td>\n",
       "      <td>8.774895</td>\n",
       "      <td>-1.570542</td>\n",
       "      <td>-1.101833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>36</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.2357</td>\n",
       "      <td>7.1067</td>\n",
       "      <td>4.5170</td>\n",
       "      <td>-1.286713</td>\n",
       "      <td>-0.379443</td>\n",
       "      <td>-0.379443</td>\n",
       "      <td>-2.797203</td>\n",
       "      <td>-0.775406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.704583</td>\n",
       "      <td>0.704583</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>9.841726</td>\n",
       "      <td>16.308768</td>\n",
       "      <td>-1.042851</td>\n",
       "      <td>-0.064270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>37</td>\n",
       "      <td>64.0</td>\n",
       "      <td>7.0928</td>\n",
       "      <td>6.8967</td>\n",
       "      <td>4.2447</td>\n",
       "      <td>-0.992806</td>\n",
       "      <td>-0.158855</td>\n",
       "      <td>-0.158855</td>\n",
       "      <td>-2.158273</td>\n",
       "      <td>-0.690244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.935174</td>\n",
       "      <td>-0.935174</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>11.101963</td>\n",
       "      <td>10.543942</td>\n",
       "      <td>-0.825635</td>\n",
       "      <td>-0.858200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject   Age  Hippocampus_GM_Vol  Parahippocampal_Gyrus_GM_Vol  \\\n",
       "0       101  62.0              5.8883                        4.5970   \n",
       "1       102  77.0              3.7634                        3.9036   \n",
       "2       103  76.0              4.8575                        4.8177   \n",
       "3       104  65.0              4.8569                        4.8655   \n",
       "4       105  50.0              5.9636                        4.8434   \n",
       "..      ...   ...                 ...                           ...   \n",
       "68       30  58.0              7.1449                        6.5446   \n",
       "69       31  64.0              0.0067                        0.0478   \n",
       "70       33  60.0              8.5035                        7.4388   \n",
       "72       36  52.0              8.2357                        7.1067   \n",
       "73       37  64.0              7.0928                        6.8967   \n",
       "\n",
       "    Entorhinal_Cortex_GM_Vol  Normalized_Percent_Cognitive_Improvement  \\\n",
       "0                     2.4587                                 -0.392857   \n",
       "1                     2.2905                                 -0.666667   \n",
       "2                     3.1596                                 -1.447368   \n",
       "3                     2.6641                                 -2.372549   \n",
       "4                     3.3463                                 -0.192982   \n",
       "..                       ...                                       ...   \n",
       "68                    3.8850                                 -0.638889   \n",
       "69                    0.0376                                  0.666667   \n",
       "70                    4.5143                                 -0.643357   \n",
       "72                    4.5170                                 -1.286713   \n",
       "73                    4.2447                                 -0.992806   \n",
       "\n",
       "    Z_Scored_Percent_Cognitive_Improvement_By_Origin_Group  \\\n",
       "0                                            0.314066        \n",
       "1                                            0.013999        \n",
       "2                                           -0.841572        \n",
       "3                                           -1.855477        \n",
       "4                                            0.533109        \n",
       "..                                                ...        \n",
       "68                                           0.106772        \n",
       "69                                           1.086636        \n",
       "70                                           0.103418        \n",
       "72                                          -0.379443        \n",
       "73                                          -0.158855        \n",
       "\n",
       "    Z_Scored_Percent_Cognitive_Improvement  Percent_Cognitive_Improvement  \\\n",
       "0                                 0.314066                     -21.428571   \n",
       "1                                 0.013999                     -36.363636   \n",
       "2                                -0.841572                     -78.947368   \n",
       "3                                -1.855477                    -129.411765   \n",
       "4                                 0.533109                     -10.526316   \n",
       "..                                     ...                            ...   \n",
       "68                                0.106772                      -1.388889   \n",
       "69                                1.086636                       1.449275   \n",
       "70                                0.103418                      -1.398601   \n",
       "72                               -0.379443                      -2.797203   \n",
       "73                               -0.158855                      -2.158273   \n",
       "\n",
       "    Z_Scored_Subiculum_T_By_Origin_Group_  ...  DECLINE  Cognitive_Improve  \\\n",
       "0                               -1.282630  ...      1.0                 No   \n",
       "1                               -1.760917  ...      1.0                 No   \n",
       "2                               -0.595369  ...      1.0                 No   \n",
       "3                               -0.945206  ...      1.0                 No   \n",
       "4                               -1.151973  ...      0.0                 No   \n",
       "..                                    ...  ...      ...                ...   \n",
       "68                              -0.590767  ...      0.0                 No   \n",
       "69                              -1.065220  ...      0.0                Yes   \n",
       "70                              -1.108473  ...      0.0                 No   \n",
       "72                              -0.775406  ...      0.0                 No   \n",
       "73                              -0.690244  ...      0.0                 No   \n",
       "\n",
       "    Z_Scored_Cognitive_Baseline  \\\n",
       "0                      1.518764   \n",
       "1                      0.465551   \n",
       "2                     -0.061056   \n",
       "3                     -0.412127   \n",
       "4                     -0.061056   \n",
       "..                          ...   \n",
       "68                     1.114522   \n",
       "69                    -1.345113   \n",
       "70                     0.704583   \n",
       "72                     0.704583   \n",
       "73                    -0.935174   \n",
       "\n",
       "    Z_Scored_Cognitive_Baseline__Lower_is_Better_  \\\n",
       "0                                       -1.518764   \n",
       "1                                       -0.465551   \n",
       "2                                        0.061056   \n",
       "3                                        0.412127   \n",
       "4                                        0.061056   \n",
       "..                                            ...   \n",
       "68                                       1.114522   \n",
       "69                                      -1.345113   \n",
       "70                                       0.704583   \n",
       "72                                       0.704583   \n",
       "73                                      -0.935174   \n",
       "\n",
       "    Min_Max_Normalized_Baseline  MinMaxNormBaseline_Higher_is_Better  \\\n",
       "0                         0.720                                0.280   \n",
       "1                         0.480                                0.520   \n",
       "2                         0.360                                0.640   \n",
       "3                         0.280                                0.720   \n",
       "4                         0.360                                0.640   \n",
       "..                          ...                                  ...   \n",
       "68                        1.000                                1.000   \n",
       "69                        0.250                                0.250   \n",
       "70                        0.875                                0.875   \n",
       "72                        0.875                                0.875   \n",
       "73                        0.375                                0.375   \n",
       "\n",
       "    ROI_to_Alz_Max  ROI_to_PD_Max  Standardzied_AD_Max  Standardized_PD_Max  \n",
       "0        12.222658      14.493929            -1.714513            -1.227368  \n",
       "1        14.020048      15.257338            -1.155843            -1.022243  \n",
       "2        15.118727      17.376384            -0.814348            -0.452865  \n",
       "3        13.112424      15.287916            -1.437954            -1.014027  \n",
       "4        15.086568      12.951426            -0.824344            -1.641831  \n",
       "..             ...            ...                  ...                  ...  \n",
       "68       13.873339      15.685024            -0.347959            -0.150172  \n",
       "69       10.930371      11.599140            -0.855211            -0.712879  \n",
       "70        6.780175       8.774895            -1.570542            -1.101833  \n",
       "72        9.841726      16.308768            -1.042851            -0.064270  \n",
       "73       11.101963      10.543942            -0.825635            -0.858200  \n",
       "\n",
       "[72 rows x 61 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = cal_palm.drop_nans_from_columns(columns_to_drop_from=drop_list)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop Row Based on Value of Column**\n",
    "\n",
    "Define the column, condition, and value for dropping rows\n",
    "- column = 'your_column_name'\n",
    "- condition = 'above'  # Options: 'equal', 'above', 'below'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject', 'Age', 'Hippocampus_GM_Vol', 'Parahippocampal_Gyrus_GM_Vol',\n",
       "       'Entorhinal_Cortex_GM_Vol', 'Normalized_Percent_Cognitive_Improvement',\n",
       "       'Z_Scored_Percent_Cognitive_Improvement_By_Origin_Group',\n",
       "       'Z_Scored_Percent_Cognitive_Improvement',\n",
       "       'Percent_Cognitive_Improvement',\n",
       "       'Z_Scored_Subiculum_T_By_Origin_Group_',\n",
       "       'Z_Scored_Subiculum_Connectivity_T', 'Subiculum_Connectivity_T_Redone',\n",
       "       'Subiculum_Connectivity_T', 'Amnesia_Lesion_T_Map', 'Memory_Network_T',\n",
       "       'Z_Scored_Memory_Network_R', 'Memory_Network_R',\n",
       "       'Subiculum_Grey_Matter', 'Subiculum_White_Matter', 'Subiculum_CSF',\n",
       "       'Subiculum_Total', 'Standardized_Age',\n",
       "       'Standardized_Percent_Improvement',\n",
       "       'Standardized_Subiculum_Connectivity',\n",
       "       'Standardized_Subiculum_Grey_Matter',\n",
       "       'Standardized_Subiculum_White_Matter', 'Standardized_Subiculum_CSF',\n",
       "       'Standardized_Subiculum_Total', 'Disease', 'Cohort', 'City',\n",
       "       'Inclusion_Cohort', 'Categorical_Age_Group', 'Age_Group',\n",
       "       'Age_And_Disease', 'Age_Disease_and_Cohort', 'Age_Disease_Cohort_Stim',\n",
       "       'Age_And_Stim', 'Subiculum_Group_By_Z_Score_Sign',\n",
       "       'Subiculum_Group_By_Inflection_Point', 'Subiculum_Group_By_24',\n",
       "       'Cognitive_Outcome', 'StimMatch', 'StimMatch24', 'Cognitive_Baseline',\n",
       "       'Cognitive_Score_1_Yr', 'MinMaxNorm_Cog_Score_1_Yr',\n",
       "       'Abs_Cognitive_Improve', 'IMPROVE_OR_STABLE', 'DECLINE_OR_STABLE',\n",
       "       'IMPROVE', 'DECLINE', 'Cognitive_Improve',\n",
       "       'Z_Scored_Cognitive_Baseline',\n",
       "       'Z_Scored_Cognitive_Baseline__Lower_is_Better_',\n",
       "       'Min_Max_Normalized_Baseline', 'MinMaxNormBaseline_Higher_is_Better',\n",
       "       'ROI_to_Alz_Max', 'ROI_to_PD_Max', 'Standardzied_AD_Max',\n",
       "       'Standardized_PD_Max'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the parameters for dropping rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'City'  # The column you'd like to evaluate\n",
    "condition = 'equal'  # The condition to check ('equal', 'above', 'below', 'not')\n",
    "value = 'BIH' # The value to drop if T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>Age</th>\n",
       "      <th>Hippocampus_GM_Vol</th>\n",
       "      <th>Parahippocampal_Gyrus_GM_Vol</th>\n",
       "      <th>Entorhinal_Cortex_GM_Vol</th>\n",
       "      <th>Normalized_Percent_Cognitive_Improvement</th>\n",
       "      <th>Z_Scored_Percent_Cognitive_Improvement_By_Origin_Group</th>\n",
       "      <th>Z_Scored_Percent_Cognitive_Improvement</th>\n",
       "      <th>Percent_Cognitive_Improvement</th>\n",
       "      <th>Z_Scored_Subiculum_T_By_Origin_Group_</th>\n",
       "      <th>...</th>\n",
       "      <th>DECLINE</th>\n",
       "      <th>Cognitive_Improve</th>\n",
       "      <th>Z_Scored_Cognitive_Baseline</th>\n",
       "      <th>Z_Scored_Cognitive_Baseline__Lower_is_Better_</th>\n",
       "      <th>Min_Max_Normalized_Baseline</th>\n",
       "      <th>MinMaxNormBaseline_Higher_is_Better</th>\n",
       "      <th>ROI_to_Alz_Max</th>\n",
       "      <th>ROI_to_PD_Max</th>\n",
       "      <th>Standardzied_AD_Max</th>\n",
       "      <th>Standardized_PD_Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>62.0</td>\n",
       "      <td>5.8883</td>\n",
       "      <td>4.5970</td>\n",
       "      <td>2.4587</td>\n",
       "      <td>-0.392857</td>\n",
       "      <td>0.314066</td>\n",
       "      <td>0.314066</td>\n",
       "      <td>-21.428571</td>\n",
       "      <td>-1.282630</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1.518764</td>\n",
       "      <td>-1.518764</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.280</td>\n",
       "      <td>12.222658</td>\n",
       "      <td>14.493929</td>\n",
       "      <td>-1.714513</td>\n",
       "      <td>-1.227368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>77.0</td>\n",
       "      <td>3.7634</td>\n",
       "      <td>3.9036</td>\n",
       "      <td>2.2905</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.013999</td>\n",
       "      <td>0.013999</td>\n",
       "      <td>-36.363636</td>\n",
       "      <td>-1.760917</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.465551</td>\n",
       "      <td>-0.465551</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.520</td>\n",
       "      <td>14.020048</td>\n",
       "      <td>15.257338</td>\n",
       "      <td>-1.155843</td>\n",
       "      <td>-1.022243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>76.0</td>\n",
       "      <td>4.8575</td>\n",
       "      <td>4.8177</td>\n",
       "      <td>3.1596</td>\n",
       "      <td>-1.447368</td>\n",
       "      <td>-0.841572</td>\n",
       "      <td>-0.841572</td>\n",
       "      <td>-78.947368</td>\n",
       "      <td>-0.595369</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.061056</td>\n",
       "      <td>0.061056</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.640</td>\n",
       "      <td>15.118727</td>\n",
       "      <td>17.376384</td>\n",
       "      <td>-0.814348</td>\n",
       "      <td>-0.452865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4.8569</td>\n",
       "      <td>4.8655</td>\n",
       "      <td>2.6641</td>\n",
       "      <td>-2.372549</td>\n",
       "      <td>-1.855477</td>\n",
       "      <td>-1.855477</td>\n",
       "      <td>-129.411765</td>\n",
       "      <td>-0.945206</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.412127</td>\n",
       "      <td>0.412127</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.720</td>\n",
       "      <td>13.112424</td>\n",
       "      <td>15.287916</td>\n",
       "      <td>-1.437954</td>\n",
       "      <td>-1.014027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.9636</td>\n",
       "      <td>4.8434</td>\n",
       "      <td>3.3463</td>\n",
       "      <td>-0.192982</td>\n",
       "      <td>0.533109</td>\n",
       "      <td>0.533109</td>\n",
       "      <td>-10.526316</td>\n",
       "      <td>-1.151973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.061056</td>\n",
       "      <td>0.061056</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.640</td>\n",
       "      <td>15.086568</td>\n",
       "      <td>12.951426</td>\n",
       "      <td>-0.824344</td>\n",
       "      <td>-1.641831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>30</td>\n",
       "      <td>58.0</td>\n",
       "      <td>7.1449</td>\n",
       "      <td>6.5446</td>\n",
       "      <td>3.8850</td>\n",
       "      <td>-0.638889</td>\n",
       "      <td>0.106772</td>\n",
       "      <td>0.106772</td>\n",
       "      <td>-1.388889</td>\n",
       "      <td>-0.590767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1.114522</td>\n",
       "      <td>1.114522</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>13.873339</td>\n",
       "      <td>15.685024</td>\n",
       "      <td>-0.347959</td>\n",
       "      <td>-0.150172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>31</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0478</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.086636</td>\n",
       "      <td>1.086636</td>\n",
       "      <td>1.449275</td>\n",
       "      <td>-1.065220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-1.345113</td>\n",
       "      <td>-1.345113</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.250</td>\n",
       "      <td>10.930371</td>\n",
       "      <td>11.599140</td>\n",
       "      <td>-0.855211</td>\n",
       "      <td>-0.712879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>33</td>\n",
       "      <td>60.0</td>\n",
       "      <td>8.5035</td>\n",
       "      <td>7.4388</td>\n",
       "      <td>4.5143</td>\n",
       "      <td>-0.643357</td>\n",
       "      <td>0.103418</td>\n",
       "      <td>0.103418</td>\n",
       "      <td>-1.398601</td>\n",
       "      <td>-1.108473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.704583</td>\n",
       "      <td>0.704583</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>6.780175</td>\n",
       "      <td>8.774895</td>\n",
       "      <td>-1.570542</td>\n",
       "      <td>-1.101833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>36</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.2357</td>\n",
       "      <td>7.1067</td>\n",
       "      <td>4.5170</td>\n",
       "      <td>-1.286713</td>\n",
       "      <td>-0.379443</td>\n",
       "      <td>-0.379443</td>\n",
       "      <td>-2.797203</td>\n",
       "      <td>-0.775406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.704583</td>\n",
       "      <td>0.704583</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>9.841726</td>\n",
       "      <td>16.308768</td>\n",
       "      <td>-1.042851</td>\n",
       "      <td>-0.064270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>37</td>\n",
       "      <td>64.0</td>\n",
       "      <td>7.0928</td>\n",
       "      <td>6.8967</td>\n",
       "      <td>4.2447</td>\n",
       "      <td>-0.992806</td>\n",
       "      <td>-0.158855</td>\n",
       "      <td>-0.158855</td>\n",
       "      <td>-2.158273</td>\n",
       "      <td>-0.690244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.935174</td>\n",
       "      <td>-0.935174</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>11.101963</td>\n",
       "      <td>10.543942</td>\n",
       "      <td>-0.825635</td>\n",
       "      <td>-0.858200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject   Age  Hippocampus_GM_Vol  Parahippocampal_Gyrus_GM_Vol  \\\n",
       "0       101  62.0              5.8883                        4.5970   \n",
       "1       102  77.0              3.7634                        3.9036   \n",
       "2       103  76.0              4.8575                        4.8177   \n",
       "3       104  65.0              4.8569                        4.8655   \n",
       "4       105  50.0              5.9636                        4.8434   \n",
       "..      ...   ...                 ...                           ...   \n",
       "68       30  58.0              7.1449                        6.5446   \n",
       "69       31  64.0              0.0067                        0.0478   \n",
       "70       33  60.0              8.5035                        7.4388   \n",
       "72       36  52.0              8.2357                        7.1067   \n",
       "73       37  64.0              7.0928                        6.8967   \n",
       "\n",
       "    Entorhinal_Cortex_GM_Vol  Normalized_Percent_Cognitive_Improvement  \\\n",
       "0                     2.4587                                 -0.392857   \n",
       "1                     2.2905                                 -0.666667   \n",
       "2                     3.1596                                 -1.447368   \n",
       "3                     2.6641                                 -2.372549   \n",
       "4                     3.3463                                 -0.192982   \n",
       "..                       ...                                       ...   \n",
       "68                    3.8850                                 -0.638889   \n",
       "69                    0.0376                                  0.666667   \n",
       "70                    4.5143                                 -0.643357   \n",
       "72                    4.5170                                 -1.286713   \n",
       "73                    4.2447                                 -0.992806   \n",
       "\n",
       "    Z_Scored_Percent_Cognitive_Improvement_By_Origin_Group  \\\n",
       "0                                            0.314066        \n",
       "1                                            0.013999        \n",
       "2                                           -0.841572        \n",
       "3                                           -1.855477        \n",
       "4                                            0.533109        \n",
       "..                                                ...        \n",
       "68                                           0.106772        \n",
       "69                                           1.086636        \n",
       "70                                           0.103418        \n",
       "72                                          -0.379443        \n",
       "73                                          -0.158855        \n",
       "\n",
       "    Z_Scored_Percent_Cognitive_Improvement  Percent_Cognitive_Improvement  \\\n",
       "0                                 0.314066                     -21.428571   \n",
       "1                                 0.013999                     -36.363636   \n",
       "2                                -0.841572                     -78.947368   \n",
       "3                                -1.855477                    -129.411765   \n",
       "4                                 0.533109                     -10.526316   \n",
       "..                                     ...                            ...   \n",
       "68                                0.106772                      -1.388889   \n",
       "69                                1.086636                       1.449275   \n",
       "70                                0.103418                      -1.398601   \n",
       "72                               -0.379443                      -2.797203   \n",
       "73                               -0.158855                      -2.158273   \n",
       "\n",
       "    Z_Scored_Subiculum_T_By_Origin_Group_  ...  DECLINE  Cognitive_Improve  \\\n",
       "0                               -1.282630  ...      1.0                 No   \n",
       "1                               -1.760917  ...      1.0                 No   \n",
       "2                               -0.595369  ...      1.0                 No   \n",
       "3                               -0.945206  ...      1.0                 No   \n",
       "4                               -1.151973  ...      0.0                 No   \n",
       "..                                    ...  ...      ...                ...   \n",
       "68                              -0.590767  ...      0.0                 No   \n",
       "69                              -1.065220  ...      0.0                Yes   \n",
       "70                              -1.108473  ...      0.0                 No   \n",
       "72                              -0.775406  ...      0.0                 No   \n",
       "73                              -0.690244  ...      0.0                 No   \n",
       "\n",
       "    Z_Scored_Cognitive_Baseline  \\\n",
       "0                      1.518764   \n",
       "1                      0.465551   \n",
       "2                     -0.061056   \n",
       "3                     -0.412127   \n",
       "4                     -0.061056   \n",
       "..                          ...   \n",
       "68                     1.114522   \n",
       "69                    -1.345113   \n",
       "70                     0.704583   \n",
       "72                     0.704583   \n",
       "73                    -0.935174   \n",
       "\n",
       "    Z_Scored_Cognitive_Baseline__Lower_is_Better_  \\\n",
       "0                                       -1.518764   \n",
       "1                                       -0.465551   \n",
       "2                                        0.061056   \n",
       "3                                        0.412127   \n",
       "4                                        0.061056   \n",
       "..                                            ...   \n",
       "68                                       1.114522   \n",
       "69                                      -1.345113   \n",
       "70                                       0.704583   \n",
       "72                                       0.704583   \n",
       "73                                      -0.935174   \n",
       "\n",
       "    Min_Max_Normalized_Baseline  MinMaxNormBaseline_Higher_is_Better  \\\n",
       "0                         0.720                                0.280   \n",
       "1                         0.480                                0.520   \n",
       "2                         0.360                                0.640   \n",
       "3                         0.280                                0.720   \n",
       "4                         0.360                                0.640   \n",
       "..                          ...                                  ...   \n",
       "68                        1.000                                1.000   \n",
       "69                        0.250                                0.250   \n",
       "70                        0.875                                0.875   \n",
       "72                        0.875                                0.875   \n",
       "73                        0.375                                0.375   \n",
       "\n",
       "    ROI_to_Alz_Max  ROI_to_PD_Max  Standardzied_AD_Max  Standardized_PD_Max  \n",
       "0        12.222658      14.493929            -1.714513            -1.227368  \n",
       "1        14.020048      15.257338            -1.155843            -1.022243  \n",
       "2        15.118727      17.376384            -0.814348            -0.452865  \n",
       "3        13.112424      15.287916            -1.437954            -1.014027  \n",
       "4        15.086568      12.951426            -0.824344            -1.641831  \n",
       "..             ...            ...                  ...                  ...  \n",
       "68       13.873339      15.685024            -0.347959            -0.150172  \n",
       "69       10.930371      11.599140            -0.855211            -0.712879  \n",
       "70        6.780175       8.774895            -1.570542            -1.101833  \n",
       "72        9.841726      16.308768            -1.042851            -0.064270  \n",
       "73       11.101963      10.543942            -0.825635            -0.858200  \n",
       "\n",
       "[72 rows x 61 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_df, other_df = cal_palm.drop_rows_based_on_value(column, condition, value)\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standardize Data**\n",
    "- Enter Columns you Don't want to standardize into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove anything you don't want to standardize\n",
    "cols_not_to_standardize = ['Ordinal_Target_Type', 'Ordinal_Epilepsy_Type'] #['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = cal_palm.standardize_columns(cols_not_to_standardize)\n",
    "data_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mediation, Moderation, and Conditional Process Analyses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediation and moderation are two distinct concepts in statistics that help in understanding the relationships among three or more variables. Mediation deals with explaining the underlying process through which an independent variable (X) influences a dependent variable (Y). Moderation, on the other hand, addresses how the relationship between X and Y changes based on the level of a third variable, known as the moderator (W).\n",
    "\n",
    "**Mediation Analysis**:\n",
    "\n",
    "In mediation analysis, we are interested in whether the relationship between X and Y is explained (or mediated) through another variable, called the mediator (M).\n",
    "\n",
    "- **Path a**: The independent variable (X) affects the mediator (M). This is the \"a\" path.\n",
    "- **Path b**: The mediator (M) affects the dependent variable (Y). This is the \"b\" path.\n",
    "- **Path c'**: There might also be a direct effect of X on Y that doesn't go through the mediator. This is the \"c'\" path or direct effect.\n",
    "\n",
    "```\n",
    "X ---(a)---> M ---(b)---> Y\n",
    " \\                        /\n",
    "  ---------(c')----------\n",
    "```\n",
    "\n",
    "The indirect effect is a*b, which is the portion of the effect of X on Y that is transmitted through the mediator M. The total effect of X on Y is the sum of the indirect effect and the direct effect (c').\n",
    "\n",
    "**Moderated Mediation Analysis**:\n",
    "\n",
    "Moderated mediation incorporates the idea that the mediation process itself can be contingent upon the levels of another variable (W), known as the moderator. In other words, the indirect effect of X on Y through M may change depending on the level of W.\n",
    "\n",
    "```\n",
    "X ---(a)---> M ---(b)---> Y\n",
    "|            | \n",
    "|------(W)---|\n",
    " \\                        /\n",
    "  ---------(c')----------\n",
    "```\n",
    "\n",
    "**Interpreting the Results**:\n",
    "\n",
    "In the results of a moderated mediation analysis, you'll encounter several terms:\n",
    "\n",
    "- ACME (control/treated): Average Causal Mediation Effects. This represents the average effect of the independent variable on the dependent variable through the mediator.\n",
    "- ADE (control/treated): Average Direct Effects. This represents the average direct effect of the independent variable on the dependent variable not through the mediator.\n",
    "- Total effect: Sum of ACME and ADE, representing the total effect of the independent variable on the dependent variable.\n",
    "- Prop. mediated (control/treated): Proportion of the total effect that is mediated by the mediator.\n",
    "- The 'control' and 'treated' distinction in ACME and ADE accounts for possible treatment or intervention that could affect the mediation. If there's no treatment/intervention involved, they will be the same.\n",
    "- Lower CI bound and Upper CI bound represent the lower and upper bounds of the confidence interval for the estimates.\n",
    "- P-value: Indicates the statistical significance of the estimates. A lower p-value (<0.05) typically indicates a statistically significant effect.\n",
    "\n",
    "- Control: baseline regression without effect of the mediator\n",
    "- Treatment: mediated regression wherein the mediator is accounted for\n",
    " \n",
    "\n",
    "**Identifying Partial Mediations**:\n",
    "\n",
    "In partial mediation, the mediator explains some, but not all, of the relationship between the independent variable (exposure) and the dependent variable (outcome). Here's how you can identify partial mediation:\n",
    "\n",
    "Significant Direct Effect (ADE): In partial mediation, the direct effect of the independent variable on the dependent variable remains significant even after accounting for the mediator. This means that there is still a direct path from the independent variable to the dependent variable that is not explained by the mediator.\n",
    "\n",
    "Significant Indirect Effect (ACME): The indirect effect through the mediator must also be significant. This means that the mediator is explaining part of the relationship between the independent variable and the dependent variable.\n",
    "\n",
    "Total Effect > Direct Effect: The total effect of the independent variable on the dependent variable (before the mediator is added to the model) is generally greater than the direct effect (after accounting for the mediator). This shows that the mediator is explaining some portion of the effect.\n",
    "\n",
    "In the results you usually get from mediation analysis, check for the following:\n",
    "\n",
    "ADE (average direct effect) should be significant.\n",
    "ACME (average causal mediation effect) should be significant.\n",
    "The total effect should be greater than the direct effect, indicating that some portion of the effect is being accounted for by the mediator.\n",
    "In summary, partial mediation is present when both the direct and indirect paths are significant, but the inclusion of the mediator in the model reduces the direct effect of the independent variable on the dependent variable (without rendering it non-significant).\n",
    "\n",
    "**Identifying a Mediated Exposure**:\n",
    "\n",
    "If the exposure was being mediated, you would expect to see:\n",
    "\n",
    "A significant ACME (Average Causal Mediation Effect) - This indicates that the mediator is having a significant effect in the relationship between the exposure and the outcome.\n",
    "\n",
    "A significant proportion mediated - This tells you the proportion of the total effect that is mediated. If this is significant, it implies that a noteworthy part of the relationship between the exposure and the outcome is occurring through the mediator.\n",
    "\n",
    "Also, keep in mind that the proportion mediated can be positive or negative, and this would indicate whether the mediator is increasing or decreasing the effect of the exposure on the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/mambaforge/base/envs/nimlab_py310/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import os\n",
    "import glob as glob\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "#Calculate Correlation\n",
    "from scipy.stats import pearsonr\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = 'mediated_moderation_analysis'\n",
    "data_path = r'/Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/BIDS_PD_DBS_STN_WURZBURG/metadata/subject_age_and_atrophy_index.csv'\n",
    "out_dir = os.path.join(data_path.split('.')[0], f'{analysis}')\n",
    "\n",
    "save = True\n",
    "if os.path.exists(out_dir):\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------user input above----------------------------------------------------------------\n",
    "from calvin_utils.file_utils.dataframe_utilities import preprocess_colnames_for_regression\n",
    "data_df = preprocess_colnames_for_regression(pd.read_csv(data_path))\n",
    "data_df.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select specific subgroup\n",
    "# outlier_index = (data_df['percent_change_adascog11'] <= -50)\n",
    "# data_df = data_df.loc[outlier_index, :]\n",
    "\n",
    "#Remove outlier\n",
    "# outlier_index=[11, 47, 48, 49]\n",
    "# data_df = data_df.drop(index=outlier_index)\n",
    "data_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "data_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Rename the outcome variable\n",
    "outcome_variable = data_df.pop('%_Change_from_baseline_(ADAS_Cog11)')\n",
    "data_df['outcome'] = outcome_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize the data\n",
    "preserved_df = data_df.copy()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Remove anything you don't want to standardize\n",
    "cols_not_to_standardize = ['Sex', 'Cognitive_Cohort_ID']\n",
    "# Select the columns to be standardized\n",
    "if cols_not_to_standardize[0] is not None:\n",
    "    cols_to_standardize = [col for col in data_df.columns if col not in cols_not_to_standardize]\n",
    "else:\n",
    "    print('Will not standardize')\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "data_df[cols_to_standardize] = scaler.fit_transform(data_df[cols_to_standardize])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Drop NAN\n",
    "# data_df = data_df.dropna()\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode as needed\n",
    "# data_df['interaction'] = data_df['Subiculum_Grey_Matter']*data_df['Subiculum_Connectivity']\n",
    "data_df['Disease'] = np.where(data_df['Disease'] == 'Alzheimer', 1, 0)\n",
    "# data_df['Age'] = np.where(data_df['Age'] <= 65, 0, 1)\n",
    "\n",
    "data_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select Specific Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop a specific set of rows\n",
    "# data_df = data_df[data_df['Age'] > 65]\n",
    "data_df = data_df[data_df['Disease'] == 1]\n",
    "data_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select Specific Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tailor the Dataframe\n",
    "# data_df = data_df.loc[:, ['Age', 'Mesial_Temporal_Grade', 'Frontal', 'Temporal',\n",
    "#        'Parietal', 'Occipital', 'Cerebellar', 'Subiculum_Connectivity',\n",
    "#        'Hippocampal_CSF', 'Hippocampal_Grey_Matter',\n",
    "#        'Hippocampal_White_Matter', 'outcome']]\n",
    "data_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single Variable Mediation Analysis\n",
    "\n",
    "Model Shape:\n",
    "```\n",
    " Age ---(an)---> Atrophy Region n ---(bn)---> Outcome\n",
    "  \\                                          /\n",
    "   -------------------(c')-------------------\n",
    "```\n",
    "\n",
    "Description\n",
    "- This uses partial regressions to essentially (explain in a reductive manner) to what degree an independent variable's relationship with a dependent variable can be replaced by a 'mediator variable'. \n",
    "- Said another way, how much is the effect of x upon y mediated by z?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.genmod.generalized_linear_model import GLM\n",
    "from statsmodels.genmod.families import Gaussian\n",
    "from statsmodels.stats.mediation import Mediation\n",
    "\n",
    "def perform_mediation_analysis(dataframe, exposure, mediator, dependent_variable):\n",
    "    # Step 1: Fit the mediator model\n",
    "    # Mediator ~ Independent Variable\n",
    "    mediator_model = GLM.from_formula(f\"{mediator} ~ {exposure}\", data=dataframe, family=Gaussian())\n",
    "    \n",
    "    # Step 2: Fit the outcome model\n",
    "    # Dependent Variable ~ Independent Variable + Mediator\n",
    "    outcome_model = GLM.from_formula(f\"{dependent_variable} ~ {exposure} + {mediator}\", data=dataframe, family=Gaussian())\n",
    "    \n",
    "    # Step 3: Perform mediation analysis\n",
    "    med = Mediation(outcome_model, mediator_model, exposure=exposure, mediator=mediator)\n",
    "    try:\n",
    "        med_result = med.fit()\n",
    "        # Step 4: Print the results\n",
    "        print(f'Mediation of {exposure} by {mediator}:')\n",
    "        print(med_result.summary())\n",
    "    except:\n",
    "        print(f\"Mediation failed, perfect separation detected. Aborting assessment of {mediator}.\")\n",
    "\n",
    "# Example usage:\n",
    "# Assuming your DataFrame is named df, and the columns of interest are 'age', 'brain_atrophy', and 'dependent_variable'\n",
    "# perform_mediation_analysis(data_df, \n",
    "                        #    exposure = 'age', \n",
    "                        #    mediator = 'brain_atrophy', \n",
    "                        #    dependent_variable='dependent_variable')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_mediation_analysis(data_df, \n",
    "                           exposure = 'Age', \n",
    "                           mediator = 'Hippocampus', \n",
    "                           dependent_variable='outcome')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the above code on an entire spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[perform_mediation_analysis(data_df, exposure='Age', mediator=f'{col}', dependent_variable='outcome') for col in data_df.columns]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "**Multivariate Mediation Analysis (Independent)**\n",
    "\n",
    "**NOTE**\n",
    "This is not a proper 'multivariate mediation analysis'.\n",
    "It does something slightly different: it performs individual mediation analyses for each mediator, while controlling for the exposure. This is different from assessing the conglomerate mediation effect of all mediators acting in unison.\n",
    "\n",
    "\n",
    "To investigate whether the effect of an independent variable on an outcome variable is fully mediated through multiple variables (e.g., atrophy in different brain regions), you would want to conduct a multiple mediator analysis.\n",
    "\n",
    "In a multiple mediator analysis, you examine the indirect effects of an independent variable (in this case, age) on a dependent variable through several mediators simultaneously. This allows you to estimate the portion of the effect of the independent variable that is transmitted through each mediator and whether, when taken together, these mediators account for the entirety of the effect.\n",
    "\n",
    "In your case, the different atrophy regions will serve as multiple mediators. Here’s how this might look diagrammatically:\n",
    "\n",
    "```\n",
    " Age ---(a1)---> Atrophy Region 1 ---(b1)---> Outcome\n",
    "  |           |\n",
    " Age ---(a2)---> Atrophy Region 2 ---(b2)---> Outcome\n",
    "  |           |\n",
    "   ...       ...\n",
    " Age ---(an)---> Atrophy Region n ---(bn)---> Outcome\n",
    "  \\                                          /\n",
    "   -------------------(c')-------------------\n",
    "```\n",
    "\n",
    "In this example, each atrophy region (1 through n) is a mediator. The indirect effect of age on the outcome through each atrophy region is a_i * b_i, and the total indirect effect is the sum of all these individual indirect effects. If this total indirect effect is significant and accounts for most of the effect of age on the outcome, and the direct effect (c') is non-significant, it indicates full mediation.\n",
    "\n",
    "You can perform multiple mediator analysis using the same statistical tools you use for single mediator analysis, but you will need to include multiple mediators in your model. This can be done using statistical software such as R, SAS, or Python's statsmodels. I have implemented this below using statsmodels.\n",
    "\n",
    "Here's how the mediation model is constructed in conceptual terms:\n",
    "\n",
    "1. Fit a model for each mediator (Atrophy Region 1, Atrophy Region 2, ..., Atrophy Region n) as a function of the independent variable, Age.\n",
    "2. Fit a model for the outcome as a function of Age and all atrophy regions.\n",
    "3. Estimate the indirect effect of Age on the outcome through each atrophy region and sum them to get the total indirect effect.\n",
    "4. Compare the total indirect effect to the total effect of Age on the outcome to determine the proportion mediated.\n",
    "\n",
    "By performing this analysis, you can ascertain whether the combined atrophy in different regions fully mediates the effect of age on the outcome variable. If you also have a moderation effect to consider (such as subiculum connectivity), this would be a moderated multiple mediation analysis. In this case, the indirect effects and the direct effect may change at different levels of the moderator.\n",
    "\n",
    "I have generated code which will run mutliple mediation analyses independently, but will therefor not be able to tell you how they sum to contribute to the proportion of the independent variable mediated by them. this is perform_individual_multiple_mediator_analysis. Python does not have a combined multiple mediator analysis supported, so I have developed one. It is perform_combined_multiple_mediator_analysis. Please use with caution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.genmod.generalized_linear_model import GLM\n",
    "from statsmodels.genmod.families import Gaussian\n",
    "from statsmodels.stats.mediation import Mediation\n",
    "\n",
    "def perform_individual_multiple_mediator_analysis(dataframe, exposure, mediator_list, outcome):\n",
    "    # Check if mediator_cols is a list, if not, convert it to a list\n",
    "    if not isinstance(mediator_list, list):\n",
    "        mediator_list = [mediator_list]\n",
    "    \n",
    "    # Convert mediator columns into formula expression\n",
    "    mediator_expression = ' + '.join(mediator_list)\n",
    "    \n",
    "    # Step 1: Fit the mediator models\n",
    "    # Mediators ~ Independent Variable\n",
    "    mediator_models = [GLM.from_formula(f\"{mediator} ~ {exposure}\", data=dataframe, family=Gaussian()) for mediator in mediator_list]\n",
    "    \n",
    "    # Step 2: Fit the outcome model\n",
    "    # Dependent Variable ~ Independent Variable + Mediators\n",
    "    outcome_model = GLM.from_formula(f\"{outcome} ~ {exposure} + {mediator_expression}\", data=dataframe, family=Gaussian())\n",
    "    \n",
    "    # Step 3: Perform mediation analysis for each mediator\n",
    "    for mediator, mediator_model in zip(mediator_list, mediator_models):\n",
    "        med = Mediation(outcome_model, mediator_model, exposure=exposure, mediator=mediator)\n",
    "        med_result = med.fit()\n",
    "        \n",
    "        # Step 4: Print the results for each mediator\n",
    "        print(f\"Mediation analysis for mediator: {mediator}\")\n",
    "        print(med_result.summary())\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_individual_multiple_mediator_analysis(data_df, \n",
    "                                   exposure='Age', \n",
    "                                   mediator_list=['Hippocampus', 'Cerebellum', 'Frontal', 'Parietal',\n",
    "       'Temporal', 'Occipital'], \n",
    "                                   outcome='outcome')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "**Multivariate Mediation Analysis**\n",
    "Based on Preacher and Hayes 2008, Asymptotic Asymptotic and resampling strategies for assessing and comparing indirect effects in multiple mediator models\n",
    "\n",
    "**NOTE**: This is a proper multivariate mediation analysis\n",
    "\n",
    "Model Explanation:\n",
    "In a multiple mediation analysis, you are interested in investigating the indirect effects of an independent variable (exposure) on a dependent variable (outcome) through more than one mediator simultaneously. You are also interested in the direct effect of the independent variable on the dependent variable, controlling for the mediators. This analysis helps in understanding how different mediators may carry the influence of an independent variable to a dependent variable.\n",
    "\n",
    "Model Form:\n",
    "```\n",
    "Independent Variable (IV) -----(c')------> Dependent Variable (DV)\n",
    "    |        |        |                       ^      ^         ^\n",
    "    |        |        | (a1)                  |      |         |\n",
    "    |        |        v                       |      |         |\n",
    "    |        |        Mediator 1 --(b1)-------|      |         |\n",
    "    |        |                                       |         |\n",
    "    |        | (a2)                                  |         |\n",
    "    |        v                                       |         |\n",
    "    |    Mediator 2 --------(b2)---------------------|         |\n",
    "    |                                                          |\n",
    "    ...                                                        |\n",
    "    |                                                          |\n",
    "    | (ak)                                                     |\n",
    "    v                                                          |\n",
    "Mediator k --------(bk)----------------------------------------|\n",
    "```\n",
    "In this diagram:\n",
    "\n",
    "IV represents the independent variable.\n",
    "Mediator 1, Mediator 2, ..., Mediator k represent the k mediators in the model.\n",
    "DV represents the dependent variable.\n",
    "The path labeled a1 represents the effect of the IV on Mediator 1. Similarly, a2 represents the effect of the IV on Mediator 2, and so on.\n",
    "The path labeled b1 represents the effect of Mediator 1 on the DV, controlling for other mediators and the IV. Similarly, b2 represents the effect of Mediator 2 on the DV, controlling for other mediators and the IV, and so on.\n",
    "The path labeled c' represents the direct effect of the IV on the DV, controlling for all the mediators.\n",
    "\n",
    "**Technical Notes**\n",
    "\n",
    "This is not formally implemented in Python as well as in R, so this is Calvin's custom code. Use with care.\n",
    "This is a more 'true' multivariate mediation analysis than the one above"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Technical Explanation**\n",
    "The perform_multiple_mediation_analysis function is designed to perform a multiple mediation analysis to estimate the joint indirect effects of an exposure variable through multiple mediators on a dependent variable. This is achieved through the use of bootstrapping.\n",
    "\n",
    "Bootstrapping is a statistical technique where resampling of the dataset is done with replacement to estimate the sampling distribution of a statistic. In the case of multiple mediation analysis, it's used to estimate the joint indirect effects of mediators.\n",
    "\n",
    "In the function, for each bootstrap sample, the dataset is resampled with replacement. For each mediator, a simple linear regression is performed to estimate the path from the exposure variable to the mediator, denoted as 'a' paths. The product of these 'a' paths is computed, as this represents the joint effect of the exposure on all the mediators.\n",
    "\n",
    "Next, a multiple regression is performed with the dependent variable as the response, and the mediators and exposure as predictors. The coefficients for the mediators represent the effect of the mediators on the dependent variable, controlling for the exposure, denoted as 'b' paths. The sum of these 'b' paths is computed.\n",
    "\n",
    "The indirect effect for the bootstrap sample is then calculated as the product of the 'a' paths and the 'b' path sum. This process is repeated for a specified number of bootstrap samples (default is 5000), and the mean indirect effect is calculated from these bootstrap samples.\n",
    "\n",
    "Finally, the function prints the mean indirect effect and its 95% confidence interval, which is estimated using the 2.5th and 97.5th percentiles of the bootstrap indirect effects.\n",
    "\n",
    "This approach provides an approximate estimate of the joint indirect effect through multiple mediators and allows for the calculation of confidence intervals around this effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "def calculate_confidence_intervals(ab_paths, total_indirect_effects, mediators):\n",
    "    \"\"\"\n",
    "    Calculates the confidence intervals and p-value based on the bootstrapped samples.\n",
    "\n",
    "    Parameters:\n",
    "    - ab_paths: list of lists containing the bootstrapped ab paths for each mediator.\n",
    "    - total_indirect_effects: list of bootstrapped summed ab paths.\n",
    "    - mediators: list of mediator names.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with the mean indirect effect, confidence intervals, and p-values for each mediator and the total indirect effect.\n",
    "    \"\"\"\n",
    "\n",
    "    ab_path_values = np.array(ab_paths)\n",
    "    total_indirect_effects = np.array(total_indirect_effects)\n",
    "\n",
    "    # Calculate mean indirect effect and confidence intervals for each mediator\n",
    "    mean_ab_paths = np.mean(ab_path_values, axis=0)\n",
    "    lower_bounds = np.percentile(ab_path_values, 2.5, axis=0)\n",
    "    upper_bounds = np.percentile(ab_path_values, 97.5, axis=0)\n",
    "\n",
    "    # Calculate p-values for each mediator\n",
    "    ab_path_p_values = [np.mean(np.sign(mean_ab_paths[i]) * ab_path_values[:, i] <= 0) for i in range(len(mean_ab_paths))]\n",
    "\n",
    "\n",
    "    # Calculate mean indirect effect and confidence intervals for the total indirect effect\n",
    "    mean_total_indirect_effect = np.mean(total_indirect_effects)\n",
    "    lower_bound_total = np.percentile(total_indirect_effects, 2.5)\n",
    "    upper_bound_total = np.percentile(total_indirect_effects, 97.5)\n",
    "    p_value_total = np.mean(total_indirect_effects > 0) if np.mean(total_indirect_effects) < 0 else np.mean(total_indirect_effects <= 1)\n",
    "\n",
    "    # Create DataFrame to store the results\n",
    "    result_df = pd.DataFrame({\n",
    "        'Point Estimate': np.concatenate((mean_ab_paths, [mean_total_indirect_effect])),\n",
    "        '2.5th Percentile': np.concatenate((lower_bounds, [lower_bound_total])),\n",
    "        '97.5th Percentile': np.concatenate((upper_bounds, [upper_bound_total])),\n",
    "        'P-value': ab_path_p_values + [p_value_total]\n",
    "    }, index=mediators + ['Total Indirect Effect'])\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def perform_multiple_mediation_analysis(dataframe, exposure, mediators, dependent_variable, bootstrap_samples=5000):\n",
    "    \"\"\"\n",
    "    Performs a multiple mediation analysis by estimating the joint indirect effects of an exposure variable\n",
    "    through multiple mediators on a dependent variable using bootstrapping.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe: DataFrame containing the data.\n",
    "    - exposure: str, column name of the exposure variable.\n",
    "    - mediators: list, column names of the mediator variables.\n",
    "    - dependent_variable: str, column name of the dependent variable.\n",
    "    - bootstrap_samples: int, optional, number of bootstrap samples to be used (default is 5000).\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with the mean indirect effect, confidence intervals, and p-values for each mediator and the total indirect effect.\n",
    "\n",
    "    Example Usage:\n",
    "    result_df = perform_multiple_mediation_analysis(data_df, exposure='Age',\n",
    "                                                    mediators=['Brain_Lobe1', 'Brain_Lobe2'],\n",
    "                                                    dependent_variable='outcome')\n",
    "    \"\"\"\n",
    "\n",
    "    # Perform multiple mediation analysis\n",
    "    ab_paths, total_indirect_effects = [], []\n",
    "\n",
    "    # Loop over each bootstrap sample\n",
    "    for i in range(bootstrap_samples):\n",
    "        # Resample the data with replacement\n",
    "        sample = dataframe.sample(frac=1, replace=True)\n",
    "\n",
    "        # Paths from exposure to mediators and from mediators to DV\n",
    "        ab_paths_sample = [ols(f\"{mediator} ~ {exposure}\", data=sample).fit().params[exposure] *\n",
    "                           ols(f\"{dependent_variable} ~ {mediator} + {exposure}\", data=sample).fit().params[mediator]\n",
    "                           for mediator in mediators]\n",
    "\n",
    "        # Sum the individual indirect effects for this bootstrap sample\n",
    "        total_indirect_effect = sum(ab_paths_sample)\n",
    "\n",
    "        # Append the ab paths and total indirect effect to the lists\n",
    "        ab_paths.append(ab_paths_sample)\n",
    "        total_indirect_effects.append(total_indirect_effect)\n",
    "\n",
    "    # Calculate confidence intervals and p-values\n",
    "    result_df = calculate_confidence_intervals(ab_paths, total_indirect_effects, mediators)\n",
    "\n",
    "    return result_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = perform_multiple_mediation_analysis(data_df, \n",
    "                                    exposure='Age', \n",
    "                                    mediators=['Hippocampus', 'Cerebellum', 'Frontal', 'Parietal',\n",
    "       'Temporal', 'Occipital']\n",
    "                                               , \n",
    "                                    dependent_variable='outcome',\n",
    "                                    bootstrap_samples=10000)\n",
    "result_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Stage Model Moderated Mediation Analyses\n",
    "\n",
    "Model Structure:\n",
    "```\n",
    " #Age ---(a1)------> Mediator ---(b1)---> Outcome\n",
    "  |       |                                                                        \n",
    "   ---(Moderator)\n",
    "```\n",
    "This is a 'first-stage model'\n",
    "\n",
    "First Stage Moderated Mediation: basically just checks if the mediation is dependent on a moderator relating the independent variable to the mediator. Essentially, it's an interaction effect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.genmod.generalized_linear_model import GLM\n",
    "from statsmodels.genmod.families import Gaussian\n",
    "from statsmodels.stats.mediation import Mediation\n",
    "\n",
    "def first_stage_moderated_mediation(dataframe, exposure, moderator, mediator, dependent_variable):\n",
    "    \"\"\"\n",
    "    This function performs a moderated_mediation analysis on the provided data.\n",
    "    \n",
    "    Parameters:\n",
    "    - dataframe: DataFrame containing the data.\n",
    "    - exposure: str, column name of the independent variable (e.g., 'Age').\n",
    "    - moderator: str, column name of the moderator variable, the variable interacting with the independent variable (e.g., 'Subiculum_Connectivity').\n",
    "    - mediator: str, column name of the mediator variable, the variable acting through the independent variable (e.g., 'Hippocampus').\n",
    "    - dependent_variable: str, column name of the dependent variable (e.g., 'outcome').\n",
    "       \n",
    "    Example Usage:\n",
    "    perform_moderation_analysis(data_df, independent_variable='Age', moderator='Subiculum_Connectivity', mediator='Hippocampus', dependent_variable='outcome')\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Fit the mediator model with interaction term\n",
    "    # Mediator ~ IV + Moderator + IV*Moderator\n",
    "    mediator_model = GLM.from_formula(f\"{mediator} ~ {exposure} + {moderator} + {exposure}:{moderator}\", data=dataframe, family=Gaussian())\n",
    "    \n",
    "    # Step 2: Fit the outcome model with mediator\n",
    "    # Dependent Variable ~ IV + Moderator + IV*Moderator + Mediator\n",
    "    outcome_model = GLM.from_formula(f\"{dependent_variable} ~ {exposure} + {moderator} + {exposure}:{moderator} + {mediator}\", data=dataframe, family=Gaussian())\n",
    "    \n",
    "    # Step 3: Perform mediation analysis\n",
    "    med = Mediation(outcome_model, mediator_model, exposure=exposure, mediator=mediator)\n",
    "    try:\n",
    "        med_result = med.fit()\n",
    "        print(f'Exposure {exposure} moderated by {moderator} mediated by {mediator}')\n",
    "        print(med_result.summary())\n",
    "        return med_result\n",
    "    except:\n",
    "        print(f'Perfect separation detected, aborting {mediator}')\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# Assuming your DataFrame is named data_df, and you're investigating if 'Hippocampus' mediates the relationship between 'Age' and 'outcome', with 'Subiculum_Connectivity' as a moderator.\n",
    "mediation_results = first_stage_moderated_mediation(data_df, \n",
    "                                     exposure='Age', \n",
    "                                     moderator='Subiculum_Connectivity', \n",
    "                                     mediator='Atrophy_Pattern_Index', \n",
    "                                     dependent_variable='outcome')\n",
    "mediation_results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[first_stage_moderated_mediation(data_df, exposure='Age', moderator='Subiculum_Connectivity', mediator=f'{col}', dependent_variable='outcome') for col in data_df.columns]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________\n",
    "Second Stage Model Moderated Mediation\n",
    "\n",
    "The moderation is on the path from the independent variable (age) to the mediator (atrophy region). This type of model is often termed as a first-stage moderated mediation. The moderation in this case can show if the relationship between age and the atrophy region varies at different levels of another variable (the moderator).\n",
    "\n",
    "This is model is not natively supported in Python, thus I have developed it myself. \n",
    "Highly complex and experimental model. Use with caution. \n",
    "\n",
    "\n",
    "Model Structure:\n",
    "```\n",
    " #Age ---(a1)------> Mediator ---(b1)---> Outcome\n",
    "  |                                  |\n",
    "  |                                  |\n",
    "   |                                 |\n",
    "   ---(Moderator)---------------------\n",
    "```\n",
    "Second Stage Moderated Mediation: When the moderation is occurring in the second part of the mediation process, it is called second stage moderated mediation. In this case, the relationship between the mediator (M) and the dependent variable (DV) depends on the moderator. This is sometimes referred to as \"moderated b path.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.genmod.generalized_linear_model import GLM\n",
    "from statsmodels.genmod.families import Gaussian\n",
    "from statsmodels.stats.mediation import Mediation\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.genmod.generalized_linear_model import GLM\n",
    "from statsmodels.genmod.families import Gaussian\n",
    "from statsmodels.stats.mediation import Mediation\n",
    "\n",
    "def second_stage_moderated_mediation(dataframe, exposure, moderator, mediator, dependent_variable):\n",
    "    \"\"\"\n",
    "    This function performs a moderated mediation analysis on the provided data.\n",
    "    \n",
    "    Parameters:\n",
    "    - dataframe: DataFrame containing the data.\n",
    "    - independent_variable: str, column name of the independent variable (e.g., 'Age').\n",
    "    - moderator: str, column name of the moderator variable, the variable interacting with the independent variable (e.g., 'Subiculum_Connectivity').\n",
    "    - mediator: str, column name of the mediator variable, the variable acting through the independent variable (e.g., 'Hippocampus').\n",
    "    - dependent_variable: str, column name of the dependent variable (e.g., 'outcome').\n",
    "       \n",
    "    Example Usage:\n",
    "    perform_moderated_mediation_analysis(data_df, independent_variable='Age', moderator='Subiculum_Connectivity', mediator='Hippocampus', dependent_variable='outcome')\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Fit the mediator model with interaction term\n",
    "    # Mediator ~ IV\n",
    "    mediator_model = GLM.from_formula(f\"{mediator} ~ {exposure}\", data=dataframe, family=Gaussian())\n",
    "    \n",
    "    # Step 2: Fit the outcome model with mediator\n",
    "    # Dependent Variable ~ IV + Moderator + IV*Moderator + Mediator\n",
    "    outcome_model = GLM.from_formula(f\"{dependent_variable} ~ {exposure} + {moderator} + {mediator}:{moderator} + {mediator}\", data=dataframe, family=Gaussian())\n",
    "\n",
    "    # Step 3: Perform mediation analysis\n",
    "    med = Mediation(outcome_model, mediator_model, exposure=exposure, mediator=mediator)\n",
    "    try:\n",
    "        med_result = med.fit()\n",
    "        print(f'Exposure {exposure} mediated by {mediator} and then moderated by {moderator}')\n",
    "        print(med_result.summary())\n",
    "        return med_result\n",
    "    except:\n",
    "        print(f'Perfect separation detected, aborting {mediator}')\n",
    "        return np.NaN\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_result = second_stage_moderated_mediation(data_df, \n",
    "                                exposure='Age', \n",
    "                                moderator='Subiculum_Connectivity', \n",
    "                                mediator='Atrophy_Pattern_Index', \n",
    "                                dependent_variable='outcome')\n",
    "med_result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code above for an entire spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[second_stage_moderated_mediation(data_df, exposure='Age', moderator='Subiculum_Connectivity', mediator=f'{col}', dependent_variable='outcome') for col in data_df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mediated Moderation Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classic Mediated Moderation**\n",
    "\n",
    "The indirect effect of the exposure on the outcome through the mediator is conditional based on the levels of the moderator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.genmod.generalized_linear_model import GLM\n",
    "from statsmodels.genmod.families import Gaussian\n",
    "from statsmodels.stats.mediation import Mediation\n",
    "\n",
    "def perform_mediated_moderation_analysis(dataframe, exposure, mediator, moderator, dependent_variable):\n",
    "    # Step 1: Fit the mediator model\n",
    "    # Mediator ~ Independent Variable * Moderator\n",
    "    mediator_model = GLM.from_formula(f\"{mediator} ~ {exposure} * {moderator}\", data=dataframe, family=Gaussian())\n",
    "    \n",
    "    # Step 2: Fit the outcome model\n",
    "    # Dependent Variable ~ Independent Variable + Mediator + Independent Variable * Moderator + Mediator * Moderator\n",
    "    outcome_model = GLM.from_formula(f\"{dependent_variable} ~ {exposure} + {mediator} + {exposure}:{moderator} + {mediator}:{moderator}\", data=dataframe, family=Gaussian())\n",
    "    \n",
    "    # Step 3: Perform mediation analysis\n",
    "    med = Mediation(outcome_model, mediator_model, exposure=exposure, mediator=mediator)\n",
    "    try:\n",
    "        med_result = med.fit()\n",
    "        # Step 4: Print the results\n",
    "        print(f'Mediated Moderation of {exposure} by {mediator} with {moderator} as the moderator:')\n",
    "        print(med_result.summary())\n",
    "    except Exception as e:\n",
    "        print(f\"Error {e}. Aborting assessment of {mediator}.\")\n",
    "        print(len(dataframe[mediator]), len(dataframe[moderator]), len(dataframe[exposure]))\n",
    "\n",
    "# Example usage:\n",
    "# Assuming your DataFrame is named df, and the columns of interest are 'DBS', 'brain_atrophy', 'age', and 'dependent_variable'\n",
    "# perform_mediated_moderation_analysis(data_df, \n",
    "#                                      exposure = 'DBS', \n",
    "#                                      mediator = 'brain_atrophy', \n",
    "#                                      moderator = 'age',\n",
    "#                                      dependent_variable='dependent_variable')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Everything!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data_df.columns[6:-1]:\n",
    "    print(perform_mediated_moderation_analysis(data_df, \n",
    "                                     exposure='Subiculum_Connectivity', \n",
    "                                     mediator=f'{col}', \n",
    "                                     moderator='Age', \n",
    "                                     dependent_variable='outcome'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run One Thing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_mediated_moderation_analysis(data_df, \n",
    "                                     exposure='Subiculum_Connectivity', \n",
    "                                     mediator='Z_Scored_Atrophy_Pattern_Index', \n",
    "                                     moderator='Age', \n",
    "                                     dependent_variable='percent_improvement_mdrs')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Process Analysis\n",
    "Based on Preacher and Hayes 2008, Asymptotic Asymptotic and resampling strategies for assessing and comparing indirect effects in multiple mediator models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________  \n",
    "Multiple Mediators and Moderation Analysis\n",
    "Also known as a conditional process analysis\n",
    "the two code segments below will vary the moderator, \n",
    "1) allowing the moderator to interact with the exposure upon mediators,\n",
    "or \n",
    "2) allowing the moderator to interact with the mediators upon outcome. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multiple Mediator Analysis with First Stager Moderator**:\n",
    "\n",
    "This code estimates the joint indirect effects of an exposure variable through multiple mediators on a dependent variable while considering the moderation effect of a specified moderator variable.\n",
    "\n",
    "In this code, similar to the previous code, the function loops over each bootstrap sample and computes the indirect effects for each mediator, considering the moderation effect of the specified moderator variable in the first stage. It calculates the total indirect effect as the sum of the individual indirect effects for each mediator. The mean indirect effect, 95% confidence interval, and p-value are then calculated based on the bootstrap samples.\n",
    "\n",
    "The inclusion of the moderator variable and its interaction with the exposure variable in the first stage allows for examining how the mediation effects may vary based on different levels of the moderator. By considering the moderation effect at the first stage, this analysis investigates the conditional indirect effects of the exposure through the mediators.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "def perform_multiple_mediation_first_stage_moderator_analysis(dataframe, exposure, mediators, moderator, dependent_variable, bootstrap_samples=5000):\n",
    "    \"\"\"\n",
    "    Performs a multiple mediation analysis by estimating the joint indirect effects of an exposure variable\n",
    "    through multiple mediators on a dependent variable using bootstrapping.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe: DataFrame containing the data.\n",
    "    - exposure: str, column name of the exposure variable (e.g., 'Age').\n",
    "    - mediators: list, column names of the mediator variables (e.g., ['Brain_Lobe1', 'Brain_Lobe2']).\n",
    "    - moderator: str, column name of the moderator variable.\n",
    "    - dependent_variable: str, column name of the dependent variable (e.g., 'outcome').\n",
    "    - bootstrap_samples: int, optional, number of bootstrap samples to be used (default is 5000).\n",
    "\n",
    "    Returns:\n",
    "    - None. Prints the mean indirect effect and 95% confidence interval.\n",
    "\n",
    "    Example Usage:\n",
    "    perform_multiple_mediation_analysis(data_df, exposure='Age', mediators=['Brain_Lobe1', 'Brain_Lobe2'], dependent_variable='outcome')\n",
    "    \"\"\"\n",
    "\n",
    "    ab_paths, total_indirect_effects = [], []\n",
    "    \n",
    "    # Loop over each bootstrap sample\n",
    "    for i in range(bootstrap_samples):\n",
    "        # Resample the data with replacement\n",
    "        sample = dataframe.sample(frac=1, replace=True)\n",
    "        # Paths from exposure to mediators and from mediators to DV\n",
    "        ab_paths_sample = [ols(f\"{mediator} ~ {exposure} + {moderator} + {exposure}:{moderator}\", data=sample).fit().params[exposure] * \n",
    "                    ols(f\"{dependent_variable} ~ {exposure} + {moderator} + {exposure}:{moderator} + {mediator}\", data=sample).fit().params[mediator]\n",
    "                    for mediator in mediators]\n",
    "        \n",
    "        # Sum the individual indirect effects for this bootstrap sample\n",
    "        total_indirect_effect = sum(ab_paths_sample)\n",
    "        ab_paths.append(ab_paths_sample)\n",
    "        total_indirect_effects.append(total_indirect_effect)\n",
    "    \n",
    "    # Calculate confidence intervals and p-values\n",
    "    result_df = calculate_confidence_intervals(ab_paths, total_indirect_effects, mediators)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "def calculate_confidence_intervals(ab_paths, total_indirect_effects, mediators):\n",
    "    \"\"\"\n",
    "    Calculates the confidence intervals and p-value based on the bootstrapped samples.\n",
    "\n",
    "    Parameters:\n",
    "    - ab_paths: list of lists containing the bootstrapped ab paths for each mediator.\n",
    "    - total_indirect_effects: list of bootstrapped summed ab paths.\n",
    "    - mediators: list of mediator names.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with the mean indirect effect, confidence intervals, and p-values for each mediator and the total indirect effect.\n",
    "    \"\"\"\n",
    "\n",
    "    ab_path_values = np.array(ab_paths)\n",
    "    total_indirect_effects = np.array(total_indirect_effects)\n",
    "\n",
    "    # Calculate mean indirect effect and confidence intervals for each mediator\n",
    "    mean_ab_paths = np.mean(ab_path_values, axis=0)\n",
    "    lower_bounds = np.percentile(ab_path_values, 2.5, axis=0)\n",
    "    upper_bounds = np.percentile(ab_path_values, 97.5, axis=0)\n",
    "\n",
    "    # Calculate p-values for each mediator\n",
    "    ab_path_p_values = [np.mean(np.sign(mean_ab_paths[i]) * ab_path_values[:, i] <= 0) for i in range(len(mean_ab_paths))]\n",
    "\n",
    "\n",
    "    # Calculate mean indirect effect and confidence intervals for the total indirect effect\n",
    "    mean_total_indirect_effect = np.mean(total_indirect_effects)\n",
    "    lower_bound_total = np.percentile(total_indirect_effects, 2.5)\n",
    "    upper_bound_total = np.percentile(total_indirect_effects, 97.5)\n",
    "    p_value_total = np.mean(total_indirect_effects > 0) if np.mean(total_indirect_effects) < 0 else np.mean(total_indirect_effects <= 1)\n",
    "\n",
    "    # Create DataFrame to store the results\n",
    "    result_df = pd.DataFrame({\n",
    "        'Point Estimate': np.concatenate((mean_ab_paths, [mean_total_indirect_effect])),\n",
    "        '2.5th Percentile': np.concatenate((lower_bounds, [lower_bound_total])),\n",
    "        '97.5th Percentile': np.concatenate((upper_bounds, [upper_bound_total])),\n",
    "        'P-value': ab_path_p_values + [p_value_total]\n",
    "    }, index=mediators + ['Total Indirect Effect'])\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['subject', 'Age', 'Hippocampus_GM_Vol', 'Parahippocampal_Gyrus_GM_Vol',\n",
      "       'Entorhinal_Cortex_GM_Vol', 'Normalized_Percent_Cognitive_Improvement',\n",
      "       'Z_Scored_Percent_Cognitive_Improvement_By_Origin_Group',\n",
      "       'Z_Scored_Percent_Cognitive_Improvement',\n",
      "       'Percent_Cognitive_Improvement',\n",
      "       'Z_Scored_Subiculum_T_By_Origin_Group_',\n",
      "       'Z_Scored_Subiculum_Connectivity_T', 'Subiculum_Connectivity_T_Redone',\n",
      "       'Subiculum_Connectivity_T', 'Amnesia_Lesion_T_Map', 'Memory_Network_T',\n",
      "       'Z_Scored_Memory_Network_R', 'Memory_Network_R',\n",
      "       'Subiculum_Grey_Matter', 'Subiculum_White_Matter', 'Subiculum_CSF',\n",
      "       'Subiculum_Total', 'Standardized_Age',\n",
      "       'Standardized_Percent_Improvement',\n",
      "       'Standardized_Subiculum_Connectivity',\n",
      "       'Standardized_Subiculum_Grey_Matter',\n",
      "       'Standardized_Subiculum_White_Matter', 'Standardized_Subiculum_CSF',\n",
      "       'Standardized_Subiculum_Total', 'Disease', 'Cohort', 'City',\n",
      "       'Inclusion_Cohort', 'Categorical_Age_Group', 'Age_Group',\n",
      "       'Age_And_Disease', 'Age_Disease_and_Cohort', 'Age_Disease_Cohort_Stim',\n",
      "       'Age_And_Stim', 'Subiculum_Group_By_Z_Score_Sign',\n",
      "       'Subiculum_Group_By_Inflection_Point', 'Subiculum_Group_By_24',\n",
      "       'Cognitive_Outcome', 'StimMatch', 'StimMatch24', 'Cognitive_Baseline',\n",
      "       'Cognitive_Score_1_Yr', 'MinMaxNorm_Cog_Score_1_Yr',\n",
      "       'Abs_Cognitive_Improve', 'IMPROVE_OR_STABLE', 'DECLINE_OR_STABLE',\n",
      "       'IMPROVE', 'DECLINE', 'Cognitive_Improve',\n",
      "       'Z_Scored_Cognitive_Baseline',\n",
      "       'Z_Scored_Cognitive_Baseline__Lower_is_Better_',\n",
      "       'Min_Max_Normalized_Baseline', 'MinMaxNormBaseline_Higher_is_Better',\n",
      "       'ROI_to_Alz_Max', 'ROI_to_PD_Max', 'Standardzied_AD_Max',\n",
      "       'Standardized_PD_Max'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Point Estimate</th>\n",
       "      <th>2.5th Percentile</th>\n",
       "      <th>97.5th Percentile</th>\n",
       "      <th>P-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hippocampus_GM_Vol</th>\n",
       "      <td>-0.565603</td>\n",
       "      <td>-3.534627</td>\n",
       "      <td>2.892323</td>\n",
       "      <td>0.281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Indirect Effect</th>\n",
       "      <td>-0.565603</td>\n",
       "      <td>-3.534627</td>\n",
       "      <td>2.892323</td>\n",
       "      <td>0.281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Point Estimate  2.5th Percentile  97.5th Percentile  \\\n",
       "Hippocampus_GM_Vol          -0.565603         -3.534627           2.892323   \n",
       "Total Indirect Effect       -0.565603         -3.534627           2.892323   \n",
       "\n",
       "                       P-value  \n",
       "Hippocampus_GM_Vol       0.281  \n",
       "Total Indirect Effect    0.281  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perform_multiple_mediation_first_stage_moderator_analysis(data_df, \n",
    "                                                    exposure='Subiculum_Connectivity_T_Redone', \n",
    "                                                    moderator='Age', \n",
    "                                                    mediators= ['Hippocampus_GM_Vol'],\n",
    "                                                    dependent_variable='Percent_Cognitive_Improvement',\n",
    "                                                    bootstrap_samples=1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------\n",
    "Moderated Mulitple Mediation Analysis, but with all mediators combined instead of run individually\n",
    "- This is not supported natively in Python libraries, so I have developed it myself. \n",
    "\n",
    "Experimental, please use with caution. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "**Multiple Mediator Analysis with Second Stage Moderator**\n",
    "\n",
    "\n",
    "In this code, the function loops over each bootstrap sample and computes the indirect effects for each mediator, taking into account the moderation effect of the specified moderator variable. It calculates the total indirect effect as the sum of the individual indirect effects for each mediator. The mean indirect effect, 95% confidence interval, and p-value are then calculated based on the bootstrap samples.\n",
    "\n",
    "The addition of the moderator variable in the second-stage analysis allows for assessing how the mediation effects may vary across different levels of the moderator. By including the moderator variable and its interaction with the mediators, the analysis investigates whether the indirect effects of the exposure through the mediators differ depending on the levels of the moderator.\n",
    "\n",
    "Overall, this code provides a way to examine multiple mediation effects while considering a second-stage moderation analysis to explore potential moderation effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "def perform_multiple_mediation_second_stage_moderator_analysis(dataframe, exposure, mediators, moderator, dependent_variable, bootstrap_samples=5000):\n",
    "    \"\"\"\n",
    "    Performs a multiple mediation analysis by estimating the joint indirect effects of an exposure variable\n",
    "    through multiple mediators on a dependent variable using bootstrapping.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe: DataFrame containing the data.\n",
    "    - exposure: str, column name of the exposure variable (e.g., 'Age').\n",
    "    - mediators: list, column names of the mediator variables (e.g., ['Brain_Lobe1', 'Brain_Lobe2']).\n",
    "    - moderator: str, column name of the moderator variable.\n",
    "    - dependent_variable: str, column name of the dependent variable (e.g., 'outcome').\n",
    "    - bootstrap_samples: int, optional, number of bootstrap samples to be used (default is 5000).\n",
    "\n",
    "    Returns:\n",
    "    - None. Prints the mean indirect effect and 95% confidence interval.\n",
    "\n",
    "    Example Usage:\n",
    "    perform_multiple_mediation_analysis(data_df, exposure='Age', mediators=['Brain_Lobe1', 'Brain_Lobe2'], dependent_variable='outcome')\n",
    "    \"\"\"\n",
    "\n",
    "    ab_paths, total_indirect_effects = [], []\n",
    "    \n",
    "    # Loop over each bootstrap sample\n",
    "    for i in range(bootstrap_samples):\n",
    "        # Resample the data with replacement\n",
    "        sample = dataframe.sample(frac=1, replace=True)\n",
    "        # Paths from exposure to mediators and from mediators to DV\n",
    "        ab_paths_sample = [ols(f\"{mediator} ~ {exposure}\", data=sample).fit().params[exposure] * \n",
    "                    ols(f\"{dependent_variable} ~ {exposure} + {moderator} + {mediator}:{moderator} + {mediator}\", data=sample).fit().params[mediator]\n",
    "                    for mediator in mediators]\n",
    "        \n",
    "        # Sum the individual indirect effects for this bootstrap sample\n",
    "        total_indirect_effect = sum(ab_paths_sample)\n",
    "        ab_paths.append(ab_paths_sample)\n",
    "        total_indirect_effects.append(total_indirect_effect)\n",
    "    \n",
    "    # Calculate confidence intervals and p-values\n",
    "    result_df = calculate_confidence_intervals(ab_paths, total_indirect_effects, mediators)\n",
    "\n",
    "\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Point Estimate</th>\n",
       "      <th>2.5th Percentile</th>\n",
       "      <th>97.5th Percentile</th>\n",
       "      <th>P-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.007178</td>\n",
       "      <td>-0.305493</td>\n",
       "      <td>0.294824</td>\n",
       "      <td>0.4797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Indirect Effect</th>\n",
       "      <td>-0.007178</td>\n",
       "      <td>-0.305493</td>\n",
       "      <td>0.294824</td>\n",
       "      <td>0.4797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Point Estimate  2.5th Percentile  97.5th Percentile  \\\n",
       "Age                         -0.007178         -0.305493           0.294824   \n",
       "Total Indirect Effect       -0.007178         -0.305493           0.294824   \n",
       "\n",
       "                       P-value  \n",
       "Age                     0.4797  \n",
       "Total Indirect Effect   0.4797  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perform_multiple_mediation_second_stage_moderator_analysis(data_df, \n",
    "                                                    exposure='Z_Scored_Subiculum_Connectivity_T', \n",
    "                                                    moderator='Age', \n",
    "                                                    mediators= ['Hippocampus_GM_Vol'],\n",
    "                                                    dependent_variable='Z_Scored_Percent_Cognitive_Improvement',\n",
    "                                                    bootstrap_samples=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject', 'Age', 'Hippocampus_GM_Vol', 'Parahippocampal_Gyrus_GM_Vol',\n",
       "       'Entorhinal_Cortex_GM_Vol', 'Normalized_Percent_Cognitive_Improvement',\n",
       "       'Z_Scored_Percent_Cognitive_Improvement_By_Origin_Group',\n",
       "       'Z_Scored_Percent_Cognitive_Improvement',\n",
       "       'Percent_Cognitive_Improvement',\n",
       "       'Z_Scored_Subiculum_T_By_Origin_Group_',\n",
       "       'Z_Scored_Subiculum_Connectivity_T', 'Subiculum_Connectivity_T_Redone',\n",
       "       'Subiculum_Connectivity_T', 'Amnesia_Lesion_T_Map', 'Memory_Network_T',\n",
       "       'Z_Scored_Memory_Network_R', 'Memory_Network_R',\n",
       "       'Subiculum_Grey_Matter', 'Subiculum_White_Matter', 'Subiculum_CSF',\n",
       "       'Subiculum_Total', 'Standardized_Age',\n",
       "       'Standardized_Percent_Improvement',\n",
       "       'Standardized_Subiculum_Connectivity',\n",
       "       'Standardized_Subiculum_Grey_Matter',\n",
       "       'Standardized_Subiculum_White_Matter', 'Standardized_Subiculum_CSF',\n",
       "       'Standardized_Subiculum_Total', 'Disease', 'Cohort', 'City',\n",
       "       'Inclusion_Cohort', 'Categorical_Age_Group', 'Age_Group',\n",
       "       'Age_And_Disease', 'Age_Disease_and_Cohort', 'Age_Disease_Cohort_Stim',\n",
       "       'Age_And_Stim', 'Subiculum_Group_By_Z_Score_Sign',\n",
       "       'Subiculum_Group_By_Inflection_Point', 'Subiculum_Group_By_24',\n",
       "       'Cognitive_Outcome', 'StimMatch', 'StimMatch24', 'Cognitive_Baseline',\n",
       "       'Cognitive_Score_1_Yr', 'MinMaxNorm_Cog_Score_1_Yr',\n",
       "       'Abs_Cognitive_Improve', 'IMPROVE_OR_STABLE', 'DECLINE_OR_STABLE',\n",
       "       'IMPROVE', 'DECLINE', 'Cognitive_Improve',\n",
       "       'Z_Scored_Cognitive_Baseline',\n",
       "       'Z_Scored_Cognitive_Baseline__Lower_is_Better_',\n",
       "       'Min_Max_Normalized_Baseline', 'MinMaxNormBaseline_Higher_is_Better',\n",
       "       'ROI_to_Alz_Max', 'ROI_to_PD_Max', 'Standardzied_AD_Max',\n",
       "       'Standardized_PD_Max'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complex Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mediated Moderator Analysis AKA Second Stage Moderation Mediation**\n",
    "\n",
    "The indirect effect of the moderator on the outcome through the mediator is conditional on the exposure and its interactions with the mediator and the moderator.\n",
    "_____\n",
    "\n",
    "Let's break this down:\n",
    "\n",
    "Similar to my previous examples, we will use the same variables. This model suggests that:\n",
    "\n",
    "Age (the initial moderator) interacts with DBS (the exposure) to influence the outcome.\n",
    "However, the moderation effect of age might not be the \"true\" or direct moderation. Instead, it might be that something underlying age (another variable) is what's truly driving this moderation.\n",
    "In terms of a pathway:\n",
    "\n",
    "DBS influences the outcome.\n",
    "The effect of DBS on the outcome varies based on age.\n",
    "However, the moderating effect of age is itself influenced (or mediated) by another variable. This other variable could be a more direct measure or something that captures the biological, psychological, or physiological changes that come with age.\n",
    "Here's a step-by-step breakdown of the model:\n",
    "\n",
    "Mediator Model (for the \"true\" underlying mediator of age's moderation):\n",
    "- Mediator is predicted by age.\n",
    "\n",
    "Outcome Model:\n",
    "- Outcome is predicted by DBS, the mediator, age, and interactions between DBS and both age and the mediator.\n",
    "This model seeks to understand if the interaction between age and DBS is not just because of chronological age itself but due to some underlying factor associated with age.\n",
    "\n",
    "Is it just a mediated moderation?\n",
    "It's close but slightly different. In a typical mediated moderation:\n",
    "\n",
    "The exposure affects the mediator.\n",
    "The mediator, the exposure, and their interaction influence the outcome.In the Second Stage Moderation Mediation:\n",
    "\n",
    "Age (the moderator) affects the mediator.\n",
    "The mediator, the exposure (DBS), age, and their interactions influence the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.mediation import Mediation\n",
    "\n",
    "def mediated_moderator_analysis(dataframe, exposure, mediator, moderator, dependent_variable, bootstrap_samples=5000):\n",
    "    \"\"\"\n",
    "    Performs a mediated moderator analysis.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with the mean indirect effect, confidence intervals, and p-values for the indirect effect.\n",
    "\n",
    "    Example Usage:\n",
    "    result_df = mediated_moderator_analysis(data_df, exposure='DBS',\n",
    "                                            mediator='UnderlyingVariable',\n",
    "                                            moderator='Age',\n",
    "                                            dependent_variable='Outcome')\n",
    "    \"\"\"\n",
    "\n",
    "    ab_paths = []\n",
    "\n",
    "    # Loop over each bootstrap sample\n",
    "    for i in range(bootstrap_samples):\n",
    "        # Resample the data with replacement\n",
    "        sample = dataframe.sample(frac=1, replace=True)\n",
    "\n",
    "        # Fit the mediator model: Mediator ~ Moderator\n",
    "        model_M = ols(f\"{mediator} ~ {moderator}\", data=sample).fit()\n",
    "\n",
    "        # Fit the outcome model: Outcome ~ Exposure + Mediator + Moderator + Exposure:Mediator + Exposure:Moderator\n",
    "        model_Y = ols(f\"{dependent_variable} ~ {exposure} + {mediator} + {moderator} + {exposure}:{mediator} + {exposure}:{moderator}\", data=sample).fit()\n",
    "\n",
    "        # Calculate the indirect effect for this bootstrap sample\n",
    "        indirect_effect = model_M.params[moderator] * (model_Y.params[exposure] + model_Y.params[f'{exposure}:{mediator}'])\n",
    "\n",
    "        # Append the indirect effect to the list\n",
    "        ab_paths.append(indirect_effect)\n",
    "\n",
    "    # Calculate confidence intervals and p-values\n",
    "    result_df = calculate_confidence_intervals(ab_paths, mediators=mediator)\n",
    "\n",
    "    return result_df\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_confidence_intervals(ab_paths, mediators):\n",
    "    \"\"\"\n",
    "    Calculates the confidence intervals and p-value based on the bootstrapped samples.\n",
    "\n",
    "    Parameters:\n",
    "    - ab_paths: list of lists containing the bootstrapped ab paths for each mediator.\n",
    "    - mediators: list of mediator names.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with the mean indirect effect, confidence intervals, and p-values for each mediator and the total indirect effect.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert ab_paths to a NumPy array for easier manipulation\n",
    "    ab_path_values = np.array(ab_paths)\n",
    "\n",
    "    # Calculate mean indirect effect for each mediator\n",
    "    mean_ab_paths = np.mean(ab_path_values, axis=1)\n",
    "\n",
    "    # Calculate 2.5th and 97.5th percentiles for confidence intervals\n",
    "    lower_bounds = np.percentile(ab_path_values, 2.5, axis=1)\n",
    "    upper_bounds = np.percentile(ab_path_values, 97.5, axis=1)\n",
    "\n",
    "    # Calculate p-values based on the distribution of bootstrapped samples\n",
    "    ab_path_p_values = np.mean(ab_path_values > 0, axis=1)\n",
    "\n",
    "    # Create a DataFrame to store the results\n",
    "    result_df = pd.DataFrame({\n",
    "        'Point Estimate': mean_ab_paths,\n",
    "        '2.5th Percentile': lower_bounds,\n",
    "        '97.5th Percentile': upper_bounds,\n",
    "        'P-value': ab_path_p_values\n",
    "    }, index=mediators)\n",
    "\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject', 'Age', 'Hippocampus_GM_Vol', 'Parahippocampal_Gyrus_GM_Vol',\n",
       "       'Entorhinal_Cortex_GM_Vol', 'Normalized_Percent_Cognitive_Improvement',\n",
       "       'Z_Scored_Percent_Cognitive_Improvement_By_Origin_Group',\n",
       "       'Z_Scored_Percent_Cognitive_Improvement',\n",
       "       'Percent_Cognitive_Improvement',\n",
       "       'Z_Scored_Subiculum_T_By_Origin_Group_',\n",
       "       'Z_Scored_Subiculum_Connectivity_T', 'Subiculum_Connectivity_T_Redone',\n",
       "       'Subiculum_Connectivity_T', 'Amnesia_Lesion_T_Map', 'Memory_Network_T',\n",
       "       'Z_Scored_Memory_Network_R', 'Memory_Network_R',\n",
       "       'Subiculum_Grey_Matter', 'Subiculum_White_Matter', 'Subiculum_CSF',\n",
       "       'Subiculum_Total', 'Standardized_Age',\n",
       "       'Standardized_Percent_Improvement',\n",
       "       'Standardized_Subiculum_Connectivity',\n",
       "       'Standardized_Subiculum_Grey_Matter',\n",
       "       'Standardized_Subiculum_White_Matter', 'Standardized_Subiculum_CSF',\n",
       "       'Standardized_Subiculum_Total', 'Disease', 'Cohort', 'City',\n",
       "       'Inclusion_Cohort', 'Categorical_Age_Group', 'Age_Group',\n",
       "       'Age_And_Disease', 'Age_Disease_and_Cohort', 'Age_Disease_Cohort_Stim',\n",
       "       'Age_And_Stim', 'Subiculum_Group_By_Z_Score_Sign',\n",
       "       'Subiculum_Group_By_Inflection_Point', 'Subiculum_Group_By_24',\n",
       "       'Cognitive_Outcome', 'StimMatch', 'StimMatch24', 'Cognitive_Baseline',\n",
       "       'Cognitive_Score_1_Yr', 'MinMaxNorm_Cog_Score_1_Yr',\n",
       "       'Abs_Cognitive_Improve', 'IMPROVE_OR_STABLE', 'DECLINE_OR_STABLE',\n",
       "       'IMPROVE', 'DECLINE', 'Cognitive_Improve',\n",
       "       'Z_Scored_Cognitive_Baseline',\n",
       "       'Z_Scored_Cognitive_Baseline__Lower_is_Better_',\n",
       "       'Min_Max_Normalized_Baseline', 'MinMaxNormBaseline_Higher_is_Better',\n",
       "       'ROI_to_Alz_Max', 'ROI_to_PD_Max', 'Standardzied_AD_Max',\n",
       "       'Standardized_PD_Max'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmediated_moderator_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mexposure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mZ_Scored_Subiculum_Connectivity_T\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mmediator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHippocampus_GM_Vol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mmoderator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAge\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdependent_variable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mZ_Scored_Percent_Cognitive_Improvement\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mbootstrap_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[47], line 40\u001b[0m, in \u001b[0;36mmediated_moderator_analysis\u001b[0;34m(dataframe, exposure, mediator, moderator, dependent_variable, bootstrap_samples)\u001b[0m\n\u001b[1;32m     37\u001b[0m     ab_paths\u001b[38;5;241m.\u001b[39mappend(indirect_effect)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Calculate confidence intervals and p-values\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m result_df \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_confidence_intervals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mab_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmediators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmediator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result_df\n",
      "Cell \u001b[0;32mIn[47], line 62\u001b[0m, in \u001b[0;36mcalculate_confidence_intervals\u001b[0;34m(ab_paths, mediators)\u001b[0m\n\u001b[1;32m     59\u001b[0m ab_path_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(ab_paths)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Calculate mean indirect effect for each mediator\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m mean_ab_paths \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mab_path_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Calculate 2.5th and 97.5th percentiles for confidence intervals\u001b[39;00m\n\u001b[1;32m     65\u001b[0m lower_bounds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpercentile(ab_path_values, \u001b[38;5;241m2.5\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3501\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3502\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 3504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3505\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/_methods.py:106\u001b[0m, in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    102\u001b[0m arr \u001b[38;5;241m=\u001b[39m asanyarray(a)\n\u001b[1;32m    104\u001b[0m is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m rcount \u001b[38;5;241m=\u001b[39m \u001b[43m_count_reduce_items\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rcount \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m umr_any(rcount \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    108\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean of empty slice.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/_methods.py:77\u001b[0m, in \u001b[0;36m_count_reduce_items\u001b[0;34m(arr, axis, keepdims, where)\u001b[0m\n\u001b[1;32m     75\u001b[0m     items \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m axis:\n\u001b[0;32m---> 77\u001b[0m         items \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mshape[\u001b[43mmu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_axis_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     78\u001b[0m     items \u001b[38;5;241m=\u001b[39m nt\u001b[38;5;241m.\u001b[39mintp(items)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m# TODO: Optimize case when `where` is broadcast along a non-reduction\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# axis and full sum is more excessive than needed.\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \n\u001b[1;32m     83\u001b[0m     \u001b[38;5;66;03m# guarded to protect circular imports\u001b[39;00m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "mediated_moderator_analysis(dataframe=data_df, \n",
    "                            exposure='Z_Scored_Subiculum_Connectivity_T', \n",
    "                            mediator='Hippocampus_GM_Vol', \n",
    "                            moderator='Age', \n",
    "                            dependent_variable='Z_Scored_Percent_Cognitive_Improvement', \n",
    "                            bootstrap_samples=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimlab_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
