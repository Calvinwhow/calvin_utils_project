{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Any Kind of Logistic Regression (Binomial, Multinomial, etc.)\n",
    "\n",
    "### Authors: Calvin Howard.\n",
    "\n",
    "#### Last updated: March 16, 2024\n",
    "\n",
    "Use this to run/test a statistical model on a spreadsheet.\n",
    "\n",
    "Notes:\n",
    "- To best use this notebook, you should be familar with GLM design and Contrast Matrix design. See this webpage to get started:\n",
    "[FSL's GLM page](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/GLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 - Import CSV with All Data\n",
    "**The CSV is expected to be in this format**\n",
    "- ID and absolute paths to niftis are critical\n",
    "```\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "| ID  | Nifti_File_Path            | Covariate_1  | Covariate_2  | Covariate_3  |\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "| 1   | /path/to/file1.nii.gz      | 0.5          | 1.2          | 3.4          |\n",
    "| 2   | /path/to/file2.nii.gz      | 0.7          | 1.4          | 3.1          |\n",
    "| 3   | /path/to/file3.nii.gz      | 0.6          | 1.5          | 3.5          |\n",
    "| 4   | /path/to/file4.nii.gz      | 0.9          | 1.1          | 3.2          |\n",
    "| ... | ...                        | ...          | ...          | ...          |\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prep Output Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify where you want to save your results to\n",
    "out_dir = '/Users/cu135/Partners HealthCare Dropbox/Calvin Howard/studies/atrophy_seeds_2023/shared_analysis/diagnostic_analysis/csf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your CSV file containing NIFTI paths\n",
    "input_csv_path = '/Volumes/OneTouch/datasets/adni/metadata/updated_master_list/train_test_splits/train_data_csf.csv'\n",
    "sheet = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.permutation_analysis_utils.statsmodels_palm import CalvinStatsmodelsPalm\n",
    "# Instantiate the PalmPrepararation class\n",
    "cal_palm = CalvinStatsmodelsPalm(input_csv_path=input_csv_path, output_dir=out_dir, sheet=sheet)\n",
    "# Call the process_nifti_paths method\n",
    "data_df = cal_palm.read_and_display_data()\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Preprocess Your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handle NANs**\n",
    "- Set drop_nans=True is you would like to remove NaNs from data\n",
    "- Provide a column name or a list of column names to remove NaNs from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['peak_atrophy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df = cal_palm.drop_nans_from_columns(columns_to_drop_from=drop_list)\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop Row Based on Value of Column**\n",
    "\n",
    "Define the column, condition, and value for dropping rows\n",
    "- column = 'your_column_name'\n",
    "- condition = 'above'  # Options: 'equal', 'above', 'below'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the parameters for dropping rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'DX_BASELINE'  # The column you'd like to evaluate\n",
    "condition = 'equal'  # The condition to check ('equal', 'above', 'below', 'not')\n",
    "value = 'MCI' # The value to drop if found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df, other_df = cal_palm.drop_rows_based_on_value(column, condition, value)\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standardize Data**\n",
    "- Enter Columns you Don't want to standardize into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove anything you don't want to standardize\n",
    "cols_not_to_standardize = ['Age', 'Male', 'DX_BASELINE'] # ['Z_Scored_Percent_Cognitive_Improvement_By_Origin_Group', 'Z_Scored_Subiculum_T_By_Origin_Group_'] #['Age']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = cal_palm.standardize_columns(cols_not_to_standardize)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Categorical Column to Ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.file_utils.dataframe_utilities import convert_to_ordinal\n",
    "# data_df, map = convert_to_ordinal(data_df, ['DX_BASELINE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Define Your Formula\n",
    "\n",
    "This is the formula relating outcome to predictors, and takes the form:\n",
    "- y = B0 + B1 + B2 + B3 + . . . BN\n",
    "\n",
    "It is defined using the columns of your dataframe instead of the variables above:\n",
    "- 'Apples_Picked ~ hours_worked + owns_apple_picking_machine'\n",
    "\n",
    "____\n",
    "**Normal Logistic**\n",
    "- Assesses the impact of multiple predictors on an outcome.\n",
    "- formula = 'Binary Outcome ~ Predictor1 + Predictor2'\n",
    "\n",
    "**Multiple Logistic**\n",
    "- Assesses the impact of predictor on an outcome.\n",
    "- formula = 'Ordinal Outcome ~ Predictor1 + Predictor2'\n",
    "\n",
    "____\n",
    "Use the printout below to design your formula. \n",
    "- Left of the \"~\" symbol is the thing to be predicted. \n",
    "- Right of the \"~\" symbol are the predictors. \n",
    "- \":\" indicates an interaction between two things. \n",
    "- \"*\" indicates and interactions AND it accounts for the simple effects too. \n",
    "- \"+\" indicates that you want to add another predictor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "vars = ['Age', 'Male', 'Fusiform__sum_csf', 'Temporal_Pole_Mid__sum_csf',\n",
    "       'Occipital_Sup__sum_csf', 'Postcentral__sum_csf',\n",
    "       'Cerebelum_Crus2__sum_csf', 'Temporal_Inf__sum_csf',\n",
    "       'Rolandic_Oper__sum_csf', 'Cerebelum_9__sum_csf', 'Rectus__sum_csf',\n",
    "       'Temporal_Sup__sum_csf', 'Cerebelum_8__sum_csf', 'Precuneus__sum_csf',\n",
    "       'Occipital_Inf__sum_csf', 'OFCpost__sum_csf', 'Cingulate_Mid__sum_csf',\n",
    "       'Cerebelum_4_5__sum_csf', 'Vermis_10__sum_csf', 'OFClat__sum_csf',\n",
    "       'Olfactory__sum_csf', 'Cingulate_Post__sum_csf',\n",
    "       'Frontal_Sup_2__sum_csf', 'Angular__sum_csf', 'Putamen__sum_csf',\n",
    "       'Vermis_6__sum_csf', 'Heschl__sum_csf', 'OFCmed__sum_csf',\n",
    "       'Pallidum__sum_csf', 'Cuneus__sum_csf', 'Cerebelum_3__sum_csf',\n",
    "       'Cerebelum_Crus1__sum_csf', 'Vermis_7__sum_csf', 'Insula__sum_csf',\n",
    "       'Paracentral_Lobule__sum_csf', 'Hippocampus__sum_csf',\n",
    "       'ParaHippocampal__sum_csf', 'SupraMarginal__sum_csf',\n",
    "       'Precentral__sum_csf', 'Occipital_Mid__sum_csf',\n",
    "       'Temporal_Pole_Sup__sum_csf', 'Lingual__sum_csf', 'Caudate__sum_csf',\n",
    "       'Amygdala__sum_csf', 'Frontal_Inf_Tri__sum_csf',\n",
    "       'Supp_Motor_Area__sum_csf', 'Parietal_Inf__sum_csf',\n",
    "       'Frontal_Med_Orb__sum_csf', 'Vermis_1_2__sum_csf', 'Vermis_3__sum_csf',\n",
    "       'Temporal_Mid__sum_csf', 'Calcarine__sum_csf', 'Cerebelum_6__sum_csf',\n",
    "       'Parietal_Sup__sum_csf', 'Cerebelum_10__sum_csf',\n",
    "       'Cerebelum_7b__sum_csf', 'Frontal_Sup_Medial__sum_csf',\n",
    "       'Vermis_8__sum_csf', 'Vermis_4_5__sum_csf', 'Thalamus__sum_csf',\n",
    "       'OFCant__sum_csf', 'Vermis_9__sum_csf', 'Frontal_Mid_2__sum_csf',\n",
    "       'Frontal_Inf_Orb_2__sum_csf', 'Frontal_Inf_Oper__sum_csf',\n",
    "       'Cingulate_Ant__sum_csf']\n",
    "t = ' + '.join(vars)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"DX_BASELINE ~ Age + Male + Fusiform__sum_csf + Temporal_Pole_Mid__sum_csf + Occipital_Sup__sum_csf + Postcentral__sum_csf + Cerebelum_Crus2__sum_csf + Temporal_Inf__sum_csf + Rolandic_Oper__sum_csf + Cerebelum_9__sum_csf + Rectus__sum_csf + Temporal_Sup__sum_csf + Cerebelum_8__sum_csf + Precuneus__sum_csf + Occipital_Inf__sum_csf + OFCpost__sum_csf + Cingulate_Mid__sum_csf + Cerebelum_4_5__sum_csf + Vermis_10__sum_csf + OFClat__sum_csf + Olfactory__sum_csf + Cingulate_Post__sum_csf + Frontal_Sup_2__sum_csf + Angular__sum_csf + Putamen__sum_csf + Vermis_6__sum_csf + Heschl__sum_csf + OFCmed__sum_csf + Pallidum__sum_csf + Cuneus__sum_csf + Cerebelum_3__sum_csf + Cerebelum_Crus1__sum_csf + Vermis_7__sum_csf + Insula__sum_csf + Paracentral_Lobule__sum_csf + Hippocampus__sum_csf + ParaHippocampal__sum_csf + SupraMarginal__sum_csf + Precentral__sum_csf + Occipital_Mid__sum_csf + Temporal_Pole_Sup__sum_csf + Lingual__sum_csf + Caudate__sum_csf + Amygdala__sum_csf + Frontal_Inf_Tri__sum_csf + Supp_Motor_Area__sum_csf + Parietal_Inf__sum_csf + Frontal_Med_Orb__sum_csf + Vermis_1_2__sum_csf + Vermis_3__sum_csf + Temporal_Mid__sum_csf + Calcarine__sum_csf + Cerebelum_6__sum_csf + Parietal_Sup__sum_csf + Cerebelum_10__sum_csf + Cerebelum_7b__sum_csf + Frontal_Sup_Medial__sum_csf + Vermis_8__sum_csf + Vermis_4_5__sum_csf + Thalamus__sum_csf + OFCant__sum_csf + Vermis_9__sum_csf + Frontal_Mid_2__sum_csf + Frontal_Inf_Orb_2__sum_csf + Frontal_Inf_Oper__sum_csf + Cingulate_Ant__sum_csf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Visualize Your Design Matrix\n",
    "\n",
    "This is the explanatory variable half of your regression formula\n",
    "_______________________________________________________\n",
    "Create Design Matrix: Use the create_design_matrix method. You can provide a list of formula variables which correspond to column names in your dataframe.\n",
    "\n",
    "- design_matrix = palm.create_design_matrix(formula_vars=[\"var1\", \"var2\", \"var1*var2\"])\n",
    "- To include interaction terms, use * between variables, like \"var1*var2\".\n",
    "- By default, an intercept will be added unless you set intercept=False\n",
    "- **don't explicitly add the 'intercept' column. I'll do it for you.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the design matrix\n",
    "outcome_matrix, design_matrix = cal_palm.define_design_matrix(formula, data_df, add_intercept=True)\n",
    "design_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check multicollinearity in design matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multico. Check\n",
    "from calvin_utils.statistical_utils.statistical_measurements import calculate_vif\n",
    "calculate_vif(design_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Visualize Your Dependent Variable\n",
    "\n",
    "I have generated this for you based on the formula you provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outcome_matrix = outcome_matrix.iloc[:, [0]]\n",
    "outcome_matrix\n",
    "\n",
    "outcome_matrix.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Run the Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression Results Are Displayed Below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This will run a binomial or a multinomial logit dependig on your outcome matrix. \n",
    "- A multinomial logit will display N-1 categories, where N is the number of potential classifications you have. This occurs because everything is set in reference to that class. \n",
    "- So, the reference will either be the first column in your outcomes_matrix, or you can manually set it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(design_matrix)\n",
    "\n",
    "# Train SVM\n",
    "y = outcome_matrix.idxmax(axis=1)\n",
    "svm = SVC(probability=True, kernel='linear', random_state=42)\n",
    "svm.fit(X_scaled, y)\n",
    "\n",
    "# Predict probabilities on training data\n",
    "probabilities = svm.predict_proba(X_scaled)\n",
    "predictions_df = pd.DataFrame(probabilities, columns=svm.classes_)\n",
    "\n",
    "# Output\n",
    "print(predictions_df)\n",
    "\n",
    "# Optional: evaluate performance on training data\n",
    "y_pred = svm.predict(X_scaled)\n",
    "print(classification_report(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.statistical_utils.logistic_regression import LogisticRegression\n",
    "logreg = LogisticRegression(outcome_matrix, design_matrix)\n",
    "results = logreg.run()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Receiver Operating Characteristic\n",
    "- The ROC considers clasisfications acoss ALL POSSIBLE PROBABILITIES, demonstrating what is ultiamtely accomplishable at the best possible threshold\n",
    "\n",
    "- First curve is ROC for classifcation of each class with respect to all other classes\n",
    "- Second Curve (Macro Average) is basically a meta-analytic ROC with equal weight per class.\n",
    "- Third Curve (Micro Average) is basically a meta-analytic ROC with weight proportional to class sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.statistical_utils.classification_statistics import ComprehensiveMulticlassROC\n",
    "evaluator = ComprehensiveMulticlassROC(fitted_model=results, predictions_df=None, observation_df=outcome_matrix, normalization='pred', thresholds=None, out_dir=out_dir+'/train_results')\n",
    "evaluator.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visuialize OVR CIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, bootstrap  = evaluator.bootstrap_ovr_auroc(raw_observations=evaluator.raw_observations, raw_predictions=evaluator.raw_predictions, outcome_matrix_cols=evaluator.outcome_matrix.columns)\n",
    "ComprehensiveMulticlassROC.plot_ovr_auc_with_ci(df, out_dir=out_dir+'/train_auc_per_diagnosis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADVANCED\n",
    "- code specific manual thresholds to intervene upon classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: relate integer (index) to class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# evaluator.relate_index_to_class()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: in a dictionary of the indices (corresponding to class), key in the lambda function to edit the probability. \n",
    "- Code from left to right, giving priority to each method. \n",
    "- Example:\n",
    "```\n",
    ">thresholds = {\n",
    ">            0: lambda probs: 0 if probs[0] > 0.5 else (1 if probs[0] > 0.25 else 2),  # Adjust class_0 predictions\n",
    ">            1: lambda probs: None,  # No threshold adjustment for class_1\n",
    ">            2: lambda probs: None   # No threshold adjustment for class_2\n",
    ">        }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresholds = {\n",
    "#     0: lambda prob: 0,  # Always keep class 0\n",
    "#     1: lambda prob: 1,  # Always keep class 1\n",
    "#     2: lambda prob: 2 if prob[2] > 0.5 else (1 if prob[1] > 0.3 else 0)  # Conditional adjustment for class 2\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Check the effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# from calvin_utils.statistical_utils.classification_statistics import ComprehensiveMulticlassROC\n",
    "# evaluator = ComprehensiveMulticlassROC(fitted_model=results, observation_df=outcome_matrix, normalization='pred', thresholds=thresholds, out_dir=out_dir)\n",
    "# evaluator.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: YOU MUST LOOCV AND VALIDATE IN OUT-OF-SAMPLE DATA.\n",
    "- add thresholds as an argument to any further calls to ComprehensiveMulticlassROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrap the Micro Average AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib\n",
    "# from calvin_utils.statistical_utils.classification_statistics import bootstrap_auc\n",
    "# matplotlib.use('Agg')  # Use a non-interactive backend\n",
    "\n",
    "# mean_auc, lower_ci, upper_ci = bootstrap_auc(outcome_matrix, design_matrix, n_iterations=1000)\n",
    "# print(f'Mean AUC: {mean_auc}, 95% CI: ({lower_ci}, {upper_ci})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permutation Test Two Different Formulas by Comparing Their AUCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 = \"Diagnosis ~ CerebellumCSF + ParietalCSF + MTLCSF + OccipitalCSF + FrontalCSF + temp_ins_csf + SubcortexCSF\"\n",
    "# f2 = \"Diagnosis ~ CerebellumGM + ParietalGM + MTLGM + OccipitalGM + FrontalGM + temp_ins_gm + SubcortexGM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib\n",
    "# matplotlib.use('Agg')  # Use a non-interactive backend\n",
    "# from calvin_utils.statistical_utils.classification_statistics import permute_auc_difference\n",
    "# obs_diff, lower_ci, upper_ci, p_value = permute_auc_difference(data_df, formula1=f1, \n",
    "#                                                                   formula2=f2,\n",
    "#                                                                   cal_palm=cal_palm, n_iterations=1000)\n",
    "# print(f'Observde AUC Difference: {obs_diff}, 95% CI: ({lower_ci}, {upper_ci}), p-value: {p_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 - Visualize the Regression as a Forest Plot\n",
    "- This will probably look poor if you ran a regression without standardizing your data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.statistical_utils.statistical_measurements import MultinomialForestPlot\n",
    "\n",
    "# multinomial_forest = MultinomialForestPlot(model=results, sig_digits=2, out_dir=out_dir+'/forest_plots', table=False)\n",
    "# multinomial_forest.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07 - Generate Partial Dependence Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.statistical_utils.statistical_measurements import PartialDependencePlot\n",
    "# pdp = PartialDependencePlot(formula=formula, data_df=data_df, model=results, design_matrix=design_matrix, outcomes_df=outcome_matrix, data_range=[-1,1], out_dir=out_dir+'/partial_dep_plots', marginal_method='mean', debug=False)\n",
    "# pdp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08 - Visualize the Partial Regression Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.statistical_utils.statistical_measurements import PartialRegressionPlot\n",
    "# partial_plot = PartialRegressionPlot(model=results, design_matrix=design_matrix, out_dir=out_dir+'/partial_regression_plot', palette=None)\n",
    "# partial_plot = partial_plot.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09 - LOOCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from calvin_utils.statistical_utils.logistic_regression import LogisticRegression\n",
    "# from calvin_utils.statistical_utils.classification_statistics import ComprehensiveMulticlassROC\n",
    "# y_true, y_pred, test_prob = LogisticRegression.run_loocv(outcome_matrix, design_matrix)\n",
    "# loocv_evaluator = ComprehensiveMulticlassROC(fitted_model=None, predictions_df=pd.DataFrame(design_matrix, columns=outcome_matrix.columns), observation_df=outcome_matrix, normalization='true', thresholds=None, out_dir=out_dir+'/loocv_results')\n",
    "# loocv_evaluator.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df, bootstrap  = loocv_evaluator.bootstrap_ovr_auroc(raw_observations=loocv_evaluator.raw_observations, raw_predictions=loocv_evaluator.raw_predictions, outcome_matrix_cols=loocv_evaluator.outcome_matrix.columns)\n",
    "# ComprehensiveMulticlassROC.plot_ovr_auc_with_ci(df, out_dir=out_dir+'/loocv_auc_per_diagnosis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 - Predict Unseen Data\n",
    "- Unseen data is expected to be in a held-out CSV with the exact same naming conventions used by the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_csv_path='/Volumes/OneTouch/datasets/adni/metadata/updated_master_list/train_test_splits/test_data_csf.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.permutation_analysis_utils.statsmodels_palm import CalvinStatsmodelsPalm\n",
    "new_palm = CalvinStatsmodelsPalm(input_csv_path=new_csv_path, output_dir=out_dir+'/test_results', sheet=sheet)\n",
    "other_df = new_palm.read_and_display_data()\n",
    "other_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'DX_BASELINE'  # The column you'd like to evaluate\n",
    "condition = 'equal'  # The condition to check ('equal', 'above', 'below', 'not')\n",
    "value = 'MCI' # The value to drop if found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_df, _ = new_palm.drop_rows_based_on_value(column, condition, value)\n",
    "display(other_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the minimum count among the categories in DX_BASELINE\n",
    "category_counts = other_df['DX_BASELINE'].value_counts()\n",
    "min_count = category_counts.min()\n",
    "\n",
    "# Downsample each category to the minimum count\n",
    "other_df_balanced = (\n",
    "    other_df.groupby('DX_BASELINE', group_keys=False)\n",
    "    .apply(lambda x: x.sample(min_count, random_state=42))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Display the balanced dataframe\n",
    "other_df_balanced['DX_BASELINE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "other_outcome_matrix, other_design_matrix = new_palm.define_design_matrix(formula, other_df, add_intercept=True)\n",
    "\n",
    "# Ensure both matrices have the same columns\n",
    "if len(other_outcome_matrix.columns) != len(outcome_matrix.columns):\n",
    "    # Create a zero-filled DataFrame with the same columns as outcome_matrix\n",
    "    zero_df = pd.DataFrame(0, index=other_outcome_matrix.index, columns=outcome_matrix.columns)\n",
    "    \n",
    "    # Fill zero_df with values from other_outcome_matrix where columns exist\n",
    "    common_columns = other_outcome_matrix.columns.intersection(outcome_matrix.columns)\n",
    "    zero_df.loc[:, common_columns] = other_outcome_matrix.loc[:, common_columns]\n",
    "    \n",
    "    other_outcome_matrix = zero_df\n",
    "\n",
    "other_design_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Standardize features\n",
    "if choice=='SVM'\n",
    "    scaler = StandardScaler()\n",
    "    testX_scaled = scaler.fit_transform(other_design_matrix)\n",
    "    probabilities = svm.predict_proba(testX_scaled)\n",
    "    predictions_df = pd.DataFrame(probabilities)\n",
    "elif choice=='Logistic':\n",
    "    # Use the same scaler as for training\n",
    "    testX_scaled = scaler.transform(other_design_matrix)\n",
    "    predictions_df = results.predict(testX_scaled)\n",
    "else:\n",
    "    raise ValueError(\"Invalid choice. Please select either 'SVM' or 'Logistic'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresholds = {\n",
    "#     0: lambda prob: 0 if prob < 0.33 else 1,\n",
    "#     1: lambda prob: 1 if prob > 0.33 else 0\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.statistical_utils.classification_statistics import ComprehensiveMulticlassROC\n",
    "loocv_evaluator = ComprehensiveMulticlassROC(fitted_model=None, predictions_df=predictions_df, observation_df=other_outcome_matrix, normalization='true', thresholds=None, out_dir=out_dir+'/test_results')\n",
    "loocv_evaluator.run() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loocv_evaluator.save_dataframes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get One Vs. All Confidence Intervals on AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, bootstrap = ComprehensiveMulticlassROC.bootstrap_ovr_auroc(raw_observations=loocv_evaluator.raw_observations, raw_predictions=loocv_evaluator.raw_predictions, outcome_matrix_cols=loocv_evaluator.outcome_matrix.columns)\n",
    "ComprehensiveMulticlassROC.plot_ovr_auc_with_ci(df, out_dir=out_dir+'/test_auc_per_diagnosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Confidence Intervals on Sensitivity, Specificity, NPV, PPV, and Accuracy for Each Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.statistical_utils.classification_statistics import calculate_youden_and_metrics, save_dfs\n",
    "dfs, youden_dict = calculate_youden_and_metrics(raw_observations=loocv_evaluator.raw_observations, \n",
    "                                                raw_predictions=loocv_evaluator.raw_predictions, \n",
    "                                                outcome_matrix_cols=loocv_evaluator.outcome_matrix.columns,\n",
    "                                                out_dir=out_dir+'/metrics_per_diagnosis')\n",
    "save_dfs(dfs, out_dir=out_dir+'/metrics_per_diagnosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ComprehensiveMulticlassROC.generate_all_plots(dfs, out_dir=out_dir+'/metrics_per_diagnosis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Overall Micro Average AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loocv_evaluator.get_micro_auc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all\n",
    "\n",
    "-Calvin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_3.7.7_nimlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
