{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '/Users/cu135/Partners HealthCare Dropbox/Calvin Howard/studies/ccm_memory/results/control_analyses/cmn_vs_others'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your CSV file containing NIFTI paths\n",
    "input_csv_path = '/Users/cu135/Partners HealthCare Dropbox/Calvin Howard/studies/ccm_memory/metadata/comparison_of_maps/damage_to_target_correlated_to_memory_paired_targets.csv'\n",
    "sheet=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 - Import CSV with All Data\n",
    "**The CSV is expected to be in this format**\n",
    "- ID and absolute paths to niftis are critical\n",
    "```\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "| ID  | Nifti_File_Path            | Covariate_1  | Covariate_2  | Covariate_3  |\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "| 1   | /path/to/file1.nii.gz      | 0.5          | 1.2          | 3.4          |\n",
    "| 2   | /path/to/file2.nii.gz      | 0.7          | 1.4          | 3.1          |\n",
    "| 3   | /path/to/file3.nii.gz      | 0.6          | 1.5          | 3.5          |\n",
    "| 4   | /path/to/file4.nii.gz      | 0.9          | 1.1          | 3.2          |\n",
    "| ... | ...                        | ...          | ...          | ...          |\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Relevant Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>Lesion_Specific</th>\n",
       "      <th>DBS_Specific</th>\n",
       "      <th>TMS_Specific</th>\n",
       "      <th>Convergent_Memory_Map_Lesions</th>\n",
       "      <th>Convergent_Memory_Map_DBS</th>\n",
       "      <th>Convergent_Memory_Map_TMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx  Lesion_Specific  DBS_Specific  TMS_Specific  \\\n",
       "0    1            -0.12          0.04          0.27   \n",
       "1    2            -0.23          0.08          0.15   \n",
       "2    3            -0.22          0.06          0.25   \n",
       "3    4            -0.16          0.06          0.07   \n",
       "\n",
       "   Convergent_Memory_Map_Lesions  Convergent_Memory_Map_DBS  \\\n",
       "0                           0.15                      -0.30   \n",
       "1                           0.30                      -0.16   \n",
       "2                           0.28                      -0.11   \n",
       "3                           0.19                      -0.05   \n",
       "\n",
       "   Convergent_Memory_Map_TMS  \n",
       "0                      -0.27  \n",
       "1                      -0.39  \n",
       "2                      -0.39  \n",
       "3                       0.12  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from calvin_utils.permutation_analysis_utils.statsmodels_palm import CalvinStatsmodelsPalm\n",
    "# Instantiate the PalmPrepararation class. Enter value for sheet if you are using an Excel spreadsheet.\n",
    "cal_palm = CalvinStatsmodelsPalm(input_csv_path=input_csv_path, output_dir=out_dir, sheet=sheet)\n",
    "# Call the process_nifti_paths method\n",
    "data_df = cal_palm.read_and_display_data()\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handle NANs**\n",
    "- Set drop_nans=True is you would like to remove NaNs from data\n",
    "- Provide a column name or a list of column names to remove NaNs from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['idx', 'Lesion_Specific', 'DBS_Specific', 'TMS_Specific',\n",
       "       'Convergent_Memory_Map_Lesions', 'Convergent_Memory_Map_DBS',\n",
       "       'Convergent_Memory_Map_TMS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['Z_Scored_Percent_Cognitive_Improvement', 'Subiculum_Group_By_24', 'City', 'Age_Group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = cal_palm.drop_nans_from_columns(columns_to_drop_from=drop_list)\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop Row Based on Value of Column**\n",
    "\n",
    "Define the column, condition, and value for dropping rows\n",
    "- column = 'your_column_name'\n",
    "- condition = 'above'  # Options: 'equal', 'above', 'below'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the parameters for dropping rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'Cohort'  # The column you'd like to evaluate\n",
    "condition = 'equal'  # Thecondition to check ('equal', 'above', 'below', 'not')\n",
    "value = 3  # The value to compare against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df, other_df = cal_palm.drop_rows_based_on_value(column, condition, value)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Transformations**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A) Standardize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove anything you don't want to standardize\n",
    "cols_not_to_standardize = ['Z_Scored_Percent_Cognitive_Improvement', 'Z_Scored_Subiculum_Connectivity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = cal_palm.standardize_columns(cols_not_to_standardize)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B) Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Normalize each factor using Min-Max scaling\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "for col in data_df.columns:\n",
    "    try:\n",
    "        data_df[col] = scaler.fit_transform(data_df[[col]])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recompose a new Dataframe if Needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add columns based on condition\n",
    "import numpy as np\n",
    "def add_columns_based_on_condition(df, condition_col, condition, suffix):\n",
    "    for col in df.columns:\n",
    "        if col != condition_col:  # Skip the condition column itself\n",
    "            # Create a new column name by appending the suffix\n",
    "            new_col_name = f\"{col}{suffix}\"\n",
    "            \n",
    "            # Apply condition; set value in new column if condition is met, otherwise set to NaN\n",
    "            df[new_col_name] = df.apply(lambda x: x[col] if x[condition_col] != condition else np.nan, axis=1)\n",
    "    \n",
    "    # Optional: You can drop the original columns if they are no longer needed\n",
    "    # df.drop(columns=df.columns.difference([condition_col] + df.filter(like=suffix).columns.tolist()), inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to your DataFrame\n",
    "data_df = add_columns_based_on_condition(data_df, condition_col='Disease_Status', condition='Normal', suffix='_c')\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pivot DF If needed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivot_dataframe(df, concat_col, category_col):\n",
    "    # Create a new DataFrame where each unique category becomes a column\n",
    "    # and the values from concat_col are listed under these category columns\n",
    "    # First, ensure that the index is reset for the DataFrame to avoid issues during pivoting\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Create a new DataFrame where each row will have the category as a column and the corresponding values\n",
    "    # from concat_col under that category\n",
    "    pivoted_df = df.pivot(columns=category_col, values=concat_col)\n",
    "    \n",
    "    return pivoted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pivot_dataframe(data_df, 'Z_Scored_Percent_Cognitive_Improvement_residual','Age_Group')\n",
    "pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regress out a Covariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.statistical_utils.regression_utils import RegressOutCovariates\n",
    "# use this code block to regress out covariates. Generally better to just include as covariates in a model..\n",
    "dependent_variable_list = ['Z_Scored_Percent_Cognitive_Improvement']\n",
    "regressors = ['Subiculum_Connectivity_T_Redone']\n",
    "\n",
    "data_df, adjusted_dep_vars_list = RegressOutCovariates.run(df=data_df, dependent_variable_list=dependent_variable_list, covariates_list=regressors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.79 / 20**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Total'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.pairplot(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_axis = 'Randomization_Group'\n",
    "x_axis = 'Age'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.scatterplot(data=data_df, x=x_axis, y=y_axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Data in 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def generate_scatterplot(dataframe, data_dict, correlation, palette, out_dir):\n",
    "    \"\"\"\n",
    "    Generates a 3D scatter plot from the given DataFrame and saves it to the specified directory.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe: pandas DataFrame containing the data.\n",
    "    - data_dict: Dictionary with one key-value pair, where the key is the dependent variable \n",
    "                 and the value is a list of independent variables (length should be 2 for 3D scatter).\n",
    "    - x_label, y_label, z_label: Labels for the x, y, and z axes.\n",
    "    - correlation: Whether to display correlation information on the plot (True/False).\n",
    "    - palette: Color palette for the plot.\n",
    "    - out_dir: Directory path where the plot image will be saved.\n",
    "    \"\"\"\n",
    "    dependent_var = list(data_dict.keys())[0]\n",
    "    independent_vars = data_dict[dependent_var]\n",
    "\n",
    "    if len(independent_vars) != 2:\n",
    "        raise ValueError(\"Independent variable list must contain exactly two elements for 3D scatter plot.\")\n",
    "\n",
    "    fig = px.scatter_3d(dataframe, x=independent_vars[0], y=independent_vars[1], z=dependent_var,\n",
    "                        color=dependent_var, color_continuous_scale=palette)\n",
    "\n",
    "    # Set the labels\n",
    "    fig.update_layout(scene=dict(\n",
    "        xaxis_title=independent_vars[0],\n",
    "        yaxis_title=independent_vars[1],\n",
    "        zaxis_title=dependent_var\n",
    "    ))\n",
    "\n",
    "    # Optionally, add correlation info as annotation\n",
    "    if correlation:\n",
    "        # Compute and display correlation (requires additional implementation)\n",
    "        pass\n",
    "\n",
    "    # Save the plot to the output directory\n",
    "    fig.write_image(f\"{out_dir}/3d_scatter_plot.png\")\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {'Cognitive_Status_Code': ['Convolutional_Neural_Network']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "plot = generate_scatterplot(dataframe=data_df, \n",
    "                            data_dict=data_dict,\n",
    "                            correlation=True,\n",
    "                            palette='Reds',\n",
    "                            out_dir=out_dir)\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data_df[(data_df['Cognitive_Status_Code'] == 0) & (data_df['Convolutional_Neural_Network'] == 8)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Distributions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input columns to test like this:\n",
    "- group1_col_name = 'Alzheimer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['idx', 'Lesion_Specific', 'DBS_Specific', 'TMS_Specific',\n",
       "       'Convergent_Memory_Map_Lesions', 'Convergent_Memory_Map_DBS',\n",
       "       'Convergent_Memory_Map_TMS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>Lesion_Specific</th>\n",
       "      <th>DBS_Specific</th>\n",
       "      <th>TMS_Specific</th>\n",
       "      <th>Convergent_Memory_Map_Lesions</th>\n",
       "      <th>Convergent_Memory_Map_DBS</th>\n",
       "      <th>Convergent_Memory_Map_TMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx  Lesion_Specific  DBS_Specific  TMS_Specific  \\\n",
       "0  1.0             0.12          0.04          0.27   \n",
       "1  2.0             0.23          0.08          0.15   \n",
       "2  3.0             0.22          0.06          0.25   \n",
       "3  4.0             0.16          0.06          0.07   \n",
       "\n",
       "   Convergent_Memory_Map_Lesions  Convergent_Memory_Map_DBS  \\\n",
       "0                           0.15                       0.30   \n",
       "1                           0.30                       0.16   \n",
       "2                           0.28                       0.11   \n",
       "3                           0.19                       0.05   \n",
       "\n",
       "   Convergent_Memory_Map_TMS  \n",
       "0                       0.27  \n",
       "1                       0.39  \n",
       "2                       0.39  \n",
       "3                       0.12  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in data_df.columns:\n",
    "    data_df[col] = (data_df[col]**2)**.5\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "group1_col_name = 'Lesion_Specific'\n",
    "group2_col_name = 'Convergent_Memory_Map_Lesions'\n",
    "x_label = 'Network'\n",
    "y_label = 'R-Squared'\n",
    "test_type = 't-test_ind'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>Lesion_Specific</th>\n",
       "      <th>DBS_Specific</th>\n",
       "      <th>TMS_Specific</th>\n",
       "      <th>Convergent_Memory_Map_Lesions</th>\n",
       "      <th>Convergent_Memory_Map_DBS</th>\n",
       "      <th>Convergent_Memory_Map_TMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx  Lesion_Specific  DBS_Specific  TMS_Specific  \\\n",
       "0  1.0             0.12          0.04          0.27   \n",
       "1  2.0             0.23          0.08          0.15   \n",
       "2  3.0             0.22          0.06          0.25   \n",
       "3  4.0             0.16          0.06          0.07   \n",
       "\n",
       "   Convergent_Memory_Map_Lesions  Convergent_Memory_Map_DBS  \\\n",
       "0                           0.15                       0.30   \n",
       "1                           0.30                       0.16   \n",
       "2                           0.28                       0.11   \n",
       "3                           0.19                       0.05   \n",
       "\n",
       "   Convergent_Memory_Map_TMS  \n",
       "0                       0.27  \n",
       "1                       0.39  \n",
       "2                       0.39  \n",
       "3                       0.12  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved to:  /Users/cu135/Partners HealthCare Dropbox/Calvin Howard/studies/ccm_memory/results/control_analyses/cmn_vs_others/distribution_figures/validation/Network_t-test_ind_R-Squared\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaoAAAEiCAYAAACobJZDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAhhElEQVR4nO3dC7RdVX3v8d/PUGKEIq+USxOeJi1S0aAHtOWKisFGrYEqCigVvFy5WEmjXC0gHeilYhW0GCPaoPJSBJFbatRgtAhaFSQPQiAB5BheOaJEARETA4F/x/9kbsZic57h7LPXOfv7GWOdvdZcr7nOXnv/15xr7rkcEQIAoK6e0+4MAAAwEAIVAKDWCFQAgFojUAEAao1ABQCota3UAXbeeefYc889250NAMAAli1b9uuImNyRgSqD1NKlS9udDQDAAGzf01c6VX8AgFojUAEAao1ABQCoNQIVAKDWCFQAgFojUAEAOjdQ2Z5l+w7b3bZP7WP+ibZvsb3C9o9s71uZd1pZL9f/66FuEwAwvrQsUNmeIOk8Sa+XlAHo6GogKr4aEftFxAxJZ0v617JuLneUpL+QNEvS53J7Q9wmAGAcaeUPfg+U1B0Ra3LC9uWSDpO0urFARDxSWX6bTCrjudzlEbFR0l1Zeirb02DbBDB2zZ8/X93d+XGvh56ent7XKVOmqC6mTZumOXPmqJO0MlDlO3tfZXqtpJc3L2T7vZJOlrS1pEMq697QtG7jTBl0m2W7J0jKQbvvvvtIHA+ADrNhw4Z2ZwF16EIpIrIq7zzbb5f0T5KOHaHtni8pB3V1dfEYY2AMqFtJYe7cub2v8+bNa3dWOlorA1WWmXerTE8taf3JarzPD2Hd4WwTADDGtbLV3xJJ023vZXvr0jhiYXUB29Mrk2+UdGcZz+WOsj0x18/tSLpxKNsEAIwvLStRRcQm2ydJWiwpW+tdEBGrbJ8paWlEZIA5yfZMSY9LeqhR7VeWu6I0ktgk6b0R8UTO62ubrToGAMA4v0cVEYskLWpKO6MyPneAdc+SdNZQtgkAGL/omQIAUGsEKgBArRGoAAC1RqACANQagQoAUGsEKgBArRGoAAC1RqACANQagQoAUGsEKgBArRGoAAC1RqACANRa2x+cCKA96vbY9zpq/H8aD1DEM02bNq3lD7wkUAEd/CV856qbtPu2vU/QQR+2fnxzpdPGe5a2Oyu1dO+j+bSl1iNQAR0sg9SHXvpIu7OBMepjy7cblf1wjwoAUGsEKgBArRGoAAC1RqACANQagQoAUGsEKgBArRGoAACdG6hsz7J9h+1u26f2Mf9k26ttr7R9je09SvprbK+oDH+wfXiZd5HtuyrzZrTyGAAA7dWyH/zazp8snyfpUElrJS2xvTAiVlcWu0lSV0Sst/0eSWdLOjIirpXUG4Bs75g/opf03cp6H4yIK1uVdwBAZ5SoDswAExFrIuIxSZdLOqy6QAakDFJl8gZJU/vYzhGSrq4sBwDoIK0MVFMk3VeZXlvS+nN8BqQ+0o+SdFlT2lmluvBc2xP72pjtE2wvzWHdunVbdgQAgLarRWMK28dkFaCkc5rSd5W0n6TFleTTJO0j6QBJWS14Sl/bjIjzIyKrFbsmT57c8mMAAIy9QNUjabfK9NSS9jS2Z0o6XdLsiNjYNPttkq6KiMcbCRFxf2yWy15YqhgBAONUKwPVEknTbe9le+tShbewuoDt/SUtKEHqgT62cXRztV8pZeWrJWVLwFtbeAwAgPHa6i8iNtk+qVTbZQvACyJile0zJS2NiIWlqm9bSV/fHHd0b0TMzhHbe5YS2Q+aNn2p7azLyxVWSDqxVccAAGi/lj6PKiIWSVrUlHZGZXzmAOve3Vfji4g4pAVZBQDUVC0aUwAA0B8CFQCg1ghUAIBaI1ABAGqNQAUAqDUCFQCg1ghUAIBaI1ABAGqNQAUAqDUCFQCg1ghUAIBaI1ABAGqNQAUAqDUCFQCg1ghUAIBaI1ABAGqNQAUAqDUCFQCg1ghUAIBaI1ABAGqNQAUAqDUCFQCgcwOV7Vm277DdbfvUPuafbHu17ZW2r7G9R2XeE7ZXlGFhJX0v2z8t2/ya7a1beQwAgHEaqGxPkHSepNdL2lfS0bbzteomSV0R8WJJV0o6uzJvQ0TMKMPsSvonJJ0bEdMkPSTp+FYdAwBgfJeoDpTUHRFrIuIxSZdLOqy6QERcGxHry+QNkqYOtEHblnRICWrpYkmHt+wIAADjOlBNkXRfZXptSetPloyurkw/1/ZS2zfYbgSjnSQ9HBGbBtum7RPK+kvXrVv37I8GANAWW6kGbB+TVYCSXlVJ3iMiemzvLen7tm+R9NuhbjMizpeUg7q6uqIlGQcAjOkSVY+k3SrTU0va09ieKel0SbMjYmMjPYNUeV0j6TpJ+0v6jaTtbW810DYBAONHKwPVEknTSyu9bJl3lKSnWu8l2xl8FpQg9UAlfQfbE8v4zpIOkrQ6IrJkdK2kI8qix0r6RguPAQAwXgNVuY90kqTFkm6TdEVErLJ9pu1GK75zJG0r6etNzdBfKCnvL91cAtPHI2J1mXeKpGzW3l3uWX2pVccAABjn96giYpGkRU1pZ1TGZ/az3k8k7dfPvDWlRSEAoAPQMwUAoNYIVACAWiNQAQBqjUAFAKg1AhUAoNYIVACAWiNQAQBqjUAFAKg1AhUAoNYIVACAWiNQAQBqjUAFAKi1Wjw4EcDo6+np0e9/N0EfW75du7OCMeqe303QNj2tfyQgJSoAQK1RogI61JQpU7Rx0/360EsfaXdWMEZ9bPl2mjhlSsv3Q4kKAFBrBCoAQK0RqAAAtcY9qjFq/vz56u7uVt1akTXufdTFtGnTNGfOnHZnA8CzQKDCiNmwYUO7swBgHCJQjVF1LCXMnTu393XevHntzgqATglUtr8pKfqbHxGzW5IrAACG2Jjik5I+JemurNmR9IUyPCrp54Osm4Fulu07bHfbPrWP+SfbXm17pe1rbO9R0mfYvt72qjLvyMo6F9m+y/aKMswYLB8AgHFaooqIH+Sr7U9FRFdl1jdtLx1oXdsTJJ0n6VBJayUtsb0wIlZXFrtJUldErLf9HklnS8qgtF7SOyPiTtt/KmmZ7cUR8XBZ74MRceWzOXAAwPhqnr6N7b0bE7b3yrRB1jlQUndErImIxyRdLumw6gIRcW0GqTJ5g6SpJf1nGaTK+C8kPSBp8jCPDQDQQYHq/ZKus51DlrKulfS+QdbJNsr3VaazVDVQu+XjJV3dnGg7A97WTVWNZ5UqwXNtT+xrY7ZPyFJfDuvWrRv0AAEAY7jVX0R8x/Z0SfuUpNsjYuNIZcL2MVkFKOlVTem7SvqypGMj4smSfJqkX5bgdb6kUySd2Ueec14O6urq6rdBCABgHAQq28+TdLKkPSLi3Rm0bP95RHxrgNXy15+7VaazWu8Z/cHbninp9AxS1eBnO5898O2cFxFZLdgrIu4voxttXyjpA+rQH9jWTeP/02imjmfiB8hA635HlQFhmaS/LNMZcL4uaaBAtUTS9HI/K5c/StLbqwvY3l/SAkmzIuKBSnqWlq6SdElzo4ksZWWwsm1Jh0u6VaP0Jbzi1tv0xPN2HI3djUnPeWxzwXXZml+1Oyu1NGH9g+3OAjCuA9ULIuJI20fnRGmll4GiXxGxyfZJkhbnZ1TSBRGRzc2zmm5pRCyUdI6kbTPolc3dW36b9TZJB0vayfZxZZPHRcQKSZfazoYVuUJOn6hRkkFqwz5vGK3dYZyZdPuidmcBGNeB6jHbkxo//rX9gqx6G2yliMhP5tM+nRFxRmV8Zj/rfUXSV/qZd8gQ8wwA6KBA9WFJ38l7TrYvlXRQlnBanDcAAAYPVLazCfsOkt4s6RWlym1uRPx6dLIIAOhkgwaqbBZu+x8j4orSCg8AgNr94Pc/bX/Adlb97dgYWpw3AACGfI+q0Snseytp2bDiqW6VAABoZ88U+VsoAADq++BE2y+StK+k5zbSIuKSluUMAIBhdKGUzdNfXQJV/i7q9ZJ+lD1HtD6LAIBONtTGFEdIem12BhsR75L0EknPb3HeAAAYcqDaUHov31Q6i32gqcNZAADaeo8qn+u0fXkM/bLyKPrrW5MlAACG3+rv78vov9nOrpS2i4iVQ1kXAIDRaExxcF9pEfHDZ7V3AABGqOrvg5XxbJ5+YKkCpCdzAEAtqv7eVJ3OrpQkfbpluQIAYJit/pqtlfTCLVwXAIARv0c1v/HQxBLcZkhaPvTdAADQ4ubplfFNki6LiB9v4T4BABjxe1QXD32TAACMftXfLZWqv6fN2hzH4sUjmCcAAIZd9Xd1ef1yeX1Hef38ENcHAKClgerQiNi/Mn2q7eURceqW7RYAgJFtnm7bB1Um/moo69qeZfsO2922nxHUbJ9se7Xtlbavsb1HZd6xtu8sw7GV9JdlVWTZ5mcyY0M8BgDAOA5Ux0v6nO27bd+T45L+10Ar2J4g6bzy7Kp8jtXRtvO16iZJXeUe15WSzi7r7igpn4H18tILxodt71Cpbny3pOllmLVFRw4AGD+BKiKWRUQ+gyqHF0fEjIgY7HdUGWC6I2JNRDwm6XJJhzVt99qIWF8mb5A0tYz/taTvRcSDEfFQjmdAsr1r6RD3hmzBUR7cePgWHTkAYOwHKttvqlbHSZor6Ye2F9rea5BtT5F0X1NvFpk2UKnt6kHWnVLGB92m7RNs5+NJlq5bt26QrAIAxmqJ6ixJvd/ytv9G0jGlym9hPvJjpDJhO7fbJemckdpmRJwfEVmt2DV58uSR2iwAoGaBKipVc2+W9KVSDfhFSYN9+/c0PQV4akl7GtszJZ0uaXZEbBxk3Z5K9WC/2wQAdE6gykZ129rO5V4r6Zqmx30MZEk2dsgqQttbSzqqlMSqG88m7wtKkMrH2zcslvS6bEBRGlG8LtMi4n5Jj9h+RWnt905J3xj+YQMAxsvvqPJRHisyOEi6LSKWVgJMBo1+RcQm2yeVoJMtAC+IiFW2z8y+AyNiYanq21bS10sr83sjIoPWg7b/uQS7dGamlfF82vBFkiaVe1qN+1oAgE4LVBFxge0MNH8i6ebKrF9KetdgG4+IRZIWNaWdURmfOdC+M7j1kZ7B8kWD7RsA0CHN0yOiJyJuiognc9r2R7IKLiLuHZUcAgA62pY8OHF2C/IBAMCIBSq6LAIA1DpQZV97z7Hd6EEdAIC29Uyxne3TbH/WdjYXd2l1t0bS21qXLQAAhtY8PZ8/lX3tXS/pf0v6UKn6Ozwistl6x+jp6dGE9b/VpNuf1ogRGLIJ63+jnp5N7c4GMO4C1d4RsV+O2P5i+e3U7hHxh9HJHgCg0w0WqB5vjETEE7bXdmqQmjJlin65cStt2OcN7c4KxqgsjU+Zsku7swGMu0D1EtvZK4VKld+kMu3SD+B2o5BHAEAHG6xniuz6CACAMdU8HQCAUUOgAgDUGoEKAFBrBCoAQK0RqAAAtUagAgDUGoEKAFBrBCoAwJjumQLAOHbvoxP0seV0MNOfX63ffC2/y/N6H3COPs6f6Wo9AhXQoaZNm9buLNTeY93dva8T9+B/1Zfpo3QeEaiADjVnzpx2Z6H25s6d2/s6b968dmelo3GPCgDQuYHK9izbd9jutn1qH/MPtr3c9ibbR1TSX2N7RWX4g+3Dy7yLbN9VmTejlccAAGivllX92c6e18+TdKiktZKW2F4YEasri90r6ThJH6iuGxHXSuoNQLZ3lJQVxd+tLPLBiLiyVXkHANRHK+9RHZgBJiLW5ITtyyUdJumpQBURd5d5AzWpyZLW1RGxvoV5BQB0YNXfFEn3VabXlrThOkrSZU1pZ9leaftc2xP7Wsn2CbaX5rBu3bot2C0AoA5q3ZjC9q6S9pO0uJJ8mqR9JB0gKasFT+lr3Yg4PyK6cpg8efLoZRoAMGYCVY+k3SrTU0vacLxN0lUR8XgjISLuj802SrqwVDECAMapVgaqJfl7MNt72d66VOEtHOY2jm6u9iulrHy1pGwJeOuI5hoA0BmBKiI2STqpVNvdJumKiFhl+0zbs3MZ2wfYzntXb5W0wPaqxvq29ywlsh80bfpS27dIymFnSR9t1TEAANqvpT1TRMQiSYua0s6ojC8pVYJ9rXt3X40vIuKQFmUXAFBDtW5MAQAAgQoAUGsEKgBArRGoAAC1RqACANQagQoAUGsEKgBArRGoAAC1RqACANQagQoAUGsEKgBArRGoAAC1RqACANQagQoAUGsEKgBArRGoAAC1RqACANQagQoAUGsEKgBArRGoAAC1RqACANQagQoA0LmByvYs23fY7rZ9ah/zD7a93PYm20c0zXvC9ooyLKyk72X7p2WbX7O9dSuPAQAwTgOV7QmSzpP0ekn7Sjradr5W3SvpOElf7WMTGyJiRhlmV9I/IenciJgm6SFJx7fqGAAA7bdVC7d9oKTuiFiTE7Yvl3SYpNWNBSLi7jLvyaFs0LYlHSLp7SXpYkkfkfR5jYIJ6x/UpNsXjcauxqTn/OGR3tcnn7tdu7NSS3n+SLu0Oxu1Nn/+fHV3d6suGnmZO3eu6mLatGmaM2eOOkkrA9UUSfdVptdKevkw1n+u7aWSNkn6eET8h6SdJD0cEZsq28z9PIPtEyTloN13310jcXJgYN3dv+t9nbY3X8Z924XzaIyZNGlSu7OAFgeqZ2uPiOixvbek79u+RdJvh7pyRJwvKQd1dXXFs81Mp13BbInGVee8efPanRWMUXzOMNqNKXok7VaZnlrShiSDVHnNqsPrJO0v6TeStre91ZZsEwAw9rQyUC2RNL200suWeUdJeqr13kBs72B7YhnfWdJBeW8rIrJkdK2kRgvBYyV9o4XHAAAYr4Gq3Ec6SdJiSbdJuiIiVtk+03ZvKz7bB9jO+0xvlbTA9qqy+gslLbV9cwlMeY+q0QjjFEknZ/P0cs/qS606BgDAOL9HFRHZRO5pzeQi4ozK+JJSfde83k8k7dfPNteUFoUAgA5AzxQAgFojUAEAao1ABQCoNQIVAKDWCFQAgFojUAEAao1ABQCoNQIVAKDWCFQAgFojUAEAao1ABQCoNQIVAKDWCFQAgFojUAEAao1ABQCoNQIVAKDWCFQAgFojUAEAao1ABQCoNQIVAKDWCFQAgFojUAEAOjdQ2Z5l+w7b3bZP7WP+wbaX295k+4hK+gzb19teZXul7SMr8y6yfZftFWWY0cpjAAC011at2rDtCZLOk3SopLWSltheGBGrK4vdK+k4SR9oWn29pHdGxJ22/1TSMtuLI+LhMv+DEXFlq/IOAOiAQCXpQEndEbEmJ2xfLukwSU8Fqoi4u8x7srpiRPysMv4L2w9ImiypEagAAB2ilVV/UyTdV5leW9KGxXYGvK0l/bySfFapEjzX9sR+1jvB9tIc1q1bt0UHAABov1o3prC9q6QvS3pXRDRKXadJ2kfSAZJ2lHRKX+tGxPkR0ZXD5MlZGAMAjEWtDFQ9knarTE8taUNieztJ35Z0ekTc0EiPiPtjs42SLixVjACAcaqVgWqJpOm297KdVXdHSVo4lBXL8ldJuqS50UQpZeWrJR0u6dZWHQAAYBwHqojYJOkkSYsl3SbpiojI5uZn2p6dy9g+wHbeu3qrpAXZHL2s/jZJB2eLwD6aoV9q+xZJOews6aOtOgYAQPs5IjTedXV1xdKlSzWezJ8/X93d3aqTRn6mTZumusi8zJkzp93ZADAEtpdlu4LRbJ6ODjNp0qR2ZwHAOESgGqMoJQDoFLVung4AAIEKAFBrBCoAQK0RqAAAtUagAgDUGoEKAFBrBCoAQK0RqAAAtUagAgDUWkf09Wc7n5x4T7vz0SGyo+BftzsTwAjinB49e0TE5I4MVBg9+UTlvjqVBMYqzun2o+oPAFBrBCoAQK0RqDDSzm93BoARxjndZtyjAgDUGiUqAECtEagAALVGoAIA1BqBaoyy/eizXL/L9mdGLke92zzd9irbK22vsP3yEd7+Itvbl/F/sH2b7Uttz7Z96kjuayyz/T9sX27757aXlf/bn2kMs/2hISwTtr9Smd4qf+xv+1uqKdsX2V5v+48raZ8ux7LzCO/niJH6/I22rdqxU7RfRCyVlMOIsP2Xkv5G0ksjYmP5kG2tERQRb6hM/r2kmRGxtkwvHMl9jVW2LekqSRdHxFEl7SWSdpH0s1HMx4SIeGIEN5mB6mODLPN7SS+yPSkiNkg6VFKPRlEGx4jYNMzVuiUdJukrtrPwcMho53sLPn+jihLVOGL7Bba/U66i/8v2PiX9rbZvtX2z7R+WtFc3rjRt72j7P0pJ6AbbLy7pH7F9ge3rbK/JUswAu981u5nJIJUTEZHjvyjbudv22bZvsX2j7WklfbLt/297SRkOKunb2r6wLJ95ektlOzvb/jdJe0u62vb7bR9n+7NlmV1sX1WONYe/Umd5jaTHIyL/R70i4mZJP7J9TjkP8v96ZOU8yPf3Stu3lxJqmmX7641tNJ0vr7N9ve3luUy+X5X35xOZLinPuTeUbeb5+JnK+tuU8yrPhZtsH1bS833893IO35nnTEn/uKRJpZR+6SDHv0jSG8v40ZIuqxzDQPvN8/975RhOsn1yWSY/DzuW5WaU6ZXlHNuhpF9XSkF54Ze1CnfZ/qMyb7vqdD8ul9T7fkh6taQfS3oq2Hlz3paV2ooTKumP2j63pF+Tn6ehnCCV9SeUc2JJOab/U9J3ze+J8v/O8+WVlfe3t5RX/j+3luF9JW3PUsvxhZKn7+ZFQ6UGZHXZTx7v8GTzdIaxN0h6tI+0ayRNL+NZ7fb9Mn6LpCllfPvymh+Ib5Xx+ZI+XMbzam5FGf+IpJ9Imlj6O/uNpD/qJz/5ZbWiXLV/TtKrKvPuzg9wGX9nZb9flfQ/y/jukm4r45+Q9OnK+jtUtrNzH+PHSfpsGf+apPeV8QmSnt9h50VeTJzbR3oG+++V/0mWru4tFxd5HvxW0tRy4Xp9vieltiWX2aas/3lJx5Tz4IeV9FMknVF5T/6xjD9X0n2S9irTl1Xe9ywZHdM4H8s5s015H9fke1bWz/45d+vvfO/rMyEpL7KuLOuvaDrPB9pvlmqy+m1y+X+cWJY7t3I+rWyc15LObJyjkq7Lc76SjwslHV7GM7B8aoA8XyQpq+RuyPNc0hdyH03n947lNb/0b5W0U5nOP+8o42c0PgMD7acpLfP2T2U8P+MZaPeS9H8rn9c8X/64+pmT9LLynbJN+dyvkrS/pD1LgJ1Rlr+i8v/Oi9aJjf/9cM9rSlTjRLmqzdJDXuHmB3RB+SJSuULLOup3lxOvWX4xfTlHIuL7+UHIK8Ey79tZSsoSkqQHypfcM0TEo+UEzpM/OwH+Wl6pVha5rPKa1YRpZn64Sn6z6m67chyZfl5l2w8N419xSPlSzfWeiIj80sHm9/iy8j/5laQfSDqgzLsxq1Aj4sny5b5nqb76jqQ3ZXVWKaV8Q9IrJO2b51R5347NjkQr+8kLhZSl+TURcVeZfqpkI+l1kk4t619XgkpeqKRr8j2LiD9IWt207UFFxMryhXl0KV1piPu9NiJ+FxF57uY5882Snl/IWVJ4fvmCzf9buljSwX0cd/qipHeV8XeVwDWYf5d0VLnA/K+mef+QtQMlmO2WF6Ml/cnKfr9S3uPhyP/HO8v/46f5uS/bXpL5zhoVSfvl/6VpvdzPVRHx+/K5z7z3lrok3RURub20rLwXKd+XLK3nxc5wq0a5RzWO5EXHwxExo3lGRJxYGjbkl01WIWRAGareqrziiYHOmXJPIr8AsirklvIldlFjdnXRSp5fUb6UnrL5Ngu2UF7dDvemeX/vcVbRnCTpwbzazi+scg/sexGRgaC/+0SDyW28JSLueFri5nN0yOfbAPKi55OlNLXTFuz3ycr0k0PMw1PHHREZxDO45f7zXl2WggbztfLFnvcWn2x8Bso2ZubFXURko4tGgO3LcHtvyJ3MiYjFz5hhH1y+L/IC918j4pIhbrP5/eut+ivbym2+qVSPZgAccsCiRDVORMQjeTWT96NyutxneEnj3lVE/DQisnpgXbkqq8oruHdUPhi/LtsbMtt/brtxpZdmND1a5cjKa1Yvpe/mB6WyjUaQzSqq91bSe+8FDFFWf76nUgefV8KdJEvEE5vuZWR12MP5vy//k8nlS+PGQbaVpYeXSsqSeOO+Ql7VH1S5z7hNPy0KMxjsnV/YTe9/yi/GOSXo5Tay2mgwjw9yn6fqAkn/LyLyYknPcr+9Ssn8ocb9Gkl/V/4//bmkVG1fOMTt52fl9FJtXvX83G8JUvuUEm31+7txUfL2vA+p4cn/x3sq99P+rLyfWYr9VUR8oZQO8xxo/r443PbzcnlJf9tHKfAppYFIVuFeW6qK85h672sOFYFq7MqTZG1lOLkEm+NLNUFeWffeLJZ0TrmBfmu555Tzq7KI/7K80Snp46UkNFx54l3cuGFaqodyuw07lPS5kt5f0vJ+Sle5wZrVPCeW9I+W5XsbgJQGAkOV239NKdEtK/noGLH5JkB+ccwszdPzPPiX8qWZ//+bSzDLe0m/HGRbeUWcDSBeX14zLS90skr3svJ+5kXHPn2su6G0zOxt3CMpq48a1bD/nPc6Mz8lfzk9lP72Vg6hMYVKNWZfP73Ykv1WHVs+S3ncM8p9qv5kPndoqvIcLN8LIuLnTcnfyRJdNlIon828UKiW4g4sn+tDBslPWlD5vri+BKH83C0v21hQSo95sZoNkW4qFxjzmvK5vNSU3FiqDL8YEblsfyaUFo35mczlPhMReeE0ZPT1h5bL1kIZkMp9LnSIvN+Y9zBKCSbvOd4ZEdk4Ydwrv1k6LCL+roX7eDQihlUyGau4RwWgVd5t+9jye7qbyhX7uGd7fimFtu13R+MNJSoMi+2dyn2gZq+NiGy+DrTMWD3/bGeJsvd3ghXzIuLCsbif0UagAgDUGo0pAAC1RqACANQagQoYBaU37E9Vpj9Qfvk/0DqvbkVfhdW+EYGxgEAFjI78xf6bh/nohvw9y4gGqtIdEjCmEKiA0bGp/Gi18WPnp/TVi3zp0SF/AP3+0ov1q0ov3Gl720+Ubm5UerqePkgv+F+2/eNGn46Vfb+x9IQ+Ys8+AkYaV1fA6Mmmwysbj6+omFd6PM9HcWQnqYsj4oXlcSb5o85PlqByR+lpI3u4zt4BXmn7p6V7mjvL73duiojs3uaQ0o1Po1uqfUtP9RsanQXbzh4sskeTNwyz419gVBGogFGS/SfavqR0HZVdDDVkp6P7VjrjbfQi3yz7Uzu4BKp/KX3w/aD0dt3o1fotjV7w8zdHlV7wF5ZujRoykHVlD9rD7dcRGG1U/QGj69PZH2N5lo+aepGfUYYp5fEJzfI5UNkp6oHlERbbl/tY/XYIOkCv5j8vz18a04+oR2cgUAGjKCIeLA+Uy2ClQXqR/10JJg03lsYVT5ZHo+Rzf/KprD/cgl7w7ymlr0ts/8WIHygwgghUwOjLZurVxgv99SKfD+/729KY4pX5AMvy1NwbKoEpA9ktW9ILfkTcXgJbPmzzBa05VODZowslAECtUaICANQagQoAUGsEKgBArRGoAAC1RqACANQagQoAUGsEKgCA6uy/AeUZI4wA1ZM2AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 468x324 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "from calvin_utils.statistical_utils.distribution_statistics import plot_with_annotation\n",
    "plt = plot_with_annotation(dataframe=data_df, \n",
    "                           col1=group1_col_name, \n",
    "                           col2=group2_col_name,\n",
    "                           xlabel=x_label, \n",
    "                           ylabel=y_label, \n",
    "                           test_type=test_type,\n",
    "                           colours=sns.set_palette('tab10')\n",
    ")\n",
    "\n",
    "os.makedirs(os.path.join(out_dir, 'distribution_figures/validation'), exist_ok=True)\n",
    "plt.savefig(os.path.join(out_dir, f'distribution_figures/validation/{x_label}_{test_type}_{y_label}.png'))\n",
    "plt.savefig(os.path.join(out_dir, f'distribution_figures/validation/{x_label}_{test_type}_{y_label}.svg'))\n",
    "print('Figure saved to: ', (os.path.join(out_dir, f'distribution_figures/validation/{x_label}_{test_type}_{y_label}')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Multiple Distribution Tests and Correct for Multiple Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a detailed description of the `plot_distribution_tests` function.\n",
    "\n",
    "### `plot_distribution_tests` Function\n",
    "\n",
    "This function creates a plot of distribution tests with optional annotations for multiple key-value pair comparisons.\n",
    "\n",
    "#### Parameters\n",
    "\n",
    "- `dataframe`: A pandas DataFrame containing the data for comparison.\n",
    "- `comparisons_dict`: A dictionary mapping comparisons with keys and values representing column names in the DataFrame.\n",
    "- `test_type`: Specifies the statistical method used for testing. Available options are:\n",
    "  - `'t-test_ind'`: Independent t-test\n",
    "  - `'t-test_paired'`: Paired t-test\n",
    "  - `'Mann-Whitney'`: Mann-Whitney U test\n",
    "  - `'Wilcoxon'`: Wilcoxon signed-rank test\n",
    "- `correction_method`: Specifies the method used to correct for multiple comparisons. Available options are:\n",
    "  - `'bonferroni'`: Bonferroni correction\n",
    "  - `'holm'`: Holm's correction\n",
    "  - `'fdr_bh'`: Benjamini-Hochberg false discovery rate correction\n",
    "- `key_label`: A string label for the keys in the plot.\n",
    "- `value_label`: A string label for the values in the plot.\n",
    "- `x_label`: Label for the x-axis.\n",
    "- `y_label`: Label for the y-axis.\n",
    "- `display`: Controls how the keys and values are displayed. Available options are:\n",
    "  - `'split_pairs'`: Displays keys and values side by side, with keys on the left and values on the right.\n",
    "  - `'group_pairs'`: Groups the key-value pairs together.\n",
    "- `full_legend_patches`: A boolean that controls the appearance of the legend. If `True`, full key-value pairs are shown in the legend; if `False`, only keys are shown.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statannotations.Annotator import Annotator\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def plot_distribution_tests(dataframe, comparisons_dict, test_type, correction_method, key_label, value_label, x_label, y_label, display='split_pairs', full_legend_patches=False):\n",
    "    valid_tests = ['t-test_ind', 't-test_paired', 'Mann-Whitney', 'Wilcoxon']\n",
    "    valid_corrections = ['bonferroni', 'holm', 'fdr_bh']\n",
    "    if test_type not in valid_tests:\n",
    "        raise ValueError(f\"Invalid test type. Choose from: {', '.join(valid_tests)}\")\n",
    "    if correction_method not in valid_corrections:\n",
    "        raise ValueError(f\"Invalid correction method. Choose from: {', '.join(valid_corrections)}\")\n",
    "\n",
    "    # Create a color palette with enough unique colors\n",
    "    colors = sns.color_palette(\"tab10\", len(comparisons_dict))\n",
    "\n",
    "    # Create a new DataFrame to hold the data for plotting\n",
    "    data = pd.DataFrame(columns=['GroupType', 'Metric', 'Value'])\n",
    "    pairs = []\n",
    "    # Create legend patches\n",
    "    legend_patches = []\n",
    "\n",
    "    # Iterate through comparisons_dict\n",
    "    for idx, (key, value) in enumerate(comparisons_dict.items()):\n",
    "        key_series = dataframe[key]\n",
    "        value_series = dataframe[value]\n",
    "        color = colors[idx]\n",
    "        temp_data = pd.DataFrame({\n",
    "            'GroupType': [f'Key'] * len(key_series) + [f'Value'] * len(value_series),\n",
    "            'Metric': [key] * len(key_series) + [value] * len(value_series),\n",
    "            'Value': key_series.tolist() + value_series.tolist(),\n",
    "            'Color': [color] * (len(key_series) + len(value_series))\n",
    "        })\n",
    "        data = pd.concat([data, temp_data], axis=0)\n",
    "        pairs.append(((key, 'Key'), (value, 'Value')))\n",
    "        \n",
    "        if full_legend_patches:\n",
    "            legend_patches.append(mpatches.Patch(color=colors[idx], label=f'{key} vs {value}'))\n",
    "        else:\n",
    "            legend_patches.append(mpatches.Patch(color=colors[idx], label=f'{value}'))\n",
    "\n",
    "    # Map colour\n",
    "    palette_mapping = {row['Metric']: row['Color'] for _, row in data.iterrows()}\n",
    "\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(len(comparisons_dict)*1.3, 5))\n",
    "    # Add annotations\n",
    "    if display=='group_pairs':\n",
    "        # Plot with seaborn (split image)\n",
    "        sns.set_style('white')\n",
    "        palette = sns.color_palette('tab10', 2, desat=1)  # Define palette with 2 colors\n",
    "        sns.set_palette(palette)\n",
    "        ax = sns.boxplot(x='Metric', y='Value', hue='GroupType', data=data, ax=ax, palette=palette)\n",
    "        \n",
    "        # Define the Legend\n",
    "        key_color = palette[0]  # Color for the 'Key' group\n",
    "        value_color = palette[1]  # Color for the 'Value' group\n",
    "        legend_patches = [mpatches.Patch(color=key_color, label=key_label),\n",
    "                        mpatches.Patch(color=value_color, label=value_label)]\n",
    "        \n",
    "        # Add annotations\n",
    "        annotator = Annotator(ax=ax,\n",
    "                              data=data,\n",
    "                              x='Metric',\n",
    "                              y='Value',\n",
    "                              hue='GroupType',\n",
    "                              pairs=pairs,\n",
    "                              test=test_type,\n",
    "                              text_format='full',\n",
    "                              loc='inside',\n",
    "                              verbose=2)\n",
    "        x_labels = [pair[0][0] for pair in pairs]\n",
    "        result = [' '] * (len(x_labels) * 2)\n",
    "        result[0::2] = x_labels\n",
    "        x_labels = result\n",
    "        x_ticks = [i for i in range(0, len(pairs)*2)]\n",
    "        plt.xticks(ticks=x_ticks, labels=x_labels)\n",
    "    elif display=='split_pairs':\n",
    "        # Plot with seaborn (side-by-side)\n",
    "        ax = sns.boxplot(x='GroupType', y='Value', hue='Metric', data=data, ax=ax, palette={row['Metric']: row['Color'] for _, row in data.iterrows()})\n",
    "        # Adjust pairs for side-by-side\n",
    "        pairs = [(('Key', col1), ('Value', col2)) for col1, col2 in comparisons_dict.items()]\n",
    "        # Add annotations\n",
    "        annotator = Annotator(ax=ax,\n",
    "                              data=data,\n",
    "                              x='GroupType',\n",
    "                              y='Value',\n",
    "                              hue='Metric',\n",
    "                              pairs=pairs,\n",
    "                              test=test_type,\n",
    "                              text_format='full',\n",
    "                              loc='outside',\n",
    "                              verbose=1)\n",
    "        x_labels = [key_label] + [value_label]\n",
    "        plt.xticks(ticks=range(len(x_labels)), labels=x_labels)\n",
    "    else:\n",
    "        raise ValueError(f'display {display} not supported please choose \"split_pairs\" or \"group_pairs\"')\n",
    "\n",
    "    # Configure and annotate\n",
    "    _, corrected_results = annotator.configure(test=test_type, comparisons_correction=correction_method).apply_and_annotate()\n",
    "\n",
    "    # Label and show plot\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    plt.title(f'Distribution Test: {test_type} with {correction_method} correction')\n",
    "    plt.legend(handles=legend_patches, frameon=False, loc=(0.025, 0.05))\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons_dict = {'Convolutional_Neural_Network':'Convolutional_Neural_Network_Equivalent', \n",
    "                    'Natural_Language_Processing':'Natural_Language_Processing_Equivalent', \n",
    "                    'Expert_Algorithm':'Expert_Algorithm_Equivalent'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparisons_dict = {'ACE3_Question_2': 'Question_2', 'ACE3_Question_3': 'Question_3', 'ACE3_Question_4': 'Question_4', 'ACE3_Question_5': 'Question_5', 'ACE3_Question_6': 'Question_6', 'ACE3_Question_7': 'Question_7', 'ACE3_Question_8': 'Question_8', 'ACE3_Question_9': 'Question_9', 'ACE3_Question_10': 'Question_10', 'ACE3_Question_11': 'Question_11', 'ACE3_Question_12': 'Question_12', 'ACE3_Question_13': 'Question_13', 'ACE3_Question_14': 'Question_14', 'ACE3_Question_15': 'Question_15', 'ACE3_Question_16': 'Question_16', 'ACE3_Question_17': 'Question_17', 'ACE3_Question_18': 'Question_18', 'ACE3_Question_19': 'Question_19', 'ACE3_Question_20': 'Question_20'}\n",
    "test_type = 'Mann-Whitney'\n",
    "correction_method = 'bonferroni'\n",
    "key_label = 'ACoE'\n",
    "value_label = 'ACE3'\n",
    "x_label = 'Test'\n",
    "y_label = 'Score'\n",
    "\n",
    "#----------------------------------------------------------------\n",
    "plt = plot_distribution_tests(dataframe=data_df,\n",
    "                        comparisons_dict=comparisons_dict, \n",
    "                        test_type=test_type, \n",
    "                        correction_method=correction_method,\n",
    "                        key_label=key_label, \n",
    "                        value_label=value_label, \n",
    "                        x_label=x_label, \n",
    "                        y_label=y_label,\n",
    "                        display='group_pairs')\n",
    "plt\n",
    "\n",
    "os.makedirs(os.path.join(out_dir, 'distribution_figures'), exist_ok=True)\n",
    "plt.savefig(os.path.join(out_dir, f'distribution_figures/{test_type}_{correction_method}_multiple_comparison_barplot.png'))\n",
    "plt.savefig(os.path.join(out_dir, f'distribution_figures/{test_type}_{correction_method}_multiple_comparison_barplot_barplot.svg'))\n",
    "print('Figure saved to: ', (os.path.join(out_dir, f'icc_figures/{test_type}_{correction_method}_multiple_comparison_barplot')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['ParietalWM_AD']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measures of Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spearman/Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr, pearsonr, kendalltau\n",
    "from natsort import index_natsorted\n",
    "\n",
    "# Correcting the function to remove natural sorting and ensure DataFrame is passed\n",
    "\n",
    "def generate_scatterplot(dataframe, data_dict, columns_per_row=3, x_label='xlabel', y_label='ylabel', correlation='pearson', palette='Greys'):\n",
    "    '''\n",
    "    Generate scatterplots with specified correlation coefficient annotated.\n",
    "\n",
    "    :param dataframe: DataFrame containing the data\n",
    "    :param data_dict: Dictionary where key is the dependent variable name, and value is a list of independent variable names\n",
    "    :param columns_per_row: Number of columns per row in the facet plot\n",
    "    :param x_label: Label for the x-axis\n",
    "    :param y_label: Label for the y-axis\n",
    "    :param correlation: method of correlation ('pearson', 'spearman', 'kendall')\n",
    "    :return: Facet plot\n",
    "    '''\n",
    "    sns.set_style('white')\n",
    "    sns.set_palette(palette, 1, desat=1)\n",
    "    \n",
    "    for dependent_var, independent_vars in data_dict.items():\n",
    "        # Melt the DataFrame for each dependent variable\n",
    "        melted_df = pd.melt(dataframe, id_vars=[dependent_var], value_vars=independent_vars,\n",
    "                            var_name='independent_variable_name', value_name='independent_variable_units')\n",
    "\n",
    "        # Sort the DataFrame\n",
    "        melted_df = melted_df.sort_values(by='independent_variable_name')\n",
    "\n",
    "        # Begin plotting\n",
    "        facet_plot = sns.lmplot(y=dependent_var, x='independent_variable_units', data=melted_df,\n",
    "                                col='independent_variable_name', truncate=False, col_wrap=columns_per_row,\n",
    "                                facet_kws=dict(sharex=False, sharey=True))\n",
    "\n",
    "        # Calculate correlation for each cluster\n",
    "        grouped_df = melted_df.groupby('independent_variable_name')\n",
    "        \n",
    "        if correlation == 'pearson':\n",
    "            result = grouped_df.apply(lambda x: pearsonr(x['independent_variable_units'], x[dependent_var]))\n",
    "        elif correlation == 'spearman':\n",
    "            result = grouped_df.apply(lambda x: spearmanr(x['independent_variable_units'], x[dependent_var]))\n",
    "        elif correlation == 'kendall':\n",
    "            result = grouped_df.apply(lambda x: kendalltau(x['independent_variable_units'], x[dependent_var]))\n",
    "        else:\n",
    "            raise ValueError(f'Correlation {correlation} not specified, please select \"pearson\", \"kendall\" or \"spearman\"')\n",
    "\n",
    "        # Annotate with correlation\n",
    "        for ax in facet_plot.axes:\n",
    "            # Get the title of the current subplot\n",
    "            region = ax.get_title().split(\"=\")[-1].strip()\n",
    "            # Get the corresponding r, p values from the result\n",
    "            r, p = result[region]\n",
    "            ax.set_title(region)\n",
    "            ax.annotate(f\"r = {r:.2f}, p = {p:.5f}\", xy=(.5, 1.0), xycoords='axes fraction',\n",
    "                        xytext=(0, 0), textcoords='offset points', ha='center', va='top',\n",
    "                        bbox=dict(boxstyle='round,pad=0.0', alpha=0.0),\n",
    "                        arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "            \n",
    "        facet_plot.set_xlabels(x_label)\n",
    "        facet_plot.set_ylabels(y_label)\n",
    "        return facet_plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_correlate_to = 'ventricleVisualCH'\n",
    "columns_to_correlate_list = ['ventricleVisualCH', 'SubcortexCSF',\n",
    "       'SubcortexCSFCount', 'SubcortexGM', 'SubcortexGMCount', 'SubcortexWM',\n",
    "       'SubcortexWMCount']\n",
    "x_label = 'exploratory_measure'\n",
    "y_label = columns_to_correlate_to\n",
    "correlation = 'pearson'\n",
    "\n",
    "#---------\n",
    "plot = generate_scatterplot(dataframe=data_df, \n",
    "                     data_dict={columns_to_correlate_to:columns_to_correlate_list}, \n",
    "                     x_label=x_label, \n",
    "                     y_label=y_label,\n",
    "                     correlation=correlation,\n",
    "                     palette='Greys')\n",
    "\n",
    "import os\n",
    "os.makedirs(os.path.join(out_dir, 'scatterplot_figures'), exist_ok=True)\n",
    "plot.savefig(os.path.join(out_dir, f'scatterplot_figures/{x_label}_to_{y_label}.png'))\n",
    "plot.savefig(os.path.join(out_dir, f'scatterplot_figures/{x_label}_to_{y_label}.svg'))\n",
    "print('Figure saved to: ', (os.path.join(out_dir, f'scatterplot_figures/{x_label}_to_{y_label}')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Split Between Correlation of Variables**\n",
    "\n",
    "The ScatterWithConfidence class is designed to generate scatter plots with associated confidence intervals and permutation-based p-values. It creates plots of two variables and segregates them by a specified criterion, such as age. These plots are further enhanced by overlaying regression lines with their associated confidence intervals. The class can also perform permutation tests to compute a p-value, which is then prominently displayed in the plot title.\n",
    "\n",
    "Attributes:\n",
    "data_df (pandas.DataFrame): The main dataframe containing the data intended for plotting.\n",
    "Key Methods:\n",
    "1. compute_analytic_confidence_interval(x, y, x_vals)\n",
    "Purpose: Computes the regression line and its 95% confidence intervals using analytic methods.\n",
    "Parameters:\n",
    "x (pandas.Series): The x-values of the data.\n",
    "y (pandas.Series): The y-values of the data.\n",
    "x_vals (numpy.ndarray): The x-values where the regression line and confidence intervals should be computed.\n",
    "Returns:\n",
    "y_fit: Regression line values.\n",
    "lower_bound: Lower 95% confidence interval.\n",
    "upper_bound: Upper 95% confidence interval.\n",
    "2. permute_data_and_difference_in_pearson_r(...)\n",
    "Purpose: Computes the difference in Pearson R between two groups using permutation tests.\n",
    "Parameters:\n",
    "x_one, x_two (str): Column names of the two variables to be correlated.\n",
    "split_by (str): Column name used to segregate the data.\n",
    "split_value (float): The criterion value for data segregation.\n",
    "n_permutations (int, optional): Number of permutations to perform (default is 1000).\n",
    "permute_columns (list of str, optional): List of column names to be permuted.\n",
    "Returns:\n",
    "original_diff: Difference in Pearson R of the original data between two groups.\n",
    "p_value: Permutation-based p-value.\n",
    "3. plot_with_analytic_ci_manual_pvalue(...)\n",
    "Purpose: Generates a scatter plot with regression lines, confidence intervals, and the permutation-based p-value in the title.\n",
    "Parameters:\n",
    "x_one, x_two (str): Column names of the two variables for plotting.\n",
    "split_by (str): Column name for data segregation.\n",
    "... (Other parameters for customization, saving, etc.)\n",
    "Returns:\n",
    "A matplotlib scatter plot.\n",
    "To utilize this class:\n",
    "\n",
    "Initialize the class with your dataset.\n",
    "Use the methods described above to compute confidence intervals or perform permutation tests.\n",
    "Generate and visualize your enhanced scatter plot using the provided methods.\n",
    "Example:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "scatter_plotter = ScatterWithConfidence(data_df)\n",
    "scatter_plotter.plot_with_analytic_ci_manual_pvalue(...)\n",
    "Remember to replace ... with appropriate arguments as your situation demands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefining the class and its methods\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import t\n",
    "import seaborn as sns\n",
    "class ScatterWithConfidence:\n",
    "    def __init__(self, data_df):\n",
    "        self.data_df = data_df\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_analytic_confidence_interval(x, y, x_vals):\n",
    "        slope, intercept = np.polyfit(x, y, 1)\n",
    "        y_fit = slope * x_vals + intercept\n",
    "        \n",
    "        residuals = y - (slope * x + intercept)\n",
    "        stderr = np.sqrt(np.sum(residuals**2) / (len(y) - 2))\n",
    "        \n",
    "        t_value = t.ppf(0.975, df=len(x)-2)\n",
    "        ci = t_value * stderr * np.sqrt(1/len(x) + (x_vals - np.mean(x))**2 / np.sum((x - np.mean(x))**2))\n",
    "        \n",
    "        upper_bound = y_fit + ci\n",
    "        lower_bound = y_fit - ci\n",
    "        \n",
    "        return y_fit, lower_bound, upper_bound\n",
    "\n",
    "    def permute_data_and_difference_in_pearson_r(self, x_one, x_two, split_by, split_value, n_permutations=1000, permute_columns=[]):\n",
    "        original_diff = self.data_df[self.data_df[split_by] < split_value][x_one].corr(self.data_df[self.data_df[split_by] < split_value][x_two]) - \\\n",
    "                       self.data_df[self.data_df[split_by] >= split_value][x_one].corr(self.data_df[self.data_df[split_by] >= split_value][x_two])\n",
    "\n",
    "        permuted_diffs = []\n",
    "\n",
    "        for _ in range(n_permutations):\n",
    "            permuted_df = self.data_df.copy()\n",
    "            for column in permute_columns:\n",
    "                permuted_df[column] = np.random.permutation(permuted_df[column].values)\n",
    "            \n",
    "            diff = permuted_df[permuted_df[split_by] < split_value][x_one].corr(permuted_df[permuted_df[split_by] < split_value][x_two]) - \\\n",
    "                   permuted_df[permuted_df[split_by] >= split_value][x_one].corr(permuted_df[permuted_df[split_by] >= split_value][x_two])\n",
    "            \n",
    "            permuted_diffs.append(diff)\n",
    "\n",
    "        p_value = np.mean([diff <= original_diff for diff in permuted_diffs])\n",
    "        return original_diff, p_value\n",
    "\n",
    "    def plot_with_analytic_ci_manual_pvalue(self, x_one, x_two, \n",
    "                                            split_by, split_value, \n",
    "                                            x_label='X1', y_label='X2', \n",
    "                                            upper_split_legend='Above Split', lower_split_legend='Below Split',\n",
    "                                            alpha=0.3, manual_p_value=None, permute_column=None, \n",
    "                                            save=False, out_dir=None):\n",
    "        fig, ax = plt.subplots(figsize=(6, 5))\n",
    "        \n",
    "        group1 = self.data_df[self.data_df[split_by] < split_value]\n",
    "        group2 = self.data_df[self.data_df[split_by] >= split_value]\n",
    "        \n",
    "        ax.scatter(group1[x_one], group1[x_two], color='red', label=lower_split_legend, s=40, alpha=alpha, marker='o')\n",
    "        ax.scatter(group2[x_one], group2[x_two], color='blue', label=upper_split_legend, s=40, alpha=alpha, marker='o')\n",
    "        \n",
    "        x_vals = np.linspace(self.data_df[x_one].min(), self.data_df[x_one].max(), 400)\n",
    "        \n",
    "        for group, color in [(group1, 'red'), (group2, 'blue')]:\n",
    "            y_fit, lower_bound, upper_bound = self.compute_analytic_confidence_interval(group[x_one], group[x_two], x_vals)\n",
    "            ax.plot(x_vals, y_fit, color=color)\n",
    "            ax.fill_between(x_vals, lower_bound, upper_bound, color=color, alpha=alpha/7)\n",
    "        \n",
    "        if manual_p_value is None:\n",
    "            if permute_column:\n",
    "                rho, manual_p_value = self.permute_data_and_difference_in_pearson_r(x_one, x_two, split_by, split_value, n_permutations=10000, permute_columns=[permute_column])\n",
    "            else:\n",
    "                rho, manual_p_value = self.permute_data_and_difference_in_pearson_r(x_one, x_two, split_by, split_value, n_permutations=10000, permute_columns=[x_one, x_two, split_by])\n",
    "        \n",
    "        ax.set_title(f\"\\u0394 r = {rho:.2f} , p = {manual_p_value:.4f}\")\n",
    "        ax.set_ylabel(y_label)\n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.legend(loc='best', frameon=False)\n",
    "        ax.grid(False)\n",
    "        sns.despine(ax=ax)\n",
    "        \n",
    "        if save and out_dir is not None:\n",
    "            plt.savefig(f\"{out_dir}/scatter_with_polyfit_and_analytic_ci.png\", bbox_inches='tight')\n",
    "            plt.savefig(f\"{out_dir}/scatter_with_polyfit_and_analytic_ci.svg\", bbox_inches='tight')\n",
    "            print(f'Saved to {out_dir}/scatter_with_polyfit_and_analytic_ci.svg')\n",
    "        return fig\n",
    "    \n",
    "class DeltaCorrelation(ScatterWithConfidence):\n",
    "    def __init__(self, data_df):\n",
    "        super().__init__(data_df)\n",
    "\n",
    "    def plot_histogram_of_delta_r(self, x_one, x_two, split_by, split_value, n_permutations=1000, \n",
    "                                permute_columns=[], bins=50, one_tail=False, color_palette='dark'):\n",
    "        # Generate the empirical distribution of delta_r\n",
    "        delta_rs = []\n",
    "        for _ in range(n_permutations):\n",
    "            permuted_df = self.data_df.copy()\n",
    "            for column in permute_columns:\n",
    "                permuted_df[column] = np.random.permutation(permuted_df[column].values)\n",
    "\n",
    "            delta_r = permuted_df[permuted_df[split_by] < split_value][x_one].corr(permuted_df[permuted_df[split_by] < split_value][x_two]) - \\\n",
    "                    permuted_df[permuted_df[split_by] >= split_value][x_one].corr(permuted_df[permuted_df[split_by] >= split_value][x_two])\n",
    "            delta_rs.append(delta_r)\n",
    "\n",
    "        # Calculate the observed delta_r\n",
    "        observed_delta_r, _ = self.permute_data_and_difference_in_pearson_r(x_one, x_two, split_by, split_value, permute_columns=permute_columns)\n",
    "\n",
    "        if one_tail:\n",
    "            observed_delta_r = np.abs(observed_delta_r)\n",
    "            delta_rs = np.abs(delta_rs)\n",
    "\n",
    "        # Calculate p-value\n",
    "        if one_tail:\n",
    "            p_value = np.mean([delta_r >= observed_delta_r for delta_r in delta_rs])\n",
    "        else:\n",
    "            p_value = np.mean([delta_r <= observed_delta_r for delta_r in delta_rs])\n",
    "\n",
    "        # Generate the displot (KDE + Histogram) using Seaborn\n",
    "        sns.set_palette(color_palette)\n",
    "        current_palette = sns.color_palette(color_palette)\n",
    "        chosen_color = current_palette[4]\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        g = sns.displot(delta_rs, kde=True, bins=bins, label=\"Empirical $\\\\Delta r$ Distribution\", element=\"step\",color='blue', alpha=.3)\n",
    "        plt.axvline(x=observed_delta_r, color='red', linestyle='-', linewidth=1.5, label=f\"Observed $\\\\Delta r$\", alpha=0.6)\n",
    "        plt.title(f\"$\\\\Delta r$ = {observed_delta_r}, p = {p_value}\")\n",
    "        plt.xlabel(\"$\\\\Delta r$\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.legend()\n",
    "        \n",
    "        fig = g.fig\n",
    "        \n",
    "        fig.savefig(f\"{out_dir}/hist_kde.png\", bbox_inches='tight')\n",
    "        fig.savefig(f\"{out_dir}/hist_kde.svg\", bbox_inches='tight')\n",
    "        print(f'Saved to {out_dir}/hist_kde.svg')\n",
    "    \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Variables\n",
    "variable_to_correlate_2 = 'Z-Scored Percent Cognitive Improvement'\n",
    "variable_to_correlate_1 = 'Age'\n",
    "split_by_var = 'Cohort' # This is the column which contains the values you are going to split the data by \n",
    "split_value_var = 1.5 # This is the value which will be used to determine how rows of the given column split the entire dataset\n",
    "\n",
    "# Plotting Variables\n",
    "x_label='Age'\n",
    "y_label='Standardized Percent Improvement'\n",
    "legend_string_for_lower_split='Alzheimer Disease'\n",
    "legend_string_for_upper_split='Parkinson Disease'\n",
    "out_dir='/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Research/2023/subiculum_cognition_and_age/figures/final/figure_two'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_sctr = ScatterWithConfidence(data_df)\n",
    "delta_sctr_plot = delta_sctr.plot_with_analytic_ci_manual_pvalue(\n",
    "                                            x_one=variable_to_correlate_1, x_two=variable_to_correlate_2, \n",
    "                                            split_by=split_by_var, split_value=split_value_var, \n",
    "                                            x_label=x_label, y_label=y_label, \n",
    "                                            upper_split_legend=legend_string_for_upper_split, lower_split_legend=legend_string_for_lower_split,\n",
    "                                            alpha=0.3, manual_p_value=None, permute_column=None, \n",
    "                                            save=True, out_dir=out_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram of The Permutation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_permutations_var = 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an object from the new Seaborn-based class\n",
    "histogram_plotter_seaborn = DeltaCorrelation(data_df)\n",
    "\n",
    "# Generate the histogram using Seaborn\n",
    "fig = histogram_plotter_seaborn.plot_histogram_of_delta_r(x_one=variable_to_correlate_1, x_two=variable_to_correlate_2, \n",
    "                                                    split_by=split_by_var, split_value=split_value_var, \n",
    "                                                    n_permutations=n_permutations_var, \n",
    "                                                    permute_columns=[variable_to_correlate_1, variable_to_correlate_2, split_by_var], \n",
    "                                                    bins=50,\n",
    "                                                    one_tail=True, \n",
    "                                                    color_palette='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrapped ICC 95% Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the class\n",
    "scatter_plotter = ScatterWithConfidence(data_df)\n",
    "\n",
    "# Generate and display the plot\n",
    "fig = scatter_plotter.plot_with_analytic_ci_manual_pvalue(x_one=\"Subiculum Connectivity\",\n",
    "                                                         x_two=\"Z-Scored Cognitive Improvement By Group\",\n",
    "                                                         split_by=\"Cohort\",\n",
    "                                                         split_value=0.5,\n",
    "                                                         x_label=\"Subiculum Connectivity\",\n",
    "                                                         y_label=\"Z-Scored Percent Cognitive Improvement\",\n",
    "                                                         upper_split_legend='AD', lower_split_legend='PD',\n",
    "                                                         manual_p_value=None,\n",
    "                                                         alpha=0.7,\n",
    "                                                         save=True, \n",
    "                                                         out_dir=out_dir)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize ICC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a Bunch of ICCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Example usage\n",
    "# comparisons_dict = {\n",
    "#     'Total': 'Total.1',\n",
    "#     'Score1': 'Score2'\n",
    "# }\n",
    "\n",
    "# plot_icc_forest(comparisons_dict, dataframe=data_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_var_column = 'Question_16'\n",
    "dependent_var_column = 'Cognitive_Status_Code'\n",
    "positive_outcome = 0\n",
    "negative_outcome = 1\n",
    "\n",
    "#----------------------------------------------------------------DO NOT TOUCH----------------------------------------------------------------\n",
    "import numpy as np\n",
    "data_df = data_df.loc[:, [independent_var_column, dependent_var_column]].copy()\n",
    "data_df['one_hot_status'] = np.where(data_df[dependent_var_column] == positive_outcome, 0, 1)\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "#----------------------------------------------------------------DO NOT TOUCH----------------------------------------------------------------\n",
    "# assuming 'one_hot_status' is the target with MCI encoded as 1 and intact as 0, and 'Question_16' is the score\n",
    "y_true = data_df['one_hot_status']\n",
    "scores = data_df[independent_var_column]\n",
    "\n",
    "# calculate the false positive rate and true positive rate for all thresholds of the classification\n",
    "fpr, tpr, thresholds = roc_curve(y_true, scores)\n",
    "\n",
    "# calculate the AUC (Area Under Curve)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Create a DataFrame to store FPR, TPR, and corresponding thresholds\n",
    "df_roc = pd.DataFrame({\n",
    "    \"FPR\": fpr,\n",
    "    \"TPR\": tpr,\n",
    "    \"Threshold\": thresholds\n",
    "})\n",
    "\n",
    "# Plot\n",
    "sns.set_style(\"white\")\n",
    "roc = plt.figure(figsize=(7, 6))\n",
    "sns.lineplot(x=\"FPR\", y=\"TPR\", data=df_roc, marker='o', color=\"#1f77b4\")\n",
    "\n",
    "\n",
    "plt.title(f'AUC = {roc_auc:.2f}', fontsize=16)\n",
    "plt.xlabel('False Positive Rate', fontsize=13)\n",
    "plt.ylabel('True Positive Rate', fontsize=13)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
    "\n",
    "sns.despine()\n",
    "plt.show()\n",
    "\n",
    "if not os.path.exists(out_dir + '/roc'):\n",
    "    os.makedirs(out_dir + '/roc')\n",
    "    \n",
    "roc.savefig(out_dir + '/roc/roc.png')\n",
    "roc.savefig(out_dir + '/roc/roc.svg')\n",
    "print('saved to: ', out_dir + '/roc/roc.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrap Confidence Intervals for the AUC Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.statistical_utils.distribution_statistics import bootstrap_distribution_statistics\n",
    "from calvin_utils.statistical_utils.classification_statistics import compute_auc\n",
    "# Use the bootstrap function\n",
    "roc_func_args = {'y_true_variable': 'one_hot_status', 'independent_variable': f'{independent_var_column}'}\n",
    "result_df = bootstrap_distribution_statistics(data_df, compute_auc, roc_func_args, bootstrap_samples=10000)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrapped ROC Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot CIs with Observed Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from numpy import interp\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "def plot_bootstrapped_roc(data, y_true_variable, independent_variable, n_bootstraps=2000):\n",
    "    \"\"\"\n",
    "    Plot ROC curve with bootstrapped confidence intervals.\n",
    "\n",
    "    Parameters:\n",
    "    - data: DataFrame with the data.\n",
    "    - y_true_variable: string with the name of the column containing the true binary labels.\n",
    "    - independent_variable: string with the name of the column containing the independent variable (classifier scores).\n",
    "    - n_bootstraps: number of bootstrap samples to use for generating confidence intervals.\n",
    "    \"\"\"\n",
    "    # Real values\n",
    "    y_true = data[y_true_variable]\n",
    "    scores = data[independent_variable]\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, scores)\n",
    "\n",
    "    # Calculate the AUC (Area Under Curve)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Create a DataFrame to store FPR, TPR, and corresponding thresholds\n",
    "    df_roc = pd.DataFrame({\n",
    "        \"FPR\": fpr,\n",
    "        \"TPR\": tpr,\n",
    "        \"Threshold\": thresholds\n",
    "    })\n",
    "\n",
    "    # Empirical values\n",
    "    roc_auc_bootstraps = []\n",
    "    base_fpr = np.linspace(0, 1, 101)\n",
    "    sns.set_style(\"white\")\n",
    "\n",
    "    # Generate bootstrap samples and calculate ROC curve for each\n",
    "    for i in tqdm(range(n_bootstraps)):\n",
    "        sample = data.sample(frac=1, replace=True)\n",
    "        y_true_sample = sample[y_true_variable]\n",
    "        scores_sample = sample[independent_variable]\n",
    "        fpr, tpr, thresholds = roc_curve(y_true_sample, scores_sample)\n",
    "        tpr = interp(base_fpr, fpr, tpr)\n",
    "        tpr[0] = 0.0\n",
    "        roc_auc_bootstraps.append(tpr)\n",
    "\n",
    "    roc_auc_bootstraps = np.array(roc_auc_bootstraps)\n",
    "\n",
    "    # Calculate mean and confidence intervals\n",
    "    roc_auc_mean = roc_auc_bootstraps.mean(axis=0)\n",
    "    ci_lower = np.percentile(roc_auc_bootstraps, 2.5, axis=0)\n",
    "    ci_upper = np.percentile(roc_auc_bootstraps, 97.5, axis=0)\n",
    "\n",
    "    # Compute AUC using mean ROC curve\n",
    "    roc_auc = auc(base_fpr, roc_auc_mean)\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    sns.set_style(\"white\")\n",
    "    sns.lineplot(x=\"FPR\", y=\"TPR\", data=df_roc, marker='o', color=\"darkblue\", ci=None)\n",
    "    ax.fill_between(base_fpr, ci_lower, ci_upper, color='blue', alpha=0.15)\n",
    "    ax.plot(base_fpr, ci_lower, 'b-', alpha=0.05)\n",
    "    ax.plot(base_fpr, ci_upper, 'b-', alpha=0.05)\n",
    "\n",
    "    ax.set_title('AUC = %0.2f' % roc_auc, fontsize=16)\n",
    "    ax.plot([0, 1], [0, 1],'--', color='#ADD8E6')\n",
    "    ax.set_xlim([0, 1])\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.set_ylabel('True Positive Rate', fontsize=13)\n",
    "    ax.set_xlabel('False Positive Rate', fontsize=13)\n",
    "    \n",
    "    sns.despine()\n",
    "    if not os.path.exists(out_dir + '/roc'):\n",
    "        os.makedirs(out_dir + '/roc')\n",
    "    fig.savefig(out_dir + f'/roc/bootstrapped_roc_observed_plotted.png')\n",
    "    fig.savefig(out_dir + f'/roc/bootstrapped_roc_observed_plotted.svg')\n",
    "    print('Saved to: ', out_dir + f'/roc/bootstrapped_roc_observed_plotted.svg')\n",
    "    \n",
    "plot_bootstrapped_roc(data_df, 'one_hot_status', f'{independent_var_column}', 10000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrapped Presenting Mean Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "def plot_bootstrapped_roc(data, y_true_variable, independent_variable, n_bootstraps=2000):\n",
    "    \"\"\"\n",
    "    Plot ROC curve with bootstrapped confidence intervals.\n",
    "\n",
    "    Parameters:\n",
    "    - data: DataFrame with the data.\n",
    "    - y_true_variable: string with the name of the column containing the true binary labels.\n",
    "    - independent_variable: string with the name of the column containing the independent variable (classifier scores).\n",
    "    - n_bootstraps: number of bootstrap samples to use for generating confidence intervals.\n",
    "    \"\"\"\n",
    "    roc_auc_bootstraps = []\n",
    "    base_fpr = np.linspace(0, 1, 101)\n",
    "    sns.set_style(\"white\")\n",
    "\n",
    "    # Generate bootstrap samples and calculate ROC curve for each\n",
    "    for i in tqdm(range(n_bootstraps)):\n",
    "        sample = data.sample(frac=1, replace=True)\n",
    "        y_true = sample[y_true_variable]\n",
    "        scores = sample[independent_variable]\n",
    "\n",
    "        # Exclude rows with NaN values\n",
    "        mask = ~(y_true.isna() | scores.isna())\n",
    "        y_true = y_true[mask]\n",
    "        scores = scores[mask]\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, scores)\n",
    "\n",
    "        # Interpolate the ROC curve to ensure it starts from (0,0)\n",
    "        tpr = np.interp(base_fpr, fpr, tpr)\n",
    "        tpr[0] = 0.0\n",
    "\n",
    "        roc_auc_bootstraps.append(tpr)\n",
    "\n",
    "    roc_auc_bootstraps = np.array(roc_auc_bootstraps)\n",
    "\n",
    "    # Calculate mean and confidence intervals, ignoring NaN values\n",
    "    roc_auc_mean = np.nanmean(roc_auc_bootstraps, axis=0)\n",
    "    ci_lower = np.percentile(roc_auc_bootstraps, 2.5, axis=0)\n",
    "    ci_upper = np.percentile(roc_auc_bootstraps, 97.5, axis=0)\n",
    "\n",
    "    # Compute AUC using mean ROC curve\n",
    "    roc_auc = auc(base_fpr, roc_auc_mean)\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.plot(base_fpr, roc_auc_mean, '#1f77b4')\n",
    "    ax.fill_between(base_fpr, ci_lower, ci_upper, color='#1f77b4', alpha=0.25)\n",
    "    ax.plot(base_fpr, ci_lower, 'b-', alpha=0.05)\n",
    "    ax.plot(base_fpr, ci_upper, 'b-', alpha=0.05)\n",
    "\n",
    "    ax.set_title('AUC = %0.2f' % roc_auc, fontsize=20)\n",
    "    ax.plot([0, 1], [0, 1],'--', color='#ff7f0e')\n",
    "    ax.set_xlim([0, 1])\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.set_ylabel('True Positive Rate', fontsize=20)\n",
    "    ax.set_xlabel('False Positive Rate', fontsize=20)\n",
    "\n",
    "    sns.despine()\n",
    "    if not os.path.exists(out_dir + '/roc'):\n",
    "        os.makedirs(out_dir + '/roc')\n",
    "    plt.savefig(out_dir + f'/roc/bootstrapped_roc_mean_plotted.png')\n",
    "    plt.savefig(out_dir + f'/roc/bootstrapped_roc_mean_plotted.svg')\n",
    "    print('Saved to: ', out_dir + f'/roc/bootstrapped_roc_mean_plotted.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bootstrapped_roc(data_df, 'one_hot_status', f'{independent_var_column}', 10000)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Accuracy Curves Across Thresolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------DO NOT TOUCH----------------------------------------------------------------\n",
    "data_df = data_df.loc[:, [independent_var_column, dependent_var_column]]\n",
    "data_df['one_hot_status'] = np.where(data_df[dependent_var_column] == positive_outcome, 0, 1)\n",
    "\n",
    "scores = data_df[independent_var_column]\n",
    "y_true = data_df['one_hot_status']\n",
    "\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "from calvin_utils.statistical_utils.distribution_statistics import bootstrap_distribution_statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "def compute_accuracy(sample, threshold, y_true_variable, independent_variable):\n",
    "    \"\"\"\n",
    "    Computes the accuracy for a given threshold.\n",
    "\n",
    "    Parameters:\n",
    "    - sample: DataFrame with the data.\n",
    "    - threshold: float with the threshold to use for classifying the scores.\n",
    "    - y_true_variable: string with the name of the column containing the true binary labels.\n",
    "    - independent_variable: string with the name of the column containing the independent variable (classifier scores).\n",
    "\n",
    "    Returns:\n",
    "    - Scalar with the accuracy.\n",
    "    \"\"\"\n",
    "    y_true = sample[y_true_variable]\n",
    "    scores = sample[independent_variable]\n",
    "    \n",
    "    predictions = [0 if score <= threshold else 1 for score in scores]\n",
    "    return accuracy_score(y_true, predictions)\n",
    "\n",
    "def point_accuracy_and_distribution(data, scores_var, y_true_var, bootstrap_samples=1000):\n",
    "    # Extract the scores and true labels\n",
    "    scores = data[scores_var]\n",
    "    y_true = data[y_true_var]\n",
    "\n",
    "    # Calculate accuracies for all thresholds\n",
    "    thresholds_unique = sorted(list(set(scores)))  # get unique score values and sort them\n",
    "    accuracies = []\n",
    "\n",
    "    bootstrap_results = {}\n",
    "    for threshold in thresholds_unique:\n",
    "        predictions = [0 if score <= threshold else 1 for score in scores]\n",
    "        accuracy = accuracy_score(y_true, predictions)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        # Bootstrap Distribution\n",
    "        func_args = {'threshold': threshold, 'y_true_variable': y_true_var, 'independent_variable': scores_var}\n",
    "        bootstrap_results[f'{threshold}'] = bootstrap_distribution_statistics(data, compute_accuracy, func_args, bootstrap_samples)\n",
    "    # Create a DataFrame to store thresholds and corresponding accuracies\n",
    "    df_accuracies = pd.DataFrame({\n",
    "        \"Threshold\": thresholds_unique,\n",
    "        \"Accuracy\": accuracies\n",
    "    })\n",
    "    \n",
    "    return df_accuracies, bootstrap_results\n",
    "\n",
    "def plot_accuracy_with_ci(df_accuracies, bootstrap_results, output_dir):\n",
    "    \"\"\"\n",
    "    Plots accuracy as a function of threshold with 95% confidence intervals.\n",
    "\n",
    "    Parameters:\n",
    "    - df_accuracies: DataFrame with 'Threshold' and 'Accuracy' columns.\n",
    "    - bootstrap_results: Dictionary with keys as thresholds and values as DataFrames containing bootstrapped statistics.\n",
    "    - output_dir: String with the path to the output directory.\n",
    "\n",
    "    Returns:\n",
    "    - No return value. The plot is saved to the output directory.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the lower and upper bounds of the 95% confidence interval for each threshold\n",
    "    lower_bounds = [bootstrap_results[str(threshold)].loc['Bootstrapped 95-CIs', '2.5th Percentile'] for threshold in df_accuracies[\"Threshold\"]]\n",
    "    upper_bounds = [bootstrap_results[str(threshold)].loc['Bootstrapped 95-CIs', '97.5th Percentile'] for threshold in df_accuracies[\"Threshold\"]]\n",
    "\n",
    "    # Plot accuracy as a function of threshold\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot the accuracies \n",
    "    ax.plot(df_accuracies[\"Threshold\"], df_accuracies[\"Accuracy\"], '-o', color=\"darkblue\")\n",
    "\n",
    "    # Plot the 95% confidence intervals with lighter shade\n",
    "    ax.fill_between(df_accuracies[\"Threshold\"], lower_bounds, upper_bounds, color='blue', alpha=0.05)\n",
    "\n",
    "    # Labels\n",
    "    ax.set_ylabel('Accuracy', fontsize=13)\n",
    "    ax.set_xlabel('Threshold', fontsize=13)\n",
    "\n",
    "    sns.despine()\n",
    "\n",
    "    # Check if the directory exists and create it if it doesn't\n",
    "    if not os.path.exists(output_dir + '/accuracy_curves'):\n",
    "        os.makedirs(output_dir + '/accuracy_curves')\n",
    "\n",
    "    # Save the figure before calling show()\n",
    "    fig.savefig(output_dir + f'/accuracy_curves/accuracy_curves_rct_group.svg')\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracies, bootstrap_results = point_accuracy_and_distribution(data_df, scores_var=f'{independent_var_column}', y_true_var='one_hot_status', bootstrap_samples=10000)\n",
    "display(bootstrap_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "# df_accuracies, bootstrap_results = point_accuracy_and_distribution(data_df, scores_var=f'{independent_var_column}', y_true_var='one_hot_status', bootstrap_samples=1000)\n",
    "plot_accuracy_with_ci(df_accuracies, bootstrap_results, output_dir=out_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Displaying bootstrap results of threshold with highest accuracy')\n",
    "bootstrap_results[str(df_accuracies.loc[df_accuracies['Accuracy'].idxmax(), 'Threshold'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Sensitivity and Specificity Across Different Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_outcome = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------DO NOT TOUCH----------------------------------------------------------------\n",
    "data_df = data_df.copy().loc[:, [independent_var_column, dependent_var_column]]\n",
    "data_df['one_hot_status'] = np.where(data_df[dependent_var_column] == positive_outcome, 1, 0)\n",
    "\n",
    "scores = data_df[independent_var_column]\n",
    "y_true = data_df['one_hot_status']\n",
    "\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#----------------------------------------------------------------DO NOT TOUCH----------------------------------------------------------------\n",
    "# Unique thresholds\n",
    "thresholds_unique = sorted(list(set(scores)))  # get unique score values and sort them\n",
    "\n",
    "sensitivities = []\n",
    "specificities = []\n",
    "\n",
    "for threshold in thresholds_unique:\n",
    "    # Compute predictions based on threshold\n",
    "    predictions = [1 if score <= threshold else 0 for score in scores]\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, predictions).ravel()\n",
    "    \n",
    "    # Compute sensitivity and specificity\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    \n",
    "    # Append to lists\n",
    "    sensitivities.append(sensitivity)\n",
    "    specificities.append(specificity)\n",
    "\n",
    "# Create a DataFrame to store thresholds, sensitivities, and specificities\n",
    "df_threshold_metrics = pd.DataFrame({\n",
    "    \"Threshold\": thresholds_unique,\n",
    "    \"Sensitivity\": sensitivities,\n",
    "    \"Specificity\": specificities\n",
    "})\n",
    "\n",
    "# Plot sensitivity and specificity as functions of threshold\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Sensitivity\n",
    "sns.lineplot(x=\"Threshold\", y=\"Sensitivity\", data=df_threshold_metrics, marker='o', color=\"lightblue\", label=\"Sensitivity\")\n",
    "\n",
    "# Specificity\n",
    "sns.lineplot(x=\"Threshold\", y=\"Specificity\", data=df_threshold_metrics, marker='o', color=\"darkblue\", label=\"Specificity\")\n",
    "\n",
    "# Labels\n",
    "plt.ylabel('Metric Value', fontsize=13)\n",
    "plt.xlabel('Threshold', fontsize=13)\n",
    "plt.legend()\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "if not os.path.exists(out_dir + '/sensitivity_specificity_curves'):\n",
    "    os.makedirs(out_dir + '/sensitivity_specificity_curves')\n",
    "plt.savefig(out_dir + f'/sensitivity_specificity_curves/sensitivity_specificity_curves.png')\n",
    "plt.savefig(out_dir + f'/sensitivity_specificity_curves/sensitivity_specificity_curves.svg')\n",
    "df_threshold_metrics.to_csv(out_dir + f'/sensitivity_specificity_curves/sensitivity_specificity_curves_values.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_threshold_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "\n",
    "bootstrap_iterations = 10000\n",
    "\n",
    "sensitivities = []\n",
    "specificities = []\n",
    "lower_sensitivity_bounds = []\n",
    "upper_sensitivity_bounds = []\n",
    "lower_specificity_bounds = []\n",
    "upper_specificity_bounds = []\n",
    "\n",
    "for threshold in thresholds_unique:\n",
    "    bootstrap_sensitivities = []\n",
    "    bootstrap_specificities = []\n",
    "\n",
    "    for i in range(bootstrap_iterations):\n",
    "        # Resample data with replacement\n",
    "        resampled_scores, resampled_y_true = resample(scores, y_true)\n",
    "        \n",
    "        # Compute predictions based on threshold\n",
    "        predictions = [1 if score <= threshold else 0 for score in resampled_scores]\n",
    "        \n",
    "        # Compute confusion matrix\n",
    "        try:\n",
    "            tn, fp, fn, tp = confusion_matrix(resampled_y_true, predictions).ravel()\n",
    "        except:\n",
    "            continue \n",
    "        if tp + fn != 0:\n",
    "            sensitivity = tp / (tp + fn)\n",
    "        else:\n",
    "            sensitivity = np.nan\n",
    "\n",
    "        if tn + fp != 0:\n",
    "            specificity = tn / (tn + fp)\n",
    "        else:\n",
    "            specificity = np.nan\n",
    "        # # Compute sensitivity and specificity\n",
    "        # sensitivity = tp / (tp + fn)\n",
    "        # specificity = tn / (tn + fp)\n",
    "\n",
    "        # Append to lists\n",
    "        bootstrap_sensitivities.append(sensitivity)\n",
    "        bootstrap_specificities.append(specificity)\n",
    "\n",
    "    # Append mean values to lists\n",
    "    # sensitivities.append(np.mean(bootstrap_sensitivities))\n",
    "    # specificities.append(np.mean(bootstrap_specificities))\n",
    "    sensitivities.append(np.nanmean(bootstrap_sensitivities))\n",
    "    specificities.append(np.nanmean(bootstrap_specificities))\n",
    "    \n",
    "    # Compute 95% confidence intervals for sensitivity and specificity\n",
    "    # lower_sensitivity, upper_sensitivity = np.percentile(bootstrap_sensitivities, [2.5, 97.5])\n",
    "    # lower_specificity, upper_specificity = np.percentile(bootstrap_specificities, [2.5, 97.5])\n",
    "    # Compute 95% confidence intervals for sensitivity and specificity\n",
    "    lower_sensitivity, upper_sensitivity = np.nanpercentile(bootstrap_sensitivities, [2.5, 97.5])\n",
    "    lower_specificity, upper_specificity = np.nanpercentile(bootstrap_specificities, [2.5, 97.5])\n",
    "    \n",
    "    lower_sensitivity_bounds.append(lower_sensitivity)\n",
    "    upper_sensitivity_bounds.append(upper_sensitivity)\n",
    "    lower_specificity_bounds.append(lower_specificity)\n",
    "    upper_specificity_bounds.append(upper_specificity)\n",
    "    \n",
    "confidence_interval_df = pd.DataFrame({\n",
    "    'threshold': thresholds_unique,\n",
    "    'sensitivity': sensitivities,\n",
    "    'lower_sensitivity_bound': lower_sensitivity_bounds,\n",
    "    'upper_sensitivity_bound': upper_sensitivity_bounds,\n",
    "    'specificity': specificities,\n",
    "    'lower_specificity_bound': lower_specificity_bounds,\n",
    "    'upper_specificity_bound': upper_specificity_bounds,\n",
    "})\n",
    "confidence_interval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Merge the two dataframes on the 'Threshold' column\n",
    "df_threshold_metrics = df_threshold_metrics.merge(confidence_interval_df, how='inner', left_on='Threshold', right_on='threshold')\n",
    "\n",
    "# Plot sensitivity and specificity as functions of threshold\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Sensitivity\n",
    "sns.lineplot(x=\"Threshold\", y=\"Sensitivity\", data=df_threshold_metrics, marker='o', color=\"#1f77b4\", label=\"Sensitivity\")\n",
    "plt.fill_between(df_threshold_metrics['Threshold'], df_threshold_metrics['lower_sensitivity_bound'], df_threshold_metrics['upper_sensitivity_bound'], color='#1f77b4', alpha=0.25)\n",
    "\n",
    "# Specificity\n",
    "sns.lineplot(x=\"Threshold\", y=\"Specificity\", data=df_threshold_metrics, marker='o', color=\"#ff7f0e\", label=\"Specificity\")\n",
    "plt.fill_between(df_threshold_metrics['Threshold'], df_threshold_metrics['lower_specificity_bound'], df_threshold_metrics['upper_specificity_bound'], color='#ff7f0e', alpha=0.25)\n",
    "\n",
    "# Labels\n",
    "plt.ylabel('Sensitivity/Specificity Value', fontsize=20)\n",
    "plt.xlabel('Threshold', fontsize=20)\n",
    "plt.legend(loc=(0.9, 0.5), frameon=False)\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "if not os.path.exists(out_dir + '/sensitivity_specificity_curves'):\n",
    "    os.makedirs(out_dir + '/sensitivity_specificity_curves')\n",
    "plt.savefig(out_dir + f'/sensitivity_specificity_curves/sensitivity_specificity_curves.png')\n",
    "plt.savefig(out_dir + f'/sensitivity_specificity_curves/sensitivity_specificity_curves.svg')\n",
    "df_threshold_metrics.to_csv(out_dir + f'/sensitivity_specificity_curves/sensitivity_specificity_curves_values.csv')\n",
    "print('Saved to: ', out_dir + f'/sensitivity_specificity_curves/sensitivity_specificity_curves.svg')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate PPV and NPV Across All Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------DO NOT TOUCH----------------------------------------------------------------\n",
    "data_df = data_df.loc[:, [independent_var_column, dependent_var_column]]\n",
    "data_df['one_hot_status'] = np.where(data_df[dependent_var_column] == positive_outcome, 1, 0)\n",
    "\n",
    "scores = data_df[independent_var_column]\n",
    "y_true = data_df['one_hot_status']\n",
    "\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Unique thresholds\n",
    "thresholds_unique = sorted(list(set(scores)))  # get unique score values and sort them\n",
    "\n",
    "ppv_list = []\n",
    "npv_list = []\n",
    "\n",
    "for threshold in thresholds_unique:\n",
    "    # Compute predictions based on threshold\n",
    "    predictions = [1 if score <= threshold else 0 for score in scores]\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, predictions).ravel()\n",
    "    \n",
    "    # Compute Positive Predictive Value (PPV) and Negative Predictive Value (NPV)\n",
    "    ppv = tp / (tp + fp) if (tp + fp) != 0 else 0  # Prevent division by zero\n",
    "    npv = tn / (tn + fn) if (tn + fn) != 0 else 0  # Prevent division by zero\n",
    "    \n",
    "    # Append to lists\n",
    "    ppv_list.append(ppv)\n",
    "    npv_list.append(npv)\n",
    "\n",
    "# Create a DataFrame to store thresholds, PPVs, and NPVs\n",
    "df_ppv_npv = pd.DataFrame({\n",
    "    \"Threshold\": thresholds_unique,\n",
    "    \"Positive Predictive Value\": ppv_list,\n",
    "    \"Negative Predictive Value\": npv_list\n",
    "})\n",
    "\n",
    "# Plot PPV and NPV as functions of threshold\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# PPV\n",
    "sns.lineplot(x=\"Threshold\", y=\"Positive Predictive Value\", data=df_ppv_npv, marker='o', color=\"1f77b4\", label=\"PPV\")\n",
    "\n",
    "# NPV\n",
    "sns.lineplot(x=\"Threshold\", y=\"Negative Predictive Value\", data=df_ppv_npv, marker='o', color=\"darkblue\", label=\"NPV\")\n",
    "\n",
    "# Labels\n",
    "plt.ylabel('Metric Value', fontsize=13)\n",
    "plt.xlabel('Threshold', fontsize=13)\n",
    "plt.legend()\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "if not os.path.exists(out_dir + '/ppv_npv_curves'):\n",
    "    os.makedirs(out_dir + '/ppv_npv_curves')\n",
    "plt.savefig(out_dir + f'/ppv_npv_curves/ppv_npv_curves.png')\n",
    "plt.savefig(out_dir + f'/ppv_npv_curves/ppv_npv_curves.svg')\n",
    "df_ppv_npv.to_csv(out_dir + f'/ppv_npv_curves/ppv_npv_curves.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "bootstrap_samples = 10000  # number of bootstrap samples to generate\n",
    "\n",
    "# Unique thresholds\n",
    "thresholds_unique = sorted(list(set(scores)))  # get unique score values and sort them\n",
    "\n",
    "ppv_list = []\n",
    "npv_list = []\n",
    "ppv_lower = []\n",
    "ppv_upper = []\n",
    "npv_lower = []\n",
    "npv_upper = []\n",
    "\n",
    "y_true_array = y_true.to_numpy()\n",
    "scores_array = scores.to_numpy()\n",
    "for threshold in thresholds_unique:\n",
    "    # Compute predictions based on threshold\n",
    "    predictions = [1 if score <= threshold else 0 for score in scores_array]\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    try:\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, predictions).ravel()\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    # Compute Positive Predictive Value (PPV) and Negative Predictive Value (NPV)\n",
    "    ppv = tp / (tp + fp) if (tp + fp) != 0 else 0  # Prevent division by zero\n",
    "    npv = tn / (tn + fn) if (tn + fn) != 0 else 0  # Prevent division by zero\n",
    "\n",
    "    # Bootstrap samples\n",
    "    ppv_bootstrap = []\n",
    "    npv_bootstrap = []\n",
    "\n",
    "    # Generate bootstrap samples\n",
    "    for _ in range(bootstrap_samples):\n",
    "        # Create bootstrap sample\n",
    "        bootstrap_indices = np.random.choice(np.arange(len(predictions)), size=len(predictions), replace=True)\n",
    "        bootstrap_predictions = [predictions[i] for i in bootstrap_indices]\n",
    "        bootstrap_y_true = [y_true_array[i] for i in bootstrap_indices]\n",
    "\n",
    "        \n",
    "        # Compute confusion matrix for bootstrap sample\n",
    "        tn, fp, fn, tp = confusion_matrix(bootstrap_y_true, bootstrap_predictions).ravel()\n",
    "        \n",
    "        # Compute PPV and NPV for bootstrap sample\n",
    "        ppv_bootstrap_sample = tp / (tp + fp) if (tp + fp) != 0 else 0  # Prevent division by zero\n",
    "        npv_bootstrap_sample = tn / (tn + fn) if (tn + fn) != 0 else 0  # Prevent division by zero\n",
    "\n",
    "        # Append to lists\n",
    "        ppv_bootstrap.append(ppv_bootstrap_sample)\n",
    "        npv_bootstrap.append(npv_bootstrap_sample)\n",
    "\n",
    "    # Compute 95% confidence intervals\n",
    "    ppv_lower.append(np.percentile(ppv_bootstrap, 2.5))\n",
    "    ppv_upper.append(np.percentile(ppv_bootstrap, 97.5))\n",
    "    npv_lower.append(np.percentile(npv_bootstrap, 2.5))\n",
    "    npv_upper.append(np.percentile(npv_bootstrap, 97.5))\n",
    "    \n",
    "    # Append to lists\n",
    "    ppv_list.append(ppv)\n",
    "    npv_list.append(npv)\n",
    "\n",
    "# Create a DataFrame to store thresholds, PPVs, and NPVs\n",
    "df_ppv_npv = pd.DataFrame({\n",
    "    \"Threshold\": thresholds_unique,\n",
    "    \"Positive Predictive Value\": ppv_list,\n",
    "    \"PPV Lower\": ppv_lower,\n",
    "    \"PPV Upper\": ppv_upper,\n",
    "    \"Negative Predictive Value\": npv_list,\n",
    "    \"NPV Lower\": npv_lower,\n",
    "    \"NPV Upper\": npv_upper\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Research/2023/roca/figures/confidence_evaluation'\n",
    "# Plot PPV and NPV as functions of threshold\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# PPV\n",
    "sns.lineplot(x=\"Threshold\", y=\"Positive Predictive Value\", data=df_ppv_npv, marker='o', color=\"#1f77b4\", label=\"PPV\")\n",
    "plt.fill_between(df_ppv_npv[\"Threshold\"], df_ppv_npv[\"PPV Lower\"], df_ppv_npv[\"PPV Upper\"], color='#1f77b4', alpha=0.25)\n",
    "\n",
    "# NPV\n",
    "sns.lineplot(x=\"Threshold\", y=\"Negative Predictive Value\", data=df_ppv_npv, marker='o', color=\"#ff7f0e\", label=\"NPV\")\n",
    "plt.fill_between(df_ppv_npv[\"Threshold\"], df_ppv_npv[\"NPV Lower\"], df_ppv_npv[\"NPV Upper\"], color='#ff7f0e', alpha=0.25)\n",
    "\n",
    "# Labels\n",
    "plt.ylabel('NPV/PPV Value', fontsize=20)\n",
    "plt.xlabel('Threshold', fontsize=20)\n",
    "plt.legend(loc=(0.9, 0.5), frameon=False)\n",
    "sns.despine()\n",
    "\n",
    "if not os.path.exists(out_dir + '/ppv_npv_curves'):\n",
    "    os.makedirs(out_dir + '/ppv_npv_curves')\n",
    "plt.savefig(out_dir + f'/ppv_npv_curves/ppv_npv_curves.png')\n",
    "plt.savefig(out_dir + f'/ppv_npv_curves/ppv_npv_curves.svg')\n",
    "df_ppv_npv.to_csv(out_dir + f'/ppv_npv_curves/ppv_npv_curves.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_threshold_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot sensitivity and specificity as functions of threshold\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Sensitivity\n",
    "sns.lineplot(x=\"Threshold\", y=\"Sensitivity\", data=df_threshold_metrics, marker='o', color=\"#1f77b4\", label=\"Sensitivity\")\n",
    "plt.fill_between(df_threshold_metrics['Threshold'], df_threshold_metrics['lower_sensitivity_bound'], df_threshold_metrics['upper_sensitivity_bound'], color='#1f77b4', alpha=0.25)\n",
    "\n",
    "# Specificity\n",
    "sns.lineplot(x=\"Threshold\", y=\"Specificity\", data=df_threshold_metrics, marker='o', color=\"#ff7f0e\", label=\"Specificity\")\n",
    "plt.fill_between(df_threshold_metrics['Threshold'], df_threshold_metrics['lower_specificity_bound'], df_threshold_metrics['upper_specificity_bound'], color='#ff7f0e', alpha=0.25)\n",
    "\n",
    "\n",
    "if not os.path.exists(out_dir + '/sens_spec_curves'):\n",
    "    os.makedirs(out_dir + '/sens_spec_curves')\n",
    "plt.savefig(out_dir + f'/sens_spec_curves/sens_spec_curves.png')\n",
    "plt.savefig(out_dir + f'/sens_spec_curves/sens_spec_curves.svg')\n",
    "df_threshold_metrics.to_csv(out_dir + f'/sens_spec_curves/sens_spec_curves.csv')\n",
    "\n",
    "sns.despine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_threshold_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_calvin (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
