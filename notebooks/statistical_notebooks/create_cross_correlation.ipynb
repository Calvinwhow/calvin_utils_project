{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nimlab import datasets as nimds\n",
    "import numpy as np\n",
    "from nilearn import image, plotting, maskers\n",
    "import nibabel as nib\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import platform\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Paths Input Here\n",
    "analysis = \"roi_roi_overlap/yeo_vta_cross_correl\"\n",
    "if platform.uname().system == 'Darwin': #------------------------------Mac OS X---------------------------------------------------------------\n",
    "    conn_path = r'/Users/cu135/Dropbox (Partners HealthCare)/memory/seeds/non_fl_vtas_bilateral_t_con'\n",
    "    roi_path = r'/Users/cu135/Dropbox (Partners HealthCare)/memory/functional_networks/seed_generated_networks/yeo_networks_from_thick_yeo_seeds'\n",
    "    \n",
    "    # clin_path = 'path to clinical values'\n",
    "    out_dir = os.path.join(os.path.dirname(conn_path), f'{analysis}')\n",
    "    \n",
    "    #roi_names = '<path to roi name location>'\n",
    "    print('I have set pathnames in the Mac style')\n",
    "    print('I will save to:', out_dir)\n",
    "else: #----------------------------------------------------------------Windows----------------------------------------------------------------\n",
    "    print('add the paths')\n",
    "\n",
    "if os.path.isdir(out_dir) != True:\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "save = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get and Prepare Dataframes\n",
    "from calvin_utils.import_matrices import import_matrices_from_folder\n",
    "vta_df = import_matrices_from_folder(conn_path, file_pattern='/*.nii')\n",
    "display(vta_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yeo_df = import_matrices_from_folder(roi_path, file_pattern='/*.nii')\n",
    "display(yeo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_correlation_diagonal = (vta_df.iloc[:,1]) * (yeo_df.iloc[:,1]).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Define the number of principal components to extract from each voxelwise PCA\n",
    "n_components = 7\n",
    "\n",
    "# Loop over each column in vta_df and perform cross-correlation with each column in yeo_df\n",
    "dfs_pca = []\n",
    "\n",
    "#Iterate over each subject network\n",
    "for col in vta_df.columns:\n",
    "    vta_col = vta_df[col].values\n",
    "    dfs_corr = []\n",
    "    \n",
    "    #Iterate over each reference network\n",
    "    for yeo_col in yeo_df.columns:\n",
    "        #Achieve the diagonal of the cross-correlation matrix\n",
    "        cross_correlation_diagonal = (vta_df.iloc[:,1] - np.mean(vta_col)) * (yeo_col - np.mean(yeo_col)).transpose()\n",
    "        \n",
    "        \n",
    "        std_vta_col = np.std(vta_col)\n",
    "        std_yeo_col = np.std(yeo_col)\n",
    "        corr = corr / (len(vta_col) * std_vta_col * std_yeo_col)\n",
    "        dfs_corr.append(pd.DataFrame({'corr': corr}))\n",
    "    # Concatenate the correlation dataframes along the columns axis\n",
    "    df_corr = pd.concat(dfs_corr, axis=1)\n",
    "    # Perform voxelwise PCA on the correlation dataframe\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(df_corr.values.T)\n",
    "    # Extract the first principal component and store it in a new dataframe\n",
    "    df_pca = pd.DataFrame({col: pca.components_[0]})\n",
    "    dfs_pca.append(df_pca)\n",
    "\n",
    "# Concatenate the principal component dataframes along the columns axis to create a new dataframe\n",
    "df_pca_all = pd.concat(dfs_pca, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.10 (nimlab)",
   "language": "python",
   "name": "nimlab_py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
