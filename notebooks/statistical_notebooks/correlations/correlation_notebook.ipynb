{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Correlation-Based Analyses\n",
    "\n",
    "### Authors: Calvin Howard.\n",
    "\n",
    "#### Last updated: July 6, 2023\n",
    "\n",
    "Use this to assess if a correlation between a dependent variable and an independent variable is statistically significant using permutation analysis. \n",
    "\n",
    "Further, follow this up with a contrast analysis which sees which categorical variables have significantly different correlations from each other. \n",
    "\n",
    "Notes:\n",
    "- To best use this notebook, you should be familar with mixed effects models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 - Import CSV with All Data\n",
    "**The CSV is expected to be in this format**\n",
    "- ID and absolute paths to niftis are critical\n",
    "```\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "| ID  | Nifti_File_Path            | Covariate_1  | Covariate_2  | Covariate_3  |\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "| 1   | /path/to/file1.nii.gz      | 0.5          | 1.2          | 3.4          |\n",
    "| 2   | /path/to/file2.nii.gz      | 0.7          | 1.4          | 3.1          |\n",
    "| 3   | /path/to/file3.nii.gz      | 0.6          | 1.5          | 3.5          |\n",
    "| 4   | /path/to/file4.nii.gz      | 0.9          | 1.1          | 3.2          |\n",
    "| ... | ...                        | ...          | ...          | ...          |\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your CSV file containing NIFTI paths\n",
    "input_csv_path = '/Users/cu135/Partners HealthCare Dropbox/Calvin Howard/studies/atrophy_seeds_2023/metadata/atrophy_roi_scores/master_list_z_only_unthresholded.csv'\n",
    "sheet = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify where you want to save your results to\n",
    "out_dir = '/Users/cu135/Partners HealthCare Dropbox/Calvin Howard/studies/atrophy_seeds_2023/Figures/supplement_scatterplots_to_baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>CerebellumSBM</th>\n",
       "      <th>CerebellumCSF</th>\n",
       "      <th>CerebellumGM</th>\n",
       "      <th>CerebellumWM</th>\n",
       "      <th>FrontalSurface</th>\n",
       "      <th>FrontalCSF</th>\n",
       "      <th>FrontalGM</th>\n",
       "      <th>...</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>Q11</th>\n",
       "      <th>Q12</th>\n",
       "      <th>Q14</th>\n",
       "      <th>TOTAL11</th>\n",
       "      <th>TOTALMOD</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>65.230137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4497.364934</td>\n",
       "      <td>-980.567621</td>\n",
       "      <td>-2977.241279</td>\n",
       "      <td>30.976181</td>\n",
       "      <td>-9854.189802</td>\n",
       "      <td>2592.141866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>70.578082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2201.458697</td>\n",
       "      <td>18138.572720</td>\n",
       "      <td>11183.039810</td>\n",
       "      <td>36.083698</td>\n",
       "      <td>-9149.893654</td>\n",
       "      <td>26395.833840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>87.873973</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5422.499148</td>\n",
       "      <td>5613.118199</td>\n",
       "      <td>-9831.510960</td>\n",
       "      <td>104.795906</td>\n",
       "      <td>13796.400820</td>\n",
       "      <td>18396.096240</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.00</td>\n",
       "      <td>35.00</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>79.934247</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10039.542490</td>\n",
       "      <td>-4899.249983</td>\n",
       "      <td>-6559.417793</td>\n",
       "      <td>252.720785</td>\n",
       "      <td>10684.093530</td>\n",
       "      <td>9280.278454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.67</td>\n",
       "      <td>17.67</td>\n",
       "      <td>Alzheimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>69.791781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-807.610765</td>\n",
       "      <td>10722.003290</td>\n",
       "      <td>7145.779641</td>\n",
       "      <td>48.613606</td>\n",
       "      <td>-5685.897742</td>\n",
       "      <td>16940.901910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>76.509589</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2512.170377</td>\n",
       "      <td>1056.173682</td>\n",
       "      <td>-2425.407108</td>\n",
       "      <td>92.413730</td>\n",
       "      <td>-4723.426224</td>\n",
       "      <td>6500.935230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.33</td>\n",
       "      <td>4.33</td>\n",
       "      <td>Alzheimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>81.169863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3810.571029</td>\n",
       "      <td>-2017.963719</td>\n",
       "      <td>-2364.859302</td>\n",
       "      <td>72.367939</td>\n",
       "      <td>-5452.430173</td>\n",
       "      <td>-3952.113561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>82.646575</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1377.764614</td>\n",
       "      <td>301.016853</td>\n",
       "      <td>-1047.897930</td>\n",
       "      <td>257.644674</td>\n",
       "      <td>4570.889094</td>\n",
       "      <td>-3721.107713</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>Alzheimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>77.347945</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>21528.922020</td>\n",
       "      <td>-10057.371230</td>\n",
       "      <td>-15527.412260</td>\n",
       "      <td>165.863003</td>\n",
       "      <td>24748.663740</td>\n",
       "      <td>-8417.850048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.33</td>\n",
       "      <td>14.33</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>79.712329</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-331.479770</td>\n",
       "      <td>6104.352219</td>\n",
       "      <td>-580.351404</td>\n",
       "      <td>22.831228</td>\n",
       "      <td>-1913.363895</td>\n",
       "      <td>-1692.824389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>76.923288</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9869.486016</td>\n",
       "      <td>-11122.342400</td>\n",
       "      <td>895.478236</td>\n",
       "      <td>86.666695</td>\n",
       "      <td>17608.845400</td>\n",
       "      <td>-20688.027740</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>77.583562</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4717.085594</td>\n",
       "      <td>-16826.353680</td>\n",
       "      <td>-13884.914220</td>\n",
       "      <td>137.724410</td>\n",
       "      <td>10017.086990</td>\n",
       "      <td>-19402.827040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.67</td>\n",
       "      <td>14.67</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>71.468493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1199.497876</td>\n",
       "      <td>19962.179850</td>\n",
       "      <td>14307.885460</td>\n",
       "      <td>81.470232</td>\n",
       "      <td>-6091.241026</td>\n",
       "      <td>16573.059910</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>27.00</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>83.438356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1505.740371</td>\n",
       "      <td>-1834.647957</td>\n",
       "      <td>-11441.559620</td>\n",
       "      <td>260.507399</td>\n",
       "      <td>11500.925660</td>\n",
       "      <td>11917.766050</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.67</td>\n",
       "      <td>17.67</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>71.065753</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2138.697112</td>\n",
       "      <td>-11485.524060</td>\n",
       "      <td>-8944.047318</td>\n",
       "      <td>34.296010</td>\n",
       "      <td>3958.961232</td>\n",
       "      <td>-8319.639296</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>72.101370</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3786.179144</td>\n",
       "      <td>3432.225779</td>\n",
       "      <td>-4813.191631</td>\n",
       "      <td>112.079015</td>\n",
       "      <td>451.627930</td>\n",
       "      <td>1587.288273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.33</td>\n",
       "      <td>13.33</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>84.079452</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7603.158068</td>\n",
       "      <td>1516.198249</td>\n",
       "      <td>-1050.849621</td>\n",
       "      <td>65.192509</td>\n",
       "      <td>22814.774920</td>\n",
       "      <td>-10082.905480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>82.345205</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4112.348942</td>\n",
       "      <td>4522.095084</td>\n",
       "      <td>8312.880945</td>\n",
       "      <td>91.675593</td>\n",
       "      <td>13779.898060</td>\n",
       "      <td>10242.476120</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>77.101370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4559.982453</td>\n",
       "      <td>2306.715670</td>\n",
       "      <td>6252.112247</td>\n",
       "      <td>31.608093</td>\n",
       "      <td>-3526.163105</td>\n",
       "      <td>-6144.537889</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>62.049315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-7629.796469</td>\n",
       "      <td>1568.993475</td>\n",
       "      <td>-915.804551</td>\n",
       "      <td>35.703737</td>\n",
       "      <td>-10044.546640</td>\n",
       "      <td>-11087.465950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>62.257534</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5526.185830</td>\n",
       "      <td>-22452.092720</td>\n",
       "      <td>-14570.054120</td>\n",
       "      <td>52.295274</td>\n",
       "      <td>19140.690400</td>\n",
       "      <td>-17671.054580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.33</td>\n",
       "      <td>12.33</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>75.986301</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6835.044151</td>\n",
       "      <td>-13134.277280</td>\n",
       "      <td>-5918.253242</td>\n",
       "      <td>38.561811</td>\n",
       "      <td>10518.274600</td>\n",
       "      <td>-4042.628162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>62.452055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-7917.877719</td>\n",
       "      <td>-2829.108559</td>\n",
       "      <td>2091.997116</td>\n",
       "      <td>18.170561</td>\n",
       "      <td>-15082.353820</td>\n",
       "      <td>-4191.354112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>Alzheimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>68.463014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4871.868954</td>\n",
       "      <td>-5714.418470</td>\n",
       "      <td>-4327.271552</td>\n",
       "      <td>93.567752</td>\n",
       "      <td>3605.186881</td>\n",
       "      <td>-24796.708190</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.67</td>\n",
       "      <td>13.67</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>64.060274</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>584.186317</td>\n",
       "      <td>-593.786472</td>\n",
       "      <td>328.309038</td>\n",
       "      <td>120.186539</td>\n",
       "      <td>-4318.369043</td>\n",
       "      <td>8410.281330</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alzheimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>84.038356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>140.358298</td>\n",
       "      <td>2790.885944</td>\n",
       "      <td>7229.608020</td>\n",
       "      <td>36.458639</td>\n",
       "      <td>3868.937890</td>\n",
       "      <td>16348.602200</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.67</td>\n",
       "      <td>21.67</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>71.917808</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6842.889851</td>\n",
       "      <td>-1829.611557</td>\n",
       "      <td>-2845.852721</td>\n",
       "      <td>55.963174</td>\n",
       "      <td>32409.225480</td>\n",
       "      <td>-32696.493660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>59.972603</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-362.152382</td>\n",
       "      <td>-15498.240640</td>\n",
       "      <td>-8462.338620</td>\n",
       "      <td>22.204505</td>\n",
       "      <td>3227.715573</td>\n",
       "      <td>-36997.985770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>74.526027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-579.449091</td>\n",
       "      <td>4457.028976</td>\n",
       "      <td>4584.381484</td>\n",
       "      <td>150.486269</td>\n",
       "      <td>1724.975248</td>\n",
       "      <td>13969.310430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>75.397260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-39.253529</td>\n",
       "      <td>3875.987928</td>\n",
       "      <td>6736.100139</td>\n",
       "      <td>79.655200</td>\n",
       "      <td>-2528.287915</td>\n",
       "      <td>16161.459660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>Alzheimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>-2726.979906</td>\n",
       "      <td>8123.317974</td>\n",
       "      <td>2699.443537</td>\n",
       "      <td>18.417506</td>\n",
       "      <td>-8983.663847</td>\n",
       "      <td>7647.710417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>83.263014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6642.389242</td>\n",
       "      <td>-5018.559162</td>\n",
       "      <td>-1857.476388</td>\n",
       "      <td>22.695699</td>\n",
       "      <td>26513.315130</td>\n",
       "      <td>-17404.061190</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>83.460274</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>634.183060</td>\n",
       "      <td>714.222526</td>\n",
       "      <td>-4729.156976</td>\n",
       "      <td>108.472697</td>\n",
       "      <td>8093.889995</td>\n",
       "      <td>269.409785</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>68.936986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2465.338531</td>\n",
       "      <td>1864.715981</td>\n",
       "      <td>-2686.673946</td>\n",
       "      <td>25.477848</td>\n",
       "      <td>-6713.509834</td>\n",
       "      <td>-2453.344085</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>73.665753</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3555.800211</td>\n",
       "      <td>-14753.220180</td>\n",
       "      <td>150.872161</td>\n",
       "      <td>242.753904</td>\n",
       "      <td>17148.432800</td>\n",
       "      <td>-799.463774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>58.427397</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3662.913619</td>\n",
       "      <td>-25114.113290</td>\n",
       "      <td>-21345.037160</td>\n",
       "      <td>102.211027</td>\n",
       "      <td>5618.037817</td>\n",
       "      <td>-15431.461800</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.33</td>\n",
       "      <td>18.33</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>62.402740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-8765.419115</td>\n",
       "      <td>14359.589150</td>\n",
       "      <td>6846.536868</td>\n",
       "      <td>58.914601</td>\n",
       "      <td>-16935.218110</td>\n",
       "      <td>-13903.760880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>81.167123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2521.557181</td>\n",
       "      <td>-12100.739480</td>\n",
       "      <td>-417.469514</td>\n",
       "      <td>102.246471</td>\n",
       "      <td>11742.379690</td>\n",
       "      <td>-5088.720537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>69.106849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3491.481790</td>\n",
       "      <td>2887.488762</td>\n",
       "      <td>4124.295062</td>\n",
       "      <td>29.664265</td>\n",
       "      <td>-2090.066558</td>\n",
       "      <td>-243.428552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.67</td>\n",
       "      <td>12.67</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>70.153425</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4501.390785</td>\n",
       "      <td>-14086.366130</td>\n",
       "      <td>-10089.115110</td>\n",
       "      <td>58.658250</td>\n",
       "      <td>11756.146820</td>\n",
       "      <td>-29855.017680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.67</td>\n",
       "      <td>16.67</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>78.090411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9090.831006</td>\n",
       "      <td>8203.018071</td>\n",
       "      <td>-3937.388504</td>\n",
       "      <td>244.496132</td>\n",
       "      <td>8036.921762</td>\n",
       "      <td>21071.482220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.33</td>\n",
       "      <td>10.33</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>82.101370</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4697.908300</td>\n",
       "      <td>6542.625302</td>\n",
       "      <td>-2982.377927</td>\n",
       "      <td>323.563475</td>\n",
       "      <td>12666.571450</td>\n",
       "      <td>19120.601390</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.67</td>\n",
       "      <td>20.67</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>82.616438</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1127.841143</td>\n",
       "      <td>9308.785805</td>\n",
       "      <td>8742.807780</td>\n",
       "      <td>55.187397</td>\n",
       "      <td>6025.086804</td>\n",
       "      <td>1165.535088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.33</td>\n",
       "      <td>22.33</td>\n",
       "      <td>Alzheimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>58.227397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2348.541294</td>\n",
       "      <td>3030.575610</td>\n",
       "      <td>1952.084806</td>\n",
       "      <td>335.655284</td>\n",
       "      <td>-3175.294289</td>\n",
       "      <td>-5612.834128</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>73.723288</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7221.251020</td>\n",
       "      <td>-5021.810228</td>\n",
       "      <td>-1499.685479</td>\n",
       "      <td>33.856108</td>\n",
       "      <td>5405.563481</td>\n",
       "      <td>-2025.419643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>74.701370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3961.355104</td>\n",
       "      <td>24031.910070</td>\n",
       "      <td>9109.204510</td>\n",
       "      <td>192.463318</td>\n",
       "      <td>-4703.781559</td>\n",
       "      <td>40740.635520</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>Alzheimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>70.838356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5056.305591</td>\n",
       "      <td>3548.124638</td>\n",
       "      <td>-482.194832</td>\n",
       "      <td>116.596988</td>\n",
       "      <td>-2834.427986</td>\n",
       "      <td>2232.282375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>Alzheimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>73.282192</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5243.802177</td>\n",
       "      <td>-4984.295131</td>\n",
       "      <td>-5586.470819</td>\n",
       "      <td>109.097904</td>\n",
       "      <td>13527.445630</td>\n",
       "      <td>4125.723466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.67</td>\n",
       "      <td>14.67</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>85.145205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2735.743492</td>\n",
       "      <td>26412.015930</td>\n",
       "      <td>2040.272422</td>\n",
       "      <td>187.581870</td>\n",
       "      <td>-5532.505653</td>\n",
       "      <td>31899.326300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.33</td>\n",
       "      <td>7.33</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>66.153425</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1887.333795</td>\n",
       "      <td>1577.954777</td>\n",
       "      <td>3398.982892</td>\n",
       "      <td>27.574568</td>\n",
       "      <td>-990.640509</td>\n",
       "      <td>-7074.137496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject        Age  Sex  CerebellumSBM  CerebellumCSF  CerebellumGM  \\\n",
       "0         1  65.230137  0.0              0   -4497.364934   -980.567621   \n",
       "1         2  70.578082  0.0              0   -2201.458697  18138.572720   \n",
       "2         3  87.873973  1.0              0    5422.499148   5613.118199   \n",
       "3         4  79.934247  1.0              0   10039.542490  -4899.249983   \n",
       "4         5  69.791781  0.0              0    -807.610765  10722.003290   \n",
       "5         6  76.509589  1.0              0   -2512.170377   1056.173682   \n",
       "6         7  81.169863  0.0              0   -3810.571029  -2017.963719   \n",
       "7         8  82.646575  1.0              0   -1377.764614    301.016853   \n",
       "8         9  77.347945  1.0              0   21528.922020 -10057.371230   \n",
       "9        10  79.712329  1.0              0    -331.479770   6104.352219   \n",
       "10       11  76.923288  1.0              0    9869.486016 -11122.342400   \n",
       "11       12  77.583562  1.0              0    4717.085594 -16826.353680   \n",
       "12       13  71.468493  0.0              0   -1199.497876  19962.179850   \n",
       "13       14  83.438356  1.0              0    1505.740371  -1834.647957   \n",
       "14       15  71.065753  1.0              0   -2138.697112 -11485.524060   \n",
       "15       16  72.101370  1.0              0    3786.179144   3432.225779   \n",
       "16       17  84.079452  1.0              0    7603.158068   1516.198249   \n",
       "17       18  82.345205  1.0              0    4112.348942   4522.095084   \n",
       "18       19  77.101370  0.0              0   -4559.982453   2306.715670   \n",
       "19       20  62.049315  0.0              0   -7629.796469   1568.993475   \n",
       "20       21  62.257534  1.0              0    5526.185830 -22452.092720   \n",
       "21       22  75.986301  1.0              0    6835.044151 -13134.277280   \n",
       "22       23  62.452055  0.0              0   -7917.877719  -2829.108559   \n",
       "23       24  68.463014  1.0              0    4871.868954  -5714.418470   \n",
       "24       25  64.060274  1.0              0     584.186317   -593.786472   \n",
       "25       26  84.038356  0.0              0     140.358298   2790.885944   \n",
       "26       27  71.917808  1.0              0    6842.889851  -1829.611557   \n",
       "27       28  59.972603  1.0              0    -362.152382 -15498.240640   \n",
       "28       29  74.526027  0.0              0    -579.449091   4457.028976   \n",
       "29       30  75.397260  0.0              0     -39.253529   3875.987928   \n",
       "30       31        NaN  NaN              0   -2726.979906   8123.317974   \n",
       "31       32  83.263014  1.0              0    6642.389242  -5018.559162   \n",
       "32       33  83.460274  1.0              0     634.183060    714.222526   \n",
       "33       34  68.936986  0.0              0   -2465.338531   1864.715981   \n",
       "34       35  73.665753  1.0              0    3555.800211 -14753.220180   \n",
       "35       36  58.427397  1.0              0    3662.913619 -25114.113290   \n",
       "36       37  62.402740  0.0              0   -8765.419115  14359.589150   \n",
       "37       38  81.167123  1.0              0    2521.557181 -12100.739480   \n",
       "38       39  69.106849  0.0              0   -3491.481790   2887.488762   \n",
       "39       40  70.153425  1.0              0    4501.390785 -14086.366130   \n",
       "40       41  78.090411  0.0              0    9090.831006   8203.018071   \n",
       "41       42  82.101370  1.0              0    4697.908300   6542.625302   \n",
       "42       43  82.616438  1.0              0    1127.841143   9308.785805   \n",
       "43       44  58.227397  0.0              0   -2348.541294   3030.575610   \n",
       "44       45  73.723288  1.0              0    7221.251020  -5021.810228   \n",
       "45       46  74.701370  0.0              0   -3961.355104  24031.910070   \n",
       "46       47  70.838356  1.0              0    5056.305591   3548.124638   \n",
       "47       48  73.282192  1.0              0    5243.802177  -4984.295131   \n",
       "48       49  85.145205  0.0              0   -2735.743492  26412.015930   \n",
       "49       50  66.153425  1.0              0    1887.333795   1577.954777   \n",
       "\n",
       "    CerebellumWM  FrontalSurface    FrontalCSF     FrontalGM  ...   Q7   Q8  \\\n",
       "0   -2977.241279       30.976181  -9854.189802   2592.141866  ...  0.0  0.0   \n",
       "1   11183.039810       36.083698  -9149.893654  26395.833840  ...  0.0  5.0   \n",
       "2   -9831.510960      104.795906  13796.400820  18396.096240  ...  6.0  NaN   \n",
       "3   -6559.417793      252.720785  10684.093530   9280.278454  ...  0.0  5.0   \n",
       "4    7145.779641       48.613606  -5685.897742  16940.901910  ...  0.0  0.0   \n",
       "5   -2425.407108       92.413730  -4723.426224   6500.935230  ...  0.0  0.0   \n",
       "6   -2364.859302       72.367939  -5452.430173  -3952.113561  ...  0.0  3.0   \n",
       "7   -1047.897930      257.644674   4570.889094  -3721.107713  ...  1.0  3.0   \n",
       "8  -15527.412260      165.863003  24748.663740  -8417.850048  ...  0.0  2.0   \n",
       "9    -580.351404       22.831228  -1913.363895  -1692.824389  ...  0.0  2.0   \n",
       "10    895.478236       86.666695  17608.845400 -20688.027740  ...  8.0  3.0   \n",
       "11 -13884.914220      137.724410  10017.086990 -19402.827040  ...  0.0  3.0   \n",
       "12  14307.885460       81.470232  -6091.241026  16573.059910  ...  2.0  3.0   \n",
       "13 -11441.559620      260.507399  11500.925660  11917.766050  ...  1.0  2.0   \n",
       "14  -8944.047318       34.296010   3958.961232  -8319.639296  ...  NaN  NaN   \n",
       "15  -4813.191631      112.079015    451.627930   1587.288273  ...  0.0  4.0   \n",
       "16  -1050.849621       65.192509  22814.774920 -10082.905480  ...  0.0  5.0   \n",
       "17   8312.880945       91.675593  13779.898060  10242.476120  ...  2.0  5.0   \n",
       "18   6252.112247       31.608093  -3526.163105  -6144.537889  ...  1.0  1.0   \n",
       "19   -915.804551       35.703737 -10044.546640 -11087.465950  ...  0.0  3.0   \n",
       "20 -14570.054120       52.295274  19140.690400 -17671.054580  ...  0.0  4.0   \n",
       "21  -5918.253242       38.561811  10518.274600  -4042.628162  ...  0.0  3.0   \n",
       "22   2091.997116       18.170561 -15082.353820  -4191.354112  ...  0.0  0.0   \n",
       "23  -4327.271552       93.567752   3605.186881 -24796.708190  ...  1.0  3.0   \n",
       "24    328.309038      120.186539  -4318.369043   8410.281330  ...  NaN  NaN   \n",
       "25   7229.608020       36.458639   3868.937890  16348.602200  ...  1.0  0.0   \n",
       "26  -2845.852721       55.963174  32409.225480 -32696.493660  ...  0.0  4.0   \n",
       "27  -8462.338620       22.204505   3227.715573 -36997.985770  ...  0.0  0.0   \n",
       "28   4584.381484      150.486269   1724.975248  13969.310430  ...  0.0  0.0   \n",
       "29   6736.100139       79.655200  -2528.287915  16161.459660  ...  0.0  7.0   \n",
       "30   2699.443537       18.417506  -8983.663847   7647.710417  ...  0.0  0.0   \n",
       "31  -1857.476388       22.695699  26513.315130 -17404.061190  ...  3.0  9.0   \n",
       "32  -4729.156976      108.472697   8093.889995    269.409785  ...  1.0  3.0   \n",
       "33  -2686.673946       25.477848  -6713.509834  -2453.344085  ...  1.0  1.0   \n",
       "34    150.872161      242.753904  17148.432800   -799.463774  ...  0.0  3.0   \n",
       "35 -21345.037160      102.211027   5618.037817 -15431.461800  ...  1.0  3.0   \n",
       "36   6846.536868       58.914601 -16935.218110 -13903.760880  ...  0.0  6.0   \n",
       "37   -417.469514      102.246471  11742.379690  -5088.720537  ...  0.0  3.0   \n",
       "38   4124.295062       29.664265  -2090.066558   -243.428552  ...  0.0  3.0   \n",
       "39 -10089.115110       58.658250  11756.146820 -29855.017680  ...  0.0  6.0   \n",
       "40  -3937.388504      244.496132   8036.921762  21071.482220  ...  0.0  2.0   \n",
       "41  -2982.377927      323.563475  12666.571450  19120.601390  ...  2.0  5.0   \n",
       "42   8742.807780       55.187397   6025.086804   1165.535088  ...  0.0  8.0   \n",
       "43   1952.084806      335.655284  -3175.294289  -5612.834128  ...  NaN  NaN   \n",
       "44  -1499.685479       33.856108   5405.563481  -2025.419643  ...  0.0  1.0   \n",
       "45   9109.204510      192.463318  -4703.781559  40740.635520  ...  5.0  7.0   \n",
       "46   -482.194832      116.596988  -2834.427986   2232.282375  ...  1.0  9.0   \n",
       "47  -5586.470819      109.097904  13527.445630   4125.723466  ...  0.0  NaN   \n",
       "48   2040.272422      187.581870  -5532.505653  31899.326300  ...  0.0  3.0   \n",
       "49   3398.982892       27.574568   -990.640509  -7074.137496  ...  0.0  1.0   \n",
       "\n",
       "     Q9  Q10  Q11  Q12  Q14  TOTAL11  TOTALMOD  Diagnosis  \n",
       "0   0.0  0.0  0.0  0.0  0.0     3.00      6.00    Control  \n",
       "1   0.0  0.0  0.0  0.0  0.0     9.00     13.00    Control  \n",
       "2   0.0  1.0  0.0  0.0  1.0    24.00     35.00        MCI  \n",
       "3   0.0  0.0  0.0  0.0  1.0     9.67     17.67  Alzheimer  \n",
       "4   0.0  0.0  0.0  0.0  1.0     2.00      5.00        MCI  \n",
       "5   0.0  0.0  1.0  0.0  0.0     2.33      4.33  Alzheimer  \n",
       "6   0.0  0.0  0.0  0.0  0.0     5.00      7.00        MCI  \n",
       "7   0.0  0.0  1.0  1.0  1.0    12.00     22.00  Alzheimer  \n",
       "8   0.0  0.0  1.0  0.0  0.0    10.33     14.33        MCI  \n",
       "9   0.0  0.0  0.0  0.0  0.0     7.00     14.00    Control  \n",
       "10  0.0  0.0  0.0  0.0  0.0    18.00     23.00        MCI  \n",
       "11  0.0  0.0  0.0  0.0  1.0     7.67     14.67        MCI  \n",
       "12  0.0  2.0  2.0  2.0  1.0    17.00     27.00        MCI  \n",
       "13  0.0  0.0  0.0  0.0  1.0     9.67     17.67    Control  \n",
       "14  NaN  NaN  NaN  NaN  NaN      NaN       NaN        MCI  \n",
       "15  0.0  0.0  0.0  0.0  0.0     9.33     13.33    Control  \n",
       "16  0.0  0.0  0.0  0.0  0.0     8.00      9.00        MCI  \n",
       "17  0.0  1.0  0.0  0.0  0.0    13.00     20.00    Control  \n",
       "18  0.0  0.0  0.0  0.0  1.0     7.00     12.00        MCI  \n",
       "19  0.0  0.0  0.0  0.0  0.0     5.00      6.00    Control  \n",
       "20  0.0  0.0  0.0  0.0  0.0     9.33     12.33    Control  \n",
       "21  0.0  0.0  0.0  0.0  1.0    10.00     16.00    Control  \n",
       "22  0.0  0.0  0.0  0.0  0.0     3.00      4.00  Alzheimer  \n",
       "23  0.0  0.0  0.0  0.0  0.0     7.67     13.67    Control  \n",
       "24  NaN  NaN  NaN  NaN  NaN      NaN       NaN  Alzheimer  \n",
       "25  0.0  0.0  1.0  1.0  2.0    13.67     21.67        MCI  \n",
       "26  0.0  0.0  0.0  0.0  0.0     9.00     17.00        MCI  \n",
       "27  0.0  0.0  0.0  0.0  0.0     0.00      0.00    Control  \n",
       "28  0.0  0.0  0.0  0.0  1.0     2.00      4.00        MCI  \n",
       "29  0.0  0.0  0.0  0.0  0.0    14.00     23.00  Alzheimer  \n",
       "30  0.0  0.0  1.0  0.0  0.0     5.00      7.00    Control  \n",
       "31  0.0  0.0  0.0  0.0  2.0    18.00     28.00    Control  \n",
       "32  0.0  0.0  0.0  0.0  2.0    10.00     19.00    Control  \n",
       "33  0.0  0.0  0.0  0.0  0.0     4.00      6.00    Control  \n",
       "34  0.0  0.0  0.0  0.0  0.0     7.00     11.00        MCI  \n",
       "35  0.0  0.0  0.0  0.0  0.0    11.33     18.33        MCI  \n",
       "36  0.0  0.0  0.0  0.0  1.0    11.00     15.00        MCI  \n",
       "37  0.0  0.0  0.0  0.0  2.0     9.00     14.00    Control  \n",
       "38  0.0  0.0  0.0  0.0  0.0     6.67     12.67    Control  \n",
       "39  0.0  0.0  0.0  0.0  1.0    10.67     16.67        MCI  \n",
       "40  0.0  0.0  0.0  0.0  2.0     6.33     10.33    Control  \n",
       "41  0.0  0.0  0.0  0.0  2.0    11.67     20.67    Control  \n",
       "42  0.0  0.0  0.0  0.0  0.0    15.33     22.33  Alzheimer  \n",
       "43  NaN  NaN  NaN  NaN  NaN      NaN       NaN        MCI  \n",
       "44  0.0  0.0  2.0  0.0  2.0     8.00     13.00        MCI  \n",
       "45  1.0  0.0  1.0  0.0  1.0    23.00     32.00  Alzheimer  \n",
       "46  0.0  0.0  0.0  0.0  2.0    16.00     26.00  Alzheimer  \n",
       "47  0.0  0.0  0.0  0.0  0.0    13.67     14.67        MCI  \n",
       "48  0.0  0.0  0.0  0.0  0.0     6.33      7.33        MCI  \n",
       "49  0.0  0.0  0.0  0.0  1.0     4.00      8.00        MCI  \n",
       "\n",
       "[50 rows x 76 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from calvin_utils.permutation_analysis_utils.statsmodels_palm import CalvinStatsmodelsPalm\n",
    "# Instantiate the PalmPrepararation class\n",
    "cal_palm = CalvinStatsmodelsPalm(input_csv_path=input_csv_path, output_dir=out_dir, sheet=sheet)\n",
    "# Call the process_nifti_paths method\n",
    "data_df = cal_palm.read_and_display_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 01 - Preprocess Your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handle NANs**\n",
    "- Set drop_nans=True is you would like to remove NaNs from data\n",
    "- Provide a column name or a list of column names to remove NaNs from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject', 'Age', 'Sex', 'CerebellumSBM', 'CerebellumCSF',\n",
       "       'CerebellumGM', 'CerebellumWM', 'FrontalSurface', 'FrontalCSF',\n",
       "       'FrontalGM', 'FrontalWM', 'InsularSurface', 'InsularCSF', 'InsularGM',\n",
       "       'InsularWM', 'MTLSurface', 'MTLCSF', 'MTLGM', 'MTLWM',\n",
       "       'OccipitalSurface', 'OccipitalCSF', 'OccipitalGM', 'OccipitalWM',\n",
       "       'ParietalSurface', 'ParietalCSF', 'ParietalGM', 'ParietalWM',\n",
       "       'TemporalSurface', 'TemporalCSF', 'TemporalGM', 'TemporalWM',\n",
       "       'SubcortexSurface', 'SubcortexSurfaceVentricle', 'SubcortexCSF',\n",
       "       'SubcortexGM', 'SubcortexWM', 'WholeBrainSurface', 'WholeBrainCSF',\n",
       "       'WholeBrainGM', 'WholeBrainWM', 'temp_ins_csf', 'temp_ins_gm',\n",
       "       'temp_ins_wm', 'temp_ins_surface', 'frontal', 'temporal', 'parietal',\n",
       "       'occipital', 'cerebellum', 'Mesial_Temporal', 'ventricle',\n",
       "       'cerebellar_vermis', 'cerebellar_fissures', 'frontal_eh', 'temporal_eh',\n",
       "       'parietal_eh', 'occipital_eh', 'cerebellum_eh', 'mesial_temporal_eh',\n",
       "       'ventricle_eh', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9',\n",
       "       'Q10', 'Q11', 'Q12', 'Q14', 'TOTAL11', 'TOTALMOD', 'Diagnosis'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['Subiculum_Connectivity_T_Redone', 'Age_Group', 'Z_Scored_Percent_Cognitive_Improvement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = cal_palm.drop_nans_from_columns(columns_to_drop_from=drop_list)\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop Row Based on Value of Column**\n",
    "\n",
    "Define the column, condition, and value for dropping rows\n",
    "- column = 'your_column_name'\n",
    "- condition = 'above'  # Options: 'equal', 'above', 'below'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the parameters for dropping rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns\n",
    "# data_df.City.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'City'  # The column you'd like to evaluate\n",
    "condition = 'not'  # Thecondition to check ('equal', 'above', 'below', 'not')\n",
    "value = 'Boston' # The value to compare against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df, other_df = cal_palm.drop_rows_based_on_value(column, condition, value)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regress out a Covariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = []\n",
    "for col in data_df.columns:\n",
    "    if 'surface' in col.lower():\n",
    "        lis.append(col)\n",
    "print(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.statistical_utils.regression_utils import RegressOutCovariates\n",
    "# use this code block to regress out covariates. Generally better to just include as covariates in a model..\n",
    "dependent_variable_list = lis\n",
    "regressors = ['Age', 'Sex']\n",
    "\n",
    "data_df, adjusted_dep_vars_list = RegressOutCovariates.run(df=data_df, dependent_variable_list=dependent_variable_list, covariates_list=regressors)\n",
    "print(adjusted_dep_vars_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standardize Data**\n",
    "- Enter Columns you Don't want to standardize into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject', 'Age', 'Sex', 'CerebellumSBM', 'CerebellumCSF',\n",
       "       'CerebellumGM', 'CerebellumWM', 'FrontalSurface', 'FrontalCSF',\n",
       "       'FrontalGM', 'FrontalWM', 'InsularSurface', 'InsularCSF', 'InsularGM',\n",
       "       'InsularWM', 'MTLSurface', 'MTLCSF', 'MTLGM', 'MTLWM',\n",
       "       'OccipitalSurface', 'OccipitalCSF', 'OccipitalGM', 'OccipitalWM',\n",
       "       'ParietalSurface', 'ParietalCSF', 'ParietalGM', 'ParietalWM',\n",
       "       'TemporalSurface', 'TemporalCSF', 'TemporalGM', 'TemporalWM',\n",
       "       'SubcortexSurface', 'SubcortexSurfaceVentricle', 'SubcortexCSF',\n",
       "       'SubcortexGM', 'SubcortexWM', 'WholeBrainSurface', 'WholeBrainCSF',\n",
       "       'WholeBrainGM', 'WholeBrainWM', 'temp_ins_csf', 'temp_ins_gm',\n",
       "       'temp_ins_wm', 'temp_ins_surface', 'frontal', 'temporal', 'parietal',\n",
       "       'occipital', 'cerebellum', 'Mesial_Temporal', 'ventricle',\n",
       "       'cerebellar_vermis', 'cerebellar_fissures', 'frontal_eh', 'temporal_eh',\n",
       "       'parietal_eh', 'occipital_eh', 'cerebellum_eh', 'mesial_temporal_eh',\n",
       "       'ventricle_eh', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9',\n",
       "       'Q10', 'Q11', 'Q12', 'Q14', 'TOTAL11', 'TOTALMOD', 'Diagnosis'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove anything you don't want to standardize\n",
    "cols_not_to_standardize = ['TOTAL11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to standardize column Diagnosis\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>CerebellumSBM</th>\n",
       "      <th>CerebellumCSF</th>\n",
       "      <th>CerebellumGM</th>\n",
       "      <th>CerebellumWM</th>\n",
       "      <th>FrontalSurface</th>\n",
       "      <th>FrontalCSF</th>\n",
       "      <th>FrontalGM</th>\n",
       "      <th>...</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>Q11</th>\n",
       "      <th>Q12</th>\n",
       "      <th>Q14</th>\n",
       "      <th>TOTAL11</th>\n",
       "      <th>TOTALMOD</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.697749</td>\n",
       "      <td>-1.125152</td>\n",
       "      <td>-1.312335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.140269</td>\n",
       "      <td>-0.081904</td>\n",
       "      <td>-0.229820</td>\n",
       "      <td>-0.854116</td>\n",
       "      <td>-1.279321</td>\n",
       "      <td>0.175286</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481047</td>\n",
       "      <td>-1.320569</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.844484</td>\n",
       "      <td>3.00</td>\n",
       "      <td>-1.143189</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.628453</td>\n",
       "      <td>-0.434984</td>\n",
       "      <td>-1.312335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.714776</td>\n",
       "      <td>1.712007</td>\n",
       "      <td>1.733147</td>\n",
       "      <td>-0.792422</td>\n",
       "      <td>-1.214717</td>\n",
       "      <td>1.667414</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481047</td>\n",
       "      <td>0.757249</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.844484</td>\n",
       "      <td>9.00</td>\n",
       "      <td>-0.231785</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.559158</td>\n",
       "      <td>1.797100</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698148</td>\n",
       "      <td>0.536769</td>\n",
       "      <td>-1.179993</td>\n",
       "      <td>0.037548</td>\n",
       "      <td>0.890112</td>\n",
       "      <td>1.165953</td>\n",
       "      <td>...</td>\n",
       "      <td>3.185312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>2.636499</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>0.478541</td>\n",
       "      <td>24.00</td>\n",
       "      <td>2.632629</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.489862</td>\n",
       "      <td>0.772456</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.553811</td>\n",
       "      <td>-0.449586</td>\n",
       "      <td>-0.726399</td>\n",
       "      <td>1.824321</td>\n",
       "      <td>0.604625</td>\n",
       "      <td>0.594530</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481047</td>\n",
       "      <td>0.757249</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>0.478541</td>\n",
       "      <td>9.67</td>\n",
       "      <td>0.376252</td>\n",
       "      <td>Alzheimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.420566</td>\n",
       "      <td>-0.536459</td>\n",
       "      <td>-1.312335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.456458</td>\n",
       "      <td>1.016125</td>\n",
       "      <td>1.173482</td>\n",
       "      <td>-0.641074</td>\n",
       "      <td>-0.896970</td>\n",
       "      <td>1.074734</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481047</td>\n",
       "      <td>-1.320569</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>0.478541</td>\n",
       "      <td>2.00</td>\n",
       "      <td>-1.273390</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.351270</td>\n",
       "      <td>0.330494</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.772359</td>\n",
       "      <td>0.109200</td>\n",
       "      <td>-0.153322</td>\n",
       "      <td>-0.112016</td>\n",
       "      <td>-0.808684</td>\n",
       "      <td>0.420307</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481047</td>\n",
       "      <td>-1.320569</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>1.566335</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.844484</td>\n",
       "      <td>2.33</td>\n",
       "      <td>-1.360624</td>\n",
       "      <td>Alzheimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.281974</td>\n",
       "      <td>0.931915</td>\n",
       "      <td>-1.312335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.012988</td>\n",
       "      <td>-0.179240</td>\n",
       "      <td>-0.144929</td>\n",
       "      <td>-0.354147</td>\n",
       "      <td>-0.875554</td>\n",
       "      <td>-0.234940</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481047</td>\n",
       "      <td>-0.073878</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.844484</td>\n",
       "      <td>5.00</td>\n",
       "      <td>-1.012989</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.212678</td>\n",
       "      <td>1.122489</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.562123</td>\n",
       "      <td>0.038345</td>\n",
       "      <td>0.037635</td>\n",
       "      <td>1.883797</td>\n",
       "      <td>0.043870</td>\n",
       "      <td>-0.220459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130013</td>\n",
       "      <td>-0.073878</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>1.566335</td>\n",
       "      <td>2.636499</td>\n",
       "      <td>0.478541</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0.940021</td>\n",
       "      <td>Alzheimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.143382</td>\n",
       "      <td>0.438686</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.683101</td>\n",
       "      <td>-0.933562</td>\n",
       "      <td>-1.969586</td>\n",
       "      <td>0.775173</td>\n",
       "      <td>1.894746</td>\n",
       "      <td>-0.514873</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481047</td>\n",
       "      <td>-0.489442</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>1.566335</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.844484</td>\n",
       "      <td>10.33</td>\n",
       "      <td>-0.058618</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.074086</td>\n",
       "      <td>0.743816</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.368219</td>\n",
       "      <td>0.582860</td>\n",
       "      <td>0.102448</td>\n",
       "      <td>-0.952498</td>\n",
       "      <td>-0.550921</td>\n",
       "      <td>-0.093317</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481047</td>\n",
       "      <td>-0.489442</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.844484</td>\n",
       "      <td>7.00</td>\n",
       "      <td>-0.101584</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.004790</td>\n",
       "      <td>0.383883</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.522294</td>\n",
       "      <td>-1.033486</td>\n",
       "      <td>0.307035</td>\n",
       "      <td>-0.181434</td>\n",
       "      <td>1.239822</td>\n",
       "      <td>-1.284026</td>\n",
       "      <td>...</td>\n",
       "      <td>4.407432</td>\n",
       "      <td>-0.073878</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.844484</td>\n",
       "      <td>18.00</td>\n",
       "      <td>1.070221</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.935495</td>\n",
       "      <td>0.469093</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.567416</td>\n",
       "      <td>-1.568682</td>\n",
       "      <td>-1.741895</td>\n",
       "      <td>0.435289</td>\n",
       "      <td>0.543441</td>\n",
       "      <td>-1.203464</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481047</td>\n",
       "      <td>-0.073878</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>0.478541</td>\n",
       "      <td>7.67</td>\n",
       "      <td>-0.014350</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.866199</td>\n",
       "      <td>-0.320074</td>\n",
       "      <td>-1.312335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.529086</td>\n",
       "      <td>1.883113</td>\n",
       "      <td>2.166329</td>\n",
       "      <td>-0.244202</td>\n",
       "      <td>-0.934151</td>\n",
       "      <td>1.051676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741073</td>\n",
       "      <td>-0.073878</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>5.518254</td>\n",
       "      <td>3.556004</td>\n",
       "      <td>5.518254</td>\n",
       "      <td>0.478541</td>\n",
       "      <td>17.00</td>\n",
       "      <td>1.591024</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.796903</td>\n",
       "      <td>1.224671</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.027732</td>\n",
       "      <td>-0.162040</td>\n",
       "      <td>-1.403186</td>\n",
       "      <td>1.918375</td>\n",
       "      <td>0.679551</td>\n",
       "      <td>0.759860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130013</td>\n",
       "      <td>-0.489442</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>0.478541</td>\n",
       "      <td>9.67</td>\n",
       "      <td>0.376252</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.727607</td>\n",
       "      <td>-0.372049</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.703144</td>\n",
       "      <td>-1.067563</td>\n",
       "      <td>-1.056968</td>\n",
       "      <td>-0.814016</td>\n",
       "      <td>-0.012262</td>\n",
       "      <td>-0.508717</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.658311</td>\n",
       "      <td>-0.238400</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.394894</td>\n",
       "      <td>0.332140</td>\n",
       "      <td>-0.484329</td>\n",
       "      <td>0.125520</td>\n",
       "      <td>-0.333984</td>\n",
       "      <td>0.112297</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481047</td>\n",
       "      <td>0.341686</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.844484</td>\n",
       "      <td>9.33</td>\n",
       "      <td>-0.188819</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.589015</td>\n",
       "      <td>1.307406</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.102283</td>\n",
       "      <td>0.152363</td>\n",
       "      <td>0.037226</td>\n",
       "      <td>-0.440819</td>\n",
       "      <td>1.717354</td>\n",
       "      <td>-0.619247</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481047</td>\n",
       "      <td>0.757249</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.844484</td>\n",
       "      <td>8.00</td>\n",
       "      <td>-0.752587</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.519719</td>\n",
       "      <td>1.083597</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.455342</td>\n",
       "      <td>0.434400</td>\n",
       "      <td>1.335272</td>\n",
       "      <td>-0.120932</td>\n",
       "      <td>0.888598</td>\n",
       "      <td>0.654845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741073</td>\n",
       "      <td>0.757249</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>2.636499</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.844484</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0.679620</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.450423</td>\n",
       "      <td>0.406865</td>\n",
       "      <td>-1.312335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.151874</td>\n",
       "      <td>0.226536</td>\n",
       "      <td>1.049598</td>\n",
       "      <td>-0.846483</td>\n",
       "      <td>-0.698861</td>\n",
       "      <td>-0.372371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130013</td>\n",
       "      <td>-0.905005</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>0.478541</td>\n",
       "      <td>7.00</td>\n",
       "      <td>-0.361985</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.381127</td>\n",
       "      <td>-1.535646</td>\n",
       "      <td>-1.312335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.720793</td>\n",
       "      <td>0.157317</td>\n",
       "      <td>0.055946</td>\n",
       "      <td>-0.797012</td>\n",
       "      <td>-1.296782</td>\n",
       "      <td>-0.682217</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481047</td>\n",
       "      <td>-0.073878</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.844484</td>\n",
       "      <td>5.00</td>\n",
       "      <td>-1.143189</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.311832</td>\n",
       "      <td>-1.508775</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.717364</td>\n",
       "      <td>-2.096534</td>\n",
       "      <td>-1.836873</td>\n",
       "      <td>-0.596604</td>\n",
       "      <td>1.380335</td>\n",
       "      <td>-1.094908</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481047</td>\n",
       "      <td>0.341686</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.844484</td>\n",
       "      <td>9.33</td>\n",
       "      <td>-0.319019</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.242536</td>\n",
       "      <td>0.262962</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.959931</td>\n",
       "      <td>-1.222262</td>\n",
       "      <td>-0.637518</td>\n",
       "      <td>-0.762489</td>\n",
       "      <td>0.589414</td>\n",
       "      <td>-0.240613</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481047</td>\n",
       "      <td>-0.073878</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>0.478541</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.158817</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.173240</td>\n",
       "      <td>-1.483671</td>\n",
       "      <td>-1.312335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.774182</td>\n",
       "      <td>-0.255349</td>\n",
       "      <td>0.472902</td>\n",
       "      <td>-1.008794</td>\n",
       "      <td>-1.758893</td>\n",
       "      <td>-0.249936</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481047</td>\n",
       "      <td>-1.320569</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.844484</td>\n",
       "      <td>3.00</td>\n",
       "      <td>-1.403590</td>\n",
       "      <td>Alzheimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.103944</td>\n",
       "      <td>-0.707940</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.596102</td>\n",
       "      <td>-0.526071</td>\n",
       "      <td>-0.416968</td>\n",
       "      <td>-0.098077</td>\n",
       "      <td>-0.044713</td>\n",
       "      <td>-1.541578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130013</td>\n",
       "      <td>-0.073878</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.844484</td>\n",
       "      <td>7.67</td>\n",
       "      <td>-0.144550</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.034648</td>\n",
       "      <td>-1.276126</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.198521</td>\n",
       "      <td>-0.045613</td>\n",
       "      <td>0.228411</td>\n",
       "      <td>0.223450</td>\n",
       "      <td>-0.771529</td>\n",
       "      <td>0.539994</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alzheimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.034648</td>\n",
       "      <td>1.302103</td>\n",
       "      <td>-1.312335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.280774</td>\n",
       "      <td>0.271964</td>\n",
       "      <td>1.185103</td>\n",
       "      <td>-0.787893</td>\n",
       "      <td>-0.020519</td>\n",
       "      <td>1.037606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130013</td>\n",
       "      <td>-1.320569</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>1.566335</td>\n",
       "      <td>2.636499</td>\n",
       "      <td>1.801566</td>\n",
       "      <td>13.67</td>\n",
       "      <td>0.897055</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.103944</td>\n",
       "      <td>-0.262089</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.961385</td>\n",
       "      <td>-0.161568</td>\n",
       "      <td>-0.211607</td>\n",
       "      <td>-0.552299</td>\n",
       "      <td>2.597438</td>\n",
       "      <td>-2.036774</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481047</td>\n",
       "      <td>0.341686</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.844484</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.289018</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.173240</td>\n",
       "      <td>-1.803652</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.373903</td>\n",
       "      <td>-1.444068</td>\n",
       "      <td>-0.990191</td>\n",
       "      <td>-0.960068</td>\n",
       "      <td>-0.079338</td>\n",
       "      <td>-2.306412</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481047</td>\n",
       "      <td>-1.320569</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.844484</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.924393</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.242536</td>\n",
       "      <td>0.074509</td>\n",
       "      <td>-1.312335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.414174</td>\n",
       "      <td>0.428295</td>\n",
       "      <td>0.818409</td>\n",
       "      <td>0.589438</td>\n",
       "      <td>-0.217182</td>\n",
       "      <td>0.888461</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481047</td>\n",
       "      <td>-1.320569</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>0.478541</td>\n",
       "      <td>2.00</td>\n",
       "      <td>-1.403590</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.311832</td>\n",
       "      <td>0.186944</td>\n",
       "      <td>-1.312335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.314061</td>\n",
       "      <td>0.373777</td>\n",
       "      <td>1.116691</td>\n",
       "      <td>-0.266125</td>\n",
       "      <td>-0.607327</td>\n",
       "      <td>1.025875</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481047</td>\n",
       "      <td>1.588377</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.844484</td>\n",
       "      <td>14.00</td>\n",
       "      <td>1.070221</td>\n",
       "      <td>Alzheimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.381127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.812169</td>\n",
       "      <td>0.772296</td>\n",
       "      <td>0.557110</td>\n",
       "      <td>-1.005811</td>\n",
       "      <td>-1.199469</td>\n",
       "      <td>0.492193</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481047</td>\n",
       "      <td>-1.320569</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>1.566335</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.844484</td>\n",
       "      <td>5.00</td>\n",
       "      <td>-1.012989</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.450423</td>\n",
       "      <td>1.202042</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.924227</td>\n",
       "      <td>-0.460780</td>\n",
       "      <td>-0.074593</td>\n",
       "      <td>-0.954135</td>\n",
       "      <td>2.056615</td>\n",
       "      <td>-1.078172</td>\n",
       "      <td>...</td>\n",
       "      <td>1.352133</td>\n",
       "      <td>2.419504</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>1.801566</td>\n",
       "      <td>18.00</td>\n",
       "      <td>1.721225</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.519719</td>\n",
       "      <td>1.227499</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.189255</td>\n",
       "      <td>0.077115</td>\n",
       "      <td>-0.472679</td>\n",
       "      <td>0.081959</td>\n",
       "      <td>0.367029</td>\n",
       "      <td>0.029686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130013</td>\n",
       "      <td>-0.073878</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>1.801566</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.549419</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.589015</td>\n",
       "      <td>-0.646772</td>\n",
       "      <td>-1.312335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.763680</td>\n",
       "      <td>0.185064</td>\n",
       "      <td>-0.189540</td>\n",
       "      <td>-0.920529</td>\n",
       "      <td>-0.991231</td>\n",
       "      <td>-0.140990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130013</td>\n",
       "      <td>-0.905005</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.844484</td>\n",
       "      <td>4.00</td>\n",
       "      <td>-1.143189</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.658311</td>\n",
       "      <td>-0.036511</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.352199</td>\n",
       "      <td>-1.374164</td>\n",
       "      <td>0.203814</td>\n",
       "      <td>1.703932</td>\n",
       "      <td>1.197589</td>\n",
       "      <td>-0.037316</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481047</td>\n",
       "      <td>-0.073878</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.844484</td>\n",
       "      <td>7.00</td>\n",
       "      <td>-0.492186</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.727607</td>\n",
       "      <td>-2.003065</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.372050</td>\n",
       "      <td>-2.346306</td>\n",
       "      <td>-2.776054</td>\n",
       "      <td>0.006325</td>\n",
       "      <td>0.139923</td>\n",
       "      <td>-0.954520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130013</td>\n",
       "      <td>-0.073878</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.844484</td>\n",
       "      <td>11.33</td>\n",
       "      <td>0.462185</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.796903</td>\n",
       "      <td>-1.490036</td>\n",
       "      <td>-1.312335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.931254</td>\n",
       "      <td>1.357433</td>\n",
       "      <td>1.132000</td>\n",
       "      <td>-0.516649</td>\n",
       "      <td>-1.928853</td>\n",
       "      <td>-0.858756</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481047</td>\n",
       "      <td>1.172813</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>0.478541</td>\n",
       "      <td>11.00</td>\n",
       "      <td>0.028616</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.866199</td>\n",
       "      <td>0.931562</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.160526</td>\n",
       "      <td>-1.125287</td>\n",
       "      <td>0.125028</td>\n",
       "      <td>0.006753</td>\n",
       "      <td>0.701700</td>\n",
       "      <td>-0.306187</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481047</td>\n",
       "      <td>-0.073878</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>1.801566</td>\n",
       "      <td>9.00</td>\n",
       "      <td>-0.101584</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.935495</td>\n",
       "      <td>-0.624851</td>\n",
       "      <td>-1.312335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.953852</td>\n",
       "      <td>0.281028</td>\n",
       "      <td>0.754629</td>\n",
       "      <td>-0.869962</td>\n",
       "      <td>-0.567130</td>\n",
       "      <td>-0.002461</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481047</td>\n",
       "      <td>-0.073878</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.844484</td>\n",
       "      <td>6.67</td>\n",
       "      <td>-0.274751</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.004790</td>\n",
       "      <td>-0.489788</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.527442</td>\n",
       "      <td>-1.311595</td>\n",
       "      <td>-1.215703</td>\n",
       "      <td>-0.519746</td>\n",
       "      <td>0.702962</td>\n",
       "      <td>-1.858657</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481047</td>\n",
       "      <td>1.172813</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>0.478541</td>\n",
       "      <td>10.67</td>\n",
       "      <td>0.246051</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.074086</td>\n",
       "      <td>0.534503</td>\n",
       "      <td>-1.312335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.377989</td>\n",
       "      <td>0.779774</td>\n",
       "      <td>-0.362921</td>\n",
       "      <td>1.724976</td>\n",
       "      <td>0.361804</td>\n",
       "      <td>1.333659</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481047</td>\n",
       "      <td>-0.489442</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>1.801566</td>\n",
       "      <td>6.33</td>\n",
       "      <td>-0.579420</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.143382</td>\n",
       "      <td>1.052129</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.563862</td>\n",
       "      <td>0.623983</td>\n",
       "      <td>-0.230532</td>\n",
       "      <td>2.680025</td>\n",
       "      <td>0.786474</td>\n",
       "      <td>1.211368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741073</td>\n",
       "      <td>0.757249</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>1.801566</td>\n",
       "      <td>11.67</td>\n",
       "      <td>0.766854</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.212678</td>\n",
       "      <td>1.118600</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.097767</td>\n",
       "      <td>0.883526</td>\n",
       "      <td>1.394870</td>\n",
       "      <td>-0.561670</td>\n",
       "      <td>0.177261</td>\n",
       "      <td>0.085859</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481047</td>\n",
       "      <td>2.003940</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.844484</td>\n",
       "      <td>15.33</td>\n",
       "      <td>0.982987</td>\n",
       "      <td>Alzheimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.281974</td>\n",
       "      <td>-2.028876</td>\n",
       "      <td>-1.312335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.742034</td>\n",
       "      <td>0.294454</td>\n",
       "      <td>0.453507</td>\n",
       "      <td>2.826081</td>\n",
       "      <td>-0.666676</td>\n",
       "      <td>-0.339041</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.351270</td>\n",
       "      <td>-0.029087</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.031505</td>\n",
       "      <td>-0.461085</td>\n",
       "      <td>-0.024994</td>\n",
       "      <td>-0.819329</td>\n",
       "      <td>0.120433</td>\n",
       "      <td>-0.114165</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481047</td>\n",
       "      <td>-0.905005</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>3.556004</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>1.801566</td>\n",
       "      <td>8.00</td>\n",
       "      <td>-0.231785</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.420566</td>\n",
       "      <td>0.097138</td>\n",
       "      <td>-1.312335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.040932</td>\n",
       "      <td>2.264967</td>\n",
       "      <td>1.445662</td>\n",
       "      <td>1.096476</td>\n",
       "      <td>-0.806882</td>\n",
       "      <td>2.566615</td>\n",
       "      <td>...</td>\n",
       "      <td>2.574252</td>\n",
       "      <td>1.588377</td>\n",
       "      <td>6.782330</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>1.566335</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>0.478541</td>\n",
       "      <td>23.00</td>\n",
       "      <td>2.242027</td>\n",
       "      <td>Alzheimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.489862</td>\n",
       "      <td>-0.401395</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.630283</td>\n",
       "      <td>0.343015</td>\n",
       "      <td>0.116055</td>\n",
       "      <td>0.180092</td>\n",
       "      <td>-0.635409</td>\n",
       "      <td>0.152728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130013</td>\n",
       "      <td>2.419504</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>1.801566</td>\n",
       "      <td>16.00</td>\n",
       "      <td>1.460823</td>\n",
       "      <td>Alzheimer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.559158</td>\n",
       "      <td>-0.086011</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.665031</td>\n",
       "      <td>-0.457565</td>\n",
       "      <td>-0.591524</td>\n",
       "      <td>0.089511</td>\n",
       "      <td>0.865441</td>\n",
       "      <td>0.271418</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.844484</td>\n",
       "      <td>13.67</td>\n",
       "      <td>-0.014350</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.628453</td>\n",
       "      <td>1.444945</td>\n",
       "      <td>-1.312335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.813793</td>\n",
       "      <td>2.488288</td>\n",
       "      <td>0.465732</td>\n",
       "      <td>1.037513</td>\n",
       "      <td>-0.882899</td>\n",
       "      <td>2.012399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481047</td>\n",
       "      <td>-0.073878</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.844484</td>\n",
       "      <td>6.33</td>\n",
       "      <td>-0.970022</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.697749</td>\n",
       "      <td>-1.005999</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.042987</td>\n",
       "      <td>0.158157</td>\n",
       "      <td>0.654083</td>\n",
       "      <td>-0.895203</td>\n",
       "      <td>-0.466281</td>\n",
       "      <td>-0.430643</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481047</td>\n",
       "      <td>-0.905005</td>\n",
       "      <td>-0.147442</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-0.245256</td>\n",
       "      <td>0.478541</td>\n",
       "      <td>4.00</td>\n",
       "      <td>-0.882788</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subject       Age       Sex  CerebellumSBM  CerebellumCSF  CerebellumGM  \\\n",
       "0  -1.697749 -1.125152 -1.312335            NaN      -1.140269     -0.081904   \n",
       "1  -1.628453 -0.434984 -1.312335            NaN      -0.714776      1.712007   \n",
       "2  -1.559158  1.797100  0.762001            NaN       0.698148      0.536769   \n",
       "3  -1.489862  0.772456  0.762001            NaN       1.553811     -0.449586   \n",
       "4  -1.420566 -0.536459 -1.312335            NaN      -0.456458      1.016125   \n",
       "5  -1.351270  0.330494  0.762001            NaN      -0.772359      0.109200   \n",
       "6  -1.281974  0.931915 -1.312335            NaN      -1.012988     -0.179240   \n",
       "7  -1.212678  1.122489  0.762001            NaN      -0.562123      0.038345   \n",
       "8  -1.143382  0.438686  0.762001            NaN       3.683101     -0.933562   \n",
       "9  -1.074086  0.743816  0.762001            NaN      -0.368219      0.582860   \n",
       "10 -1.004790  0.383883  0.762001            NaN       1.522294     -1.033486   \n",
       "11 -0.935495  0.469093  0.762001            NaN       0.567416     -1.568682   \n",
       "12 -0.866199 -0.320074 -1.312335            NaN      -0.529086      1.883113   \n",
       "13 -0.796903  1.224671  0.762001            NaN      -0.027732     -0.162040   \n",
       "14 -0.727607 -0.372049  0.762001            NaN      -0.703144     -1.067563   \n",
       "15 -0.658311 -0.238400  0.762001            NaN       0.394894      0.332140   \n",
       "16 -0.589015  1.307406  0.762001            NaN       1.102283      0.152363   \n",
       "17 -0.519719  1.083597  0.762001            NaN       0.455342      0.434400   \n",
       "18 -0.450423  0.406865 -1.312335            NaN      -1.151874      0.226536   \n",
       "19 -0.381127 -1.535646 -1.312335            NaN      -1.720793      0.157317   \n",
       "20 -0.311832 -1.508775  0.762001            NaN       0.717364     -2.096534   \n",
       "21 -0.242536  0.262962  0.762001            NaN       0.959931     -1.222262   \n",
       "22 -0.173240 -1.483671 -1.312335            NaN      -1.774182     -0.255349   \n",
       "23 -0.103944 -0.707940  0.762001            NaN       0.596102     -0.526071   \n",
       "24 -0.034648 -1.276126  0.762001            NaN      -0.198521     -0.045613   \n",
       "25  0.034648  1.302103 -1.312335            NaN      -0.280774      0.271964   \n",
       "26  0.103944 -0.262089  0.762001            NaN       0.961385     -0.161568   \n",
       "27  0.173240 -1.803652  0.762001            NaN      -0.373903     -1.444068   \n",
       "28  0.242536  0.074509 -1.312335            NaN      -0.414174      0.428295   \n",
       "29  0.311832  0.186944 -1.312335            NaN      -0.314061      0.373777   \n",
       "30  0.381127       NaN       NaN            NaN      -0.812169      0.772296   \n",
       "31  0.450423  1.202042  0.762001            NaN       0.924227     -0.460780   \n",
       "32  0.519719  1.227499  0.762001            NaN      -0.189255      0.077115   \n",
       "33  0.589015 -0.646772 -1.312335            NaN      -0.763680      0.185064   \n",
       "34  0.658311 -0.036511  0.762001            NaN       0.352199     -1.374164   \n",
       "35  0.727607 -2.003065  0.762001            NaN       0.372050     -2.346306   \n",
       "36  0.796903 -1.490036 -1.312335            NaN      -1.931254      1.357433   \n",
       "37  0.866199  0.931562  0.762001            NaN       0.160526     -1.125287   \n",
       "38  0.935495 -0.624851 -1.312335            NaN      -0.953852      0.281028   \n",
       "39  1.004790 -0.489788  0.762001            NaN       0.527442     -1.311595   \n",
       "40  1.074086  0.534503 -1.312335            NaN       1.377989      0.779774   \n",
       "41  1.143382  1.052129  0.762001            NaN       0.563862      0.623983   \n",
       "42  1.212678  1.118600  0.762001            NaN      -0.097767      0.883526   \n",
       "43  1.281974 -2.028876 -1.312335            NaN      -0.742034      0.294454   \n",
       "44  1.351270 -0.029087  0.762001            NaN       1.031505     -0.461085   \n",
       "45  1.420566  0.097138 -1.312335            NaN      -1.040932      2.264967   \n",
       "46  1.489862 -0.401395  0.762001            NaN       0.630283      0.343015   \n",
       "47  1.559158 -0.086011  0.762001            NaN       0.665031     -0.457565   \n",
       "48  1.628453  1.444945 -1.312335            NaN      -0.813793      2.488288   \n",
       "49  1.697749 -1.005999  0.762001            NaN       0.042987      0.158157   \n",
       "\n",
       "    CerebellumWM  FrontalSurface  FrontalCSF  FrontalGM  ...        Q7  \\\n",
       "0      -0.229820       -0.854116   -1.279321   0.175286  ... -0.481047   \n",
       "1       1.733147       -0.792422   -1.214717   1.667414  ... -0.481047   \n",
       "2      -1.179993        0.037548    0.890112   1.165953  ...  3.185312   \n",
       "3      -0.726399        1.824321    0.604625   0.594530  ... -0.481047   \n",
       "4       1.173482       -0.641074   -0.896970   1.074734  ... -0.481047   \n",
       "5      -0.153322       -0.112016   -0.808684   0.420307  ... -0.481047   \n",
       "6      -0.144929       -0.354147   -0.875554  -0.234940  ... -0.481047   \n",
       "7       0.037635        1.883797    0.043870  -0.220459  ...  0.130013   \n",
       "8      -1.969586        0.775173    1.894746  -0.514873  ... -0.481047   \n",
       "9       0.102448       -0.952498   -0.550921  -0.093317  ... -0.481047   \n",
       "10      0.307035       -0.181434    1.239822  -1.284026  ...  4.407432   \n",
       "11     -1.741895        0.435289    0.543441  -1.203464  ... -0.481047   \n",
       "12      2.166329       -0.244202   -0.934151   1.051676  ...  0.741073   \n",
       "13     -1.403186        1.918375    0.679551   0.759860  ...  0.130013   \n",
       "14     -1.056968       -0.814016   -0.012262  -0.508717  ...       NaN   \n",
       "15     -0.484329        0.125520   -0.333984   0.112297  ... -0.481047   \n",
       "16      0.037226       -0.440819    1.717354  -0.619247  ... -0.481047   \n",
       "17      1.335272       -0.120932    0.888598   0.654845  ...  0.741073   \n",
       "18      1.049598       -0.846483   -0.698861  -0.372371  ...  0.130013   \n",
       "19      0.055946       -0.797012   -1.296782  -0.682217  ... -0.481047   \n",
       "20     -1.836873       -0.596604    1.380335  -1.094908  ... -0.481047   \n",
       "21     -0.637518       -0.762489    0.589414  -0.240613  ... -0.481047   \n",
       "22      0.472902       -1.008794   -1.758893  -0.249936  ... -0.481047   \n",
       "23     -0.416968       -0.098077   -0.044713  -1.541578  ...  0.130013   \n",
       "24      0.228411        0.223450   -0.771529   0.539994  ...       NaN   \n",
       "25      1.185103       -0.787893   -0.020519   1.037606  ...  0.130013   \n",
       "26     -0.211607       -0.552299    2.597438  -2.036774  ... -0.481047   \n",
       "27     -0.990191       -0.960068   -0.079338  -2.306412  ... -0.481047   \n",
       "28      0.818409        0.589438   -0.217182   0.888461  ... -0.481047   \n",
       "29      1.116691       -0.266125   -0.607327   1.025875  ... -0.481047   \n",
       "30      0.557110       -1.005811   -1.199469   0.492193  ... -0.481047   \n",
       "31     -0.074593       -0.954135    2.056615  -1.078172  ...  1.352133   \n",
       "32     -0.472679        0.081959    0.367029   0.029686  ...  0.130013   \n",
       "33     -0.189540       -0.920529   -0.991231  -0.140990  ...  0.130013   \n",
       "34      0.203814        1.703932    1.197589  -0.037316  ... -0.481047   \n",
       "35     -2.776054        0.006325    0.139923  -0.954520  ...  0.130013   \n",
       "36      1.132000       -0.516649   -1.928853  -0.858756  ... -0.481047   \n",
       "37      0.125028        0.006753    0.701700  -0.306187  ... -0.481047   \n",
       "38      0.754629       -0.869962   -0.567130  -0.002461  ... -0.481047   \n",
       "39     -1.215703       -0.519746    0.702962  -1.858657  ... -0.481047   \n",
       "40     -0.362921        1.724976    0.361804   1.333659  ... -0.481047   \n",
       "41     -0.230532        2.680025    0.786474   1.211368  ...  0.741073   \n",
       "42      1.394870       -0.561670    0.177261   0.085859  ... -0.481047   \n",
       "43      0.453507        2.826081   -0.666676  -0.339041  ...       NaN   \n",
       "44     -0.024994       -0.819329    0.120433  -0.114165  ... -0.481047   \n",
       "45      1.445662        1.096476   -0.806882   2.566615  ...  2.574252   \n",
       "46      0.116055        0.180092   -0.635409   0.152728  ...  0.130013   \n",
       "47     -0.591524        0.089511    0.865441   0.271418  ... -0.481047   \n",
       "48      0.465732        1.037513   -0.882899   2.012399  ... -0.481047   \n",
       "49      0.654083       -0.895203   -0.466281  -0.430643  ... -0.481047   \n",
       "\n",
       "          Q8        Q9       Q10       Q11       Q12       Q14  TOTAL11  \\\n",
       "0  -1.320569 -0.147442 -0.245256 -0.423334 -0.245256 -0.844484     3.00   \n",
       "1   0.757249 -0.147442 -0.245256 -0.423334 -0.245256 -0.844484     9.00   \n",
       "2        NaN -0.147442  2.636499 -0.423334 -0.245256  0.478541    24.00   \n",
       "3   0.757249 -0.147442 -0.245256 -0.423334 -0.245256  0.478541     9.67   \n",
       "4  -1.320569 -0.147442 -0.245256 -0.423334 -0.245256  0.478541     2.00   \n",
       "5  -1.320569 -0.147442 -0.245256  1.566335 -0.245256 -0.844484     2.33   \n",
       "6  -0.073878 -0.147442 -0.245256 -0.423334 -0.245256 -0.844484     5.00   \n",
       "7  -0.073878 -0.147442 -0.245256  1.566335  2.636499  0.478541    12.00   \n",
       "8  -0.489442 -0.147442 -0.245256  1.566335 -0.245256 -0.844484    10.33   \n",
       "9  -0.489442 -0.147442 -0.245256 -0.423334 -0.245256 -0.844484     7.00   \n",
       "10 -0.073878 -0.147442 -0.245256 -0.423334 -0.245256 -0.844484    18.00   \n",
       "11 -0.073878 -0.147442 -0.245256 -0.423334 -0.245256  0.478541     7.67   \n",
       "12 -0.073878 -0.147442  5.518254  3.556004  5.518254  0.478541    17.00   \n",
       "13 -0.489442 -0.147442 -0.245256 -0.423334 -0.245256  0.478541     9.67   \n",
       "14       NaN       NaN       NaN       NaN       NaN       NaN      NaN   \n",
       "15  0.341686 -0.147442 -0.245256 -0.423334 -0.245256 -0.844484     9.33   \n",
       "16  0.757249 -0.147442 -0.245256 -0.423334 -0.245256 -0.844484     8.00   \n",
       "17  0.757249 -0.147442  2.636499 -0.423334 -0.245256 -0.844484    13.00   \n",
       "18 -0.905005 -0.147442 -0.245256 -0.423334 -0.245256  0.478541     7.00   \n",
       "19 -0.073878 -0.147442 -0.245256 -0.423334 -0.245256 -0.844484     5.00   \n",
       "20  0.341686 -0.147442 -0.245256 -0.423334 -0.245256 -0.844484     9.33   \n",
       "21 -0.073878 -0.147442 -0.245256 -0.423334 -0.245256  0.478541    10.00   \n",
       "22 -1.320569 -0.147442 -0.245256 -0.423334 -0.245256 -0.844484     3.00   \n",
       "23 -0.073878 -0.147442 -0.245256 -0.423334 -0.245256 -0.844484     7.67   \n",
       "24       NaN       NaN       NaN       NaN       NaN       NaN      NaN   \n",
       "25 -1.320569 -0.147442 -0.245256  1.566335  2.636499  1.801566    13.67   \n",
       "26  0.341686 -0.147442 -0.245256 -0.423334 -0.245256 -0.844484     9.00   \n",
       "27 -1.320569 -0.147442 -0.245256 -0.423334 -0.245256 -0.844484     0.00   \n",
       "28 -1.320569 -0.147442 -0.245256 -0.423334 -0.245256  0.478541     2.00   \n",
       "29  1.588377 -0.147442 -0.245256 -0.423334 -0.245256 -0.844484    14.00   \n",
       "30 -1.320569 -0.147442 -0.245256  1.566335 -0.245256 -0.844484     5.00   \n",
       "31  2.419504 -0.147442 -0.245256 -0.423334 -0.245256  1.801566    18.00   \n",
       "32 -0.073878 -0.147442 -0.245256 -0.423334 -0.245256  1.801566    10.00   \n",
       "33 -0.905005 -0.147442 -0.245256 -0.423334 -0.245256 -0.844484     4.00   \n",
       "34 -0.073878 -0.147442 -0.245256 -0.423334 -0.245256 -0.844484     7.00   \n",
       "35 -0.073878 -0.147442 -0.245256 -0.423334 -0.245256 -0.844484    11.33   \n",
       "36  1.172813 -0.147442 -0.245256 -0.423334 -0.245256  0.478541    11.00   \n",
       "37 -0.073878 -0.147442 -0.245256 -0.423334 -0.245256  1.801566     9.00   \n",
       "38 -0.073878 -0.147442 -0.245256 -0.423334 -0.245256 -0.844484     6.67   \n",
       "39  1.172813 -0.147442 -0.245256 -0.423334 -0.245256  0.478541    10.67   \n",
       "40 -0.489442 -0.147442 -0.245256 -0.423334 -0.245256  1.801566     6.33   \n",
       "41  0.757249 -0.147442 -0.245256 -0.423334 -0.245256  1.801566    11.67   \n",
       "42  2.003940 -0.147442 -0.245256 -0.423334 -0.245256 -0.844484    15.33   \n",
       "43       NaN       NaN       NaN       NaN       NaN       NaN      NaN   \n",
       "44 -0.905005 -0.147442 -0.245256  3.556004 -0.245256  1.801566     8.00   \n",
       "45  1.588377  6.782330 -0.245256  1.566335 -0.245256  0.478541    23.00   \n",
       "46  2.419504 -0.147442 -0.245256 -0.423334 -0.245256  1.801566    16.00   \n",
       "47       NaN -0.147442 -0.245256 -0.423334 -0.245256 -0.844484    13.67   \n",
       "48 -0.073878 -0.147442 -0.245256 -0.423334 -0.245256 -0.844484     6.33   \n",
       "49 -0.905005 -0.147442 -0.245256 -0.423334 -0.245256  0.478541     4.00   \n",
       "\n",
       "    TOTALMOD  Diagnosis  \n",
       "0  -1.143189    Control  \n",
       "1  -0.231785    Control  \n",
       "2   2.632629        MCI  \n",
       "3   0.376252  Alzheimer  \n",
       "4  -1.273390        MCI  \n",
       "5  -1.360624  Alzheimer  \n",
       "6  -1.012989        MCI  \n",
       "7   0.940021  Alzheimer  \n",
       "8  -0.058618        MCI  \n",
       "9  -0.101584    Control  \n",
       "10  1.070221        MCI  \n",
       "11 -0.014350        MCI  \n",
       "12  1.591024        MCI  \n",
       "13  0.376252    Control  \n",
       "14       NaN        MCI  \n",
       "15 -0.188819    Control  \n",
       "16 -0.752587        MCI  \n",
       "17  0.679620    Control  \n",
       "18 -0.361985        MCI  \n",
       "19 -1.143189    Control  \n",
       "20 -0.319019    Control  \n",
       "21  0.158817    Control  \n",
       "22 -1.403590  Alzheimer  \n",
       "23 -0.144550    Control  \n",
       "24       NaN  Alzheimer  \n",
       "25  0.897055        MCI  \n",
       "26  0.289018        MCI  \n",
       "27 -1.924393    Control  \n",
       "28 -1.403590        MCI  \n",
       "29  1.070221  Alzheimer  \n",
       "30 -1.012989    Control  \n",
       "31  1.721225    Control  \n",
       "32  0.549419    Control  \n",
       "33 -1.143189    Control  \n",
       "34 -0.492186        MCI  \n",
       "35  0.462185        MCI  \n",
       "36  0.028616        MCI  \n",
       "37 -0.101584    Control  \n",
       "38 -0.274751    Control  \n",
       "39  0.246051        MCI  \n",
       "40 -0.579420    Control  \n",
       "41  0.766854    Control  \n",
       "42  0.982987  Alzheimer  \n",
       "43       NaN        MCI  \n",
       "44 -0.231785        MCI  \n",
       "45  2.242027  Alzheimer  \n",
       "46  1.460823  Alzheimer  \n",
       "47 -0.014350        MCI  \n",
       "48 -0.970022        MCI  \n",
       "49 -0.882788        MCI  \n",
       "\n",
       "[50 rows x 76 columns]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = cal_palm.standardize_columns(cols_not_to_standardize)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>CerebellumSBM</th>\n",
       "      <th>CerebellumCSF</th>\n",
       "      <th>CerebellumGM</th>\n",
       "      <th>CerebellumWM</th>\n",
       "      <th>FrontalSurface</th>\n",
       "      <th>FrontalCSF</th>\n",
       "      <th>FrontalGM</th>\n",
       "      <th>...</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>Q11</th>\n",
       "      <th>Q12</th>\n",
       "      <th>Q14</th>\n",
       "      <th>TOTAL11</th>\n",
       "      <th>TOTALMOD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>4.900000e+01</td>\n",
       "      <td>4.900000e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>4.700000e+01</td>\n",
       "      <td>4.700000e+01</td>\n",
       "      <td>4.500000e+01</td>\n",
       "      <td>4.700000e+01</td>\n",
       "      <td>4.700000e+01</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>4.700000e+01</td>\n",
       "      <td>4.700000e+01</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>4.700000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.401707e-16</td>\n",
       "      <td>-6.570708e-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.066192e-17</td>\n",
       "      <td>-1.332268e-17</td>\n",
       "      <td>-4.218847e-17</td>\n",
       "      <td>8.659740e-17</td>\n",
       "      <td>-8.437695e-17</td>\n",
       "      <td>4.329870e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>8.267618e-17</td>\n",
       "      <td>-3.307047e-17</td>\n",
       "      <td>7.648203e-17</td>\n",
       "      <td>-2.598394e-17</td>\n",
       "      <td>4.724353e-18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.417306e-17</td>\n",
       "      <td>-7.204639e-17</td>\n",
       "      <td>9.461064</td>\n",
       "      <td>1.700767e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.010153</td>\n",
       "      <td>1.010363e+00</td>\n",
       "      <td>1.010363e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.010153e+00</td>\n",
       "      <td>1.010153e+00</td>\n",
       "      <td>1.010153e+00</td>\n",
       "      <td>1.010153e+00</td>\n",
       "      <td>1.010153e+00</td>\n",
       "      <td>1.010153e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.010811e+00</td>\n",
       "      <td>1.010811e+00</td>\n",
       "      <td>1.011300e+00</td>\n",
       "      <td>1.010811e+00</td>\n",
       "      <td>1.010811e+00</td>\n",
       "      <td>1.010811</td>\n",
       "      <td>1.010811e+00</td>\n",
       "      <td>1.010811e+00</td>\n",
       "      <td>5.263988</td>\n",
       "      <td>1.010811e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.697749</td>\n",
       "      <td>-2.028876e+00</td>\n",
       "      <td>-1.312335e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.931254e+00</td>\n",
       "      <td>-2.346306e+00</td>\n",
       "      <td>-2.776054e+00</td>\n",
       "      <td>-1.008794e+00</td>\n",
       "      <td>-1.928853e+00</td>\n",
       "      <td>-2.306412e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.825460e-01</td>\n",
       "      <td>-4.810471e-01</td>\n",
       "      <td>-1.320569e+00</td>\n",
       "      <td>-1.474420e-01</td>\n",
       "      <td>-2.452557e-01</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-2.452557e-01</td>\n",
       "      <td>-8.444843e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.924393e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.848875</td>\n",
       "      <td>-6.248511e-01</td>\n",
       "      <td>-1.312335e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.352197e-01</td>\n",
       "      <td>-4.610091e-01</td>\n",
       "      <td>-4.814164e-01</td>\n",
       "      <td>-7.958643e-01</td>\n",
       "      <td>-7.980435e-01</td>\n",
       "      <td>-5.133341e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.825460e-01</td>\n",
       "      <td>-4.810471e-01</td>\n",
       "      <td>-9.050053e-01</td>\n",
       "      <td>-1.474420e-01</td>\n",
       "      <td>-2.452557e-01</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-2.452557e-01</td>\n",
       "      <td>-8.444843e-01</td>\n",
       "      <td>6.330000</td>\n",
       "      <td>-8.176877e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.450936e-02</td>\n",
       "      <td>7.620008e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.435112e-01</td>\n",
       "      <td>1.307813e-01</td>\n",
       "      <td>3.743017e-02</td>\n",
       "      <td>-2.551634e-01</td>\n",
       "      <td>-3.261603e-02</td>\n",
       "      <td>-6.531648e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.825460e-01</td>\n",
       "      <td>-4.810471e-01</td>\n",
       "      <td>-7.387799e-02</td>\n",
       "      <td>-1.474420e-01</td>\n",
       "      <td>-2.452557e-01</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-2.452557e-01</td>\n",
       "      <td>-8.444843e-01</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>-1.015842e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.848875</td>\n",
       "      <td>9.315618e-01</td>\n",
       "      <td>7.620008e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.217376e-01</td>\n",
       "      <td>4.328740e-01</td>\n",
       "      <td>6.298398e-01</td>\n",
       "      <td>2.126104e-01</td>\n",
       "      <td>6.961625e-01</td>\n",
       "      <td>6.397661e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.825460e-01</td>\n",
       "      <td>1.300127e-01</td>\n",
       "      <td>7.572493e-01</td>\n",
       "      <td>-1.474420e-01</td>\n",
       "      <td>-2.452557e-01</td>\n",
       "      <td>-0.423334</td>\n",
       "      <td>-2.452557e-01</td>\n",
       "      <td>4.785411e-01</td>\n",
       "      <td>11.835000</td>\n",
       "      <td>6.145193e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.697749</td>\n",
       "      <td>1.797100e+00</td>\n",
       "      <td>7.620008e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.683101e+00</td>\n",
       "      <td>2.488288e+00</td>\n",
       "      <td>2.166329e+00</td>\n",
       "      <td>2.826081e+00</td>\n",
       "      <td>2.597438e+00</td>\n",
       "      <td>2.566615e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.614065e+00</td>\n",
       "      <td>4.407432e+00</td>\n",
       "      <td>2.419504e+00</td>\n",
       "      <td>6.782330e+00</td>\n",
       "      <td>5.518254e+00</td>\n",
       "      <td>3.556004</td>\n",
       "      <td>5.518254e+00</td>\n",
       "      <td>1.801566e+00</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2.632629e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         subject           Age           Sex  CerebellumSBM  CerebellumCSF  \\\n",
       "count  50.000000  4.900000e+01  4.900000e+01            0.0   5.000000e+01   \n",
       "mean    0.000000 -2.401707e-16 -6.570708e-17            NaN  -4.066192e-17   \n",
       "std     1.010153  1.010363e+00  1.010363e+00            NaN   1.010153e+00   \n",
       "min    -1.697749 -2.028876e+00 -1.312335e+00            NaN  -1.931254e+00   \n",
       "25%    -0.848875 -6.248511e-01 -1.312335e+00            NaN  -7.352197e-01   \n",
       "50%     0.000000  7.450936e-02  7.620008e-01            NaN  -1.435112e-01   \n",
       "75%     0.848875  9.315618e-01  7.620008e-01            NaN   6.217376e-01   \n",
       "max     1.697749  1.797100e+00  7.620008e-01            NaN   3.683101e+00   \n",
       "\n",
       "       CerebellumGM  CerebellumWM  FrontalSurface    FrontalCSF     FrontalGM  \\\n",
       "count  5.000000e+01  5.000000e+01    5.000000e+01  5.000000e+01  5.000000e+01   \n",
       "mean  -1.332268e-17 -4.218847e-17    8.659740e-17 -8.437695e-17  4.329870e-17   \n",
       "std    1.010153e+00  1.010153e+00    1.010153e+00  1.010153e+00  1.010153e+00   \n",
       "min   -2.346306e+00 -2.776054e+00   -1.008794e+00 -1.928853e+00 -2.306412e+00   \n",
       "25%   -4.610091e-01 -4.814164e-01   -7.958643e-01 -7.980435e-01 -5.133341e-01   \n",
       "50%    1.307813e-01  3.743017e-02   -2.551634e-01 -3.261603e-02 -6.531648e-02   \n",
       "75%    4.328740e-01  6.298398e-01    2.126104e-01  6.961625e-01  6.397661e-01   \n",
       "max    2.488288e+00  2.166329e+00    2.826081e+00  2.597438e+00  2.566615e+00   \n",
       "\n",
       "       ...            Q6            Q7            Q8            Q9  \\\n",
       "count  ...  4.700000e+01  4.700000e+01  4.500000e+01  4.700000e+01   \n",
       "mean   ...  8.267618e-17 -3.307047e-17  7.648203e-17 -2.598394e-17   \n",
       "std    ...  1.010811e+00  1.010811e+00  1.011300e+00  1.010811e+00   \n",
       "min    ... -3.825460e-01 -4.810471e-01 -1.320569e+00 -1.474420e-01   \n",
       "25%    ... -3.825460e-01 -4.810471e-01 -9.050053e-01 -1.474420e-01   \n",
       "50%    ... -3.825460e-01 -4.810471e-01 -7.387799e-02 -1.474420e-01   \n",
       "75%    ... -3.825460e-01  1.300127e-01  7.572493e-01 -1.474420e-01   \n",
       "max    ...  2.614065e+00  4.407432e+00  2.419504e+00  6.782330e+00   \n",
       "\n",
       "                Q10        Q11           Q12           Q14    TOTAL11  \\\n",
       "count  4.700000e+01  47.000000  4.700000e+01  4.700000e+01  47.000000   \n",
       "mean   4.724353e-18   0.000000  1.417306e-17 -7.204639e-17   9.461064   \n",
       "std    1.010811e+00   1.010811  1.010811e+00  1.010811e+00   5.263988   \n",
       "min   -2.452557e-01  -0.423334 -2.452557e-01 -8.444843e-01   0.000000   \n",
       "25%   -2.452557e-01  -0.423334 -2.452557e-01 -8.444843e-01   6.330000   \n",
       "50%   -2.452557e-01  -0.423334 -2.452557e-01 -8.444843e-01   9.000000   \n",
       "75%   -2.452557e-01  -0.423334 -2.452557e-01  4.785411e-01  11.835000   \n",
       "max    5.518254e+00   3.556004  5.518254e+00  1.801566e+00  24.000000   \n",
       "\n",
       "           TOTALMOD  \n",
       "count  4.700000e+01  \n",
       "mean   1.700767e-16  \n",
       "std    1.010811e+00  \n",
       "min   -1.924393e+00  \n",
       "25%   -8.176877e-01  \n",
       "50%   -1.015842e-01  \n",
       "75%    6.145193e-01  \n",
       "max    2.632629e+00  \n",
       "\n",
       "[8 rows x 75 columns]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Perform Basic Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables to Correlate\n",
    "- dependent_variable = 'Z_Scored_Percent_Cognitive_Improvement'\n",
    "- independent_variable_list = ['Z_Scored_Cognitive_Baseline']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject', 'Age', 'Sex', 'CerebellumSBM', 'CerebellumCSF',\n",
       "       'CerebellumGM', 'CerebellumWM', 'FrontalSurface', 'FrontalCSF',\n",
       "       'FrontalGM', 'FrontalWM', 'InsularSurface', 'InsularCSF', 'InsularGM',\n",
       "       'InsularWM', 'MTLSurface', 'MTLCSF', 'MTLGM', 'MTLWM',\n",
       "       'OccipitalSurface', 'OccipitalCSF', 'OccipitalGM', 'OccipitalWM',\n",
       "       'ParietalSurface', 'ParietalCSF', 'ParietalGM', 'ParietalWM',\n",
       "       'TemporalSurface', 'TemporalCSF', 'TemporalGM', 'TemporalWM',\n",
       "       'SubcortexSurface', 'SubcortexSurfaceVentricle', 'SubcortexCSF',\n",
       "       'SubcortexGM', 'SubcortexWM', 'WholeBrainSurface', 'WholeBrainCSF',\n",
       "       'WholeBrainGM', 'WholeBrainWM', 'temp_ins_csf', 'temp_ins_gm',\n",
       "       'temp_ins_wm', 'temp_ins_surface', 'frontal', 'temporal', 'parietal',\n",
       "       'occipital', 'cerebellum', 'Mesial_Temporal', 'ventricle',\n",
       "       'cerebellar_vermis', 'cerebellar_fissures', 'frontal_eh', 'temporal_eh',\n",
       "       'parietal_eh', 'occipital_eh', 'cerebellum_eh', 'mesial_temporal_eh',\n",
       "       'ventricle_eh', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9',\n",
       "       'Q10', 'Q11', 'Q12', 'Q14', 'TOTAL11', 'TOTALMOD', 'Diagnosis'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_columns = [col for col in data_df.columns if 'occipital' in col.lower()]\n",
    "print(filtered_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_variables_list = ['TOTALMOD']\n",
    "x_variable_list = [ 'FrontalCSF', 'ParietalCSF','OccipitalCSF',  'TemporalCSF', 'MTLCSF', 'CerebellumCSF', 'temp_ins_csf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter a column for categories (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = 'City'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose Correlation Method\n",
    "- Options: 'spearman', 'pearson', 'kendall'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = 'pearson'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define plot Labels\n",
    "- These are the axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Axis Labels\n",
    "x_label = 'Brain Region'\n",
    "y_label = 'Correlation to Clinician (z)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.statistical_utils.scatterplot import ScatterplotGenerator \n",
    "for y_var in y_variables_list:\n",
    "    generator = ScatterplotGenerator(dataframe=data_df, data_dict={y_var: x_variable_list}, \n",
    "                                    x_label=x_label, y_label=y_label, correlation=correlation, \n",
    "                                    palette='tab10',\n",
    "                                    rows_per_fig=1, cols_per_fig=2,\n",
    "                                    ylim=None,\n",
    "                                    out_dir=out_dir,\n",
    "                                    category_col=cat_col)\n",
    "    generator.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrap it\n",
    "- Accepts only 1 x and 1 y var from the above lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "def bootstrap_correlation(data_df, x_var, y_var, n_bootstraps=1000):\n",
    "    correlations = []\n",
    "    \n",
    "    for i in range(n_bootstraps):\n",
    "        # Bootstrap sampling with replacement\n",
    "        bootstrap_sample = data_df.sample(n=len(data_df), replace=True, random_state=i)\n",
    "        \n",
    "        # Calculate correlation\n",
    "        corr, _ = spearmanr(bootstrap_sample[x_var], bootstrap_sample[y_var])\n",
    "        \n",
    "        if corr is not np.nan: correlations.append(corr)\n",
    "    \n",
    "    # Convert to numpy array for easier manipulation\n",
    "    correlations = np.array(correlations)\n",
    "    \n",
    "    # Calculate the required statistics\n",
    "    lower_extreme = np.min(correlations)\n",
    "    lower_quartile = np.percentile(correlations, 25)\n",
    "    median_corr = np.median(correlations)\n",
    "    upper_quartile = np.percentile(correlations, 75)\n",
    "    upper_extreme = np.max(correlations)\n",
    "    \n",
    "    return {\n",
    "        'lower_extreme': lower_extreme,\n",
    "        'lower_quartile': lower_quartile,\n",
    "        'median': median_corr,\n",
    "        'upper_quartile': upper_quartile,\n",
    "        'upper_extreme': upper_extreme\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = bootstrap_correlation(data_df, x_variable_list[0], y_variables_list[0], n_bootstraps=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Based on the Bootstap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_variable_list = [ 'frontal_eh', 'parietal_eh','occipital_eh',  'temporal_eh', 'mesial_temporal_eh', 'cerebellum_eh', 'ventricle_eh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '/Users/cu135/Partners HealthCare Dropbox/Calvin Howard/studies/atrophy_seeds_2023/Figures/association_to_baseline/lineplot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "def bootstrap_correlation(data_df, x_var_list, y_var, n_bootstraps=1000):\n",
    "    x_var_dict = {}\n",
    "    for x_var in x_var_list:\n",
    "        correlations = []\n",
    "        \n",
    "        while len(correlations) < n_bootstraps:\n",
    "            # Bootstrap sampling with replacement\n",
    "            bootstrap_sample = data_df.sample(n=len(data_df), replace=True)\n",
    "            # Calculate correlation\n",
    "            try:\n",
    "                corr, _ = spearmanr(bootstrap_sample[x_var], bootstrap_sample[y_var])\n",
    "            except:\n",
    "                continue\n",
    "            if corr is not np.nan: correlations.append(corr)\n",
    "        # Convert to numpy array for easier manipulation\n",
    "        correlations = np.array(correlations)\n",
    "        x_var_dict[x_var] = correlations\n",
    "        \n",
    "    return x_var_dict\n",
    "\n",
    "def plot_horizontal_lineplot(x_var_dict, out_dir, stdev=True):\n",
    "    \n",
    "    plt.figure(figsize=(len(x_var_dict) * 2, 6))  # Adjust width based on the number of x_vars\n",
    "\n",
    "    x_vars = list(x_var_dict.keys())\n",
    "    means = []\n",
    "    lows = []\n",
    "    highs = []\n",
    "\n",
    "    # Calculate statistics for each x_var\n",
    "    for x_var, correlations in x_var_dict.items():\n",
    "        mean_corr = np.mean(correlations)\n",
    "        means.append(mean_corr)\n",
    "        \n",
    "        if stdev:\n",
    "            low = mean_corr - np.std(correlations)\n",
    "            high = mean_corr + np.std(correlations)\n",
    "        else:\n",
    "            low = np.percentile(correlations, 2.5)\n",
    "            high = np.percentile(correlations, 97.5)\n",
    "        \n",
    "        lows.append(low)\n",
    "        highs.append(high)\n",
    "    \n",
    "    # Plot the confidence interval as a filled area, connecting each point\n",
    "    plt.fill_between(x_vars, lows, highs, color='lightblue', alpha=0.5)\n",
    "    \n",
    "    # Plot the mean correlation as a line\n",
    "    plt.plot(x_vars, means, 'o-', color='blue')\n",
    "    \n",
    "    plt.xlabel('X Variables')\n",
    "    plt.ylabel('Correlation')\n",
    "    plt.title('Line Plot of Mean and 95% CI for Each X Variable')\n",
    "    plt.ylim((-.2, 0.75))\n",
    "    plt.savefig(os.path.join(out_dir, 'nrad_lineplot.svg'))\n",
    "    plt.show()\n",
    "\n",
    "plot_horizontal_lineplot(bootstrap_correlation(data_df, x_var_list=x_variable_list, y_var=y_variables_list[0]), out_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overlay Correlations for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def overlay_lmplots_with_correlation(data_df, ivs, dv, colors=None,labels=['GM', 'WM', 'CT', 'Radiologist', 'CSF']):\n",
    "    \"\"\"\n",
    "    Generate and overlay lmplot graphs for each IV against the DV, with the legend showing the correlation value.\n",
    "\n",
    "    Parameters:\n",
    "    data_df (pd.DataFrame): The dataframe containing the data.\n",
    "    ivs (list of str): List of independent variables (column names) in the dataframe.\n",
    "    dv (str): Dependent variable (column name) in the dataframe.\n",
    "    colors (list of str, optional): List of color hex codes. If None, defaults to 'tab10' palette.\n",
    "\n",
    "    Returns:\n",
    "    None: Displays the plot.\n",
    "    \"\"\"\n",
    "    if colors is None:\n",
    "        colors = sns.color_palette(\"tab10\", len(ivs))\n",
    "    \n",
    "    plt.figure(figsize=(3, 3))\n",
    "    \n",
    "    if labels is None:\n",
    "        labels = ivs\n",
    "    \n",
    "    jitter = 0.08\n",
    "    for i, iv in enumerate(ivs):\n",
    "        jittered_df = data_df.copy()\n",
    "        jittered_df[dv] = jittered_df[dv] + jitter*i\n",
    "        correlation = data_df[iv].corr(data_df[dv], method='spearman')\n",
    "        sns.regplot(\n",
    "            truncate=False,\n",
    "            x=iv, \n",
    "            y=dv, \n",
    "            data=jittered_df, \n",
    "            scatter_kws={\"s\": 20, \"color\": colors[i]},  # Customize scatter plot size and color\n",
    "            line_kws={\"color\": colors[i]}, \n",
    "            ci=None,\n",
    "            label=f'{labels[i]} (r={correlation:.2f})'  # Adding correlation to legend\n",
    "        )\n",
    "        \n",
    "\n",
    "    plt.legend(title=\"Methods\", frameon=False, loc='best')\n",
    "    # plt.ylim(-0.1,3.25)\n",
    "    plt.xlabel(\"Atrophy (Z-score)\")\n",
    "    plt.ylabel('ADAS-Cog 13')\n",
    "    plt.title('Ventricle')\n",
    "    sns.despine()\n",
    "    plt.savefig('/Users/cu135/Partners HealthCare Dropbox/Calvin Howard/studies/atrophy_seeds_2023/Figures/correlation_to_radiologist/radiologist/z_score_correlations/figures_of_each_lobe/Ventricle.svg')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# overlay_lmplots_with_correlation(data_df, ['IV1', 'IV2', 'IV3'], 'DV', ['#1f77b4', '#ff7f0e', '#2ca02c'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject', 'Age', 'Sex', 'CerebellumSBM', 'CerebellumCSF',\n",
       "       'CerebellumGM', 'CerebellumWM', 'FrontalSurface', 'FrontalCSF',\n",
       "       'FrontalGM', 'FrontalWM', 'InsularSurface', 'InsularCSF', 'InsularGM',\n",
       "       'InsularWM', 'MTLSurface', 'MTLCSF', 'MTLGM', 'MTLWM',\n",
       "       'OccipitalSurface', 'OccipitalCSF', 'OccipitalGM', 'OccipitalWM',\n",
       "       'ParietalSurface', 'ParietalCSF', 'ParietalGM', 'ParietalWM',\n",
       "       'TemporalSurface', 'TemporalCSF', 'TemporalGM', 'TemporalWM',\n",
       "       'SubcortexSurface', 'SubcortexSurfaceVentricle', 'SubcortexCSF',\n",
       "       'SubcortexGM', 'SubcortexWM', 'WholeBrainSurface', 'WholeBrainCSF',\n",
       "       'WholeBrainGM', 'WholeBrainWM', 'temp_ins_csf', 'temp_ins_gm',\n",
       "       'temp_ins_wm', 'temp_ins_surface', 'frontal', 'temporal', 'parietal',\n",
       "       'occipital', 'cerebellum', 'Mesial_Temporal', 'ventricle',\n",
       "       'cerebellar_vermis', 'cerebellar_fissures', 'frontal_eh', 'temporal_eh',\n",
       "       'parietal_eh', 'occipital_eh', 'cerebellum_eh', 'mesial_temporal_eh',\n",
       "       'ventricle_eh', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9',\n",
       "       'Q10', 'Q11', 'Q12', 'Q14', 'TOTAL11', 'TOTALMOD', 'Diagnosis'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = 'TOTALMOD'\n",
    "iv_list = [ 'SubcortexGM', 'SubcortexWM', 'SubcortexSurfaceVentricle', 'ventricle_eh', 'SubcortexCSF']\n",
    "colour_list = ['#3A923A', '#C03D3E', '#E1812C', '#9372B2', '#3274A1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "overlay_lmplots_with_correlation(data_df, iv_list, dv, colour_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Run ANCOVA-Style Analysis Using Correlation\n",
    "- AKA a 'Delta-R Analysis'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statannotations.Annotator import Annotator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class ANCOVACorrelation:\n",
    "    \"\"\"\n",
    "    Params:\n",
    "        similarity: Bool\n",
    "            - This determins if the delta-r analysis will be performed to assess if the correlations are MORE SIMILAR THAN EXPECTED.\n",
    "            - Defaults to False, which evalutes if they are MORE DIFFERENCE THAN EXPECTED. \n",
    "        two_tail: Bool\n",
    "            - This determines if a two-tailed p-value derivation will be performed. \n",
    "            - Set to false to generate a one-tail. \n",
    "    \"\"\"\n",
    "    def __init__(self, df, dependent_variable, independent_variable, categorical_variable, spearman=False, out_dir=None, n_permutations=10000, similarity=False, two_tail=True):\n",
    "        self.df = df\n",
    "        self.dependent_variable = dependent_variable\n",
    "        self.independent_variable = independent_variable\n",
    "        self.categorical_variable = categorical_variable\n",
    "        self.out_dir = out_dir\n",
    "        self.similarity = similarity\n",
    "        self.two_tail = two_tail\n",
    "        # Initialize a dictionary to store dataframes for each category\n",
    "        self.category_dataframes = {}\n",
    "        \n",
    "        # Initialize a dictionary to store observed correlations\n",
    "        self.observed_correlations = {}\n",
    "        \n",
    "        # Call the segregator function to split the data\n",
    "        self.segregate_data()\n",
    "        self.spearman=spearman\n",
    "        \n",
    "        self.n_permutations=n_permutations\n",
    "    \n",
    "    def segregate_data(self):\n",
    "        # Group the data by unique values of the categorical variable\n",
    "        unique_categories = self.df[self.categorical_variable].unique()\n",
    "        \n",
    "        # Create separate dataframes for each category\n",
    "        for category in unique_categories:\n",
    "            self.category_dataframes[category] = self.df[self.df[self.categorical_variable] == category]\n",
    "    \n",
    "    def calculate_correlation(self, category):\n",
    "        # Calculate the correlation between independent and dependent variables for a given category\n",
    "        category_df = self.category_dataframes.get(category)\n",
    "        if category_df is not None:\n",
    "            if self.spearman:\n",
    "                correlation = category_df[self.independent_variable].corr(category_df[self.dependent_variable], method='spearman')\n",
    "            else:\n",
    "                correlation = category_df[self.independent_variable].corr(category_df[self.dependent_variable])\n",
    "            self.observed_correlations[category] = correlation\n",
    "        else:\n",
    "            print(f\"Category '{category}' not found in the data.\")\n",
    "\n",
    "            \n",
    "    def calculate_observed_r_values(self):\n",
    "        # Calculate observed r values for each category and store them\n",
    "        self.observed_correlations = {}\n",
    "        for category in self.category_dataframes.keys():\n",
    "            correlation = self.calculate_correlation(category)\n",
    "            if correlation is not None:\n",
    "                self.observed_correlations[category] = correlation\n",
    "\n",
    "    def permute_and_calculate_correlations(self):\n",
    "        # Initialize a dictionary to store permuted correlations for each category\n",
    "        self.permuted_correlations = {category: [] for category in self.category_dataframes.keys()}\n",
    "\n",
    "        for _ in tqdm(range(self.n_permutations), desc=\"Permutations\"):\n",
    "            # Create a copy of the original data to permute\n",
    "            permuted_data = self.df.copy()\n",
    "\n",
    "            # Loop through each category's dataframe\n",
    "            for category, category_df in self.category_dataframes.items():\n",
    "                # Permute the outcomes (dependent variable) within the category's dataframe\n",
    "                category_outcomes = category_df[self.dependent_variable].values\n",
    "                random.shuffle(category_outcomes)\n",
    "                permuted_data.loc[category_df.index, self.dependent_variable] = category_outcomes\n",
    "\n",
    "                # Calculate and store the correlation with the independent variable\n",
    "                correlation = category_df[self.independent_variable].corr(permuted_data.loc[category_df.index, self.dependent_variable])\n",
    "                self.permuted_correlations[category].append(correlation)\n",
    "                \n",
    "    def calculate_p_values(self):\n",
    "        '''\n",
    "        This calculate a two-tailed p-value.\n",
    "        '''\n",
    "        # Initialize a dictionary to store p-values for each category\n",
    "        self.p_values = {category: None for category in self.category_dataframes.keys()}\n",
    "\n",
    "        for category in self.category_dataframes.keys():\n",
    "            observed_val = self.observed_correlations[category]\n",
    "            permuted_dist = self.permuted_correlations[category]\n",
    "\n",
    "            # Calculate the p-value\n",
    "            p_value = np.mean(np.array(np.abs(permuted_dist)) > np.abs(observed_val))\n",
    "\n",
    "            self.p_values[category] = p_value\n",
    "            \n",
    "    def calculate_delta_r(self):\n",
    "        # Initialize a dictionary to store Delta-R values and their significance for each category combination\n",
    "        self.delta_r_values = {}\n",
    "        \n",
    "        # Get all unique combinations of categories\n",
    "        category_combinations = list(itertools.combinations(self.category_dataframes.keys(), 2))\n",
    "\n",
    "        for category1, category2 in category_combinations:\n",
    "            observed_val1 = self.observed_correlations[category1]\n",
    "            observed_val2 = self.observed_correlations[category2]\n",
    "\n",
    "            # Get the permuted distributions for both categories\n",
    "            permuted_dist1 = self.permuted_correlations[category1]\n",
    "            permuted_dist2 = self.permuted_correlations[category2]\n",
    "\n",
    "            delta_r = observed_val1 - observed_val2\n",
    "            delta_r_permuted = np.array(permuted_dist1) - np.array(permuted_dist2)\n",
    "\n",
    "            # Calculate the significance using a two-tailed test\n",
    "            if self.two_tail:\n",
    "                delta_r = np.abs(delta_r)\n",
    "                delta_r_permuted = np.abs(delta_r_permuted)\n",
    "            if self.similarity:\n",
    "                p_value = np.mean(delta_r_permuted < delta_r)\n",
    "            else:\n",
    "                p_value = np.mean(delta_r_permuted > delta_r)\n",
    "            # Store the Delta-R value and its significance\n",
    "            self.delta_r_values[(category1, category2)] = {\n",
    "                'delta_r': delta_r,\n",
    "                'p_value': p_value\n",
    "            }\n",
    "\n",
    "    def plot_correlations(self):\n",
    "        # Convert observed correlations data to a DataFrame\n",
    "        observed_data = pd.DataFrame({\n",
    "            'Category': self.observed_correlations.keys(),\n",
    "            'Correlation': self.observed_correlations.values()\n",
    "        })\n",
    "\n",
    "        # Set style and increase font size\n",
    "        sns.set_style(\"white\")\n",
    "        # sns.set(font_scale=1)\n",
    "\n",
    "        # Create the bar plot using the observed data\n",
    "        sns.barplot(x='Category', y='Correlation', data=observed_data, palette='tab10')\n",
    "        sns.despine()\n",
    "        # # Add p-value annotations using Annotator\n",
    "        p_values = [self.delta_r_values[comb]['p_value'] for comb in self.delta_r_values]\n",
    "        combinations = [f'{comb[0]} vs {comb[1]}' for comb in self.delta_r_values]\n",
    "        data = pd.DataFrame({'Combination': combinations, 'p-value': p_values})\n",
    "        # annotator = Annotator(ax=ax, data=data, x='Combination', y='p-value', loc='outside', fontsize=12)\n",
    "\n",
    "        # Save the figure if out_dir is provided\n",
    "        if self.out_dir:\n",
    "            plt.savefig(f\"{self.out_dir}/delta_correlation_plot.png\", bbox_inches='tight')\n",
    "            plt.savefig(f\"{self.out_dir}/delta_correlation_plot.svg\", bbox_inches='tight')\n",
    "            print(f'Saved to {self.out_dir}/delta_correlation_plot.svg')\n",
    "\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "        return observed_data, data\n",
    "        \n",
    "    def run(self):\n",
    "        self.segregate_data()\n",
    "        self.calculate_observed_r_values()\n",
    "        self.permute_and_calculate_correlations()\n",
    "        self.calculate_p_values()\n",
    "        self.calculate_delta_r()\n",
    "        single_data, delta_data = self.plot_correlations()\n",
    "        return single_data, delta_data\n",
    "\n",
    "    def create_combined_plot(self, group_variable, dependent_variable):\n",
    "        sns.set()\n",
    "\n",
    "        fig, ax = plt.subplots(nrows=len(self.df[group_variable].unique()), sharex=True)\n",
    "        ax[-1].set_xlabel(dependent_variable)\n",
    "\n",
    "        for i, group_val in enumerate(self.df[group_variable].unique()):\n",
    "            group_data = self.df[self.df[group_variable] == group_val][dependent_variable]\n",
    "            jittered_group_data = group_data + 0.1 * (2 * random.random() - 1)  # Add small vertical jitter\n",
    "            ax[i].scatter(jittered_group_data, [0] * len(group_data))\n",
    "            sns.kdeplot(group_data, ax=ax[i], shade=False, legend=False)\n",
    "            ax[i].set_yticks([])\n",
    "            ax[i].set_ylim(-0.01)\n",
    "            ax[i].set_ylabel(f'{group_variable} ' + str(group_val))\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_correlations_with_lmplot(self, palette='Tab10'):\n",
    "        # Using seaborn's lmplot to plot linear regression lines for each category\n",
    "        if self.spearman:\n",
    "            print('Have rank-transformed data for visualization of Spearman correlation.')\n",
    "            self.df = self.df.rank()\n",
    "        lm = sns.lmplot(x=self.independent_variable, y=self.dependent_variable, \n",
    "                        hue=self.categorical_variable, data=self.df, \n",
    "                        aspect=1.5, height=5, palette=palette, legend=False, ci=0)\n",
    "\n",
    "        # Enhancements for better readability\n",
    "        lm.set_xlabels(f\"{self.independent_variable}\")\n",
    "        lm.set_ylabels(f\"{self.dependent_variable}\")\n",
    "        plt.title(\"Correlation Split by Category\")\n",
    "        plt.legend()\n",
    "        # Save the figure if out_dir is provided\n",
    "        if self.out_dir:\n",
    "            plt.savefig(f\"{self.out_dir}/delta_correlation_plot.png\", bbox_inches='tight')\n",
    "            plt.savefig(f\"{self.out_dir}/delta_correlation_plot.svg\", bbox_inches='tight')\n",
    "            print(f'Saved to {self.out_dir}/delta_correlation_plot.svg')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter Variables\n",
    "- dependent_variable: the name of the dependent variable\n",
    "- independent_variable: the name of the independent variable\n",
    "- categorical_variable: the column containing categorical information. This may be strings or numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent_variable = 'Z_Scored_Percent_Cognitive_Improvement'\n",
    "independent_variable_list = ['Z_Scored_Subiculum_Connectivity_T', 'Age_Group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Reshaping the DataFrame\n",
    "melted_df = pd.melt(data_df, id_vars=[dependent_variable], value_vars=independent_variable_list, \n",
    "                    var_name='Category', value_name='Value')\n",
    "melted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent_variable = 'Percent_Cognitive_Improvement'\n",
    "independent_variable = 'Subiculum_Connectivity_T_Redone'\n",
    "categorical_variable = 'Age_Group'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do You Want to Run A Spearman Correlation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman = True\n",
    "two_tail = True\n",
    "similarity = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Run the Correlational ANCOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_r = ANCOVACorrelation(df=data_df, dependent_variable=dependent_variable, independent_variable=independent_variable, categorical_variable=categorical_variable, out_dir=out_dir, spearman=spearman,\n",
    "                            n_permutations=10000, similarity=similarity, two_tail=two_tail)\n",
    "single_data, delta_data = delta_r.run()\n",
    "delta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the Output CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.path.join(out_dir, f'{dependent_variable}_delta_rho.csv'))\n",
    "delta_data.to_csv(os.path.join(out_dir, '{dependent_variable}_delta_rho.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Correlational ANCOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming data_prep and category_dataframes are already defined\n",
    "dependent_variable = 'Z_Scored_Percent_Cognitive_Improvement'\n",
    "independent_variable = 'Age'\n",
    "categorical_variable = 'Subiculum_Group_By_Inflection_Point'\n",
    "cohort_variable = 'City'\n",
    "correlation_method = 'pearson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class DataPreparation:\n",
    "    \"\"\"\n",
    "    A class used to segregate data by categorical variables and optional cohorts.\n",
    "\n",
    "    Attributes:\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The input dataframe containing the data.\n",
    "    dependent_variable : str\n",
    "        The name of the dependent variable column.\n",
    "    independent_variable : str\n",
    "        The name of the independent variable column.\n",
    "    categorical_variable : str\n",
    "        The name of the categorical variable column used for splitting.\n",
    "    cohort_variable : str, optional\n",
    "        The name of the cohort variable column used for additional splitting. Default is None.\n",
    "\n",
    "    Methods:\n",
    "    -------\n",
    "    segregate_data():\n",
    "        Splits the dataframe into nested dictionaries by cohort and category.\n",
    "\n",
    "    Example Usage:\n",
    "    -------------\n",
    "    dependent_variable = 'Z_Scored_Percent_Cognitive_Improvement'\n",
    "    independent_variable = 'Subiculum_Connectivity_T_Redone'\n",
    "    categorical_variable = 'Age_Group'\n",
    "    cohort_variable = 'City'  # Optional, can be None if not needed\n",
    "\n",
    "    data_prep = DataPreparation(data_df, dependent_variable, independent_variable, categorical_variable, cohort_variable)\n",
    "    category_dataframes = data_prep.category_dataframes\n",
    "\n",
    "    for cohort, categories in category_dataframes.items():\n",
    "        print(f\"Cohort: {cohort}\")\n",
    "        for category, cat_df in categories.items():\n",
    "            print(f\"  Category: {category}\")\n",
    "            print(cat_df.head())\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df, dependent_variable, independent_variable, categorical_variable, cohort_variable=None):\n",
    "        self.dependent_variable = dependent_variable\n",
    "        self.independent_variable = independent_variable\n",
    "        self.categorical_variable = categorical_variable\n",
    "        self.cohort_variable = cohort_variable\n",
    "        self.df = self.prepare_dataframe(df)\n",
    "        self.category_dataframes = self.segregate_data()\n",
    "        self.category_dataframes = self.reverse_dictionary()\n",
    "        \n",
    "    def prepare_dataframe(self, df):\n",
    "        if self.cohort_variable is None:\n",
    "            df = df.loc[:, [self.dependent_variable, self.independent_variable, self.categorical_variable]]\n",
    "        else:\n",
    "            df = df.loc[:, [self.dependent_variable, self.independent_variable, self.categorical_variable, self.cohort_variable]]\n",
    "        return df\n",
    "    \n",
    "    def segregate_data(self):\n",
    "        \"\"\"\n",
    "        Splits the dataframe into nested dictionaries by cohort and category.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        dict\n",
    "            A nested dictionary where data is first split by cohort (if provided) and then by category.\n",
    "            Each entry corresponds to a subset of the data for a specific cohort and category.\n",
    "        \"\"\"\n",
    "        # Initialize dictionary to hold dataframes for each category\n",
    "        category_dataframes = {}\n",
    "        unique_categories = self.df[self.categorical_variable].unique()\n",
    "        # We do not need to split by cohort, as we can iterate over each cohort during plotting. \n",
    "        for category in unique_categories:\n",
    "            category_dataframes[category] = self.df[self.df[self.categorical_variable] == category]\n",
    "        category_dataframes['all_categories'] = self.df\n",
    "        return category_dataframes\n",
    "    \n",
    "    def reverse_dictionary(self):\n",
    "        reversed_dict = {k: self.category_dataframes[k] for k in reversed(self.category_dataframes)}\n",
    "        return reversed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ScatterPlot:\n",
    "    \"\"\"\n",
    "    A class to create scatter plots with linear regression lines for each category and cohort.\n",
    "\n",
    "    Attributes:\n",
    "    ----------\n",
    "    data_prep : DataPreparation\n",
    "        An instance of the DataPreparation class containing the processed data.\n",
    "    colors : list\n",
    "        List of colors for each category.\n",
    "\n",
    "    Methods:\n",
    "    -------\n",
    "    get_colors(colors_list):\n",
    "        Generates a list of colors for plotting.\n",
    "    get_scatterplots():\n",
    "        Creates scatter plots with linear regression lines for each category and cohort.\n",
    "    plot():\n",
    "        Plots the scatter plots.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_prep, colors_list=None, confidence_intervals=False):\n",
    "        self.data_prep = data_prep\n",
    "        self.colors = self.get_colors(colors_list)\n",
    "        self.scatterplots_dict = self.get_scatterplots(confidence_intervals)\n",
    "        \n",
    "    def get_colors(self, colors_list):\n",
    "        if colors_list is not None:\n",
    "            return sns.color_palette(colors_list, len(self.data_prep.df[self.data_prep.cohort_variable].unique()))\n",
    "        else:\n",
    "            return sns.color_palette(\"tab10\", len(self.data_prep.df[self.data_prep.cohort_variable].unique()))\n",
    "\n",
    "    def get_scatterplots(self,confidence_intervals):\n",
    "        scatterplots_dict = {}\n",
    "        for name, dataframe in self.data_prep.category_dataframes.items():\n",
    "            fig, ax = plt.subplots(figsize=(6, 6))\n",
    "            \n",
    "            if self.data_prep.cohort_variable is not None: \n",
    "                for i, cohort in enumerate(dataframe[self.data_prep.cohort_variable].unique()):\n",
    "                    cohort_df = dataframe[dataframe[self.data_prep.cohort_variable] == cohort]\n",
    "                    sns.regplot(x=self.data_prep.independent_variable, \n",
    "                                y=self.data_prep.dependent_variable, \n",
    "                                data=cohort_df, ax=ax, label=cohort, color=self.colors[i],\n",
    "                                ci=confidence_intervals)\n",
    "            else:\n",
    "                sns.regplot(x=self.data_prep.independent_variable, \n",
    "                            y=self.data_prep.dependent_variable, \n",
    "                            data=dataframe, ax=ax, label=name, color=self.colors[0],\n",
    "                            ci=confidence_intervals)\n",
    "                \n",
    "            ax.legend()\n",
    "            plt.title(name)\n",
    "            plt.tight_layout()\n",
    "            scatterplots_dict[name] = fig\n",
    "            plt.close()\n",
    "\n",
    "        return scatterplots_dict\n",
    "\n",
    "    def plot(self):\n",
    "        import warnings\n",
    "        for name, fig in self.scatterplots_dict.items():\n",
    "            try:\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter(\"error\", UserWarning)\n",
    "                    fig.show()\n",
    "            except UserWarning:\n",
    "                from IPython.display import display\n",
    "                display(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "class BarPlot:\n",
    "    \"\"\"\n",
    "    A class to create bar plots summarizing the correlation strengths for each category and cohort.\n",
    "\n",
    "    Attributes:\n",
    "    ----------\n",
    "    data_prep : DataPreparation\n",
    "        An instance of the DataPreparation class containing the processed data.\n",
    "    colors : list\n",
    "        List of colors for each cohort.\n",
    "\n",
    "    Methods:\n",
    "    -------\n",
    "    get_colors(colors_list):\n",
    "        Generates a list of colors for plotting.\n",
    "    get_barplots(method):\n",
    "        Creates bar plots summarizing the correlation strengths for each category and cohort.\n",
    "    plot():\n",
    "        Plots the bar plots.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_prep, colors_list=None, method='pearson'):\n",
    "        self.data_prep = data_prep\n",
    "        self.colors = self.get_colors(colors_list)\n",
    "        self.method = method\n",
    "        self.barplots_dict = self.get_barplots()\n",
    "        self.set_shared_y_limits()\n",
    "        \n",
    "    def get_colors(self, colors_list):\n",
    "        if colors_list is not None:\n",
    "            return sns.color_palette(colors_list, len(self.data_prep.df[self.data_prep.cohort_variable].unique()))\n",
    "        else:\n",
    "            return sns.color_palette(\"tab10\", len(self.data_prep.df[self.data_prep.cohort_variable].unique()))\n",
    "\n",
    "    def get_barplots(self):\n",
    "        barplots_dict = {}\n",
    "        all_correlations = []\n",
    "\n",
    "        for name, dataframe in self.data_prep.category_dataframes.items():\n",
    "            correlations = {}\n",
    "            p_values = {}\n",
    "\n",
    "            if self.data_prep.cohort_variable is not None:\n",
    "                for i, cohort in enumerate(dataframe[self.data_prep.cohort_variable].unique()):\n",
    "                    cohort_df = dataframe[dataframe[self.data_prep.cohort_variable] == cohort]\n",
    "                    if self.method == 'pearson':\n",
    "                        correlation, p_value = pearsonr(cohort_df[self.data_prep.independent_variable], cohort_df[self.data_prep.dependent_variable])\n",
    "                    else:  # spearman\n",
    "                        correlation, p_value = spearmanr(cohort_df[self.data_prep.independent_variable], cohort_df[self.data_prep.dependent_variable])\n",
    "                    correlations[cohort] = correlation\n",
    "                    p_values[cohort] = p_value\n",
    "                    all_correlations.append(correlation)\n",
    "            else:\n",
    "                if self.method == 'pearson':\n",
    "                    correlation, p_value = pearsonr(dataframe[self.data_prep.independent_variable], dataframe[self.data_prep.dependent_variable])\n",
    "                else:  # spearman\n",
    "                    correlation, p_value = spearmanr(dataframe[self.data_prep.independent_variable], dataframe[self.data_prep.dependent_variable])\n",
    "                correlations[name] = correlation\n",
    "                p_values[name] = p_value\n",
    "                all_correlations.append(correlation)\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(6, 6))\n",
    "            bars = sns.barplot(y=list(correlations.keys()), x=list(correlations.values()), ax=ax, palette=self.colors[:len(correlations)])\n",
    "            ax.set_xlabel('Correlation Strength')\n",
    "            ax.set_title(name)\n",
    "\n",
    "            # Outline bars with p-value < 0.05\n",
    "            for j, bar in enumerate(bars.patches):\n",
    "                cohort_name = list(correlations.keys())[j]\n",
    "                if p_values[cohort_name] < 0.05:\n",
    "                    bar.set_edgecolor('black')\n",
    "                    bar.set_linewidth(1.5)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            barplots_dict[name] = fig\n",
    "            plt.close()\n",
    "\n",
    "        self.y_min = min(all_correlations)\n",
    "        self.y_max = max(all_correlations)\n",
    "\n",
    "        return barplots_dict\n",
    "\n",
    "    def set_shared_y_limits(self):\n",
    "        for name, fig in self.barplots_dict.items():\n",
    "            ax = fig.get_axes()[0]\n",
    "            ax.set_xlim(self.y_min, self.y_max)\n",
    "\n",
    "    def plot(self):\n",
    "        import warnings\n",
    "        for name, fig in self.barplots_dict.items():\n",
    "            try:\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter(\"error\", UserWarning)\n",
    "                    fig.show()\n",
    "            except UserWarning:\n",
    "                from IPython.display import display\n",
    "                display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "class CombinedPlotV1:\n",
    "    \"\"\"\n",
    "    A class to create a combined plot of scatter plots and bar plots.\n",
    "\n",
    "    Attributes:\n",
    "    ----------\n",
    "    scatter_plot : ScatterPlot\n",
    "        An instance of the ScatterPlot class containing the scatter plots.\n",
    "    bar_plot : BarPlot\n",
    "        An instance of the BarPlot class containing the bar plots.\n",
    "    out_dir : str\n",
    "        Directory to save the output plot.\n",
    "\n",
    "    Methods:\n",
    "    -------\n",
    "    create_figure():\n",
    "        Creates a combined figure with scatter plots and bar plots.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, scatter_plot, bar_plot, out_dir=None):\n",
    "        self.scatter_plot = scatter_plot\n",
    "        self.bar_plot = bar_plot\n",
    "        self.out_dir = out_dir\n",
    "        self.fig, self.axes = self.create_figure()\n",
    "\n",
    "    def create_figure(self):\n",
    "        \"\"\"\n",
    "        Creates a combined figure with scatter plots and bar plots.\n",
    "        \"\"\"\n",
    "        categories = list(self.scatter_plot.data_prep.category_dataframes.keys())\n",
    "        num_categories = len(categories)\n",
    "\n",
    "        fig, axes = plt.subplots(num_categories, 2, figsize=(15, 6 * num_categories))\n",
    "\n",
    "        for i, category in enumerate(categories):\n",
    "            # Scatter Plot\n",
    "            scatter_ax = axes[i, 0]\n",
    "            scatter_fig = self.scatter_plot.scatterplots_dict[category]\n",
    "            scatter_canvas = scatter_fig.canvas\n",
    "            scatter_canvas.draw()\n",
    "            scatter_image = scatter_canvas.buffer_rgba()\n",
    "            scatter_ax.imshow(scatter_image)\n",
    "            scatter_ax.axis('off')\n",
    "\n",
    "            # Bar Plot\n",
    "            bar_ax = axes[i, 1]\n",
    "            bar_fig = self.bar_plot.barplots_dict[category]\n",
    "            bar_canvas = bar_fig.canvas\n",
    "            bar_canvas.draw()\n",
    "            bar_image = bar_canvas.buffer_rgba()\n",
    "            bar_ax.imshow(bar_image)\n",
    "            bar_ax.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if self.out_dir:\n",
    "            plt.savefig(f\"{self.out_dir}/combined_plot.svg\", format='svg')\n",
    "        plt.close()\n",
    "        return fig, axes\n",
    "    \n",
    "    def plot(self):\n",
    "        import warnings\n",
    "        try:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"error\", UserWarning)\n",
    "                self.fig.show()\n",
    "        except UserWarning:\n",
    "            from IPython.display import display\n",
    "            display(self.fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "contrast cohorts within categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class PermutationAnalysis:\n",
    "    def __init__(self, data_prep, onetail=True, correlation_method='pearson'):\n",
    "        \"\"\"\n",
    "        Params:\n",
    "        onetail (bool): whether to perform 1-tail testing or not. \n",
    "            1-tail testing compares if the correlation is larger than the raw value of all other correlations. \n",
    "            2-tail testing compares the absolute value of the correlations.\n",
    "        correlation_method (str): what correlation to use. pearson | spearman | kendall \n",
    "        Notes:\n",
    "        The similarity by chance is 1-p. The difference by chance is the p value outputted. \n",
    "        \"\"\"\n",
    "        self.data_prep = data_prep\n",
    "        self.observed_correlations = {}\n",
    "        self.permuted_differences = {}\n",
    "        self.p_values = {}\n",
    "        self.onetail = onetail\n",
    "        self.correlation_method = correlation_method\n",
    "\n",
    "    def calculate_observed_differences(self, df):\n",
    "        \"\"\"Calculate the observed differences for each cohort within a dataframe.\"\"\"\n",
    "        observed_correlations = {}\n",
    "        for cohort in df[self.data_prep.cohort_variable].unique():\n",
    "            cohort_df = df[df[self.data_prep.cohort_variable] == cohort]\n",
    "            correlation = cohort_df[self.data_prep.independent_variable].corr(cohort_df[self.data_prep.dependent_variable], method=self.correlation_method)\n",
    "            observed_correlations[cohort] = correlation\n",
    "\n",
    "        observed_differences = {}\n",
    "        cohorts = list(observed_correlations.keys())\n",
    "        for i in range(len(cohorts)):\n",
    "            for j in range(i + 1, len(cohorts)):\n",
    "                cohort1, cohort2 = cohorts[i], cohorts[j]\n",
    "                diff = observed_correlations[cohort1] - observed_correlations[cohort2]\n",
    "                \n",
    "                observed_differences[(cohort1, cohort2)] = diff if self.onetail else np.abs(diff)\n",
    "\n",
    "        return observed_differences\n",
    "\n",
    "    def calculate_permuted_differences(self, df, n_permutations=1000):\n",
    "        \"\"\"Permute the data and calculate the permuted differences for each cohort within a dataframe.\"\"\"\n",
    "        permuted_differences = []\n",
    "\n",
    "        for _ in range(n_permutations):\n",
    "            permuted_df = df.copy()\n",
    "            permuted_df[self.data_prep.dependent_variable] = np.random.permutation(permuted_df[self.data_prep.dependent_variable].values)\n",
    "            correlations = {}\n",
    "            for cohort in df[self.data_prep.cohort_variable].unique():\n",
    "                cohort_df = permuted_df[permuted_df[self.data_prep.cohort_variable] == cohort]\n",
    "                correlation = cohort_df[self.data_prep.independent_variable].corr(cohort_df[self.data_prep.dependent_variable], method=self.correlation_method)\n",
    "                correlations[cohort] = correlation\n",
    "\n",
    "            permuted_diffs = {}\n",
    "            cohorts = list(correlations.keys())\n",
    "            for i in range(len(cohorts)):\n",
    "                for j in range(i + 1, len(cohorts)):\n",
    "                    cohort1, cohort2 = cohorts[i], cohorts[j]\n",
    "                    diff = correlations[cohort1] - correlations[cohort2]\n",
    "                    permuted_diffs[(cohort1, cohort2)] = diff if self.onetail else np.abs(diff)\n",
    "\n",
    "            permuted_differences.append(permuted_diffs)\n",
    "\n",
    "        return permuted_differences\n",
    "\n",
    "    def calculate_p_values(self, observed_differences, permuted_differences):\n",
    "        \"\"\"Calculate p-values based on the observed and permuted differences.\"\"\"\n",
    "        p_values = {}\n",
    "        for (cohort1, cohort2), observed_diff in observed_differences.items():\n",
    "            permuted_diffs = [permuted[(cohort1, cohort2)] for permuted in permuted_differences]\n",
    "            p_value = np.mean([diff >= observed_diff for diff in permuted_diffs])\n",
    "            p_values[(cohort1, cohort2, f'delta = {observed_diff}')] = p_value\n",
    "\n",
    "        return p_values\n",
    "\n",
    "    def run_analysis(self, n_permutations=1000):\n",
    "        \"\"\"Run the entire permutation analysis for each dataframe in the data_prep object.\"\"\"\n",
    "        for category, df in self.data_prep.category_dataframes.items():\n",
    "            observed_differences = self.calculate_observed_differences(df)\n",
    "            permuted_differences = self.calculate_permuted_differences(df, n_permutations)\n",
    "            p_values = self.calculate_p_values(observed_differences, permuted_differences)\n",
    "            self.p_values[category] = p_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "contrast across categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ContrastAnalysis:\n",
    "    def __init__(self, perm_analysis, onetail=True, correlation_method='pearson'):\n",
    "        \"\"\"\n",
    "        Params:\n",
    "        onetail (bool): whether to perform 1-tail testing or not. \n",
    "            1-tail testing compares if the correlation is larger than the raw value of all other correlations. \n",
    "            2-tail testing compares the absolute value of the correlations. \n",
    "        Notes:\n",
    "        The similarity by chance is 1-p. The difference by chance is the p value outputted. \n",
    "        \"\"\"\n",
    "        self.perm_analysis = perm_analysis\n",
    "        self.summed_correlations = {}\n",
    "        self.cross_dataframe_differences = {}\n",
    "        self.cross_dataframe_p_values = {}\n",
    "        self.onetail = onetail\n",
    "        self.correlation_method = correlation_method\n",
    "\n",
    "    def summate_correlations(self):\n",
    "        \"\"\"Summate the correlations within each dataframe.\"\"\"\n",
    "        for category, df in self.perm_analysis.data_prep.category_dataframes.items():\n",
    "            summed_correlation = 0\n",
    "            for cohort in df[self.perm_analysis.data_prep.cohort_variable].unique():\n",
    "                cohort_df = df[df[self.perm_analysis.data_prep.cohort_variable] == cohort]\n",
    "                correlation = cohort_df[self.perm_analysis.data_prep.independent_variable].corr(cohort_df[self.perm_analysis.data_prep.dependent_variable], method=self.correlation_method)\n",
    "                summed_correlation += correlation\n",
    "            self.summed_correlations[category] = summed_correlation\n",
    "\n",
    "    def calculate_cross_dataframe_differences(self, n_permutations=1000):\n",
    "        \"\"\"Calculate the difference between summed correlations from different dataframes and calculate p-values.\"\"\"\n",
    "        categories = list(self.summed_correlations.keys())\n",
    "        for i in range(len(categories)):\n",
    "            for j in range(i + 1, len(categories)):\n",
    "                category1, category2 = categories[i], categories[j]\n",
    "                observed_diff = self.summed_correlations[category1] - self.summed_correlations[category2]\n",
    "                self.cross_dataframe_differences[(category1, category2)] = observed_diff if self.onetail else np.abs(observed_diff)\n",
    "\n",
    "                permuted_diffs = []\n",
    "                for _ in range(n_permutations):\n",
    "                    permuted_df1 = self.perm_analysis.data_prep.category_dataframes[category1].copy()\n",
    "                    permuted_df2 = self.perm_analysis.data_prep.category_dataframes[category2].copy()\n",
    "\n",
    "                    permuted_df1[self.perm_analysis.data_prep.dependent_variable] = np.random.permutation(permuted_df1[self.perm_analysis.data_prep.dependent_variable].values)\n",
    "                    permuted_df2[self.perm_analysis.data_prep.dependent_variable] = np.random.permutation(permuted_df2[self.perm_analysis.data_prep.dependent_variable].values)\n",
    "\n",
    "                    permuted_sum1 = 0\n",
    "                    for cohort in permuted_df1[self.perm_analysis.data_prep.cohort_variable].unique():\n",
    "                        cohort_df = permuted_df1[permuted_df1[self.perm_analysis.data_prep.cohort_variable] == cohort]\n",
    "                        correlation = cohort_df[self.perm_analysis.data_prep.independent_variable].corr(cohort_df[self.perm_analysis.data_prep.dependent_variable], method=self.correlation_method)\n",
    "                        permuted_sum1 += correlation\n",
    "\n",
    "                    permuted_sum2 = 0\n",
    "                    for cohort in permuted_df2[self.perm_analysis.data_prep.cohort_variable].unique():\n",
    "                        cohort_df = permuted_df2[permuted_df2[self.perm_analysis.data_prep.cohort_variable] == cohort]\n",
    "                        correlation = cohort_df[self.perm_analysis.data_prep.independent_variable].corr(cohort_df[self.perm_analysis.data_prep.dependent_variable], method=self.correlation_method)\n",
    "                        permuted_sum2 += correlation\n",
    "\n",
    "                    permuted_diff = permuted_sum1 - permuted_sum2\n",
    "                    permuted_diffs.append(permuted_diff if self.onetail else np.abs(permuted_diff))\n",
    "\n",
    "                p_value = np.mean([diff >= observed_diff for diff in permuted_diffs])\n",
    "                self.cross_dataframe_p_values[(category1, category2, f'delta = {observed_diff}')] = p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the difference across categories and cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "class CrossCategoryPermutationAnalysis:\n",
    "    def __init__(self, perm_analysis, onetail=True, correlation_method='pearson'):\n",
    "        \"\"\"\n",
    "        Params:\n",
    "        onetail (bool): whether to perform 1-tail testing or not. \n",
    "            1-tail testing compares if the correlation is larger than the raw value of all other correlations. \n",
    "            2-tail testing compares the absolute value of the correlations. \n",
    "        Notes:\n",
    "        The similarity by chance is 1-p. The difference by chance is the p value outputted. \n",
    "        \"\"\"\n",
    "        self.perm_analysis = perm_analysis\n",
    "        self.observed_correlations = {}\n",
    "        self.permuted_correlations = []\n",
    "        self.observed_differences = {}\n",
    "        self.permuted_differences = []\n",
    "        self.p_values = {}\n",
    "        self.onetail = onetail\n",
    "        self.correlation_method = correlation_method\n",
    "\n",
    "    def calculate_observed_correlations(self):\n",
    "        \"\"\"Calculate the observed correlations for each cohort within each category dataframe.\"\"\"\n",
    "        for category, df in self.perm_analysis.data_prep.category_dataframes.items():\n",
    "            self.observed_correlations[category] = {}\n",
    "            for cohort in df[self.perm_analysis.data_prep.cohort_variable].unique():\n",
    "                cohort_df = df[df[self.perm_analysis.data_prep.cohort_variable] == cohort]\n",
    "                correlation = cohort_df[self.perm_analysis.data_prep.independent_variable].corr(cohort_df[self.perm_analysis.data_prep.dependent_variable], method=self.correlation_method)\n",
    "                self.observed_correlations[category][cohort] = correlation\n",
    "\n",
    "    def calculate_observed_differences(self):\n",
    "        \"\"\"Calculate the differences between correlations of every cohort in one category dataframe against every cohort in other category dataframes.\"\"\"\n",
    "        categories = list(self.observed_correlations.keys())\n",
    "        for i in range(len(categories)):\n",
    "            for j in range(i + 1, len(categories)):\n",
    "                category1, category2 = categories[i], categories[j]\n",
    "                self.observed_differences[(category1, category2)] = {}\n",
    "                for cohort1, corr1 in self.observed_correlations[category1].items():\n",
    "                    for cohort2, corr2 in self.observed_correlations[category2].items():\n",
    "                        diff = corr1 - corr2\n",
    "                        self.observed_differences[(category1, category2)][(cohort1, cohort2)] = diff if self.onetail else np.abs(diff)\n",
    "\n",
    "\n",
    "    def calculate_permuted_differences(self, n_permutations=1000):\n",
    "        \"\"\"Permute the data and calculate the permuted differences for each permutation.\"\"\"\n",
    "        categories = list(self.perm_analysis.data_prep.category_dataframes.keys())\n",
    "        all_data = pd.concat(self.perm_analysis.data_prep.category_dataframes.values())\n",
    "\n",
    "        for _ in range(n_permutations):\n",
    "            permuted_data = all_data.copy()\n",
    "            permuted_data[self.perm_analysis.data_prep.dependent_variable] = np.random.permutation(permuted_data[self.perm_analysis.data_prep.dependent_variable].values)\n",
    "\n",
    "            permuted_correlations = {}\n",
    "            for category in categories:\n",
    "                permuted_correlations[category] = {}\n",
    "                df = permuted_data[permuted_data[self.perm_analysis.data_prep.categorical_variable] == category]\n",
    "                for cohort in df[self.perm_analysis.data_prep.cohort_variable].unique():\n",
    "                    cohort_df = df[df[self.perm_analysis.data_prep.cohort_variable] == cohort]\n",
    "                    correlation = cohort_df[self.perm_analysis.data_prep.independent_variable].corr(cohort_df[self.perm_analysis.data_prep.dependent_variable], method=self.correlation_method)\n",
    "                    permuted_correlations[category][cohort] = correlation\n",
    "\n",
    "            permuted_diffs = {}\n",
    "            for i in range(len(categories)):\n",
    "                for j in range(i + 1, len(categories)):\n",
    "                    category1, category2 = categories[i], categories[j]\n",
    "                    permuted_diffs[(category1, category2)] = {}\n",
    "                    for cohort1, corr1 in permuted_correlations[category1].items():\n",
    "                        for cohort2, corr2 in permuted_correlations[category2].items():\n",
    "                            diff = corr1 - corr2\n",
    "                            permuted_diffs[(category1, category2)][(cohort1, cohort2)] = diff if self.onetail else np.abs(diff)\n",
    "\n",
    "            self.permuted_differences.append(permuted_diffs)\n",
    "\n",
    "    def calculate_p_values(self):\n",
    "        \"\"\"Calculate p-values based on the observed and permuted differences.\"\"\"\n",
    "        categories = list(self.observed_correlations.keys())\n",
    "        for i in range(len(categories)):\n",
    "            for j in range(i + 1, len(categories)):\n",
    "                category1, category2 = categories[i], categories[j]\n",
    "                self.p_values[(category1, category2)] = {}\n",
    "                for (cohort1, cohort2), observed_diff in self.observed_differences[(category1, category2)].items():\n",
    "                    permuted_diffs = [permuted[(category1, category2)][(cohort1, cohort2)] for permuted in self.permuted_differences if (category1, category2) in permuted and (cohort1, cohort2) in permuted[(category1, category2)]]\n",
    "                    p_value = np.mean([diff >= observed_diff for diff in permuted_diffs])\n",
    "                    self.p_values[(category1, category2)][(cohort1, cohort2, f'delta = {observed_diff}')] = p_value\n",
    "\n",
    "    def run_cross_category_permutation_analysis(self, n_permutations=1000):\n",
    "        \"\"\"Run the entire cross-category permutation analysis.\"\"\"\n",
    "        self.calculate_observed_correlations()\n",
    "        self.calculate_observed_differences()\n",
    "        self.calculate_permuted_differences(n_permutations)\n",
    "        self.calculate_p_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run It All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "class CombinedPlot:\n",
    "    \"\"\"\n",
    "    A class to create a combined plot of scatter plots and bar plots.\n",
    "\n",
    "    Attributes:\n",
    "    ----------\n",
    "    scatter_plot : ScatterPlot\n",
    "        An instance of the ScatterPlot class containing the scatter plots.\n",
    "    bar_plot : BarPlot\n",
    "        An instance of the BarPlot class containing the bar plots.\n",
    "    out_dir : str\n",
    "        Directory to save the output plot.\n",
    "\n",
    "    Methods:\n",
    "    -------\n",
    "    create_figure():\n",
    "        Creates a combined figure with scatter plots and bar plots.\n",
    "    plot():\n",
    "        Displays the combined figure.\n",
    "    save_figure():\n",
    "        Saves the combined figure.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, scatter_plot, bar_plot, out_dir=None):\n",
    "        self.scatter_plot = scatter_plot\n",
    "        self.bar_plot = bar_plot\n",
    "        self.out_dir = out_dir\n",
    "        self.fig, self.axes = self.create_figure()\n",
    "        self.set_shared_x_limits()\n",
    "\n",
    "    def set_shared_x_limits(self):\n",
    "        \"\"\"\n",
    "        Sets the x-limits for scatter plots and bar plots to be shared separately.\n",
    "        \"\"\"\n",
    "        scatter_x_limits = [self.axes[i, 0].get_xlim() for i in range(self.axes.shape[0])]\n",
    "        scatter_x_min = min([lim[0] for lim in scatter_x_limits])\n",
    "        scatter_x_max = max([lim[1] for lim in scatter_x_limits])\n",
    "\n",
    "        bar_x_limits = [self.axes[i, 1].get_xlim() for i in range(self.axes.shape[0])]\n",
    "        bar_x_min = min([lim[0] for lim in bar_x_limits])\n",
    "        bar_x_max = max([lim[1] for lim in bar_x_limits])\n",
    "\n",
    "        for i in range(self.axes.shape[0]):\n",
    "            self.axes[i, 0].set_xlim(scatter_x_min, scatter_x_max)\n",
    "            self.axes[i, 1].set_xlim(bar_x_min, bar_x_max)\n",
    "\n",
    "    def create_figure(self):\n",
    "        \"\"\"\n",
    "        Creates a combined figure with scatter plots and bar plots.\n",
    "        \"\"\"\n",
    "        categories = list(self.scatter_plot.data_prep.category_dataframes.keys())\n",
    "        num_categories = len(categories)\n",
    "\n",
    "        fig, axes = plt.subplots(num_categories, 2, figsize=(15, 6 * num_categories))\n",
    "\n",
    "        for i, category in enumerate(categories):\n",
    "            # Scatter Plot\n",
    "            scatter_ax = axes[i, 0]\n",
    "            scatter_data = self.scatter_plot.data_prep.category_dataframes[category]\n",
    "            if self.scatter_plot.data_prep.cohort_variable is not None:\n",
    "                for j, cohort in enumerate(scatter_data[self.scatter_plot.data_prep.cohort_variable].unique()):\n",
    "                    cohort_df = scatter_data[scatter_data[self.scatter_plot.data_prep.cohort_variable] == cohort]\n",
    "                    sns.regplot(\n",
    "                        x=self.scatter_plot.data_prep.independent_variable,\n",
    "                        y=self.scatter_plot.data_prep.dependent_variable,\n",
    "                        data=cohort_df,\n",
    "                        ax=scatter_ax,\n",
    "                        label=cohort,\n",
    "                        color=self.scatter_plot.colors[j],\n",
    "                        ci=None\n",
    "                    )\n",
    "            else:\n",
    "                sns.regplot(\n",
    "                    x=self.scatter_plot.data_prep.independent_variable,\n",
    "                    y=self.scatter_plot.data_prep.dependent_variable,\n",
    "                    data=scatter_data,\n",
    "                    ax=scatter_ax,\n",
    "                    label=category,\n",
    "                    color=self.scatter_plot.colors[0],\n",
    "                    ci=None\n",
    "                )\n",
    "            scatter_ax.legend()\n",
    "            scatter_ax.set_title(category)\n",
    "            scatter_ax.set_xlabel(self.scatter_plot.data_prep.independent_variable)\n",
    "            scatter_ax.set_ylabel(self.scatter_plot.data_prep.dependent_variable)\n",
    "\n",
    "            # Bar Plot\n",
    "            bar_ax = axes[i, 1]\n",
    "            bar_data = self.bar_plot.data_prep.category_dataframes[category]\n",
    "            correlations = []\n",
    "            p_values = []\n",
    "            cohorts = []\n",
    "\n",
    "            if self.bar_plot.data_prep.cohort_variable is not None:\n",
    "                for j, cohort in enumerate(bar_data[self.bar_plot.data_prep.cohort_variable].unique()):\n",
    "                    cohort_df = bar_data[bar_data[self.bar_plot.data_prep.cohort_variable] == cohort]\n",
    "                    if self.bar_plot.method == 'pearson':\n",
    "                        correlation, p_value = pearsonr(\n",
    "                            cohort_df[self.bar_plot.data_prep.independent_variable],\n",
    "                            cohort_df[self.bar_plot.data_prep.dependent_variable]\n",
    "                        )\n",
    "                    else:\n",
    "                        correlation, p_value = spearmanr(\n",
    "                            cohort_df[self.bar_plot.data_prep.independent_variable],\n",
    "                            cohort_df[self.bar_plot.data_prep.dependent_variable]\n",
    "                        )\n",
    "                    correlations.append(correlation)\n",
    "                    p_values.append(p_value)\n",
    "                    cohorts.append(cohort)\n",
    "            else:\n",
    "                if self.bar_plot.method == 'pearson':\n",
    "                    correlation, p_value = pearsonr(\n",
    "                        bar_data[self.bar_plot.data_prep.independent_variable],\n",
    "                        bar_data[self.bar_plot.data_prep.dependent_variable]\n",
    "                    )\n",
    "                else:\n",
    "                    correlation, p_value = spearmanr(\n",
    "                        bar_data[self.bar_plot.data_prep.independent_variable],\n",
    "                        bar_data[self.bar_plot.data_prep.dependent_variable]\n",
    "                    )\n",
    "                correlations.append(correlation)\n",
    "                p_values.append(p_value)\n",
    "                cohorts.append(category)\n",
    "            \n",
    "            sns.barplot(x=correlations, y=cohorts, ax=bar_ax, palette=self.bar_plot.colors[:len(cohorts)])\n",
    "            bar_ax.set_xlabel('Correlation Strength')\n",
    "            bar_ax.set_title(category)\n",
    "\n",
    "            # Outline bars with p-value < 0.05\n",
    "            for bar, p_value in zip(bar_ax.patches, p_values):\n",
    "                if p_value < 0.05:\n",
    "                    bar.set_edgecolor('black')\n",
    "                    bar.set_linewidth(1.5)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        self.bar_plot.set_shared_y_limits()\n",
    "        return fig, axes\n",
    "\n",
    "    def save_figure(self):\n",
    "        \"\"\"\n",
    "        Saves the combined figure to the specified output directory.\n",
    "        \"\"\"\n",
    "        if self.out_dir:\n",
    "            self.fig.savefig(f\"{self.out_dir}/combined_plot.svg\", format='svg')\n",
    "\n",
    "    def plot(self):\n",
    "        \"\"\"\n",
    "        Displays the combined figure.\n",
    "        \"\"\"\n",
    "        import warnings\n",
    "        try:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"error\", UserWarning)\n",
    "                self.fig.show()\n",
    "        except UserWarning:\n",
    "            from IPython.display import display\n",
    "            display(self.fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare data\n",
    "data_prep = DataPreparation(data_df, dependent_variable, independent_variable, categorical_variable, cohort_variable)\n",
    "\n",
    "# Create scatter plot instance\n",
    "scatter_plot = ScatterPlot(data_prep, colors_list=['#d62728', '#1f77b4', '#17becf'])\n",
    "\n",
    "# Create bar plot instance\n",
    "bar_plot = BarPlot(data_prep, method='pearson', colors_list=['#d62728', '#1f77b4', '#17becf'])\n",
    "\n",
    "# Create combined plot instance\n",
    "combined_plot = CombinedPlot(scatter_plot, bar_plot, out_dir=out_dir)\n",
    "combined_plot.save_figure()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P-Values within Categories Across Cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform permutation analysis\n",
    "perm_analysis = PermutationAnalysis(data_prep, onetail=False, correlation_method=correlation_method)\n",
    "perm_analysis.run_analysis(n_permutations=10000)\n",
    "p_values = perm_analysis.p_values\n",
    "from pprint import pprint\n",
    "pprint(p_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P-Values Across Categories Across Cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-category permutation analysis\n",
    "cross_cat_perm_analysis = CrossCategoryPermutationAnalysis(perm_analysis, onetail=False, correlation_method=correlation_method)\n",
    "cross_cat_perm_analysis.run_cross_category_permutation_analysis(n_permutations=10000)\n",
    "# Pretty print the cross-category p_values\n",
    "from pprint import pprint\n",
    "pprint(cross_cat_perm_analysis.p_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P-Values Across Categories (contrast all cohorts within category against all cohorts in another category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform contrast analysis\n",
    "contrast_analysis = ContrastAnalysis(perm_analysis, onetail=True, correlation_method=correlation_method)\n",
    "contrast_analysis.summate_correlations()\n",
    "contrast_analysis.calculate_cross_dataframe_differences(n_permutations=10000)\n",
    "\n",
    "# Pretty print the cross-dataframe p_values\n",
    "pprint(contrast_analysis.cross_dataframe_p_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the permutation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pformat\n",
    "\n",
    "def save_dicts_as_py(out_dir, **dicts):\n",
    "    \"\"\"\n",
    "    Save dictionaries as .py files in the specified directory with pretty-print formatting.\n",
    "\n",
    "    Parameters:\n",
    "    out_dir (str): Directory to save the Python files.\n",
    "    **dicts: Arbitrary number of dictionaries to save, with keys as file names (without .py extension).\n",
    "    \"\"\"\n",
    "\n",
    "    # Save each dictionary as a Python file\n",
    "    for file_name, data in dicts.items():\n",
    "        try:\n",
    "            with open(os.path.join(out_dir, f\"{file_name}.py\"), 'w') as py_file:\n",
    "                py_file.write(f\"{file_name} = {pformat(data)}\\n\")\n",
    "            print(f\"Successfully saved {file_name}.py\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred while saving {file_name}.py: {e}\")\n",
    "\n",
    "# Save dictionaries as .py files\n",
    "save_dicts_as_py(out_dir,\n",
    "                 cross_cat_perm_analysis_p_values= cross_cat_perm_analysis.p_values,\n",
    "                 contrast_analysis_cross_dataframe_p_values=contrast_analysis.cross_dataframe_p_values,\n",
    "                 perm_analysis_p_values=perm_analysis.p_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 - Delta Scatterplot (Pretty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefining the class and its methods\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import t\n",
    "import seaborn as sns\n",
    "class ScatterWithConfidence:\n",
    "    def __init__(self, data_df):\n",
    "        self.data_df = data_df\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_analytic_confidence_interval(x, y, x_vals):\n",
    "        slope, intercept = np.polyfit(x, y, 1)\n",
    "        y_fit = slope * x_vals + intercept\n",
    "        \n",
    "        residuals = y - (slope * x + intercept)\n",
    "        stderr = np.sqrt(np.sum(residuals**2) / (len(y) - 2))\n",
    "        \n",
    "        t_value = t.ppf(0.975, df=len(x)-2)\n",
    "        ci = t_value * stderr * np.sqrt(1/len(x) + (x_vals - np.mean(x))**2 / np.sum((x - np.mean(x))**2))\n",
    "        \n",
    "        upper_bound = y_fit + ci\n",
    "        lower_bound = y_fit - ci\n",
    "        \n",
    "        return y_fit, lower_bound, upper_bound\n",
    "\n",
    "    def permute_data_and_difference_in_pearson_r(self, x_one, x_two, split_by, split_value, n_permutations=1000, permute_columns=[]):\n",
    "        original_diff = self.data_df[self.data_df[split_by] < split_value][x_one].corr(self.data_df[self.data_df[split_by] < split_value][x_two]) - \\\n",
    "                       self.data_df[self.data_df[split_by] >= split_value][x_one].corr(self.data_df[self.data_df[split_by] >= split_value][x_two])\n",
    "\n",
    "        permuted_diffs = []\n",
    "\n",
    "        for _ in range(n_permutations):\n",
    "            permuted_df = self.data_df.copy()\n",
    "            for column in permute_columns:\n",
    "                permuted_df[column] = np.random.permutation(permuted_df[column].values)\n",
    "            \n",
    "            diff = permuted_df[permuted_df[split_by] < split_value][x_one].corr(permuted_df[permuted_df[split_by] < split_value][x_two]) - \\\n",
    "                   permuted_df[permuted_df[split_by] >= split_value][x_one].corr(permuted_df[permuted_df[split_by] >= split_value][x_two])\n",
    "            \n",
    "            permuted_diffs.append(diff)\n",
    "\n",
    "        p_value = np.mean([diff <= original_diff for diff in permuted_diffs])\n",
    "        return original_diff, p_value\n",
    "\n",
    "    def plot_with_analytic_ci_manual_pvalue(self, x_one, x_two, \n",
    "                                            split_by, split_value, \n",
    "                                            x_label='X1', y_label='X2', \n",
    "                                            upper_split_legend='Above Split', lower_split_legend='Below Split',\n",
    "                                            alpha=0.3, manual_p_value=None, permute_column=None, \n",
    "                                            save=False, out_dir=None,\n",
    "                                            colour1='red', colour2='blue'):\n",
    "        fig, ax = plt.subplots(figsize=(6, 5))\n",
    "        \n",
    "        group1 = self.data_df[self.data_df[split_by] < split_value]\n",
    "        group2 = self.data_df[self.data_df[split_by] >= split_value]\n",
    "\n",
    "        ax.scatter(group1[x_one], group1[x_two], color=colour1, label=lower_split_legend, s=40, alpha=alpha, marker='o')\n",
    "        ax.scatter(group2[x_one], group2[x_two], color=colour2, label=upper_split_legend, s=40, alpha=alpha, marker='o')\n",
    "        \n",
    "        x_vals = np.linspace(self.data_df[x_one].min(), self.data_df[x_one].max(), 400)\n",
    "        \n",
    "        for group, color in [(group1, colour1), (group2, colour2)]:\n",
    "            y_fit, lower_bound, upper_bound = self.compute_analytic_confidence_interval(group[x_one], group[x_two], x_vals)\n",
    "            ax.plot(x_vals, y_fit, color=color)\n",
    "            # ax.fill_between(x_vals, lower_bound, upper_bound, color=color, alpha=alpha/4)\n",
    "        \n",
    "        if manual_p_value is None:\n",
    "            if permute_column:\n",
    "                rho, manual_p_value = self.permute_data_and_difference_in_pearson_r(x_one, x_two, split_by, split_value, n_permutations=10000, permute_columns=[permute_column])\n",
    "            else:\n",
    "                rho, manual_p_value = self.permute_data_and_difference_in_pearson_r(x_one, x_two, split_by, split_value, n_permutations=10000, permute_columns=[x_one, x_two, split_by])\n",
    "        \n",
    "        ax.set_title(f\"\\u0394 r = {rho:.2f} , p = {manual_p_value:.4f}\")\n",
    "        ax.set_ylabel(y_label)\n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.legend(loc='best', frameon=False)\n",
    "        ax.grid(False)\n",
    "        sns.despine(ax=ax)\n",
    "        \n",
    "        if save and out_dir is not None:\n",
    "            plt.savefig(f\"{out_dir}/scatter_with_polyfit_and_analytic_ci.png\", bbox_inches='tight')\n",
    "            plt.savefig(f\"{out_dir}/scatter_with_polyfit_and_analytic_ci.svg\", bbox_inches='tight')\n",
    "            print(f'Saved to {out_dir}/scatter_with_polyfit_and_analytic_ci.svg')\n",
    "        return fig\n",
    "    \n",
    "class DeltaCorrelation(ScatterWithConfidence):\n",
    "    def __init__(self, data_df):\n",
    "        super().__init__(data_df)\n",
    "\n",
    "    def plot_histogram_of_delta_r(self, x_one, x_two, split_by, split_value, n_permutations=1000, \n",
    "                                permute_columns=[], bins=50, one_tail=False, color_palette='dark'):\n",
    "        # Generate the empirical distribution of delta_r\n",
    "        delta_rs = []\n",
    "        for _ in range(n_permutations):\n",
    "            permuted_df = self.data_df.copy()\n",
    "            for column in permute_columns:\n",
    "                permuted_df[column] = np.random.permutation(permuted_df[column].values)\n",
    "\n",
    "            delta_r = permuted_df[permuted_df[split_by] < split_value][x_one].corr(permuted_df[permuted_df[split_by] < split_value][x_two]) - \\\n",
    "                    permuted_df[permuted_df[split_by] >= split_value][x_one].corr(permuted_df[permuted_df[split_by] >= split_value][x_two])\n",
    "            delta_rs.append(delta_r)\n",
    "\n",
    "        # Calculate the observed delta_r\n",
    "        observed_delta_r, _ = self.permute_data_and_difference_in_pearson_r(x_one, x_two, split_by, split_value, permute_columns=permute_columns)\n",
    "\n",
    "        if one_tail:\n",
    "            observed_delta_r = np.abs(observed_delta_r)\n",
    "            delta_rs = np.abs(delta_rs)\n",
    "\n",
    "        # Calculate p-value\n",
    "        if one_tail:\n",
    "            p_value = np.mean([delta_r >= observed_delta_r for delta_r in delta_rs])\n",
    "        else:\n",
    "            p_value = np.mean([delta_r <= observed_delta_r for delta_r in delta_rs])\n",
    "\n",
    "        # Generate the displot (KDE + Histogram) using Seaborn\n",
    "        sns.set_palette(color_palette)\n",
    "        current_palette = sns.color_palette(color_palette)\n",
    "        chosen_color = current_palette[4]\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        g = sns.displot(delta_rs, kde=True, bins=bins, label=\"Empirical $\\\\Delta r$ Distribution\", element=\"step\",color='blue', alpha=.6)\n",
    "        plt.axvline(x=observed_delta_r, color='red', linestyle='-', linewidth=1.5, label=f\"Observed $\\\\Delta r$\", alpha=0.6)\n",
    "        plt.title(f\"$\\\\Delta r$ = {observed_delta_r}, p = {p_value}\")\n",
    "        plt.xlabel(\"$\\\\Delta r$\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.legend()\n",
    "        \n",
    "        fig = g.fig\n",
    "        \n",
    "        fig.savefig(f\"{out_dir}/hist_kde.png\", bbox_inches='tight')\n",
    "        fig.savefig(f\"{out_dir}/hist_kde.svg\", bbox_inches='tight')\n",
    "        print(f'Saved to {out_dir}/hist_kde.svg')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_columns = [col for col in data_df.columns if 'Occ' in col]\n",
    "print(filtered_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data To Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Variables\n",
    "dependent_variable = 'Percent_Cognitive_Improvement'\n",
    "independent_variable = 'Subiculum_Connectivity_T_Redone'\n",
    "split_by_var = 'Age' # This is the column which contains the values you are going to split the data by \n",
    "split_value_var = 65 # This is the value which will be used to determine how rows of the given column split the entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels for Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Variables\n",
    "x_label = 'Standardized Subiculum Connectivity'\n",
    "y_label = 'Standardized Percent Improvement'\n",
    "legend_string_for_lower_split='under 65'\n",
    "legend_string_for_upper_split='Over 65'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_sctr = ScatterWithConfidence(data_df)\n",
    "delta_sctr_plot = delta_sctr.plot_with_analytic_ci_manual_pvalue(\n",
    "                                            x_one=independent_variable, x_two=dependent_variable,\n",
    "                                            split_by=split_by_var, split_value=split_value_var,\n",
    "                                            x_label=x_label, y_label=y_label,\n",
    "                                            upper_split_legend=legend_string_for_upper_split, lower_split_legend=legend_string_for_lower_split,\n",
    "                                            alpha=0.3, manual_p_value=None, permute_column=None,\n",
    "                                            save=True, out_dir=out_dir,\n",
    "                                            colour1='#FF0000', colour2='#0000FF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an object from the new Seaborn-based class\n",
    "histogram_plotter_seaborn = DeltaCorrelation(data_df)\n",
    "\n",
    "# Generate the histogram using Seaborn\n",
    "fig = histogram_plotter_seaborn.plot_histogram_of_delta_r(x_one=independent_variable, x_two=dependent_variable, \n",
    "                                                    split_by=split_by_var, split_value=split_value_var, \n",
    "                                                    n_permutations=10000, \n",
    "                                                    permute_columns=[independent_variable, dependent_variable, split_by_var], \n",
    "                                                    bins=50,\n",
    "                                                    one_tail=True, \n",
    "                                                    color_palette='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlay Multiple Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_lines_of_best_fit_by_combinations(data_df, categorical_columns, x_var, y_var):\n",
    "    # Find unique values in each column\n",
    "    unique_values_per_column = [data_df[col].unique() for col in categorical_columns]\n",
    "\n",
    "    # Generate all possible combinations of these unique values across the columns\n",
    "    all_combinations = list(itertools.product(*unique_values_per_column))\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.set_palette('tab10')\n",
    "    # For each combination, create a mask and apply it to the DataFrame\n",
    "    for combination in all_combinations:\n",
    "        mask = pd.Series(True, index=data_df.index)\n",
    "        for col, val in zip(categorical_columns, combination):\n",
    "            mask &= (data_df[col] == val)\n",
    "\n",
    "        # Apply the mask to the DataFrame to get the subset\n",
    "        masked_df = data_df[mask]\n",
    "        \n",
    "        # Skip if the masked_df is empty\n",
    "        if masked_df.empty:\n",
    "            continue\n",
    "\n",
    "        # Calculate the line of best fit\n",
    "        slope, intercept = np.polyfit(masked_df[x_var], masked_df[y_var], 1)\n",
    "        x_vals = np.linspace(masked_df[x_var].min(), masked_df[x_var].max(), 100)\n",
    "        y_vals = slope * x_vals + intercept\n",
    "\n",
    "        # Plot the line of best fit\n",
    "        plt.plot(x_vals, y_vals, label=f'{combination}', linestyle='-')\n",
    "\n",
    "    plt.xlabel(x_var)\n",
    "    plt.ylabel(y_var)\n",
    "    plt.title(f'Lines of Best Fit for {x_var} vs {y_var} by Category Combinations')\n",
    "    plt.legend(title='Category Combination', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lines_of_best_fit_by_combinations(data_df,\n",
    "                                       categorical_columns=['Age_Group', 'City'], \n",
    "                                       x_var='Z_Scored_Subiculum_T_By_Origin_Group_', \n",
    "                                       y_var='Z_Scored_Percent_Cognitive_Improvement')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Matrix and Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_correlation_heatmap(dataframe):\n",
    "    # Calculate the correlation matrix\n",
    "    corr_matrix = dataframe.corr()\n",
    "\n",
    "    # Create a heatmap\n",
    "    plt.figure(figsize=(20, 16))\n",
    "    sns.heatmap(corr_matrix, annot=False, fmt=\".2f\", cmap='coolwarm', square=True, cbar_kws={'shrink': .5})\n",
    "\n",
    "    # Adjust the layout\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.title('Correlation Heatmap')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "sorted_columns = sorted(data_df.columns)\n",
    "data_df_sorted = data_df[sorted_columns]\n",
    "plot_correlation_heatmap(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canonical Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import CCA\n",
    "\n",
    "def perform_cca(data_df, set1_columns, set2_columns):\n",
    "    \"\"\"\n",
    "    Perform Canonical Correlation Analysis (CCA) between two sets of columns in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        data_df (pd.DataFrame): The DataFrame containing the data.\n",
    "        set1_columns (list): List of column names for the first set of variables.\n",
    "        set2_columns (list): List of column names for the second set of variables.\n",
    "\n",
    "    Returns:\n",
    "        cca (CCA): The CCA model object.\n",
    "        cca_results (dict): A dictionary containing the CCA results.\n",
    "    \"\"\"\n",
    "    # Extract the specified sets of columns from the DataFrame\n",
    "    set1_data = data_df[set1_columns]\n",
    "    set2_data = data_df[set2_columns]\n",
    "\n",
    "    # Initialize the CCA model\n",
    "    cca = CCA(n_components=min(len(set1_columns), len(set2_columns)))\n",
    "\n",
    "    # Fit the CCA model to the data\n",
    "    cca.fit(set1_data, set2_data)\n",
    "\n",
    "    # Transform the data using CCA\n",
    "    set1_transformed, set2_transformed = cca.transform(set1_data, set2_data)\n",
    "\n",
    "    # Calculate canonical correlations from singular values\n",
    "    canonical_correlations = cca.singular_values_\n",
    "\n",
    "    # Store the CCA results in a dictionary\n",
    "    cca_results = {\n",
    "        'Canonical Correlations': canonical_correlations,\n",
    "        'Set 1 Transformed': set1_transformed,\n",
    "        'Set 2 Transformed': set2_transformed\n",
    "    }\n",
    "\n",
    "    return cca, cca_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define 2 lists\n",
    "- 1 is the first set to CCA\n",
    "- 2 is the second set to CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templist = []\n",
    "for val in data_df.columns:\n",
    "    if 'CSF' in val:\n",
    "        templist.insert(-1, val)\n",
    "print(templist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = ['frontal', 'temporal', 'parietal', 'occipital',\n",
    "       'cerebellum', 'Mesial_Temporal', 'ventricle']\n",
    "list2 = ['frontal_eh', 'temporal_eh', 'parietal_eh',\n",
    "       'occipital_eh', 'cerebellum_eh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import CCA\n",
    "\n",
    "def perform_cca(data_df, set1_columns, set2_columns):\n",
    "    \"\"\"\n",
    "    Perform Canonical Correlation Analysis (CCA) between two sets of columns in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        data_df (pd.DataFrame): The DataFrame containing the data.\n",
    "        set1_columns (list): List of column names for the first set of variables.\n",
    "        set2_columns (list): List of column names for the second set of variables.\n",
    "\n",
    "    Returns:\n",
    "        cca (CCA): The CCA model object.\n",
    "        cca_results (dict): A dictionary containing the CCA results.\n",
    "    \"\"\"\n",
    "    # Extract the specified sets of columns from the DataFrame\n",
    "    set1_data = data_df[set1_columns]\n",
    "    set2_data = data_df[set2_columns]\n",
    "\n",
    "    # Initialize the CCA model\n",
    "    cca = CCA(n_components=min(len(set1_columns), len(set2_columns)))\n",
    "\n",
    "    # Fit the CCA model to the data\n",
    "    cca.fit(set1_data, set2_data)\n",
    "\n",
    "    # Calculate canonical correlations using the score method\n",
    "    canonical_correlations = cca.score(set1_data, set2_data)\n",
    "\n",
    "    # Store the CCA results in a dictionary\n",
    "    cca_results = {\n",
    "        'Canonical Correlations': canonical_correlations\n",
    "    }\n",
    "\n",
    "    return cca, cca_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca, cca_results = perform_cca(data_df, set1_columns=list1, set2_columns=list2)\n",
    "cca_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intraclass Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "from pingouin import intraclass_corr\n",
    "from calvin_utils.statistical_utils.distribution_statistics import BootstrappedDistributionStatistics\n",
    "from calvin_utils.statistical_utils.resampling_functions import Bootstrap\n",
    "\n",
    "def calculate_icc(df, col1, col2):\n",
    "    # Select only the specified columns and rename them for compatibility with pingouin\n",
    "    data = df[[col1, col2]].rename(columns={col1: 'rating1', col2: 'rating2'})\n",
    "\n",
    "    # Reshape data for pingouin's intraclass_corr function\n",
    "    df_melted = data.melt(value_vars=['rating1', 'rating2'], var_name='rater', value_name='rating')\n",
    "    df_melted['subject'] = df_melted.groupby('rater').cumcount()\n",
    "\n",
    "    # Calculate ICC\n",
    "    icc_result = intraclass_corr(data=df_melted, targets='subject', raters='rater', ratings='rating')\n",
    "    \n",
    "    # Return ICC(3,1)\n",
    "    return icc_result.set_index('Type').loc['ICC3', 'ICC']\n",
    "\n",
    "def bootstrap_icc(data, col1, col2, bootstrap_samples=2500):\n",
    "    # Perform the bootstrap resampling using the Bootstrap class\n",
    "    bootstrap = Bootstrap(data=data, func=calculate_icc, func_args={'col1': col1, 'col2': col2}, bootstrap_samples=bootstrap_samples)\n",
    "    bootstrap_results = bootstrap.bootstrap_function()\n",
    "\n",
    "    # Calculate the confidence intervals using the BootstrappedDistributionStatistics class\n",
    "    distribution_statistics = BootstrappedDistributionStatistics(bootstrap_results)\n",
    "    lower_bound, upper_bound = distribution_statistics.percentile_ci(alpha=0.05)\n",
    "\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "def plot_icc_forest(comparisons_dict, dataframe, bootstrap_samples=2500, full_legend_patches=False):\n",
    "    # figure = plt.figure(figsize=(4, len(comparisons_dict)*1.2))\n",
    "    figure = plt.figure(figsize=(4, 5))\n",
    "    \n",
    "    # Create a color palette with enough unique colors\n",
    "    colors = sns.color_palette(\"tab10\", len(comparisons_dict))\n",
    "    \n",
    "    # Create legend patches\n",
    "    legend_patches = []\n",
    "    \n",
    "    # Iterate through the dictionary and plot ICC for each comparison\n",
    "    for idx, (col1_name, col2_name) in enumerate(comparisons_dict.items()):\n",
    "        # Calculate ICC\n",
    "        icc_value = calculate_icc(dataframe, col1_name, col2_name)\n",
    "\n",
    "        # Bootstrap 95% confidence interval\n",
    "        ci_lower, ci_upper = bootstrap_icc(dataframe, col1_name, col2_name, bootstrap_samples=bootstrap_samples)\n",
    "\n",
    "        # Plot ICC with confidence interval\n",
    "        plt.errorbar(x=icc_value, y=idx, xerr=[[icc_value - ci_lower], [ci_upper - icc_value]], fmt='o', color=colors[idx], capsize=5)\n",
    "        \n",
    "        # Add legend patch\n",
    "        if full_legend_patches:\n",
    "            legend_patches.append(mpatches.Patch(color=colors[idx], label=f'{col1_name} vs {col2_name}'))\n",
    "        else:\n",
    "            legend_patches.append(mpatches.Patch(color=colors[idx], label=f'{col1_name}'))\n",
    "\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(-1, len(comparisons_dict))\n",
    "    plt.yticks([])\n",
    "    plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.xlabel('ICC')\n",
    "    plt.title('Intraclass Correlation Coefficients (ICC) with 95% Confidence Intervals')\n",
    "    plt.grid(axis='x', linestyle='--')\n",
    "    \n",
    "    # Add legend\n",
    "    plt.legend(handles=legend_patches, frameon=False, loc=(0.05, 0.1))\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exptl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['City'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Variables\n",
    "y_variable = 'Z_Scored_Percent_Cognitive_Improvement'\n",
    "x_variable = 'Subiculum_Connectivity_T_Redone'\n",
    "\n",
    "# Filter data for 'young' age group\n",
    "young_data = data_df[data_df['Age_Group'] == 'old']\n",
    "\n",
    "# Function to perform bootstrap and calculate correlation differences and individual correlations\n",
    "def bootstrap_corr_diff(data, y_var, x_var, group_col, n_bootstraps=1000):\n",
    "    corr_diffs = []\n",
    "    all_correlations = {group: [] for group in data[group_col].unique()}\n",
    "    unique_groups = data[group_col].unique()\n",
    "    \n",
    "    for _ in range(n_bootstraps):\n",
    "        sample_diffs = []\n",
    "        \n",
    "        for group in unique_groups:\n",
    "            group_data = data[data[group_col] == group].sample(frac=1, replace=True)\n",
    "            corr, _ = pearsonr(group_data[x_var], group_data[y_var])\n",
    "            all_correlations[group].append(corr)\n",
    "            sample_diffs.append(corr)\n",
    "        \n",
    "        if len(sample_diffs) == 2:\n",
    "            corr_diffs.append(sample_diffs[0] - sample_diffs[1])\n",
    "    \n",
    "    return corr_diffs, all_correlations\n",
    "\n",
    "# Perform bootstrapping\n",
    "bootstrap_diffs, bootstrap_correlations = bootstrap_corr_diff(young_data, y_variable, x_variable, group_col='City')\n",
    "\n",
    "# Save the bootstrap differences to a .txt file\n",
    "np.savetxt('/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Research/2023/subiculum_cognition_and_age/figures/Figures/3_cohort_delta_r/andy_similarity_test/bayes_old/bootstrap_diffs.txt', bootstrap_diffs)\n",
    "\n",
    "# Save the bootstrap correlations for each city to separate .txt files\n",
    "for city, correlations in bootstrap_correlations.items():\n",
    "    np.savetxt(f'/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Research/2023/subiculum_cognition_and_age/figures/Figures/3_cohort_delta_r/andy_similarity_test/bayes_old/bootstrap_correlations_{city}.txt', correlations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'Measurement', 'Cohort', 'Randomization_Group', 'Age',\n",
       "       'Cognitive_Status', 'Cognitive_Status_Code', 'Question_1', 'Question_2',\n",
       "       'Question_3', 'Question_4', 'Question_5', 'Question_6', 'Question_7',\n",
       "       'Question_8', 'Question_9', 'Question_10', 'Question_11', 'Question_12',\n",
       "       'Question_13', 'Question_14', 'Question_15', 'Question_16',\n",
       "       'Question_17', 'Question_18', 'Question_19', 'Total', 'Attention',\n",
       "       'Memory', 'Fluency', 'Language', 'Visuospatial', 'POCA',\n",
       "       'Convolutional_Neural_Network', 'Natural_Language_Processing',\n",
       "       'Expert_Algorithm', 'Completed', 'ACE3_Question_1', 'ACE3_Question_2',\n",
       "       'ACE3_Question_3', 'ACE3_Question_4', 'ACE3_Question_5',\n",
       "       'ACE3_Question_6', 'ACE3_Question_7', 'ACE3_Question_8',\n",
       "       'ACE3_Question_9', 'ACE3_Question_10', 'ACE3_Question_11',\n",
       "       'ACE3_Question_12', 'ACE3_Question_13', 'ACE3_Question_14',\n",
       "       'ACE3_Question_15', 'ACE3_Question_16', 'ACE3_Question_17',\n",
       "       'ACE3_Question_18', 'ACE3_Question_19', 'ACE_Total', 'ACE_Attention',\n",
       "       'ACE_Memory', 'ACE_Fluency', 'ACE_Language', 'ACE_Visuospatial',\n",
       "       'Paper_PoCA', 'Convolutional_Neural_Network_Equivalent',\n",
       "       'Natural_Language_Processing_Equivalent', 'Expert_Algorithm_Equivalent',\n",
       "       'Subjective_Complaint', 'Attention_Complaint', 'Memory_Complaint',\n",
       "       'Fluency_Complaint', 'Language_Complaint', 'Visuospatial_Complaint',\n",
       "       'Impaired_on_ACE3', 'iADL_Impaired', 'ADL_Impaired'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = ['Total', 'Attention', 'Memory', 'Fluency', 'Language', 'Visuospatial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_correlation_heatmap(df, columns, method='pearson'):\n",
    "    # Calculate the correlation matrix\n",
    "    corr_matrix = df[columns].corr(method=method)\n",
    "    \n",
    "    # Generate a heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "    plt.title(f'{method.capitalize()} Correlation Matrix')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plot_correlation_heatmap(data_df, columns_list, method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimlab_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
