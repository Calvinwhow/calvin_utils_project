{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Correlation-Based Analyses\n",
    "\n",
    "### Authors: Calvin Howard.\n",
    "\n",
    "#### Last updated: July 6, 2023\n",
    "\n",
    "Use this to assess if a correlation between a dependent variable and an independent variable is statistically significant using permutation analysis. \n",
    "\n",
    "Further, follow this up with a contrast analysis which sees which categorical variables have significantly different correlations from each other. \n",
    "\n",
    "Notes:\n",
    "- To best use this notebook, you should be familar with mixed effects models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 - Import CSV with All Data\n",
    "**The CSV is expected to be in this format**\n",
    "- ID and absolute paths to niftis are critical\n",
    "```\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "| ID  | Nifti_File_Path            | Covariate_1  | Covariate_2  | Covariate_3  |\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "| 1   | /path/to/file1.nii.gz      | 0.5          | 1.2          | 3.4          |\n",
    "| 2   | /path/to/file2.nii.gz      | 0.7          | 1.4          | 3.1          |\n",
    "| 3   | /path/to/file3.nii.gz      | 0.6          | 1.5          | 3.5          |\n",
    "| 4   | /path/to/file4.nii.gz      | 0.9          | 1.1          | 3.2          |\n",
    "| ... | ...                        | ...          | ...          | ...          |\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your CSV file containing NIFTI paths\n",
    "input_csv_path = '/Users/cu135/Partners HealthCare Dropbox/Calvin Howard/studies/cognition_2023/metadata/master_list_proper_subjects.xlsx'\n",
    "sheet = 'master_list_proper_subjects' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify where you want to save your results to\n",
    "out_dir = '/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Research/2023/subiculum_cognition_and_age/figures/Figures/3_cohort_delta_r/split_by_sbc_group/deta_btwn_corre_strengths'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.permutation_analysis_utils.statsmodels_palm import CalvinStatsmodelsPalm\n",
    "# Instantiate the PalmPrepararation class\n",
    "cal_palm = CalvinStatsmodelsPalm(input_csv_path=input_csv_path, output_dir=out_dir, sheet=sheet)\n",
    "# Call the process_nifti_paths method\n",
    "data_df = cal_palm.read_and_display_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 01 - Preprocess Your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handle NANs**\n",
    "- Set drop_nans=True is you would like to remove NaNs from data\n",
    "- Provide a column name or a list of column names to remove NaNs from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject', 'Age', 'Hippocampus_GM_Vol', 'Parahippocampal_Gyrus_GM_Vol',\n",
       "       'Entorhinal_Cortex_GM_Vol', 'Normalized_Percent_Cognitive_Improvement',\n",
       "       'Z_Scored_Percent_Cognitive_Improvement_By_Origin_Group',\n",
       "       'Z_Scored_Percent_Cognitive_Improvement',\n",
       "       'Percent_Cognitive_Improvement',\n",
       "       'Z_Scored_Subiculum_T_By_Origin_Group_',\n",
       "       'Z_Scored_Subiculum_Connectivity_T', 'Subiculum_Connectivity_T_Redone',\n",
       "       'Subiculum_Connectivity_T', 'Amnesia_Lesion_T_Map', 'Memory_Network_T',\n",
       "       'Z_Scored_Memory_Network_R', 'Memory_Network_R',\n",
       "       'Subiculum_Grey_Matter', 'Subiculum_White_Matter', 'Subiculum_CSF',\n",
       "       'Subiculum_Total', 'Standardized_Age',\n",
       "       'Standardized_Percent_Improvement',\n",
       "       'Standardized_Subiculum_Connectivity',\n",
       "       'Standardized_Subiculum_Grey_Matter',\n",
       "       'Standardized_Subiculum_White_Matter', 'Standardized_Subiculum_CSF',\n",
       "       'Standardized_Subiculum_Total', 'Disease', 'Cohort', 'City',\n",
       "       'Inclusion_Cohort', 'Categorical_Age_Group', 'Age_Group',\n",
       "       'Age_And_Disease', 'Age_Disease_and_Cohort', 'Age_Disease_Cohort_Stim',\n",
       "       'Age_And_Stim', 'Subiculum_Group_By_Z_Score_Sign',\n",
       "       'Subiculum_Group_By_Inflection_Point', 'Subiculum_Group_By_24',\n",
       "       'Cognitive_Outcome', 'StimMatch', 'StimMatch24', 'Cognitive_Baseline',\n",
       "       'Cognitive_Score_1_Yr', 'MinMaxNorm_Cog_Score_1_Yr',\n",
       "       'Abs_Cognitive_Improve', 'IMPROVE_OR_STABLE', 'DECLINE_OR_STABLE',\n",
       "       'IMPROVE', 'DECLINE', 'Cognitive_Improve',\n",
       "       'Z_Scored_Cognitive_Baseline',\n",
       "       'Z_Scored_Cognitive_Baseline__Lower_is_Better_',\n",
       "       'Min_Max_Normalized_Baseline', 'MinMaxNormBaseline_Higher_is_Better',\n",
       "       'ROI_to_Alz_Max', 'ROI_to_PD_Max', 'Standardzied_AD_Max',\n",
       "       'Standardized_PD_Max'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['Age', 'Z_Scored_Percent_Cognitive_Improvement', 'Z_Scored_Subiculum_Connectivity_T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>Age</th>\n",
       "      <th>Hippocampus_GM_Vol</th>\n",
       "      <th>Parahippocampal_Gyrus_GM_Vol</th>\n",
       "      <th>Entorhinal_Cortex_GM_Vol</th>\n",
       "      <th>Normalized_Percent_Cognitive_Improvement</th>\n",
       "      <th>Z_Scored_Percent_Cognitive_Improvement_By_Origin_Group</th>\n",
       "      <th>Z_Scored_Percent_Cognitive_Improvement</th>\n",
       "      <th>Percent_Cognitive_Improvement</th>\n",
       "      <th>Z_Scored_Subiculum_T_By_Origin_Group_</th>\n",
       "      <th>...</th>\n",
       "      <th>DECLINE</th>\n",
       "      <th>Cognitive_Improve</th>\n",
       "      <th>Z_Scored_Cognitive_Baseline</th>\n",
       "      <th>Z_Scored_Cognitive_Baseline__Lower_is_Better_</th>\n",
       "      <th>Min_Max_Normalized_Baseline</th>\n",
       "      <th>MinMaxNormBaseline_Higher_is_Better</th>\n",
       "      <th>ROI_to_Alz_Max</th>\n",
       "      <th>ROI_to_PD_Max</th>\n",
       "      <th>Standardzied_AD_Max</th>\n",
       "      <th>Standardized_PD_Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>62.0</td>\n",
       "      <td>5.8883</td>\n",
       "      <td>4.5970</td>\n",
       "      <td>2.4587</td>\n",
       "      <td>-0.392857</td>\n",
       "      <td>0.314066</td>\n",
       "      <td>0.314066</td>\n",
       "      <td>-21.428571</td>\n",
       "      <td>-1.282630</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1.518764</td>\n",
       "      <td>-1.518764</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.28</td>\n",
       "      <td>12.222658</td>\n",
       "      <td>14.493929</td>\n",
       "      <td>-1.714513</td>\n",
       "      <td>-1.227368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>77.0</td>\n",
       "      <td>3.7634</td>\n",
       "      <td>3.9036</td>\n",
       "      <td>2.2905</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.013999</td>\n",
       "      <td>0.013999</td>\n",
       "      <td>-36.363636</td>\n",
       "      <td>-1.760917</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.465551</td>\n",
       "      <td>-0.465551</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>14.020048</td>\n",
       "      <td>15.257338</td>\n",
       "      <td>-1.155843</td>\n",
       "      <td>-1.022243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>76.0</td>\n",
       "      <td>4.8575</td>\n",
       "      <td>4.8177</td>\n",
       "      <td>3.1596</td>\n",
       "      <td>-1.447368</td>\n",
       "      <td>-0.841572</td>\n",
       "      <td>-0.841572</td>\n",
       "      <td>-78.947368</td>\n",
       "      <td>-0.595369</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.061056</td>\n",
       "      <td>0.061056</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.64</td>\n",
       "      <td>15.118727</td>\n",
       "      <td>17.376384</td>\n",
       "      <td>-0.814348</td>\n",
       "      <td>-0.452865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4.8569</td>\n",
       "      <td>4.8655</td>\n",
       "      <td>2.6641</td>\n",
       "      <td>-2.372549</td>\n",
       "      <td>-1.855477</td>\n",
       "      <td>-1.855477</td>\n",
       "      <td>-129.411765</td>\n",
       "      <td>-0.945206</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.412127</td>\n",
       "      <td>0.412127</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.72</td>\n",
       "      <td>13.112424</td>\n",
       "      <td>15.287916</td>\n",
       "      <td>-1.437954</td>\n",
       "      <td>-1.014027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.9636</td>\n",
       "      <td>4.8434</td>\n",
       "      <td>3.3463</td>\n",
       "      <td>-0.192982</td>\n",
       "      <td>0.533109</td>\n",
       "      <td>0.533109</td>\n",
       "      <td>-10.526316</td>\n",
       "      <td>-1.151973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.061056</td>\n",
       "      <td>0.061056</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.64</td>\n",
       "      <td>15.086568</td>\n",
       "      <td>12.951426</td>\n",
       "      <td>-0.824344</td>\n",
       "      <td>-1.641831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>86</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.598787</td>\n",
       "      <td>-0.099428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.087220</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>87</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.598787</td>\n",
       "      <td>-0.099428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.598397</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>88</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.854050</td>\n",
       "      <td>2.637141</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>0.269872</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>89</td>\n",
       "      <td>67.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.598787</td>\n",
       "      <td>-0.099428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.158639</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>91</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.818759</td>\n",
       "      <td>0.535847</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>0.469844</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subject   Age  Hippocampus_GM_Vol  Parahippocampal_Gyrus_GM_Vol  \\\n",
       "0        101  62.0              5.8883                        4.5970   \n",
       "1        102  77.0              3.7634                        3.9036   \n",
       "2        103  76.0              4.8575                        4.8177   \n",
       "3        104  65.0              4.8569                        4.8655   \n",
       "4        105  50.0              5.9636                        4.8434   \n",
       "..       ...   ...                 ...                           ...   \n",
       "160       86  57.0                 NaN                           NaN   \n",
       "161       87  65.0                 NaN                           NaN   \n",
       "162       88  65.0                 NaN                           NaN   \n",
       "163       89  67.0                 NaN                           NaN   \n",
       "164       91  45.0                 NaN                           NaN   \n",
       "\n",
       "     Entorhinal_Cortex_GM_Vol  Normalized_Percent_Cognitive_Improvement  \\\n",
       "0                      2.4587                                 -0.392857   \n",
       "1                      2.2905                                 -0.666667   \n",
       "2                      3.1596                                 -1.447368   \n",
       "3                      2.6641                                 -2.372549   \n",
       "4                      3.3463                                 -0.192982   \n",
       "..                        ...                                       ...   \n",
       "160                       NaN                                       NaN   \n",
       "161                       NaN                                       NaN   \n",
       "162                       NaN                                       NaN   \n",
       "163                       NaN                                       NaN   \n",
       "164                       NaN                                       NaN   \n",
       "\n",
       "     Z_Scored_Percent_Cognitive_Improvement_By_Origin_Group  \\\n",
       "0                                             0.314066        \n",
       "1                                             0.013999        \n",
       "2                                            -0.841572        \n",
       "3                                            -1.855477        \n",
       "4                                             0.533109        \n",
       "..                                                 ...        \n",
       "160                                           0.598787        \n",
       "161                                           0.598787        \n",
       "162                                           5.854050        \n",
       "163                                           0.598787        \n",
       "164                                           1.818759        \n",
       "\n",
       "     Z_Scored_Percent_Cognitive_Improvement  Percent_Cognitive_Improvement  \\\n",
       "0                                  0.314066                     -21.428571   \n",
       "1                                  0.013999                     -36.363636   \n",
       "2                                 -0.841572                     -78.947368   \n",
       "3                                 -1.855477                    -129.411765   \n",
       "4                                  0.533109                     -10.526316   \n",
       "..                                      ...                            ...   \n",
       "160                               -0.099428                       0.000000   \n",
       "161                               -0.099428                       0.000000   \n",
       "162                                2.637141                      15.384615   \n",
       "163                               -0.099428                       0.000000   \n",
       "164                                0.535847                       3.571429   \n",
       "\n",
       "     Z_Scored_Subiculum_T_By_Origin_Group_  ...  DECLINE  Cognitive_Improve  \\\n",
       "0                                -1.282630  ...      1.0                 No   \n",
       "1                                -1.760917  ...      1.0                 No   \n",
       "2                                -0.595369  ...      1.0                 No   \n",
       "3                                -0.945206  ...      1.0                 No   \n",
       "4                                -1.151973  ...      0.0                 No   \n",
       "..                                     ...  ...      ...                ...   \n",
       "160                              -0.087220  ...      NaN                Yes   \n",
       "161                               0.598397  ...      NaN                Yes   \n",
       "162                               0.269872  ...      NaN                Yes   \n",
       "163                              -0.158639  ...      NaN                Yes   \n",
       "164                               0.469844  ...      NaN                Yes   \n",
       "\n",
       "     Z_Scored_Cognitive_Baseline  \\\n",
       "0                       1.518764   \n",
       "1                       0.465551   \n",
       "2                      -0.061056   \n",
       "3                      -0.412127   \n",
       "4                      -0.061056   \n",
       "..                           ...   \n",
       "160                          NaN   \n",
       "161                          NaN   \n",
       "162                          NaN   \n",
       "163                          NaN   \n",
       "164                          NaN   \n",
       "\n",
       "     Z_Scored_Cognitive_Baseline__Lower_is_Better_  \\\n",
       "0                                        -1.518764   \n",
       "1                                        -0.465551   \n",
       "2                                         0.061056   \n",
       "3                                         0.412127   \n",
       "4                                         0.061056   \n",
       "..                                             ...   \n",
       "160                                            NaN   \n",
       "161                                            NaN   \n",
       "162                                            NaN   \n",
       "163                                            NaN   \n",
       "164                                            NaN   \n",
       "\n",
       "     Min_Max_Normalized_Baseline  MinMaxNormBaseline_Higher_is_Better  \\\n",
       "0                           0.72                                 0.28   \n",
       "1                           0.48                                 0.52   \n",
       "2                           0.36                                 0.64   \n",
       "3                           0.28                                 0.72   \n",
       "4                           0.36                                 0.64   \n",
       "..                           ...                                  ...   \n",
       "160                          NaN                                  NaN   \n",
       "161                          NaN                                  NaN   \n",
       "162                          NaN                                  NaN   \n",
       "163                          NaN                                  NaN   \n",
       "164                          NaN                                  NaN   \n",
       "\n",
       "     ROI_to_Alz_Max  ROI_to_PD_Max  Standardzied_AD_Max  Standardized_PD_Max  \n",
       "0         12.222658      14.493929            -1.714513            -1.227368  \n",
       "1         14.020048      15.257338            -1.155843            -1.022243  \n",
       "2         15.118727      17.376384            -0.814348            -0.452865  \n",
       "3         13.112424      15.287916            -1.437954            -1.014027  \n",
       "4         15.086568      12.951426            -0.824344            -1.641831  \n",
       "..              ...            ...                  ...                  ...  \n",
       "160             NaN            NaN                  NaN                  NaN  \n",
       "161             NaN            NaN                  NaN                  NaN  \n",
       "162             NaN            NaN                  NaN                  NaN  \n",
       "163             NaN            NaN                  NaN                  NaN  \n",
       "164             NaN            NaN                  NaN                  NaN  \n",
       "\n",
       "[148 rows x 61 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_df = cal_palm.drop_nans_from_columns(columns_to_drop_from=drop_list)\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop Row Based on Value of Column**\n",
    "\n",
    "Define the column, condition, and value for dropping rows\n",
    "- column = 'your_column_name'\n",
    "- condition = 'above'  # Options: 'equal', 'above', 'below'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the parameters for dropping rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject', 'Age', 'Hippocampus_GM_Vol', 'Parahippocampal_Gyrus_GM_Vol',\n",
       "       'Entorhinal_Cortex_GM_Vol', 'Normalized_Percent_Cognitive_Improvement',\n",
       "       'Z_Scored_Percent_Cognitive_Improvement_By_Origin_Group',\n",
       "       'Z_Scored_Percent_Cognitive_Improvement',\n",
       "       'Percent_Cognitive_Improvement',\n",
       "       'Z_Scored_Subiculum_T_By_Origin_Group_',\n",
       "       'Z_Scored_Subiculum_Connectivity_T', 'Subiculum_Connectivity_T_Redone',\n",
       "       'Subiculum_Connectivity_T', 'Amnesia_Lesion_T_Map', 'Memory_Network_T',\n",
       "       'Z_Scored_Memory_Network_R', 'Memory_Network_R',\n",
       "       'Subiculum_Grey_Matter', 'Subiculum_White_Matter', 'Subiculum_CSF',\n",
       "       'Subiculum_Total', 'Standardized_Age',\n",
       "       'Standardized_Percent_Improvement',\n",
       "       'Standardized_Subiculum_Connectivity',\n",
       "       'Standardized_Subiculum_Grey_Matter',\n",
       "       'Standardized_Subiculum_White_Matter', 'Standardized_Subiculum_CSF',\n",
       "       'Standardized_Subiculum_Total', 'Disease', 'Cohort', 'City',\n",
       "       'Inclusion_Cohort', 'Categorical_Age_Group', 'Age_Group',\n",
       "       'Age_And_Disease', 'Age_Disease_and_Cohort', 'Age_Disease_Cohort_Stim',\n",
       "       'Age_And_Stim', 'Subiculum_Group_By_Z_Score_Sign',\n",
       "       'Subiculum_Group_By_Inflection_Point', 'Subiculum_Group_By_24',\n",
       "       'Cognitive_Outcome', 'StimMatch', 'StimMatch24', 'Cognitive_Baseline',\n",
       "       'Cognitive_Score_1_Yr', 'MinMaxNorm_Cog_Score_1_Yr',\n",
       "       'Abs_Cognitive_Improve', 'IMPROVE_OR_STABLE', 'DECLINE_OR_STABLE',\n",
       "       'IMPROVE', 'DECLINE', 'Cognitive_Improve',\n",
       "       'Z_Scored_Cognitive_Baseline',\n",
       "       'Z_Scored_Cognitive_Baseline__Lower_is_Better_',\n",
       "       'Min_Max_Normalized_Baseline', 'MinMaxNormBaseline_Higher_is_Better',\n",
       "       'ROI_to_Alz_Max', 'ROI_to_PD_Max', 'Standardzied_AD_Max',\n",
       "       'Standardized_PD_Max'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns\n",
    "# data_df.City.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'City'  # The column you'd like to evaluate\n",
    "condition = 'not'  # Thecondition to check ('equal', 'above', 'below', 'not')\n",
    "value = 'Toronto' # The value to compare against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>Age</th>\n",
       "      <th>Hippocampus_GM_Vol</th>\n",
       "      <th>Parahippocampal_Gyrus_GM_Vol</th>\n",
       "      <th>Entorhinal_Cortex_GM_Vol</th>\n",
       "      <th>Normalized_Percent_Cognitive_Improvement</th>\n",
       "      <th>Z_Scored_Percent_Cognitive_Improvement_By_Origin_Group</th>\n",
       "      <th>Z_Scored_Percent_Cognitive_Improvement</th>\n",
       "      <th>Percent_Cognitive_Improvement</th>\n",
       "      <th>Z_Scored_Subiculum_T_By_Origin_Group_</th>\n",
       "      <th>...</th>\n",
       "      <th>DECLINE</th>\n",
       "      <th>Cognitive_Improve</th>\n",
       "      <th>Z_Scored_Cognitive_Baseline</th>\n",
       "      <th>Z_Scored_Cognitive_Baseline__Lower_is_Better_</th>\n",
       "      <th>Min_Max_Normalized_Baseline</th>\n",
       "      <th>MinMaxNormBaseline_Higher_is_Better</th>\n",
       "      <th>ROI_to_Alz_Max</th>\n",
       "      <th>ROI_to_PD_Max</th>\n",
       "      <th>Standardzied_AD_Max</th>\n",
       "      <th>Standardized_PD_Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>62.0</td>\n",
       "      <td>5.8883</td>\n",
       "      <td>4.5970</td>\n",
       "      <td>2.4587</td>\n",
       "      <td>-0.392857</td>\n",
       "      <td>0.314066</td>\n",
       "      <td>0.314066</td>\n",
       "      <td>-21.428571</td>\n",
       "      <td>-1.282630</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1.518764</td>\n",
       "      <td>-1.518764</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.28</td>\n",
       "      <td>12.222658</td>\n",
       "      <td>14.493929</td>\n",
       "      <td>-1.714513</td>\n",
       "      <td>-1.227368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>77.0</td>\n",
       "      <td>3.7634</td>\n",
       "      <td>3.9036</td>\n",
       "      <td>2.2905</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.013999</td>\n",
       "      <td>0.013999</td>\n",
       "      <td>-36.363636</td>\n",
       "      <td>-1.760917</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.465551</td>\n",
       "      <td>-0.465551</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>14.020048</td>\n",
       "      <td>15.257338</td>\n",
       "      <td>-1.155843</td>\n",
       "      <td>-1.022243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>76.0</td>\n",
       "      <td>4.8575</td>\n",
       "      <td>4.8177</td>\n",
       "      <td>3.1596</td>\n",
       "      <td>-1.447368</td>\n",
       "      <td>-0.841572</td>\n",
       "      <td>-0.841572</td>\n",
       "      <td>-78.947368</td>\n",
       "      <td>-0.595369</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.061056</td>\n",
       "      <td>0.061056</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.64</td>\n",
       "      <td>15.118727</td>\n",
       "      <td>17.376384</td>\n",
       "      <td>-0.814348</td>\n",
       "      <td>-0.452865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4.8569</td>\n",
       "      <td>4.8655</td>\n",
       "      <td>2.6641</td>\n",
       "      <td>-2.372549</td>\n",
       "      <td>-1.855477</td>\n",
       "      <td>-1.855477</td>\n",
       "      <td>-129.411765</td>\n",
       "      <td>-0.945206</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.412127</td>\n",
       "      <td>0.412127</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.72</td>\n",
       "      <td>13.112424</td>\n",
       "      <td>15.287916</td>\n",
       "      <td>-1.437954</td>\n",
       "      <td>-1.014027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.9636</td>\n",
       "      <td>4.8434</td>\n",
       "      <td>3.3463</td>\n",
       "      <td>-0.192982</td>\n",
       "      <td>0.533109</td>\n",
       "      <td>0.533109</td>\n",
       "      <td>-10.526316</td>\n",
       "      <td>-1.151973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.061056</td>\n",
       "      <td>0.061056</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.64</td>\n",
       "      <td>15.086568</td>\n",
       "      <td>12.951426</td>\n",
       "      <td>-0.824344</td>\n",
       "      <td>-1.641831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>106</td>\n",
       "      <td>66.0</td>\n",
       "      <td>5.0476</td>\n",
       "      <td>4.9223</td>\n",
       "      <td>2.8478</td>\n",
       "      <td>-0.705128</td>\n",
       "      <td>-0.028151</td>\n",
       "      <td>-0.028151</td>\n",
       "      <td>-38.461538</td>\n",
       "      <td>-0.489205</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>-1.114269</td>\n",
       "      <td>1.114269</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.88</td>\n",
       "      <td>15.816634</td>\n",
       "      <td>17.617107</td>\n",
       "      <td>-0.597423</td>\n",
       "      <td>-0.388183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>107</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4.0586</td>\n",
       "      <td>4.2483</td>\n",
       "      <td>2.4046</td>\n",
       "      <td>-0.282051</td>\n",
       "      <td>0.435498</td>\n",
       "      <td>0.435498</td>\n",
       "      <td>-15.384615</td>\n",
       "      <td>-1.718309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>-1.114269</td>\n",
       "      <td>1.114269</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.88</td>\n",
       "      <td>15.524025</td>\n",
       "      <td>13.452311</td>\n",
       "      <td>-0.688373</td>\n",
       "      <td>-1.507246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>108</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.8265</td>\n",
       "      <td>4.0317</td>\n",
       "      <td>2.7601</td>\n",
       "      <td>-0.534722</td>\n",
       "      <td>0.158596</td>\n",
       "      <td>0.158596</td>\n",
       "      <td>-29.166667</td>\n",
       "      <td>-1.145694</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.816622</td>\n",
       "      <td>-0.816622</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.44</td>\n",
       "      <td>16.546984</td>\n",
       "      <td>13.932696</td>\n",
       "      <td>-0.370413</td>\n",
       "      <td>-1.378169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>109</td>\n",
       "      <td>72.0</td>\n",
       "      <td>4.6904</td>\n",
       "      <td>3.9931</td>\n",
       "      <td>2.4961</td>\n",
       "      <td>-0.557971</td>\n",
       "      <td>0.133118</td>\n",
       "      <td>0.133118</td>\n",
       "      <td>-30.434783</td>\n",
       "      <td>-0.043697</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.641086</td>\n",
       "      <td>-0.641086</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.48</td>\n",
       "      <td>19.669539</td>\n",
       "      <td>21.341523</td>\n",
       "      <td>0.600149</td>\n",
       "      <td>0.612551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>110</td>\n",
       "      <td>72.0</td>\n",
       "      <td>5.3981</td>\n",
       "      <td>5.3549</td>\n",
       "      <td>2.9588</td>\n",
       "      <td>-1.551282</td>\n",
       "      <td>-0.955451</td>\n",
       "      <td>-0.955451</td>\n",
       "      <td>-84.615385</td>\n",
       "      <td>0.240855</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>-1.114269</td>\n",
       "      <td>1.114269</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.88</td>\n",
       "      <td>18.295718</td>\n",
       "      <td>19.263977</td>\n",
       "      <td>0.173133</td>\n",
       "      <td>0.054323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>111</td>\n",
       "      <td>62.0</td>\n",
       "      <td>5.3423</td>\n",
       "      <td>4.4525</td>\n",
       "      <td>3.3324</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>1.581744</td>\n",
       "      <td>1.581744</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>2.004069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-1.289805</td>\n",
       "      <td>1.289805</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.92</td>\n",
       "      <td>17.022328</td>\n",
       "      <td>16.151031</td>\n",
       "      <td>-0.222665</td>\n",
       "      <td>-0.782112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>113</td>\n",
       "      <td>69.0</td>\n",
       "      <td>5.2798</td>\n",
       "      <td>4.2540</td>\n",
       "      <td>3.3791</td>\n",
       "      <td>-1.100000</td>\n",
       "      <td>-0.460891</td>\n",
       "      <td>-0.460891</td>\n",
       "      <td>-60.000000</td>\n",
       "      <td>0.301223</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.763198</td>\n",
       "      <td>0.763198</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>16.225059</td>\n",
       "      <td>17.818822</td>\n",
       "      <td>-0.470475</td>\n",
       "      <td>-0.333983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>114</td>\n",
       "      <td>67.0</td>\n",
       "      <td>4.0479</td>\n",
       "      <td>3.6480</td>\n",
       "      <td>1.8183</td>\n",
       "      <td>-0.295699</td>\n",
       "      <td>0.420542</td>\n",
       "      <td>0.420542</td>\n",
       "      <td>-16.129032</td>\n",
       "      <td>0.015433</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2.045371</td>\n",
       "      <td>-2.045371</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.16</td>\n",
       "      <td>15.295109</td>\n",
       "      <td>18.046377</td>\n",
       "      <td>-0.759525</td>\n",
       "      <td>-0.272840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>115</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.6552</td>\n",
       "      <td>4.4571</td>\n",
       "      <td>2.3475</td>\n",
       "      <td>-0.885057</td>\n",
       "      <td>-0.225336</td>\n",
       "      <td>-0.225336</td>\n",
       "      <td>-48.275862</td>\n",
       "      <td>0.472801</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1.694300</td>\n",
       "      <td>-1.694300</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.24</td>\n",
       "      <td>18.623736</td>\n",
       "      <td>16.113043</td>\n",
       "      <td>0.275089</td>\n",
       "      <td>-0.792319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>116</td>\n",
       "      <td>67.0</td>\n",
       "      <td>5.4663</td>\n",
       "      <td>4.9760</td>\n",
       "      <td>3.2544</td>\n",
       "      <td>-0.675439</td>\n",
       "      <td>0.004385</td>\n",
       "      <td>0.004385</td>\n",
       "      <td>-36.842105</td>\n",
       "      <td>-0.657659</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.061056</td>\n",
       "      <td>0.061056</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.64</td>\n",
       "      <td>16.462336</td>\n",
       "      <td>18.503053</td>\n",
       "      <td>-0.396724</td>\n",
       "      <td>-0.150134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>118</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.2506</td>\n",
       "      <td>4.5616</td>\n",
       "      <td>2.4472</td>\n",
       "      <td>-0.057292</td>\n",
       "      <td>0.681812</td>\n",
       "      <td>0.681812</td>\n",
       "      <td>-3.125000</td>\n",
       "      <td>0.643782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2.220907</td>\n",
       "      <td>-2.220907</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.12</td>\n",
       "      <td>15.842273</td>\n",
       "      <td>19.964170</td>\n",
       "      <td>-0.589454</td>\n",
       "      <td>0.242462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>119</td>\n",
       "      <td>75.0</td>\n",
       "      <td>4.6080</td>\n",
       "      <td>4.3267</td>\n",
       "      <td>2.4542</td>\n",
       "      <td>-1.489583</td>\n",
       "      <td>-0.887835</td>\n",
       "      <td>-0.887835</td>\n",
       "      <td>-81.250000</td>\n",
       "      <td>-0.637257</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.587663</td>\n",
       "      <td>0.587663</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.76</td>\n",
       "      <td>17.332886</td>\n",
       "      <td>19.198042</td>\n",
       "      <td>-0.126137</td>\n",
       "      <td>0.036607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>120</td>\n",
       "      <td>68.0</td>\n",
       "      <td>5.5383</td>\n",
       "      <td>5.1186</td>\n",
       "      <td>3.3269</td>\n",
       "      <td>-0.509259</td>\n",
       "      <td>0.186501</td>\n",
       "      <td>0.186501</td>\n",
       "      <td>-27.777778</td>\n",
       "      <td>-0.781964</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.236591</td>\n",
       "      <td>0.236591</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.68</td>\n",
       "      <td>10.126563</td>\n",
       "      <td>9.630690</td>\n",
       "      <td>-2.366028</td>\n",
       "      <td>-2.534098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>121</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2.4099</td>\n",
       "      <td>3.0610</td>\n",
       "      <td>1.4439</td>\n",
       "      <td>-0.079710</td>\n",
       "      <td>0.657244</td>\n",
       "      <td>0.657244</td>\n",
       "      <td>-4.347826</td>\n",
       "      <td>0.481163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.641086</td>\n",
       "      <td>-0.641086</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.48</td>\n",
       "      <td>22.476761</td>\n",
       "      <td>23.985143</td>\n",
       "      <td>1.472698</td>\n",
       "      <td>1.322880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>122</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.5542</td>\n",
       "      <td>3.8887</td>\n",
       "      <td>2.3858</td>\n",
       "      <td>-2.566667</td>\n",
       "      <td>-2.068210</td>\n",
       "      <td>-2.068210</td>\n",
       "      <td>-140.000000</td>\n",
       "      <td>0.190387</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.763198</td>\n",
       "      <td>0.763198</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>21.466327</td>\n",
       "      <td>23.582758</td>\n",
       "      <td>1.158632</td>\n",
       "      <td>1.214761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>123</td>\n",
       "      <td>47.0</td>\n",
       "      <td>7.5469</td>\n",
       "      <td>5.6989</td>\n",
       "      <td>3.8574</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.840498</td>\n",
       "      <td>1.840498</td>\n",
       "      <td>54.545455</td>\n",
       "      <td>-0.341607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.465551</td>\n",
       "      <td>-0.465551</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>19.453283</td>\n",
       "      <td>21.676897</td>\n",
       "      <td>0.532931</td>\n",
       "      <td>0.702664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>124</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.8563</td>\n",
       "      <td>5.0760</td>\n",
       "      <td>3.7145</td>\n",
       "      <td>-0.343750</td>\n",
       "      <td>0.367883</td>\n",
       "      <td>0.367883</td>\n",
       "      <td>-18.750000</td>\n",
       "      <td>-0.864253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.587663</td>\n",
       "      <td>0.587663</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.76</td>\n",
       "      <td>13.457540</td>\n",
       "      <td>15.819523</td>\n",
       "      <td>-1.330684</td>\n",
       "      <td>-0.871186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>125</td>\n",
       "      <td>73.0</td>\n",
       "      <td>3.8315</td>\n",
       "      <td>4.2910</td>\n",
       "      <td>2.9779</td>\n",
       "      <td>-0.687500</td>\n",
       "      <td>-0.008833</td>\n",
       "      <td>-0.008833</td>\n",
       "      <td>-37.500000</td>\n",
       "      <td>0.536747</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.587663</td>\n",
       "      <td>0.587663</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.76</td>\n",
       "      <td>22.443084</td>\n",
       "      <td>24.738357</td>\n",
       "      <td>1.462230</td>\n",
       "      <td>1.525265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>126</td>\n",
       "      <td>69.0</td>\n",
       "      <td>6.6456</td>\n",
       "      <td>5.5765</td>\n",
       "      <td>4.1341</td>\n",
       "      <td>-1.833333</td>\n",
       "      <td>-1.264551</td>\n",
       "      <td>-1.264551</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>1.081582</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.290015</td>\n",
       "      <td>-0.290015</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.56</td>\n",
       "      <td>20.186102</td>\n",
       "      <td>22.065363</td>\n",
       "      <td>0.760708</td>\n",
       "      <td>0.807044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>127</td>\n",
       "      <td>74.0</td>\n",
       "      <td>4.9725</td>\n",
       "      <td>4.4656</td>\n",
       "      <td>2.7874</td>\n",
       "      <td>-1.401961</td>\n",
       "      <td>-0.791810</td>\n",
       "      <td>-0.791810</td>\n",
       "      <td>-76.470588</td>\n",
       "      <td>0.009987</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.412127</td>\n",
       "      <td>0.412127</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.72</td>\n",
       "      <td>16.996513</td>\n",
       "      <td>18.394062</td>\n",
       "      <td>-0.230689</td>\n",
       "      <td>-0.179419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>128</td>\n",
       "      <td>72.0</td>\n",
       "      <td>5.3292</td>\n",
       "      <td>5.4510</td>\n",
       "      <td>3.6098</td>\n",
       "      <td>-0.381944</td>\n",
       "      <td>0.326026</td>\n",
       "      <td>0.326026</td>\n",
       "      <td>-20.833333</td>\n",
       "      <td>1.010239</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.816622</td>\n",
       "      <td>-0.816622</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.44</td>\n",
       "      <td>17.204945</td>\n",
       "      <td>18.264558</td>\n",
       "      <td>-0.165904</td>\n",
       "      <td>-0.214216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>129</td>\n",
       "      <td>69.0</td>\n",
       "      <td>5.1925</td>\n",
       "      <td>5.2932</td>\n",
       "      <td>3.8123</td>\n",
       "      <td>-0.654762</td>\n",
       "      <td>0.027045</td>\n",
       "      <td>0.027045</td>\n",
       "      <td>-35.714286</td>\n",
       "      <td>1.271528</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1.518764</td>\n",
       "      <td>-1.518764</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.28</td>\n",
       "      <td>21.078380</td>\n",
       "      <td>22.489816</td>\n",
       "      <td>1.038049</td>\n",
       "      <td>0.921092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>130</td>\n",
       "      <td>66.0</td>\n",
       "      <td>4.3523</td>\n",
       "      <td>4.8551</td>\n",
       "      <td>2.9885</td>\n",
       "      <td>-0.130952</td>\n",
       "      <td>0.601088</td>\n",
       "      <td>0.601088</td>\n",
       "      <td>-7.142857</td>\n",
       "      <td>-0.161232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.938734</td>\n",
       "      <td>0.938734</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.84</td>\n",
       "      <td>18.617648</td>\n",
       "      <td>20.415928</td>\n",
       "      <td>0.273197</td>\n",
       "      <td>0.363848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>131</td>\n",
       "      <td>68.0</td>\n",
       "      <td>3.7187</td>\n",
       "      <td>4.1660</td>\n",
       "      <td>3.1186</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>-0.059061</td>\n",
       "      <td>-0.059061</td>\n",
       "      <td>-40.000000</td>\n",
       "      <td>0.576257</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.114480</td>\n",
       "      <td>-0.114480</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.60</td>\n",
       "      <td>18.410547</td>\n",
       "      <td>19.822564</td>\n",
       "      <td>0.208825</td>\n",
       "      <td>0.204413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>133</td>\n",
       "      <td>74.0</td>\n",
       "      <td>6.0572</td>\n",
       "      <td>5.4815</td>\n",
       "      <td>3.7202</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.870170</td>\n",
       "      <td>0.870170</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>0.938667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-0.587663</td>\n",
       "      <td>0.587663</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.76</td>\n",
       "      <td>18.420784</td>\n",
       "      <td>19.612924</td>\n",
       "      <td>0.212007</td>\n",
       "      <td>0.148084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>134</td>\n",
       "      <td>66.0</td>\n",
       "      <td>5.2225</td>\n",
       "      <td>4.2588</td>\n",
       "      <td>2.3753</td>\n",
       "      <td>0.539216</td>\n",
       "      <td>1.335524</td>\n",
       "      <td>1.335524</td>\n",
       "      <td>29.411765</td>\n",
       "      <td>0.609143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-0.412127</td>\n",
       "      <td>0.412127</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.72</td>\n",
       "      <td>23.613479</td>\n",
       "      <td>26.048153</td>\n",
       "      <td>1.826016</td>\n",
       "      <td>1.877202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>135</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5.0682</td>\n",
       "      <td>5.0456</td>\n",
       "      <td>2.8341</td>\n",
       "      <td>-0.838095</td>\n",
       "      <td>-0.173870</td>\n",
       "      <td>-0.173870</td>\n",
       "      <td>-45.714286</td>\n",
       "      <td>-0.484585</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2.747514</td>\n",
       "      <td>-2.747514</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.101986</td>\n",
       "      <td>17.647381</td>\n",
       "      <td>-0.508729</td>\n",
       "      <td>-0.380049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>137</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4.8465</td>\n",
       "      <td>4.1994</td>\n",
       "      <td>2.5505</td>\n",
       "      <td>-1.416667</td>\n",
       "      <td>-0.807926</td>\n",
       "      <td>-0.807926</td>\n",
       "      <td>-77.272727</td>\n",
       "      <td>-0.210108</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.465551</td>\n",
       "      <td>-0.465551</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>16.837360</td>\n",
       "      <td>18.171505</td>\n",
       "      <td>-0.280158</td>\n",
       "      <td>-0.239219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>138</td>\n",
       "      <td>72.0</td>\n",
       "      <td>4.0167</td>\n",
       "      <td>4.3322</td>\n",
       "      <td>2.3157</td>\n",
       "      <td>-0.174603</td>\n",
       "      <td>0.553251</td>\n",
       "      <td>0.553251</td>\n",
       "      <td>-9.523810</td>\n",
       "      <td>1.634297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.290015</td>\n",
       "      <td>-0.290015</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.56</td>\n",
       "      <td>20.531868</td>\n",
       "      <td>22.371502</td>\n",
       "      <td>0.868180</td>\n",
       "      <td>0.889302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>139</td>\n",
       "      <td>58.0</td>\n",
       "      <td>6.8939</td>\n",
       "      <td>5.9491</td>\n",
       "      <td>3.8860</td>\n",
       "      <td>-1.941176</td>\n",
       "      <td>-1.382736</td>\n",
       "      <td>-1.382736</td>\n",
       "      <td>-105.882353</td>\n",
       "      <td>-0.768437</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.412127</td>\n",
       "      <td>0.412127</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.72</td>\n",
       "      <td>17.957341</td>\n",
       "      <td>19.952870</td>\n",
       "      <td>0.067958</td>\n",
       "      <td>0.239426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>140</td>\n",
       "      <td>73.0</td>\n",
       "      <td>4.0320</td>\n",
       "      <td>3.8148</td>\n",
       "      <td>2.1651</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.109898</td>\n",
       "      <td>1.109898</td>\n",
       "      <td>18.181818</td>\n",
       "      <td>0.660878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.465551</td>\n",
       "      <td>-0.465551</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>24.418011</td>\n",
       "      <td>27.143129</td>\n",
       "      <td>2.076083</td>\n",
       "      <td>2.171417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>141</td>\n",
       "      <td>72.0</td>\n",
       "      <td>4.4905</td>\n",
       "      <td>4.5031</td>\n",
       "      <td>3.2975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.744598</td>\n",
       "      <td>0.744598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.169749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-0.061056</td>\n",
       "      <td>0.061056</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.64</td>\n",
       "      <td>17.856530</td>\n",
       "      <td>19.670979</td>\n",
       "      <td>0.036624</td>\n",
       "      <td>0.163683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>142</td>\n",
       "      <td>77.0</td>\n",
       "      <td>5.0543</td>\n",
       "      <td>5.3631</td>\n",
       "      <td>3.2220</td>\n",
       "      <td>0.101852</td>\n",
       "      <td>0.856218</td>\n",
       "      <td>0.856218</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>0.328286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-0.236591</td>\n",
       "      <td>0.236591</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.68</td>\n",
       "      <td>14.769545</td>\n",
       "      <td>16.131533</td>\n",
       "      <td>-0.922882</td>\n",
       "      <td>-0.787351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>143</td>\n",
       "      <td>71.0</td>\n",
       "      <td>4.2323</td>\n",
       "      <td>4.0443</td>\n",
       "      <td>2.3112</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.870170</td>\n",
       "      <td>0.870170</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>-0.118729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-0.587663</td>\n",
       "      <td>0.587663</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.76</td>\n",
       "      <td>20.179952</td>\n",
       "      <td>19.975031</td>\n",
       "      <td>0.758797</td>\n",
       "      <td>0.245380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>144</td>\n",
       "      <td>79.0</td>\n",
       "      <td>5.3617</td>\n",
       "      <td>6.4505</td>\n",
       "      <td>4.5765</td>\n",
       "      <td>-1.128205</td>\n",
       "      <td>-0.491801</td>\n",
       "      <td>-0.491801</td>\n",
       "      <td>-61.538462</td>\n",
       "      <td>-1.032653</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>-1.114269</td>\n",
       "      <td>1.114269</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.88</td>\n",
       "      <td>11.801552</td>\n",
       "      <td>14.042861</td>\n",
       "      <td>-1.845403</td>\n",
       "      <td>-1.348567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>145</td>\n",
       "      <td>74.0</td>\n",
       "      <td>5.0643</td>\n",
       "      <td>4.3216</td>\n",
       "      <td>3.1930</td>\n",
       "      <td>0.101852</td>\n",
       "      <td>0.856218</td>\n",
       "      <td>0.856218</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>2.183535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-0.236591</td>\n",
       "      <td>0.236591</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.68</td>\n",
       "      <td>21.327670</td>\n",
       "      <td>22.294652</td>\n",
       "      <td>1.115534</td>\n",
       "      <td>0.868652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>146</td>\n",
       "      <td>76.0</td>\n",
       "      <td>5.2239</td>\n",
       "      <td>5.7734</td>\n",
       "      <td>3.3615</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.351301</td>\n",
       "      <td>-0.351301</td>\n",
       "      <td>-54.545455</td>\n",
       "      <td>-2.576474</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>-1.465341</td>\n",
       "      <td>1.465341</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.96</td>\n",
       "      <td>16.512422</td>\n",
       "      <td>18.197520</td>\n",
       "      <td>-0.381156</td>\n",
       "      <td>-0.232229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>147</td>\n",
       "      <td>59.0</td>\n",
       "      <td>5.5514</td>\n",
       "      <td>5.2097</td>\n",
       "      <td>3.7974</td>\n",
       "      <td>-0.087302</td>\n",
       "      <td>0.648924</td>\n",
       "      <td>0.648924</td>\n",
       "      <td>-4.761905</td>\n",
       "      <td>0.262965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.290015</td>\n",
       "      <td>-0.290015</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.56</td>\n",
       "      <td>19.159295</td>\n",
       "      <td>19.553377</td>\n",
       "      <td>0.441553</td>\n",
       "      <td>0.132084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>148</td>\n",
       "      <td>51.0</td>\n",
       "      <td>5.8039</td>\n",
       "      <td>5.6546</td>\n",
       "      <td>3.8950</td>\n",
       "      <td>-3.807692</td>\n",
       "      <td>-3.428250</td>\n",
       "      <td>-3.428250</td>\n",
       "      <td>-207.692308</td>\n",
       "      <td>1.035924</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>-1.114269</td>\n",
       "      <td>1.114269</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.88</td>\n",
       "      <td>19.340269</td>\n",
       "      <td>21.114119</td>\n",
       "      <td>0.497804</td>\n",
       "      <td>0.551449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>149</td>\n",
       "      <td>77.0</td>\n",
       "      <td>4.1347</td>\n",
       "      <td>4.7595</td>\n",
       "      <td>2.9376</td>\n",
       "      <td>-1.650000</td>\n",
       "      <td>-1.063636</td>\n",
       "      <td>-1.063636</td>\n",
       "      <td>-90.000000</td>\n",
       "      <td>-0.650900</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>-1.640876</td>\n",
       "      <td>1.640876</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19.062652</td>\n",
       "      <td>20.569076</td>\n",
       "      <td>0.411514</td>\n",
       "      <td>0.404998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>150</td>\n",
       "      <td>71.0</td>\n",
       "      <td>3.9939</td>\n",
       "      <td>4.7515</td>\n",
       "      <td>2.9027</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.018573</td>\n",
       "      <td>1.018573</td>\n",
       "      <td>13.636364</td>\n",
       "      <td>0.759359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.465551</td>\n",
       "      <td>-0.465551</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>23.954833</td>\n",
       "      <td>26.691505</td>\n",
       "      <td>1.932117</td>\n",
       "      <td>2.050067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject   Age  Hippocampus_GM_Vol  Parahippocampal_Gyrus_GM_Vol  \\\n",
       "0       101  62.0              5.8883                        4.5970   \n",
       "1       102  77.0              3.7634                        3.9036   \n",
       "2       103  76.0              4.8575                        4.8177   \n",
       "3       104  65.0              4.8569                        4.8655   \n",
       "4       105  50.0              5.9636                        4.8434   \n",
       "5       106  66.0              5.0476                        4.9223   \n",
       "6       107  64.0              4.0586                        4.2483   \n",
       "7       108  60.0              4.8265                        4.0317   \n",
       "8       109  72.0              4.6904                        3.9931   \n",
       "9       110  72.0              5.3981                        5.3549   \n",
       "10      111  62.0              5.3423                        4.4525   \n",
       "11      113  69.0              5.2798                        4.2540   \n",
       "12      114  67.0              4.0479                        3.6480   \n",
       "13      115  60.0              4.6552                        4.4571   \n",
       "14      116  67.0              5.4663                        4.9760   \n",
       "15      118  52.0              4.2506                        4.5616   \n",
       "16      119  75.0              4.6080                        4.3267   \n",
       "17      120  68.0              5.5383                        5.1186   \n",
       "18      121  72.0              2.4099                        3.0610   \n",
       "19      122  58.0              4.5542                        3.8887   \n",
       "20      123  47.0              7.5469                        5.6989   \n",
       "21      124  61.0              4.8563                        5.0760   \n",
       "22      125  73.0              3.8315                        4.2910   \n",
       "23      126  69.0              6.6456                        5.5765   \n",
       "24      127  74.0              4.9725                        4.4656   \n",
       "25      128  72.0              5.3292                        5.4510   \n",
       "26      129  69.0              5.1925                        5.2932   \n",
       "27      130  66.0              4.3523                        4.8551   \n",
       "28      131  68.0              3.7187                        4.1660   \n",
       "29      133  74.0              6.0572                        5.4815   \n",
       "30      134  66.0              5.2225                        4.2588   \n",
       "31      135  57.0              5.0682                        5.0456   \n",
       "32      137  57.0              4.8465                        4.1994   \n",
       "33      138  72.0              4.0167                        4.3322   \n",
       "34      139  58.0              6.8939                        5.9491   \n",
       "35      140  73.0              4.0320                        3.8148   \n",
       "36      141  72.0              4.4905                        4.5031   \n",
       "37      142  77.0              5.0543                        5.3631   \n",
       "38      143  71.0              4.2323                        4.0443   \n",
       "39      144  79.0              5.3617                        6.4505   \n",
       "40      145  74.0              5.0643                        4.3216   \n",
       "41      146  76.0              5.2239                        5.7734   \n",
       "42      147  59.0              5.5514                        5.2097   \n",
       "43      148  51.0              5.8039                        5.6546   \n",
       "44      149  77.0              4.1347                        4.7595   \n",
       "45      150  71.0              3.9939                        4.7515   \n",
       "\n",
       "    Entorhinal_Cortex_GM_Vol  Normalized_Percent_Cognitive_Improvement  \\\n",
       "0                     2.4587                                 -0.392857   \n",
       "1                     2.2905                                 -0.666667   \n",
       "2                     3.1596                                 -1.447368   \n",
       "3                     2.6641                                 -2.372549   \n",
       "4                     3.3463                                 -0.192982   \n",
       "5                     2.8478                                 -0.705128   \n",
       "6                     2.4046                                 -0.282051   \n",
       "7                     2.7601                                 -0.534722   \n",
       "8                     2.4961                                 -0.557971   \n",
       "9                     2.9588                                 -1.551282   \n",
       "10                    3.3324                                  0.763889   \n",
       "11                    3.3791                                 -1.100000   \n",
       "12                    1.8183                                 -0.295699   \n",
       "13                    2.3475                                 -0.885057   \n",
       "14                    3.2544                                 -0.675439   \n",
       "15                    2.4472                                 -0.057292   \n",
       "16                    2.4542                                 -1.489583   \n",
       "17                    3.3269                                 -0.509259   \n",
       "18                    1.4439                                 -0.079710   \n",
       "19                    2.3858                                 -2.566667   \n",
       "20                    3.8574                                  1.000000   \n",
       "21                    3.7145                                 -0.343750   \n",
       "22                    2.9779                                 -0.687500   \n",
       "23                    4.1341                                 -1.833333   \n",
       "24                    2.7874                                 -1.401961   \n",
       "25                    3.6098                                 -0.381944   \n",
       "26                    3.8123                                 -0.654762   \n",
       "27                    2.9885                                 -0.130952   \n",
       "28                    3.1186                                 -0.733333   \n",
       "29                    3.7202                                  0.114583   \n",
       "30                    2.3753                                  0.539216   \n",
       "31                    2.8341                                 -0.838095   \n",
       "32                    2.5505                                 -1.416667   \n",
       "33                    2.3157                                 -0.174603   \n",
       "34                    3.8860                                 -1.941176   \n",
       "35                    2.1651                                  0.333333   \n",
       "36                    3.2975                                  0.000000   \n",
       "37                    3.2220                                  0.101852   \n",
       "38                    2.3112                                  0.114583   \n",
       "39                    4.5765                                 -1.128205   \n",
       "40                    3.1930                                  0.101852   \n",
       "41                    3.3615                                 -1.000000   \n",
       "42                    3.7974                                 -0.087302   \n",
       "43                    3.8950                                 -3.807692   \n",
       "44                    2.9376                                 -1.650000   \n",
       "45                    2.9027                                  0.250000   \n",
       "\n",
       "    Z_Scored_Percent_Cognitive_Improvement_By_Origin_Group  \\\n",
       "0                                            0.314066        \n",
       "1                                            0.013999        \n",
       "2                                           -0.841572        \n",
       "3                                           -1.855477        \n",
       "4                                            0.533109        \n",
       "5                                           -0.028151        \n",
       "6                                            0.435498        \n",
       "7                                            0.158596        \n",
       "8                                            0.133118        \n",
       "9                                           -0.955451        \n",
       "10                                           1.581744        \n",
       "11                                          -0.460891        \n",
       "12                                           0.420542        \n",
       "13                                          -0.225336        \n",
       "14                                           0.004385        \n",
       "15                                           0.681812        \n",
       "16                                          -0.887835        \n",
       "17                                           0.186501        \n",
       "18                                           0.657244        \n",
       "19                                          -2.068210        \n",
       "20                                           1.840498        \n",
       "21                                           0.367883        \n",
       "22                                          -0.008833        \n",
       "23                                          -1.264551        \n",
       "24                                          -0.791810        \n",
       "25                                           0.326026        \n",
       "26                                           0.027045        \n",
       "27                                           0.601088        \n",
       "28                                          -0.059061        \n",
       "29                                           0.870170        \n",
       "30                                           1.335524        \n",
       "31                                          -0.173870        \n",
       "32                                          -0.807926        \n",
       "33                                           0.553251        \n",
       "34                                          -1.382736        \n",
       "35                                           1.109898        \n",
       "36                                           0.744598        \n",
       "37                                           0.856218        \n",
       "38                                           0.870170        \n",
       "39                                          -0.491801        \n",
       "40                                           0.856218        \n",
       "41                                          -0.351301        \n",
       "42                                           0.648924        \n",
       "43                                          -3.428250        \n",
       "44                                          -1.063636        \n",
       "45                                           1.018573        \n",
       "\n",
       "    Z_Scored_Percent_Cognitive_Improvement  Percent_Cognitive_Improvement  \\\n",
       "0                                 0.314066                     -21.428571   \n",
       "1                                 0.013999                     -36.363636   \n",
       "2                                -0.841572                     -78.947368   \n",
       "3                                -1.855477                    -129.411765   \n",
       "4                                 0.533109                     -10.526316   \n",
       "5                                -0.028151                     -38.461538   \n",
       "6                                 0.435498                     -15.384615   \n",
       "7                                 0.158596                     -29.166667   \n",
       "8                                 0.133118                     -30.434783   \n",
       "9                                -0.955451                     -84.615385   \n",
       "10                                1.581744                      41.666667   \n",
       "11                               -0.460891                     -60.000000   \n",
       "12                                0.420542                     -16.129032   \n",
       "13                               -0.225336                     -48.275862   \n",
       "14                                0.004385                     -36.842105   \n",
       "15                                0.681812                      -3.125000   \n",
       "16                               -0.887835                     -81.250000   \n",
       "17                                0.186501                     -27.777778   \n",
       "18                                0.657244                      -4.347826   \n",
       "19                               -2.068210                    -140.000000   \n",
       "20                                1.840498                      54.545455   \n",
       "21                                0.367883                     -18.750000   \n",
       "22                               -0.008833                     -37.500000   \n",
       "23                               -1.264551                    -100.000000   \n",
       "24                               -0.791810                     -76.470588   \n",
       "25                                0.326026                     -20.833333   \n",
       "26                                0.027045                     -35.714286   \n",
       "27                                0.601088                      -7.142857   \n",
       "28                               -0.059061                     -40.000000   \n",
       "29                                0.870170                       6.250000   \n",
       "30                                1.335524                      29.411765   \n",
       "31                               -0.173870                     -45.714286   \n",
       "32                               -0.807926                     -77.272727   \n",
       "33                                0.553251                      -9.523810   \n",
       "34                               -1.382736                    -105.882353   \n",
       "35                                1.109898                      18.181818   \n",
       "36                                0.744598                       0.000000   \n",
       "37                                0.856218                       5.555556   \n",
       "38                                0.870170                       6.250000   \n",
       "39                               -0.491801                     -61.538462   \n",
       "40                                0.856218                       5.555556   \n",
       "41                               -0.351301                     -54.545455   \n",
       "42                                0.648924                      -4.761905   \n",
       "43                               -3.428250                    -207.692308   \n",
       "44                               -1.063636                     -90.000000   \n",
       "45                                1.018573                      13.636364   \n",
       "\n",
       "    Z_Scored_Subiculum_T_By_Origin_Group_  ...  DECLINE  Cognitive_Improve  \\\n",
       "0                               -1.282630  ...      1.0                 No   \n",
       "1                               -1.760917  ...      1.0                 No   \n",
       "2                               -0.595369  ...      1.0                 No   \n",
       "3                               -0.945206  ...      1.0                 No   \n",
       "4                               -1.151973  ...      0.0                 No   \n",
       "5                               -0.489205  ...      1.0                 No   \n",
       "6                               -1.718309  ...      0.0                 No   \n",
       "7                               -1.145694  ...      1.0                 No   \n",
       "8                               -0.043697  ...      1.0                 No   \n",
       "9                                0.240855  ...      1.0                 No   \n",
       "10                               2.004069  ...      0.0                Yes   \n",
       "11                               0.301223  ...      1.0                 No   \n",
       "12                               0.015433  ...      1.0                 No   \n",
       "13                               0.472801  ...      1.0                 No   \n",
       "14                              -0.657659  ...      1.0                 No   \n",
       "15                               0.643782  ...      0.0                 No   \n",
       "16                              -0.637257  ...      1.0                 No   \n",
       "17                              -0.781964  ...      1.0                 No   \n",
       "18                               0.481163  ...      0.0                 No   \n",
       "19                               0.190387  ...      1.0                 No   \n",
       "20                              -0.341607  ...      0.0                Yes   \n",
       "21                              -0.864253  ...      0.0                 No   \n",
       "22                               0.536747  ...      1.0                 No   \n",
       "23                               1.081582  ...      1.0                 No   \n",
       "24                               0.009987  ...      1.0                 No   \n",
       "25                               1.010239  ...      1.0                 No   \n",
       "26                               1.271528  ...      1.0                 No   \n",
       "27                              -0.161232  ...      0.0                 No   \n",
       "28                               0.576257  ...      1.0                 No   \n",
       "29                               0.938667  ...      0.0                Yes   \n",
       "30                               0.609143  ...      0.0                Yes   \n",
       "31                              -0.484585  ...      1.0                 No   \n",
       "32                              -0.210108  ...      1.0                 No   \n",
       "33                               1.634297  ...      0.0                 No   \n",
       "34                              -0.768437  ...      1.0                 No   \n",
       "35                               0.660878  ...      0.0                Yes   \n",
       "36                               1.169749  ...      0.0                Yes   \n",
       "37                               0.328286  ...      0.0                Yes   \n",
       "38                              -0.118729  ...      0.0                Yes   \n",
       "39                              -1.032653  ...      1.0                 No   \n",
       "40                               2.183535  ...      0.0                Yes   \n",
       "41                              -2.576474  ...      1.0                 No   \n",
       "42                               0.262965  ...      0.0                 No   \n",
       "43                               1.035924  ...      1.0                 No   \n",
       "44                              -0.650900  ...      1.0                 No   \n",
       "45                               0.759359  ...      0.0                Yes   \n",
       "\n",
       "    Z_Scored_Cognitive_Baseline  \\\n",
       "0                      1.518764   \n",
       "1                      0.465551   \n",
       "2                     -0.061056   \n",
       "3                     -0.412127   \n",
       "4                     -0.061056   \n",
       "5                     -1.114269   \n",
       "6                     -1.114269   \n",
       "7                      0.816622   \n",
       "8                      0.641086   \n",
       "9                     -1.114269   \n",
       "10                    -1.289805   \n",
       "11                    -0.763198   \n",
       "12                     2.045371   \n",
       "13                     1.694300   \n",
       "14                    -0.061056   \n",
       "15                     2.220907   \n",
       "16                    -0.587663   \n",
       "17                    -0.236591   \n",
       "18                     0.641086   \n",
       "19                    -0.763198   \n",
       "20                     0.465551   \n",
       "21                    -0.587663   \n",
       "22                    -0.587663   \n",
       "23                     0.290015   \n",
       "24                    -0.412127   \n",
       "25                     0.816622   \n",
       "26                     1.518764   \n",
       "27                    -0.938734   \n",
       "28                     0.114480   \n",
       "29                    -0.587663   \n",
       "30                    -0.412127   \n",
       "31                     2.747514   \n",
       "32                     0.465551   \n",
       "33                     0.290015   \n",
       "34                    -0.412127   \n",
       "35                     0.465551   \n",
       "36                    -0.061056   \n",
       "37                    -0.236591   \n",
       "38                    -0.587663   \n",
       "39                    -1.114269   \n",
       "40                    -0.236591   \n",
       "41                    -1.465341   \n",
       "42                     0.290015   \n",
       "43                    -1.114269   \n",
       "44                    -1.640876   \n",
       "45                     0.465551   \n",
       "\n",
       "    Z_Scored_Cognitive_Baseline__Lower_is_Better_  \\\n",
       "0                                       -1.518764   \n",
       "1                                       -0.465551   \n",
       "2                                        0.061056   \n",
       "3                                        0.412127   \n",
       "4                                        0.061056   \n",
       "5                                        1.114269   \n",
       "6                                        1.114269   \n",
       "7                                       -0.816622   \n",
       "8                                       -0.641086   \n",
       "9                                        1.114269   \n",
       "10                                       1.289805   \n",
       "11                                       0.763198   \n",
       "12                                      -2.045371   \n",
       "13                                      -1.694300   \n",
       "14                                       0.061056   \n",
       "15                                      -2.220907   \n",
       "16                                       0.587663   \n",
       "17                                       0.236591   \n",
       "18                                      -0.641086   \n",
       "19                                       0.763198   \n",
       "20                                      -0.465551   \n",
       "21                                       0.587663   \n",
       "22                                       0.587663   \n",
       "23                                      -0.290015   \n",
       "24                                       0.412127   \n",
       "25                                      -0.816622   \n",
       "26                                      -1.518764   \n",
       "27                                       0.938734   \n",
       "28                                      -0.114480   \n",
       "29                                       0.587663   \n",
       "30                                       0.412127   \n",
       "31                                      -2.747514   \n",
       "32                                      -0.465551   \n",
       "33                                      -0.290015   \n",
       "34                                       0.412127   \n",
       "35                                      -0.465551   \n",
       "36                                       0.061056   \n",
       "37                                       0.236591   \n",
       "38                                       0.587663   \n",
       "39                                       1.114269   \n",
       "40                                       0.236591   \n",
       "41                                       1.465341   \n",
       "42                                      -0.290015   \n",
       "43                                       1.114269   \n",
       "44                                       1.640876   \n",
       "45                                      -0.465551   \n",
       "\n",
       "    Min_Max_Normalized_Baseline  MinMaxNormBaseline_Higher_is_Better  \\\n",
       "0                          0.72                                 0.28   \n",
       "1                          0.48                                 0.52   \n",
       "2                          0.36                                 0.64   \n",
       "3                          0.28                                 0.72   \n",
       "4                          0.36                                 0.64   \n",
       "5                          0.12                                 0.88   \n",
       "6                          0.12                                 0.88   \n",
       "7                          0.56                                 0.44   \n",
       "8                          0.52                                 0.48   \n",
       "9                          0.12                                 0.88   \n",
       "10                         0.08                                 0.92   \n",
       "11                         0.20                                 0.80   \n",
       "12                         0.84                                 0.16   \n",
       "13                         0.76                                 0.24   \n",
       "14                         0.36                                 0.64   \n",
       "15                         0.88                                 0.12   \n",
       "16                         0.24                                 0.76   \n",
       "17                         0.32                                 0.68   \n",
       "18                         0.52                                 0.48   \n",
       "19                         0.20                                 0.80   \n",
       "20                         0.48                                 0.52   \n",
       "21                         0.24                                 0.76   \n",
       "22                         0.24                                 0.76   \n",
       "23                         0.44                                 0.56   \n",
       "24                         0.28                                 0.72   \n",
       "25                         0.56                                 0.44   \n",
       "26                         0.72                                 0.28   \n",
       "27                         0.16                                 0.84   \n",
       "28                         0.40                                 0.60   \n",
       "29                         0.24                                 0.76   \n",
       "30                         0.28                                 0.72   \n",
       "31                         1.00                                 0.00   \n",
       "32                         0.48                                 0.52   \n",
       "33                         0.44                                 0.56   \n",
       "34                         0.28                                 0.72   \n",
       "35                         0.48                                 0.52   \n",
       "36                         0.36                                 0.64   \n",
       "37                         0.32                                 0.68   \n",
       "38                         0.24                                 0.76   \n",
       "39                         0.12                                 0.88   \n",
       "40                         0.32                                 0.68   \n",
       "41                         0.04                                 0.96   \n",
       "42                         0.44                                 0.56   \n",
       "43                         0.12                                 0.88   \n",
       "44                         0.00                                 1.00   \n",
       "45                         0.48                                 0.52   \n",
       "\n",
       "    ROI_to_Alz_Max  ROI_to_PD_Max  Standardzied_AD_Max  Standardized_PD_Max  \n",
       "0        12.222658      14.493929            -1.714513            -1.227368  \n",
       "1        14.020048      15.257338            -1.155843            -1.022243  \n",
       "2        15.118727      17.376384            -0.814348            -0.452865  \n",
       "3        13.112424      15.287916            -1.437954            -1.014027  \n",
       "4        15.086568      12.951426            -0.824344            -1.641831  \n",
       "5        15.816634      17.617107            -0.597423            -0.388183  \n",
       "6        15.524025      13.452311            -0.688373            -1.507246  \n",
       "7        16.546984      13.932696            -0.370413            -1.378169  \n",
       "8        19.669539      21.341523             0.600149             0.612551  \n",
       "9        18.295718      19.263977             0.173133             0.054323  \n",
       "10       17.022328      16.151031            -0.222665            -0.782112  \n",
       "11       16.225059      17.818822            -0.470475            -0.333983  \n",
       "12       15.295109      18.046377            -0.759525            -0.272840  \n",
       "13       18.623736      16.113043             0.275089            -0.792319  \n",
       "14       16.462336      18.503053            -0.396724            -0.150134  \n",
       "15       15.842273      19.964170            -0.589454             0.242462  \n",
       "16       17.332886      19.198042            -0.126137             0.036607  \n",
       "17       10.126563       9.630690            -2.366028            -2.534098  \n",
       "18       22.476761      23.985143             1.472698             1.322880  \n",
       "19       21.466327      23.582758             1.158632             1.214761  \n",
       "20       19.453283      21.676897             0.532931             0.702664  \n",
       "21       13.457540      15.819523            -1.330684            -0.871186  \n",
       "22       22.443084      24.738357             1.462230             1.525265  \n",
       "23       20.186102      22.065363             0.760708             0.807044  \n",
       "24       16.996513      18.394062            -0.230689            -0.179419  \n",
       "25       17.204945      18.264558            -0.165904            -0.214216  \n",
       "26       21.078380      22.489816             1.038049             0.921092  \n",
       "27       18.617648      20.415928             0.273197             0.363848  \n",
       "28       18.410547      19.822564             0.208825             0.204413  \n",
       "29       18.420784      19.612924             0.212007             0.148084  \n",
       "30       23.613479      26.048153             1.826016             1.877202  \n",
       "31       16.101986      17.647381            -0.508729            -0.380049  \n",
       "32       16.837360      18.171505            -0.280158            -0.239219  \n",
       "33       20.531868      22.371502             0.868180             0.889302  \n",
       "34       17.957341      19.952870             0.067958             0.239426  \n",
       "35       24.418011      27.143129             2.076083             2.171417  \n",
       "36       17.856530      19.670979             0.036624             0.163683  \n",
       "37       14.769545      16.131533            -0.922882            -0.787351  \n",
       "38       20.179952      19.975031             0.758797             0.245380  \n",
       "39       11.801552      14.042861            -1.845403            -1.348567  \n",
       "40       21.327670      22.294652             1.115534             0.868652  \n",
       "41       16.512422      18.197520            -0.381156            -0.232229  \n",
       "42       19.159295      19.553377             0.441553             0.132084  \n",
       "43       19.340269      21.114119             0.497804             0.551449  \n",
       "44       19.062652      20.569076             0.411514             0.404998  \n",
       "45       23.954833      26.691505             1.932117             2.050067  \n",
       "\n",
       "[46 rows x 61 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df, other_df = cal_palm.drop_rows_based_on_value(column, condition, value)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regress out a Covariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = []\n",
    "for col in data_df.columns:\n",
    "    if 'surface' in col.lower():\n",
    "        lis.append(col)\n",
    "print(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.statistical_utils.regression_utils import RegressOutCovariates\n",
    "# use this code block to regress out covariates. Generally better to just include as covariates in a model..\n",
    "dependent_variable_list = lis\n",
    "regressors = ['Age', 'Sex']\n",
    "\n",
    "data_df, adjusted_dep_vars_list = RegressOutCovariates.run(df=data_df, dependent_variable_list=dependent_variable_list, covariates_list=regressors)\n",
    "print(adjusted_dep_vars_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standardize Data**\n",
    "- Enter Columns you Don't want to standardize into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed__0', 'subid', 'Age', 'Sex', 'Cohort', 'Diagnosis', 'Region',\n",
       "       'Tissue', 'Visual', 'Measurement', 'Q4', 'TOTAL11', 'TOTALMOD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove anything you don't want to standardize\n",
    "cols_not_to_standardize = ['TOTAL11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = cal_palm.standardize_columns(cols_not_to_standardize)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize Columns by Specific Category Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/82/946tskyj68b6htgvndtppmz80000gp/T/ipykernel_10346/190447241.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_df['Measurement'] = data_df.groupby('Tissue')['Measurement'].transform(lambda x: (x - x.mean()) / x.std())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed__0</th>\n",
       "      <th>subid</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Region</th>\n",
       "      <th>Tissue</th>\n",
       "      <th>Visual</th>\n",
       "      <th>Measurement</th>\n",
       "      <th>Q4</th>\n",
       "      <th>TOTAL11</th>\n",
       "      <th>TOTALMOD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10512</th>\n",
       "      <td>10512</td>\n",
       "      <td>002_S_0816</td>\n",
       "      <td>70.838356</td>\n",
       "      <td>F</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alzheimer</td>\n",
       "      <td>MTL</td>\n",
       "      <td>CSF</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.013261</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10513</th>\n",
       "      <td>10513</td>\n",
       "      <td>002_S_0816</td>\n",
       "      <td>70.838356</td>\n",
       "      <td>F</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alzheimer</td>\n",
       "      <td>MTL</td>\n",
       "      <td>GM</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.345670</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10514</th>\n",
       "      <td>10514</td>\n",
       "      <td>002_S_0816</td>\n",
       "      <td>70.838356</td>\n",
       "      <td>F</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alzheimer</td>\n",
       "      <td>MTL</td>\n",
       "      <td>WM</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.997631</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10515</th>\n",
       "      <td>10515</td>\n",
       "      <td>002_S_0816</td>\n",
       "      <td>70.838356</td>\n",
       "      <td>F</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alzheimer</td>\n",
       "      <td>MTL</td>\n",
       "      <td>CTh</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.517443</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10516</th>\n",
       "      <td>10516</td>\n",
       "      <td>002_S_4270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>MTL</td>\n",
       "      <td>CSF</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.051088</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31739</th>\n",
       "      <td>31739</td>\n",
       "      <td>141_S_4438</td>\n",
       "      <td>76.923288</td>\n",
       "      <td>F</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>Temporal</td>\n",
       "      <td>CTh</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.548472</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>23.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31740</th>\n",
       "      <td>31740</td>\n",
       "      <td>941_S_1202</td>\n",
       "      <td>77.583562</td>\n",
       "      <td>F</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>Temporal</td>\n",
       "      <td>CSF</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.202748</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.67</td>\n",
       "      <td>14.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31741</th>\n",
       "      <td>31741</td>\n",
       "      <td>941_S_1202</td>\n",
       "      <td>77.583562</td>\n",
       "      <td>F</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>Temporal</td>\n",
       "      <td>GM</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.760384</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.67</td>\n",
       "      <td>14.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31742</th>\n",
       "      <td>31742</td>\n",
       "      <td>941_S_1202</td>\n",
       "      <td>77.583562</td>\n",
       "      <td>F</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>Temporal</td>\n",
       "      <td>WM</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.206911</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.67</td>\n",
       "      <td>14.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31743</th>\n",
       "      <td>31743</td>\n",
       "      <td>941_S_1202</td>\n",
       "      <td>77.583562</td>\n",
       "      <td>F</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MCI</td>\n",
       "      <td>Temporal</td>\n",
       "      <td>CTh</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.500699</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.67</td>\n",
       "      <td>14.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>980 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed__0       subid        Age Sex  Cohort  Diagnosis    Region  \\\n",
       "10512       10512  002_S_0816  70.838356   F     1.0  Alzheimer       MTL   \n",
       "10513       10513  002_S_0816  70.838356   F     1.0  Alzheimer       MTL   \n",
       "10514       10514  002_S_0816  70.838356   F     1.0  Alzheimer       MTL   \n",
       "10515       10515  002_S_0816  70.838356   F     1.0  Alzheimer       MTL   \n",
       "10516       10516  002_S_4270        NaN   F     1.0     Normal       MTL   \n",
       "...           ...         ...        ...  ..     ...        ...       ...   \n",
       "31739       31739  141_S_4438  76.923288   F     1.0        MCI  Temporal   \n",
       "31740       31740  941_S_1202  77.583562   F     1.0        MCI  Temporal   \n",
       "31741       31741  941_S_1202  77.583562   F     1.0        MCI  Temporal   \n",
       "31742       31742  941_S_1202  77.583562   F     1.0        MCI  Temporal   \n",
       "31743       31743  941_S_1202  77.583562   F     1.0        MCI  Temporal   \n",
       "\n",
       "      Tissue  Visual  Measurement   Q4  TOTAL11  TOTALMOD  \n",
       "10512    CSF     3.0     1.013261  8.0    16.00     26.00  \n",
       "10513     GM     3.0     0.345670  8.0    16.00     26.00  \n",
       "10514     WM     3.0     0.997631  8.0    16.00     26.00  \n",
       "10515    CTh     3.0     0.517443  8.0    16.00     26.00  \n",
       "10516    CSF     0.0     1.051088  2.0     5.00      7.00  \n",
       "...      ...     ...          ...  ...      ...       ...  \n",
       "31739    CTh     2.0     0.548472  5.0    18.00     23.00  \n",
       "31740    CSF     2.0    -0.202748  6.0     7.67     14.67  \n",
       "31741     GM     2.0    -0.760384  6.0     7.67     14.67  \n",
       "31742     WM     2.0    -0.206911  6.0     7.67     14.67  \n",
       "31743    CTh     2.0    -0.500699  6.0     7.67     14.67  \n",
       "\n",
       "[980 rows x 13 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming your DataFrame is named data_df and you want to standardize 'Measurement' within each 'Tissue' group\n",
    "\n",
    "# Standardize 'Measurement' within each 'Tissue' group\n",
    "data_df['Measurement'] = data_df.groupby('Tissue')['Measurement'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "\n",
    "# Print or inspect the resulting DataFrame\n",
    "data_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Perform Basic Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables to Correlate\n",
    "- dependent_variable = 'Z_Scored_Percent_Cognitive_Improvement'\n",
    "- independent_variable_list = ['Z_Scored_Cognitive_Baseline']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_columns = [col for col in data_df.columns if 'occipital' in col.lower()]\n",
    "print(filtered_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_variables_list = ['TOTALMOD']\n",
    "x_variable_list = [ 'FrontalCSF', 'ParietalCSF','OccipitalCSF',  'TemporalCSF', 'MTLCSF', 'CerebellumCSF', 'temp_ins_csf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter a column for categories (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = 'City'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose Correlation Method\n",
    "- Options: 'spearman', 'pearson', 'kendall'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = 'pearson'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define plot Labels\n",
    "- These are the axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Axis Labels\n",
    "x_label = 'Brain Region'\n",
    "y_label = 'Correlation to Clinician (z)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.statistical_utils.scatterplot import ScatterplotGenerator \n",
    "for y_var in y_variables_list:\n",
    "    generator = ScatterplotGenerator(dataframe=data_df, data_dict={y_var: x_variable_list}, \n",
    "                                    x_label=x_label, y_label=y_label, correlation=correlation, \n",
    "                                    palette='tab10',\n",
    "                                    rows_per_fig=1, cols_per_fig=2,\n",
    "                                    ylim=None,\n",
    "                                    out_dir=out_dir,\n",
    "                                    category_col=cat_col)\n",
    "    generator.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrap it\n",
    "- Accepts only 1 x and 1 y var from the above lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "def bootstrap_correlation(data_df, x_var, y_var, n_bootstraps=1000):\n",
    "    correlations = []\n",
    "    \n",
    "    for i in range(n_bootstraps):\n",
    "        # Bootstrap sampling with replacement\n",
    "        bootstrap_sample = data_df.sample(n=len(data_df), replace=True, random_state=i)\n",
    "        \n",
    "        # Calculate correlation\n",
    "        corr, _ = spearmanr(bootstrap_sample[x_var], bootstrap_sample[y_var])\n",
    "        \n",
    "        if corr is not np.nan: correlations.append(corr)\n",
    "    \n",
    "    # Convert to numpy array for easier manipulation\n",
    "    correlations = np.array(correlations)\n",
    "    \n",
    "    # Calculate the required statistics\n",
    "    lower_extreme = np.min(correlations)\n",
    "    lower_quartile = np.percentile(correlations, 25)\n",
    "    median_corr = np.median(correlations)\n",
    "    upper_quartile = np.percentile(correlations, 75)\n",
    "    upper_extreme = np.max(correlations)\n",
    "    \n",
    "    return {\n",
    "        'lower_extreme': lower_extreme,\n",
    "        'lower_quartile': lower_quartile,\n",
    "        'median': median_corr,\n",
    "        'upper_quartile': upper_quartile,\n",
    "        'upper_extreme': upper_extreme\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = bootstrap_correlation(data_df, x_variable_list[0], y_variables_list[0], n_bootstraps=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Based on the Bootstap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_variable_list = [ 'frontal_eh', 'parietal_eh','occipital_eh',  'temporal_eh', 'mesial_temporal_eh', 'cerebellum_eh', 'ventricle_eh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '/Users/cu135/Partners HealthCare Dropbox/Calvin Howard/studies/atrophy_seeds_2023/Figures/association_to_baseline/lineplot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "def bootstrap_correlation(data_df, x_var_list, y_var, n_bootstraps=1000):\n",
    "    x_var_dict = {}\n",
    "    for x_var in x_var_list:\n",
    "        correlations = []\n",
    "        \n",
    "        while len(correlations) < n_bootstraps:\n",
    "            # Bootstrap sampling with replacement\n",
    "            bootstrap_sample = data_df.sample(n=len(data_df), replace=True)\n",
    "            # Calculate correlation\n",
    "            try:\n",
    "                corr, _ = spearmanr(bootstrap_sample[x_var], bootstrap_sample[y_var])\n",
    "            except:\n",
    "                continue\n",
    "            if corr is not np.nan: correlations.append(corr)\n",
    "        # Convert to numpy array for easier manipulation\n",
    "        correlations = np.array(correlations)\n",
    "        x_var_dict[x_var] = correlations\n",
    "        \n",
    "    return x_var_dict\n",
    "\n",
    "def plot_horizontal_lineplot(x_var_dict, out_dir, stdev=True):\n",
    "    \n",
    "    plt.figure(figsize=(len(x_var_dict) * 2, 6))  # Adjust width based on the number of x_vars\n",
    "\n",
    "    x_vars = list(x_var_dict.keys())\n",
    "    means = []\n",
    "    lows = []\n",
    "    highs = []\n",
    "\n",
    "    # Calculate statistics for each x_var\n",
    "    for x_var, correlations in x_var_dict.items():\n",
    "        mean_corr = np.mean(correlations)\n",
    "        means.append(mean_corr)\n",
    "        \n",
    "        if stdev:\n",
    "            low = mean_corr - np.std(correlations)\n",
    "            high = mean_corr + np.std(correlations)\n",
    "        else:\n",
    "            low = np.percentile(correlations, 2.5)\n",
    "            high = np.percentile(correlations, 97.5)\n",
    "        \n",
    "        lows.append(low)\n",
    "        highs.append(high)\n",
    "    \n",
    "    # Plot the confidence interval as a filled area, connecting each point\n",
    "    plt.fill_between(x_vars, lows, highs, color='lightblue', alpha=0.5)\n",
    "    \n",
    "    # Plot the mean correlation as a line\n",
    "    plt.plot(x_vars, means, 'o-', color='blue')\n",
    "    \n",
    "    plt.xlabel('X Variables')\n",
    "    plt.ylabel('Correlation')\n",
    "    plt.title('Line Plot of Mean and 95% CI for Each X Variable')\n",
    "    plt.ylim((-.2, 0.75))\n",
    "    plt.savefig(os.path.join(out_dir, 'nrad_lineplot.svg'))\n",
    "    plt.show()\n",
    "\n",
    "plot_horizontal_lineplot(bootstrap_correlation(data_df, x_var_list=x_variable_list, y_var=y_variables_list[0]), out_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overlay Correlations for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def overlay_lmplots_with_correlation(data_df, ivs, dv, colors=None,labels=['GM', 'WM', 'CT', 'Radiologist', 'CSF']):\n",
    "    \"\"\"\n",
    "    Generate and overlay lmplot graphs for each IV against the DV, with the legend showing the correlation value.\n",
    "\n",
    "    Parameters:\n",
    "    data_df (pd.DataFrame): The dataframe containing the data.\n",
    "    ivs (list of str): List of independent variables (column names) in the dataframe.\n",
    "    dv (str): Dependent variable (column name) in the dataframe.\n",
    "    colors (list of str, optional): List of color hex codes. If None, defaults to 'tab10' palette.\n",
    "\n",
    "    Returns:\n",
    "    None: Displays the plot.\n",
    "    \"\"\"\n",
    "    if colors is None:\n",
    "        colors = sns.color_palette(\"tab10\", len(ivs))\n",
    "    \n",
    "    plt.figure(figsize=(3, 3))\n",
    "    \n",
    "    if labels is None:\n",
    "        labels = ivs\n",
    "    \n",
    "    jitter = 0.08\n",
    "    for i, iv in enumerate(ivs):\n",
    "        jittered_df = data_df.copy()\n",
    "        jittered_df[dv] = jittered_df[dv] + jitter*i\n",
    "        correlation = data_df[iv].corr(data_df[dv], method='spearman')\n",
    "        sns.regplot(\n",
    "            truncate=False,\n",
    "            x=iv, \n",
    "            y=dv, \n",
    "            data=jittered_df, \n",
    "            scatter_kws={\"s\": 20, \"color\": colors[i]},  # Customize scatter plot size and color\n",
    "            line_kws={\"color\": colors[i]}, \n",
    "            ci=None,\n",
    "            label=f'{labels[i]} (r={correlation:.2f})'  # Adding correlation to legend\n",
    "        )\n",
    "        \n",
    "\n",
    "    plt.legend(title=\"Methods\", frameon=False, loc='best')\n",
    "    # plt.ylim(-0.1,3.25)\n",
    "    plt.xlabel(\"Atrophy (Z-score)\")\n",
    "    plt.ylabel('ADAS-Cog 13')\n",
    "    plt.title('Ventricle')\n",
    "    sns.despine()\n",
    "    plt.savefig('/Users/cu135/Partners HealthCare Dropbox/Calvin Howard/studies/atrophy_seeds_2023/Figures/correlation_to_radiologist/radiologist/z_score_correlations/figures_of_each_lobe/Ventricle.svg')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# overlay_lmplots_with_correlation(data_df, ['IV1', 'IV2', 'IV3'], 'DV', ['#1f77b4', '#ff7f0e', '#2ca02c'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = 'TOTALMOD'\n",
    "iv_list = [ 'SubcortexGM', 'SubcortexWM', 'SubcortexSurfaceVentricle', 'ventricle_eh', 'SubcortexCSF']\n",
    "colour_list = ['#3A923A', '#C03D3E', '#E1812C', '#9372B2', '#3274A1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_lmplots_with_correlation(data_df, iv_list, dv, colour_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Correlational ANCOVA\n",
    "- Accepts up to 2 categorical variables, allowing comparison of correlations across and within categories.\n",
    "- Categorical variable - this will group correlations into a single subplot\n",
    "- Cohort variable - this is a second variable, not visualized, which is used for statistical comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject', 'Age', 'Hippocampus_GM_Vol', 'Parahippocampal_Gyrus_GM_Vol',\n",
       "       'Entorhinal_Cortex_GM_Vol', 'Normalized_Percent_Cognitive_Improvement',\n",
       "       'Z_Scored_Percent_Cognitive_Improvement_By_Origin_Group',\n",
       "       'Z_Scored_Percent_Cognitive_Improvement',\n",
       "       'Percent_Cognitive_Improvement',\n",
       "       'Z_Scored_Subiculum_T_By_Origin_Group_',\n",
       "       'Z_Scored_Subiculum_Connectivity_T', 'Subiculum_Connectivity_T_Redone',\n",
       "       'Subiculum_Connectivity_T', 'Amnesia_Lesion_T_Map', 'Memory_Network_T',\n",
       "       'Z_Scored_Memory_Network_R', 'Memory_Network_R',\n",
       "       'Subiculum_Grey_Matter', 'Subiculum_White_Matter', 'Subiculum_CSF',\n",
       "       'Subiculum_Total', 'Standardized_Age',\n",
       "       'Standardized_Percent_Improvement',\n",
       "       'Standardized_Subiculum_Connectivity',\n",
       "       'Standardized_Subiculum_Grey_Matter',\n",
       "       'Standardized_Subiculum_White_Matter', 'Standardized_Subiculum_CSF',\n",
       "       'Standardized_Subiculum_Total', 'Disease', 'Cohort', 'City',\n",
       "       'Inclusion_Cohort', 'Categorical_Age_Group', 'Age_Group',\n",
       "       'Age_And_Disease', 'Age_Disease_and_Cohort', 'Age_Disease_Cohort_Stim',\n",
       "       'Age_And_Stim', 'Subiculum_Group_By_Z_Score_Sign',\n",
       "       'Subiculum_Group_By_Inflection_Point', 'Subiculum_Group_By_24',\n",
       "       'Cognitive_Outcome', 'StimMatch', 'StimMatch24', 'Cognitive_Baseline',\n",
       "       'Cognitive_Score_1_Yr', 'MinMaxNorm_Cog_Score_1_Yr',\n",
       "       'Abs_Cognitive_Improve', 'IMPROVE_OR_STABLE', 'DECLINE_OR_STABLE',\n",
       "       'IMPROVE', 'DECLINE', 'Cognitive_Improve',\n",
       "       'Z_Scored_Cognitive_Baseline',\n",
       "       'Z_Scored_Cognitive_Baseline__Lower_is_Better_',\n",
       "       'Min_Max_Normalized_Baseline', 'MinMaxNormBaseline_Higher_is_Better',\n",
       "       'ROI_to_Alz_Max', 'ROI_to_PD_Max', 'Standardzied_AD_Max',\n",
       "       'Standardized_PD_Max'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming data_prep and category_dataframes are already defined\n",
    "dependent_variable = 'Z_Scored_Percent_Cognitive_Improvement'\n",
    "independent_variable = 'Age'\n",
    "categorical_variable = 'Subiculum_Group_By_Inflection_Point'\n",
    "cohort_variable = 'City'\n",
    "correlation_method = 'pearson'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x1296 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from calvin_utils.statistical_utils.delta_r import CombinedPlot, DataPreparation, ScatterPlot, BarPlot\n",
    "data_prep = DataPreparation(data_df, dependent_variable, independent_variable, categorical_variable, cohort_variable)\n",
    "scatter_plot = ScatterPlot(data_prep, colors_list=None)\n",
    "bar_plot = BarPlot(data_prep, method=correlation_method, colors_list=None)\n",
    "combined_plot = CombinedPlot(scatter_plot, bar_plot, out_dir=out_dir)\n",
    "combined_plot.save_figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P-Values within Categories Across Cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_absolute_difference_of_correlations = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'all_categories': {}, 'high': {}, 'low': {}}\n"
     ]
    }
   ],
   "source": [
    "from calvin_utils.statistical_utils.delta_r import PermutationAnalysis\n",
    "\n",
    "# Perform permutation analysis\n",
    "perm_analysis = PermutationAnalysis(data_prep, onetail=False, correlation_method=correlation_method, abs_correl=check_absolute_difference_of_correlations)\n",
    "perm_analysis.run_analysis(n_permutations=10000)\n",
    "p_values = perm_analysis.p_values\n",
    "from pprint import pprint\n",
    "pprint(p_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P-Values Across Categories Across Cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('all_categories', 'high'): {('Toronto', 'Toronto', 'delta = 0.39600470638245877'): nan},\n",
      " ('all_categories', 'low'): {('Toronto', 'Toronto', 'delta = 0.334812933835852'): nan},\n",
      " ('high', 'low'): {('Toronto', 'Toronto', 'delta = 0.06119177254660679'): 0.5975}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cu135/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/cu135/.local/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "from calvin_utils.statistical_utils.delta_r import CrossCategoryPermutationAnalysis\n",
    "\n",
    "# Perform cross-category permutation analysis\n",
    "cross_cat_perm_analysis = CrossCategoryPermutationAnalysis(perm_analysis, onetail=False, correlation_method=correlation_method, abs_correl=check_absolute_difference_of_correlations)\n",
    "cross_cat_perm_analysis.run_cross_category_permutation_analysis(n_permutations=10000)\n",
    "# Pretty print the cross-category p_values\n",
    "from pprint import pprint\n",
    "pprint(cross_cat_perm_analysis.p_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P-Values Across Categories (contrast all cohorts within category against all cohorts in another category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ContrastAnalysis' from 'calvin_utils.statistical_utils.delta_r' (/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Work/Software/calvin_utils_project/calvin_utils_project/calvin_utils/statistical_utils/delta_r.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcalvin_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstatistical_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdelta_r\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ContrastAnalysis\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Perform contrast analysis\u001b[39;00m\n\u001b[1;32m      4\u001b[0m contrast_analysis \u001b[38;5;241m=\u001b[39m ContrastAnalysis(perm_analysis, onetail\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, correlation_method\u001b[38;5;241m=\u001b[39mcorrelation_method, abs_correl\u001b[38;5;241m=\u001b[39mcheck_absolute_difference_of_correlations)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ContrastAnalysis' from 'calvin_utils.statistical_utils.delta_r' (/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Work/Software/calvin_utils_project/calvin_utils_project/calvin_utils/statistical_utils/delta_r.py)"
     ]
    }
   ],
   "source": [
    "from calvin_utils.statistical_utils.delta_r import ContrastAnalysis\n",
    "\n",
    "# Perform contrast analysis\n",
    "contrast_analysis = ContrastAnalysis(perm_analysis, onetail=True, correlation_method=correlation_method, abs_correl=check_absolute_difference_of_correlations)\n",
    "contrast_analysis.summate_correlations()\n",
    "contrast_analysis.calculate_cross_dataframe_differences(n_permutations=10000)\n",
    "\n",
    "# Pretty print the cross-dataframe p_values\n",
    "pprint(contrast_analysis.cross_dataframe_p_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the permutation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved cross_cat_perm_analysis_p_values.py\n",
      "Successfully saved contrast_analysis_cross_dataframe_p_values.py\n",
      "Successfully saved perm_analysis_p_values.py\n"
     ]
    }
   ],
   "source": [
    "from calvin_utils.statistical_utils.delta_r import save_dicts_as_py\n",
    "\n",
    "# Save dictionaries as .py files\n",
    "save_dicts_as_py(out_dir,\n",
    "                 cross_cat_perm_analysis_p_values= cross_cat_perm_analysis.p_values,\n",
    "                 contrast_analysis_cross_dataframe_p_values=contrast_analysis.cross_dataframe_p_values,\n",
    "                 perm_analysis_p_values=perm_analysis.p_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 - Delta Scatterplot (Pretty)\n",
    "- Generates 2 categories to compare by splitting on a continuous variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefining the class and its methods\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import t\n",
    "import seaborn as sns\n",
    "class ScatterWithConfidence:\n",
    "    def __init__(self, data_df):\n",
    "        self.data_df = data_df\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_analytic_confidence_interval(x, y, x_vals):\n",
    "        slope, intercept = np.polyfit(x, y, 1)\n",
    "        y_fit = slope * x_vals + intercept\n",
    "        \n",
    "        residuals = y - (slope * x + intercept)\n",
    "        stderr = np.sqrt(np.sum(residuals**2) / (len(y) - 2))\n",
    "        \n",
    "        t_value = t.ppf(0.975, df=len(x)-2)\n",
    "        ci = t_value * stderr * np.sqrt(1/len(x) + (x_vals - np.mean(x))**2 / np.sum((x - np.mean(x))**2))\n",
    "        \n",
    "        upper_bound = y_fit + ci\n",
    "        lower_bound = y_fit - ci\n",
    "        \n",
    "        return y_fit, lower_bound, upper_bound\n",
    "\n",
    "    def permute_data_and_difference_in_pearson_r(self, x_one, x_two, split_by, split_value, n_permutations=1000, permute_columns=[]):\n",
    "        original_diff = self.data_df[self.data_df[split_by] < split_value][x_one].corr(self.data_df[self.data_df[split_by] < split_value][x_two]) - \\\n",
    "                       self.data_df[self.data_df[split_by] >= split_value][x_one].corr(self.data_df[self.data_df[split_by] >= split_value][x_two])\n",
    "\n",
    "        permuted_diffs = []\n",
    "\n",
    "        for _ in range(n_permutations):\n",
    "            permuted_df = self.data_df.copy()\n",
    "            for column in permute_columns:\n",
    "                permuted_df[column] = np.random.permutation(permuted_df[column].values)\n",
    "            \n",
    "            diff = permuted_df[permuted_df[split_by] < split_value][x_one].corr(permuted_df[permuted_df[split_by] < split_value][x_two]) - \\\n",
    "                   permuted_df[permuted_df[split_by] >= split_value][x_one].corr(permuted_df[permuted_df[split_by] >= split_value][x_two])\n",
    "            \n",
    "            permuted_diffs.append(diff)\n",
    "\n",
    "        p_value = np.mean([diff <= original_diff for diff in permuted_diffs])\n",
    "        return original_diff, p_value\n",
    "\n",
    "    def plot_with_analytic_ci_manual_pvalue(self, x_one, x_two, \n",
    "                                            split_by, split_value, \n",
    "                                            x_label='X1', y_label='X2', \n",
    "                                            upper_split_legend='Above Split', lower_split_legend='Below Split',\n",
    "                                            alpha=0.3, manual_p_value=None, permute_column=None, \n",
    "                                            save=False, out_dir=None,\n",
    "                                            colour1='red', colour2='blue'):\n",
    "        fig, ax = plt.subplots(figsize=(6, 5))\n",
    "        \n",
    "        group1 = self.data_df[self.data_df[split_by] < split_value]\n",
    "        group2 = self.data_df[self.data_df[split_by] >= split_value]\n",
    "\n",
    "        ax.scatter(group1[x_one], group1[x_two], color=colour1, label=lower_split_legend, s=40, alpha=alpha, marker='o')\n",
    "        ax.scatter(group2[x_one], group2[x_two], color=colour2, label=upper_split_legend, s=40, alpha=alpha, marker='o')\n",
    "        \n",
    "        x_vals = np.linspace(self.data_df[x_one].min(), self.data_df[x_one].max(), 400)\n",
    "        \n",
    "        for group, color in [(group1, colour1), (group2, colour2)]:\n",
    "            y_fit, lower_bound, upper_bound = self.compute_analytic_confidence_interval(group[x_one], group[x_two], x_vals)\n",
    "            ax.plot(x_vals, y_fit, color=color)\n",
    "            # ax.fill_between(x_vals, lower_bound, upper_bound, color=color, alpha=alpha/4)\n",
    "        \n",
    "        if manual_p_value is None:\n",
    "            if permute_column:\n",
    "                rho, manual_p_value = self.permute_data_and_difference_in_pearson_r(x_one, x_two, split_by, split_value, n_permutations=10000, permute_columns=[permute_column])\n",
    "            else:\n",
    "                rho, manual_p_value = self.permute_data_and_difference_in_pearson_r(x_one, x_two, split_by, split_value, n_permutations=10000, permute_columns=[x_one, x_two, split_by])\n",
    "        \n",
    "        ax.set_title(f\"\\u0394 r = {rho:.2f} , p = {manual_p_value:.4f}\")\n",
    "        ax.set_ylabel(y_label)\n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.legend(loc='best', frameon=False)\n",
    "        ax.grid(False)\n",
    "        sns.despine(ax=ax)\n",
    "        \n",
    "        if save and out_dir is not None:\n",
    "            plt.savefig(f\"{out_dir}/scatter_with_polyfit_and_analytic_ci.png\", bbox_inches='tight')\n",
    "            plt.savefig(f\"{out_dir}/scatter_with_polyfit_and_analytic_ci.svg\", bbox_inches='tight')\n",
    "            print(f'Saved to {out_dir}/scatter_with_polyfit_and_analytic_ci.svg')\n",
    "        return fig\n",
    "    \n",
    "class DeltaCorrelation(ScatterWithConfidence):\n",
    "    def __init__(self, data_df):\n",
    "        super().__init__(data_df)\n",
    "\n",
    "    def plot_histogram_of_delta_r(self, x_one, x_two, split_by, split_value, n_permutations=1000, \n",
    "                                permute_columns=[], bins=50, one_tail=False, color_palette='dark'):\n",
    "        # Generate the empirical distribution of delta_r\n",
    "        delta_rs = []\n",
    "        for _ in range(n_permutations):\n",
    "            permuted_df = self.data_df.copy()\n",
    "            for column in permute_columns:\n",
    "                permuted_df[column] = np.random.permutation(permuted_df[column].values)\n",
    "\n",
    "            delta_r = permuted_df[permuted_df[split_by] < split_value][x_one].corr(permuted_df[permuted_df[split_by] < split_value][x_two]) - \\\n",
    "                    permuted_df[permuted_df[split_by] >= split_value][x_one].corr(permuted_df[permuted_df[split_by] >= split_value][x_two])\n",
    "            delta_rs.append(delta_r)\n",
    "\n",
    "        # Calculate the observed delta_r\n",
    "        observed_delta_r, _ = self.permute_data_and_difference_in_pearson_r(x_one, x_two, split_by, split_value, permute_columns=permute_columns)\n",
    "\n",
    "        if one_tail:\n",
    "            observed_delta_r = np.abs(observed_delta_r)\n",
    "            delta_rs = np.abs(delta_rs)\n",
    "\n",
    "        # Calculate p-value\n",
    "        if one_tail:\n",
    "            p_value = np.mean([delta_r >= observed_delta_r for delta_r in delta_rs])\n",
    "        else:\n",
    "            p_value = np.mean([delta_r <= observed_delta_r for delta_r in delta_rs])\n",
    "\n",
    "        # Generate the displot (KDE + Histogram) using Seaborn\n",
    "        sns.set_palette(color_palette)\n",
    "        current_palette = sns.color_palette(color_palette)\n",
    "        chosen_color = current_palette[4]\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        g = sns.displot(delta_rs, kde=True, bins=bins, label=\"Empirical $\\\\Delta r$ Distribution\", element=\"step\",color='blue', alpha=.6)\n",
    "        plt.axvline(x=observed_delta_r, color='red', linestyle='-', linewidth=1.5, label=f\"Observed $\\\\Delta r$\", alpha=0.6)\n",
    "        plt.title(f\"$\\\\Delta r$ = {observed_delta_r}, p = {p_value}\")\n",
    "        plt.xlabel(\"$\\\\Delta r$\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.legend()\n",
    "        \n",
    "        fig = g.fig\n",
    "        \n",
    "        fig.savefig(f\"{out_dir}/hist_kde.png\", bbox_inches='tight')\n",
    "        fig.savefig(f\"{out_dir}/hist_kde.svg\", bbox_inches='tight')\n",
    "        print(f'Saved to {out_dir}/hist_kde.svg')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed__0', 'subid', 'Age', 'Sex', 'Cohort', 'Diagnosis', 'Region',\n",
       "       'Tissue', 'Visual', 'Measurement', 'Q4', 'TOTAL11', 'TOTALMOD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data To Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Variables\n",
    "dependent_variable = 'Percent_Cognitive_Improvement'\n",
    "independent_variable = 'Subiculum_Connectivity_T_Redone'\n",
    "split_by_var = 'Age' # This is the column which contains the values you are going to split the data by \n",
    "split_value_var = 65 # This is the value which will be used to determine how rows of the given column split the entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels for Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Variables\n",
    "x_label = 'Standardized Subiculum Connectivity'\n",
    "y_label = 'Standardized Percent Improvement'\n",
    "legend_string_for_lower_split='under 65'\n",
    "legend_string_for_upper_split='Over 65'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_sctr = ScatterWithConfidence(data_df)\n",
    "delta_sctr_plot = delta_sctr.plot_with_analytic_ci_manual_pvalue(\n",
    "                                            x_one=independent_variable, x_two=dependent_variable,\n",
    "                                            split_by=split_by_var, split_value=split_value_var,\n",
    "                                            x_label=x_label, y_label=y_label,\n",
    "                                            upper_split_legend=legend_string_for_upper_split, lower_split_legend=legend_string_for_lower_split,\n",
    "                                            alpha=0.3, manual_p_value=None, permute_column=None,\n",
    "                                            save=True, out_dir=out_dir,\n",
    "                                            colour1='#FF0000', colour2='#0000FF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an object from the new Seaborn-based class\n",
    "histogram_plotter_seaborn = DeltaCorrelation(data_df)\n",
    "\n",
    "# Generate the histogram using Seaborn\n",
    "fig = histogram_plotter_seaborn.plot_histogram_of_delta_r(x_one=independent_variable, x_two=dependent_variable, \n",
    "                                                    split_by=split_by_var, split_value=split_value_var, \n",
    "                                                    n_permutations=10000, \n",
    "                                                    permute_columns=[independent_variable, dependent_variable, split_by_var], \n",
    "                                                    bins=50,\n",
    "                                                    one_tail=True, \n",
    "                                                    color_palette='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlay Multiple Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_lines_of_best_fit_by_combinations(data_df, categorical_columns, x_var, y_var):\n",
    "    # Find unique values in each column\n",
    "    unique_values_per_column = [data_df[col].unique() for col in categorical_columns]\n",
    "\n",
    "    # Generate all possible combinations of these unique values across the columns\n",
    "    all_combinations = list(itertools.product(*unique_values_per_column))\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.set_palette('tab10')\n",
    "    # For each combination, create a mask and apply it to the DataFrame\n",
    "    for combination in all_combinations:\n",
    "        mask = pd.Series(True, index=data_df.index)\n",
    "        for col, val in zip(categorical_columns, combination):\n",
    "            mask &= (data_df[col] == val)\n",
    "\n",
    "        # Apply the mask to the DataFrame to get the subset\n",
    "        masked_df = data_df[mask]\n",
    "        \n",
    "        # Skip if the masked_df is empty\n",
    "        if masked_df.empty:\n",
    "            continue\n",
    "\n",
    "        # Calculate the line of best fit\n",
    "        slope, intercept = np.polyfit(masked_df[x_var], masked_df[y_var], 1)\n",
    "        x_vals = np.linspace(masked_df[x_var].min(), masked_df[x_var].max(), 100)\n",
    "        y_vals = slope * x_vals + intercept\n",
    "\n",
    "        # Plot the line of best fit\n",
    "        plt.plot(x_vals, y_vals, label=f'{combination}', linestyle='-')\n",
    "\n",
    "    plt.xlabel(x_var)\n",
    "    plt.ylabel(y_var)\n",
    "    plt.title(f'Lines of Best Fit for {x_var} vs {y_var} by Category Combinations')\n",
    "    plt.legend(title='Category Combination', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lines_of_best_fit_by_combinations(data_df,\n",
    "                                       categorical_columns=['Age_Group', 'City'], \n",
    "                                       x_var='Z_Scored_Subiculum_T_By_Origin_Group_', \n",
    "                                       y_var='Z_Scored_Percent_Cognitive_Improvement')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Matrix and Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_correlation_heatmap(dataframe):\n",
    "    # Calculate the correlation matrix\n",
    "    corr_matrix = dataframe.corr()\n",
    "\n",
    "    # Create a heatmap\n",
    "    plt.figure(figsize=(20, 16))\n",
    "    sns.heatmap(corr_matrix, annot=False, fmt=\".2f\", cmap='coolwarm', square=True, cbar_kws={'shrink': .5})\n",
    "\n",
    "    # Adjust the layout\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.title('Correlation Heatmap')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "sorted_columns = sorted(data_df.columns)\n",
    "data_df_sorted = data_df[sorted_columns]\n",
    "plot_correlation_heatmap(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canonical Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import CCA\n",
    "\n",
    "def perform_cca(data_df, set1_columns, set2_columns):\n",
    "    \"\"\"\n",
    "    Perform Canonical Correlation Analysis (CCA) between two sets of columns in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        data_df (pd.DataFrame): The DataFrame containing the data.\n",
    "        set1_columns (list): List of column names for the first set of variables.\n",
    "        set2_columns (list): List of column names for the second set of variables.\n",
    "\n",
    "    Returns:\n",
    "        cca (CCA): The CCA model object.\n",
    "        cca_results (dict): A dictionary containing the CCA results.\n",
    "    \"\"\"\n",
    "    # Extract the specified sets of columns from the DataFrame\n",
    "    set1_data = data_df[set1_columns]\n",
    "    set2_data = data_df[set2_columns]\n",
    "\n",
    "    # Initialize the CCA model\n",
    "    cca = CCA(n_components=min(len(set1_columns), len(set2_columns)))\n",
    "\n",
    "    # Fit the CCA model to the data\n",
    "    cca.fit(set1_data, set2_data)\n",
    "\n",
    "    # Transform the data using CCA\n",
    "    set1_transformed, set2_transformed = cca.transform(set1_data, set2_data)\n",
    "\n",
    "    # Calculate canonical correlations from singular values\n",
    "    canonical_correlations = cca.singular_values_\n",
    "\n",
    "    # Store the CCA results in a dictionary\n",
    "    cca_results = {\n",
    "        'Canonical Correlations': canonical_correlations,\n",
    "        'Set 1 Transformed': set1_transformed,\n",
    "        'Set 2 Transformed': set2_transformed\n",
    "    }\n",
    "\n",
    "    return cca, cca_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define 2 lists\n",
    "- 1 is the first set to CCA\n",
    "- 2 is the second set to CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templist = []\n",
    "for val in data_df.columns:\n",
    "    if 'CSF' in val:\n",
    "        templist.insert(-1, val)\n",
    "print(templist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = ['frontal', 'temporal', 'parietal', 'occipital',\n",
    "       'cerebellum', 'Mesial_Temporal', 'ventricle']\n",
    "list2 = ['frontal_eh', 'temporal_eh', 'parietal_eh',\n",
    "       'occipital_eh', 'cerebellum_eh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import CCA\n",
    "\n",
    "def perform_cca(data_df, set1_columns, set2_columns):\n",
    "    \"\"\"\n",
    "    Perform Canonical Correlation Analysis (CCA) between two sets of columns in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        data_df (pd.DataFrame): The DataFrame containing the data.\n",
    "        set1_columns (list): List of column names for the first set of variables.\n",
    "        set2_columns (list): List of column names for the second set of variables.\n",
    "\n",
    "    Returns:\n",
    "        cca (CCA): The CCA model object.\n",
    "        cca_results (dict): A dictionary containing the CCA results.\n",
    "    \"\"\"\n",
    "    # Extract the specified sets of columns from the DataFrame\n",
    "    set1_data = data_df[set1_columns]\n",
    "    set2_data = data_df[set2_columns]\n",
    "\n",
    "    # Initialize the CCA model\n",
    "    cca = CCA(n_components=min(len(set1_columns), len(set2_columns)))\n",
    "\n",
    "    # Fit the CCA model to the data\n",
    "    cca.fit(set1_data, set2_data)\n",
    "\n",
    "    # Calculate canonical correlations using the score method\n",
    "    canonical_correlations = cca.score(set1_data, set2_data)\n",
    "\n",
    "    # Store the CCA results in a dictionary\n",
    "    cca_results = {\n",
    "        'Canonical Correlations': canonical_correlations\n",
    "    }\n",
    "\n",
    "    return cca, cca_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca, cca_results = perform_cca(data_df, set1_columns=list1, set2_columns=list2)\n",
    "cca_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intraclass Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "from pingouin import intraclass_corr\n",
    "from calvin_utils.statistical_utils.distribution_statistics import BootstrappedDistributionStatistics\n",
    "from calvin_utils.statistical_utils.resampling_functions import Bootstrap\n",
    "\n",
    "def calculate_icc(df, col1, col2):\n",
    "    # Select only the specified columns and rename them for compatibility with pingouin\n",
    "    data = df[[col1, col2]].rename(columns={col1: 'rating1', col2: 'rating2'})\n",
    "\n",
    "    # Reshape data for pingouin's intraclass_corr function\n",
    "    df_melted = data.melt(value_vars=['rating1', 'rating2'], var_name='rater', value_name='rating')\n",
    "    df_melted['subject'] = df_melted.groupby('rater').cumcount()\n",
    "\n",
    "    # Calculate ICC\n",
    "    icc_result = intraclass_corr(data=df_melted, targets='subject', raters='rater', ratings='rating')\n",
    "    \n",
    "    # Return ICC(3,1)\n",
    "    return icc_result.set_index('Type').loc['ICC3', 'ICC']\n",
    "\n",
    "def bootstrap_icc(data, col1, col2, bootstrap_samples=2500):\n",
    "    # Perform the bootstrap resampling using the Bootstrap class\n",
    "    bootstrap = Bootstrap(data=data, func=calculate_icc, func_args={'col1': col1, 'col2': col2}, bootstrap_samples=bootstrap_samples)\n",
    "    bootstrap_results = bootstrap.bootstrap_function()\n",
    "\n",
    "    # Calculate the confidence intervals using the BootstrappedDistributionStatistics class\n",
    "    distribution_statistics = BootstrappedDistributionStatistics(bootstrap_results)\n",
    "    lower_bound, upper_bound = distribution_statistics.percentile_ci(alpha=0.05)\n",
    "\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "def plot_icc_forest(comparisons_dict, dataframe, bootstrap_samples=2500, full_legend_patches=False):\n",
    "    # figure = plt.figure(figsize=(4, len(comparisons_dict)*1.2))\n",
    "    figure = plt.figure(figsize=(4, 5))\n",
    "    \n",
    "    # Create a color palette with enough unique colors\n",
    "    colors = sns.color_palette(\"tab10\", len(comparisons_dict))\n",
    "    \n",
    "    # Create legend patches\n",
    "    legend_patches = []\n",
    "    \n",
    "    # Iterate through the dictionary and plot ICC for each comparison\n",
    "    for idx, (col1_name, col2_name) in enumerate(comparisons_dict.items()):\n",
    "        # Calculate ICC\n",
    "        icc_value = calculate_icc(dataframe, col1_name, col2_name)\n",
    "\n",
    "        # Bootstrap 95% confidence interval\n",
    "        ci_lower, ci_upper = bootstrap_icc(dataframe, col1_name, col2_name, bootstrap_samples=bootstrap_samples)\n",
    "\n",
    "        # Plot ICC with confidence interval\n",
    "        plt.errorbar(x=icc_value, y=idx, xerr=[[icc_value - ci_lower], [ci_upper - icc_value]], fmt='o', color=colors[idx], capsize=5)\n",
    "        \n",
    "        # Add legend patch\n",
    "        if full_legend_patches:\n",
    "            legend_patches.append(mpatches.Patch(color=colors[idx], label=f'{col1_name} vs {col2_name}'))\n",
    "        else:\n",
    "            legend_patches.append(mpatches.Patch(color=colors[idx], label=f'{col1_name}'))\n",
    "\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(-1, len(comparisons_dict))\n",
    "    plt.yticks([])\n",
    "    plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.xlabel('ICC')\n",
    "    plt.title('Intraclass Correlation Coefficients (ICC) with 95% Confidence Intervals')\n",
    "    plt.grid(axis='x', linestyle='--')\n",
    "    \n",
    "    # Add legend\n",
    "    plt.legend(handles=legend_patches, frameon=False, loc=(0.05, 0.1))\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exptl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['City'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Variables\n",
    "y_variable = 'Z_Scored_Percent_Cognitive_Improvement'\n",
    "x_variable = 'Subiculum_Connectivity_T_Redone'\n",
    "\n",
    "# Filter data for 'young' age group\n",
    "young_data = data_df[data_df['Age_Group'] == 'old']\n",
    "\n",
    "# Function to perform bootstrap and calculate correlation differences and individual correlations\n",
    "def bootstrap_corr_diff(data, y_var, x_var, group_col, n_bootstraps=1000):\n",
    "    corr_diffs = []\n",
    "    all_correlations = {group: [] for group in data[group_col].unique()}\n",
    "    unique_groups = data[group_col].unique()\n",
    "    \n",
    "    for _ in range(n_bootstraps):\n",
    "        sample_diffs = []\n",
    "        \n",
    "        for group in unique_groups:\n",
    "            group_data = data[data[group_col] == group].sample(frac=1, replace=True)\n",
    "            corr, _ = pearsonr(group_data[x_var], group_data[y_var])\n",
    "            all_correlations[group].append(corr)\n",
    "            sample_diffs.append(corr)\n",
    "        \n",
    "        if len(sample_diffs) == 2:\n",
    "            corr_diffs.append(sample_diffs[0] - sample_diffs[1])\n",
    "    \n",
    "    return corr_diffs, all_correlations\n",
    "\n",
    "# Perform bootstrapping\n",
    "bootstrap_diffs, bootstrap_correlations = bootstrap_corr_diff(young_data, y_variable, x_variable, group_col='City')\n",
    "\n",
    "# Save the bootstrap differences to a .txt file\n",
    "np.savetxt('/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Research/2023/subiculum_cognition_and_age/figures/Figures/3_cohort_delta_r/andy_similarity_test/bayes_old/bootstrap_diffs.txt', bootstrap_diffs)\n",
    "\n",
    "# Save the bootstrap correlations for each city to separate .txt files\n",
    "for city, correlations in bootstrap_correlations.items():\n",
    "    np.savetxt(f'/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Research/2023/subiculum_cognition_and_age/figures/Figures/3_cohort_delta_r/andy_similarity_test/bayes_old/bootstrap_correlations_{city}.txt', correlations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = ['Total', 'Attention', 'Memory', 'Fluency', 'Language', 'Visuospatial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_correlation_heatmap(df, columns, method='pearson'):\n",
    "    # Calculate the correlation matrix\n",
    "    corr_matrix = df[columns].corr(method=method)\n",
    "    \n",
    "    # Generate a heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "    plt.title(f'{method.capitalize()} Correlation Matrix')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_correlation_heatmap(data_df, columns_list, method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimlab_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
