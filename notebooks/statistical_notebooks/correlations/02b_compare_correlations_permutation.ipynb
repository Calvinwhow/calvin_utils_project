{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Correlation-Based Analyses\n",
    "\n",
    "### Authors: Calvin Howard.\n",
    "\n",
    "#### Last updated: July 6, 2023\n",
    "\n",
    "Use this to assess if a correlation between a dependent variable and an independent variable is statistically significant using permutation analysis. \n",
    "\n",
    "Further, follow this up with a contrast analysis which sees which categorical variables have significantly different correlations from each other. \n",
    "\n",
    "Notes:\n",
    "- To best use this notebook, you should be familar with mixed effects models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 - Import CSV with All Data\n",
    "**The CSV is expected to be in this format**\n",
    "- ID and absolute paths to niftis are critical\n",
    "```\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "| ID  | Nifti_File_Path            | Covariate_1  | Covariate_2  | Covariate_3  |\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "| 1   | /path/to/file1.nii.gz      | 0.5          | 1.2          | 3.4          |\n",
    "| 2   | /path/to/file2.nii.gz      | 0.7          | 1.4          | 3.1          |\n",
    "| 3   | /path/to/file3.nii.gz      | 0.6          | 1.5          | 3.5          |\n",
    "| 4   | /path/to/file4.nii.gz      | 0.9          | 1.1          | 3.2          |\n",
    "| ... | ...                        | ...          | ...          | ...          |\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your CSV file containing NIFTI paths\n",
    "input_csv_path = '/Users/cu135/Partners HealthCare Dropbox/Calvin Howard/resources/datasets/05c_Howard_MetaAlzheimerReview_DBS-TMS_Coordinates/metadata/comparison_data.xlsx'\n",
    "sheet = \"Sheet1\" #'master_list_proper_subjects' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify where you want to save your results to\n",
    "out_dir = '/Users/cu135/Partners HealthCare Dropbox/Calvin Howard/studies/ccm_memory/results/supplement_syst_review_ad_cognition_specificity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.permutation_analysis_utils.statsmodels_palm import CalvinStatsmodelsPalm\n",
    "# Instantiate the PalmPrepararation class\n",
    "cal_palm = CalvinStatsmodelsPalm(input_csv_path=input_csv_path, output_dir=out_dir, sheet=sheet)\n",
    "# Call the process_nifti_paths method\n",
    "data_df = cal_palm.read_and_display_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 01 - Preprocess Your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handle NANs**\n",
    "- Set drop_nans=True is you would like to remove NaNs from data\n",
    "- Provide a column name or a list of column names to remove NaNs from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['overlap_values', 'region', 'outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = cal_palm.drop_nans_from_columns(columns_to_drop_from=drop_list)\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop Row Based on Value of Column**\n",
    "\n",
    "Define the column, condition, and value for dropping rows\n",
    "- column = 'your_column_name'\n",
    "- condition = 'above'  # Options: 'equal', 'above', 'below'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the parameters for dropping rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns\n",
    "# data_df.City.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'Cognitive_Test'  # The column you'd like to evaluate\n",
    "condition = 'equal'  # Thecondition to check ('equal', 'above', 'below', 'not')\n",
    "value = 'UPDRS-1' # The value to compare against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df, other_df = cal_palm.drop_rows_based_on_value(column, condition, value)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regress out a Covariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = []\n",
    "for col in data_df.columns:\n",
    "    if 'surface' in col.lower():\n",
    "        lis.append(col)\n",
    "print(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.statistical_utils.regression_utils import RegressOutCovariates\n",
    "# use this code block to regress out covariates. Generally better to just include as covariates in a model..\n",
    "dependent_variable_list = lis\n",
    "regressors = ['Age', 'Sex']\n",
    "\n",
    "# data_df, adjusted_dep_vars_list = RegressOutCovariates.run(df=data_df, dependent_variable_list=dependent_variable_list, covariates_list=regressors)\n",
    "# print(adjusted_dep_vars_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standardize Data**\n",
    "- Enter Columns you Don't want to standardize into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove anything you don't want to standardize\n",
    "cols_not_to_standardize = ['Cohort', 'Age', 'Z_Scored_Percent_Cognitive_Improvement', 'MinMaxNormBaseline_Higher_is_Better']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = cal_palm.standardize_columns(cols_not_to_standardize)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 - Delta Scatterplot (Pretty)\n",
    "- Generates 2 categories to compare by splitting on a continuous variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data To Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Variables\n",
    "dependent_variable = 'outcome'\n",
    "independent_variable = 'overlap_values'\n",
    "group_variable = 'region' # This is the column which contains the values you are going to split the data by "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels for Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import t\n",
    "from itertools import combinations\n",
    "\n",
    "class DeltaCorrelationAnalysis:\n",
    "    \"\"\"Multigroup Pearson-r analysis with bootstraps, permutations, and plots.\"\"\"\n",
    "\n",
    "    # ---------- basic ----------\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df.copy(deep=False)\n",
    "        self.boot_corrs: dict[str, np.ndarray] = {}\n",
    "        self.perm_results: dict[tuple[str, str], tuple[float, float]] = {}\n",
    "\n",
    "    # ---------- statistics ----------\n",
    "    @staticmethod\n",
    "    def _analytic_ci(x, y, x_grid):\n",
    "        slope, intercept = np.polyfit(x, y, 1)\n",
    "        y_fit = slope * x_grid + intercept\n",
    "\n",
    "        resid = y - (slope * x + intercept)\n",
    "        stderr = np.sqrt(resid.dot(resid) / (len(y) - 2))\n",
    "        t_val = t.ppf(0.975, len(y) - 2)\n",
    "        ci = t_val * stderr * np.sqrt(\n",
    "            1 / len(x) + (x_grid - x.mean()) ** 2 / ((x - x.mean()) ** 2).sum()\n",
    "        )\n",
    "        return y_fit - ci, y_fit, y_fit + ci\n",
    "    \n",
    "    def bootstrap_correlations(self, x, y, group, n=1000, seed=None):\n",
    "        rng = np.random.default_rng(seed)\n",
    "        for g, sub in self.df.groupby(group):\n",
    "            print(f\"Group '{g}' has {len(sub)} values.\")\n",
    "            r = np.empty(n)\n",
    "            for i in range(n):\n",
    "                boot = sub.sample(len(sub), replace=True, random_state=rng.integers(2**32))\n",
    "                r[i] = boot[x].corr(boot[y])\n",
    "            self.boot_corrs[g] = r\n",
    "        return self.boot_corrs\n",
    "\n",
    "    def permute_delta_r(self, x, y, group, pairs=None, n=10000, seed=None):\n",
    "        if pairs is None:\n",
    "            pairs = combinations(self.df[group].unique(), 2)\n",
    "        rng = np.random.default_rng(seed)\n",
    "\n",
    "        for a, b in pairs:\n",
    "            sub_a = self.df[self.df[group] == a]\n",
    "            sub_b = self.df[self.df[group] == b]\n",
    "            n_a, n_b = len(sub_a), len(sub_b)\n",
    "\n",
    "            obs = sub_a[x].corr(sub_a[y]) - sub_b[x].corr(sub_b[y])\n",
    "\n",
    "            joined = pd.concat([sub_a, sub_b], ignore_index=True)\n",
    "            diffs = np.empty(n)\n",
    "            for i in range(n):\n",
    "                shuffle = rng.permutation(n_a + n_b)\n",
    "                pa = joined.iloc[shuffle[:n_a]]\n",
    "                pb = joined.iloc[shuffle[n_a:]]\n",
    "                diffs[i] = pa[x].corr(pa[y]) - pb[x].corr(pb[y])\n",
    "            p_val = (np.abs(diffs) >= abs(obs)).mean()\n",
    "            self.perm_results[(a, b)] = (obs, p_val)\n",
    "\n",
    "        return self.perm_results\n",
    "\n",
    "    # ---------- plotting ----------\n",
    "    def scatter(self, x, y, group, palette=\"tab10\", alpha=.3, figsize=(4, 5), point_hue=None, point_palette=\"tab20\"):\n",
    "        plt.rcParams.update({'font.family': 'Helvetica', 'font.size': 16})  # Set font to Helvetica 16\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        if point_hue is None:\n",
    "            hue_vals = sorted(self.df[group].dropna().unique())\n",
    "            hue_cols = sns.color_palette(palette, len(hue_vals))\n",
    "            colour_map = dict(zip(hue_vals, hue_cols))\n",
    "\n",
    "            for g, col in colour_map.items():\n",
    "                sub = self.df[self.df[group] == g]\n",
    "                ax.scatter(sub[x], sub[y], color=col, s=20, alpha=alpha, label=g)\n",
    "        else:\n",
    "            hue_vals = sorted(self.df[point_hue].dropna().unique())\n",
    "            hue_cols = sns.color_palette(point_palette, len(hue_vals))\n",
    "            colour_map = dict(zip(hue_vals, hue_cols))\n",
    "\n",
    "            for h in hue_vals:\n",
    "                sub = self.df[self.df[point_hue] == h]\n",
    "                ax.scatter(sub[x], sub[y], color=colour_map[h], s=20, alpha=alpha, label=str(h), edgecolors=\"none\")\n",
    "\n",
    "        # ------------ 2) regression lines per GROUP -------------------\n",
    "        grp_vals = sorted(self.df[group].dropna().unique())\n",
    "        line_cols = sns.color_palette(palette, len(grp_vals))\n",
    "        x_grid = np.linspace(self.df[x].min(), self.df[x].max(), 400)\n",
    "\n",
    "        for g, col in zip(grp_vals, line_cols):\n",
    "            sub = self.df[self.df[group] == g]\n",
    "            y_lo, y_fit, y_hi = self._analytic_ci(sub[x], sub[y], x_grid)\n",
    "            ax.plot(x_grid, y_fit, color=col, linewidth=2.0, label=f\"fit {g}\")\n",
    "            ax.fill_between(x_grid, y_lo, y_hi, color=col, alpha=alpha / 4)\n",
    "\n",
    "        # ------------ 3) permutation text (if already computed) -------\n",
    "        if self.perm_results:\n",
    "            txt = \"\\n\".join(\n",
    "                f\"{a}–{b}: Δr={d:.2f}, p={p:.3f}\"\n",
    "                for (a, b), (d, p) in self.perm_results.items()\n",
    "            )\n",
    "            ax.set_title(txt, fontsize=9)\n",
    "\n",
    "        ax.set_xlabel(x)\n",
    "        ax.set_ylabel(y)\n",
    "        sns.despine(ax=ax)\n",
    "        ax.legend(frameon=False)\n",
    "        return fig\n",
    "\n",
    "    # ---------- plotting ----------\n",
    "    def boxplot_boot(self, x: str, y: str, group: str, *,\n",
    "        xlim=(-1, 1), horiz: bool = True, figsize=(4, 4), out_path: str | None = None):\n",
    "        \"\"\"\n",
    "        Box-plots of bootstrapped Pearson-r per group with observed r over-laid.\n",
    "        Call `bootstrap_correlations` first (or `run`).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x, y        : column names whose correlation is analysed.\n",
    "        group       : column name used to split the data.\n",
    "        xlim        : limits for the correlation axis.\n",
    "        horiz       : plot horizontally (True) or vertically (False).\n",
    "        \"\"\"\n",
    "        if not self.boot_corrs:\n",
    "            raise RuntimeError(\"Run bootstrap_correlations (or run) first.\")\n",
    "\n",
    "        # long-form DF for Seaborn\n",
    "        df_long = (pd.DataFrame(self.boot_corrs).melt(var_name=\"Group\", value_name=\"r\").dropna())\n",
    "\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        orient = \"h\" if horiz else \"v\"\n",
    "\n",
    "        if horiz:\n",
    "            sns.boxplot( data=df_long,  x=\"r\", y=\"Group\", orient=orient, palette=\"coolwarm\")\n",
    "            plt.xlim(*xlim)\n",
    "            plt.xlabel(\"Pearson r\")\n",
    "            plt.ylabel(group)\n",
    "        else:\n",
    "            sns.boxplot(data=df_long,x=\"Group\",y=\"r\",orient=orient,palette=\"coolwarm\")\n",
    "            plt.ylim(*xlim)\n",
    "            plt.ylabel(\"Pearson r\")\n",
    "            plt.xlabel(group)\n",
    "        plt.legend(frameon=False)\n",
    "        sns.despine()\n",
    "\n",
    "        if out_path:\n",
    "            fig.savefig(out_path, bbox_inches=\"tight\")\n",
    "        return fig\n",
    "    \n",
    "    # ---------- orchestration function ----------\n",
    "    def run(self, x: str, y: str, group: str, n_boot: int = 1000, n_perm: int = 10000,\n",
    "        palette: str = \"tab10\", alpha: float = 1, xlim: tuple[float, float] = (-1, 1),\n",
    "        horiz_box: bool = True, out_dir: str | None = None,  seed: int | None = None, figsize=(4, 4.5),\n",
    "        point_hue: str | None = None, point_palette: str = \"tab20\"):\n",
    "        \"\"\"\n",
    "        One-liner entry: does bootstraps, permutations, scatter & box-plot.\n",
    "        \"\"\"\n",
    "        # Print the number of unique values in the group\n",
    "        unique_groups = self.df[group].nunique()\n",
    "        print(f\"Number of unique groups in '{group}': {unique_groups}\")\n",
    "        # 1) statistics\n",
    "        self.bootstrap_correlations(x, y, group, n=n_boot, seed=seed)\n",
    "        self.permute_delta_r(x, y, group, n=n_perm, seed=seed)\n",
    "\n",
    "        # 2) figures\n",
    "        sc_fig = self.scatter(x, y, group, palette=palette, alpha=alpha, figsize=figsize, point_hue=point_hue, point_palette=point_palette)\n",
    "        bx_fig = self.boxplot_boot(x, y, group, xlim=xlim, horiz=horiz_box, figsize=figsize)\n",
    "\n",
    "        # 3) save, if requested\n",
    "        if out_dir:\n",
    "            sc_fig.savefig(f\"{out_dir}/scatter.svg\", bbox_inches=\"tight\")\n",
    "            bx_fig.savefig(f\"{out_dir}/boot_box.svg\", bbox_inches=\"tight\")\n",
    "\n",
    "        return sc_fig, bx_fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swc = DeltaCorrelationAnalysis(data_df)\n",
    "swc.run(x=independent_variable, y=dependent_variable, group=group_variable, xlim=(-.8, .8), \n",
    "        out_dir=out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_calvin (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
