{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os\n",
    "import glob as glob\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "#Calculate Correlation\n",
    "from scipy.stats import pearsonr\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import platform"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input location of parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = 'kernel_ridge_regression_outliers_included'\n",
    "if platform.uname().system == 'Darwin': #------------------------------Mac OS X---------------------------------------------------------------\n",
    "    data_path = r'/Users/cu135/Dropbox (Partners HealthCare)/memory/analyses/roi-roi_correl/addbs_vta_to_memory_net_maxima/linear_regression_addbs_vta_to_memory_net_maxima/prepared_data_sbc_consolidated.csv'\n",
    "    out_dir = os.path.join(os.path.dirname(data_path), f'{analysis}')\n",
    "    #out_dir = r'path to out dir here'\n",
    "    \n",
    "    print('I have set pathnames in the Mac style')\n",
    "    print('I will save to :', out_dir)\n",
    "else: #----------------------------------------------------------------Windows----------------------------------------------------------------\n",
    "    data_path = r'C:\\Users\\calvin.howard\\Dropbox (Partners HealthCare)\\memory\\analyses\\roi-roi_correl\\addbs_vta_to_memory_net_maxima\\linear_regression_addbs_vta_to_memory_net_maxima\\prepared_data.csv'\n",
    "    out_dir = rf'C:\\Users\\calvin.howard\\Dropbox (Partners HealthCare)\\memory\\analyses\\roi-roi_correl\\addbs_vta_to_memory_net_maxima\\linear_regression_addbs_vta_to_memory_net_maxima\\{analysis}'\n",
    "    #out_dir = r'path to out dir here'\n",
    "\n",
    "    print('I have set pathnames in the Windows style')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import pre-prepared dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(data_path)\n",
    "data_df.tail(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.reset_index(drop=True)\n",
    "try:\n",
    "    data_df.pop('Unnamed: 0')\n",
    "except:\n",
    "    print('none to pop')\n",
    "data_df = data_df.rename(columns={'% Change from baseline (ADAS-Cog11)': 'percent_change_adascog11'})#, '07_default': 'default', '02_somatomotor_seed': 'somatomotor', '03_dorsal_attention': 'dorsal', '01_visual_seed': 'visual', '04_ventral_attention': 'ventral', '05_limbic': 'limbic', '06_frontoparietal': 'frontoparietal'})\n",
    "if np.sum(np.isnan(data_df)).any():\n",
    "    data_df.dropna(inplace=True) #data_df.fillna(method='bfill', inplace=True)\n",
    "    data_df.reset_index(inplace=True, drop=True)\n",
    "display(data_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# scaled = scaler.fit_transform(data_df)\n",
    "# data_df = pd.DataFrame(scaled)\n",
    "data_df=(data_df-data_df.mean())/data_df.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose specific columns to assess\n",
    "new_df = data_df.copy()\n",
    "# columns_of_interest = [\n",
    "#     'SBC', 'Thal. Ant. Med. L', 'PFC Mid. Vent.'\n",
    "    \n",
    "# ]\n",
    "# columns_to_extract = ['percent_change_adascog11'] + columns_of_interest\n",
    "# new_df = new_df.loc[:, columns_to_extract]\n",
    "# data_df = new_df\n",
    "data_df.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a LOOC On a Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "def kernel_ridge_loo(df:pd.DataFrame, target:str, alpha:float, gamma:float, degree:int, kernel:str):\n",
    "    y_pred = []\n",
    "    for i in range(0, len(df[target].values.tolist())):\n",
    "        # splitting dataframe into train and test set\n",
    "        df_test = df.loc[[i]]\n",
    "        df_train = df.drop(df.index[i])\n",
    "        \n",
    "        X_train = df_train.drop(target, axis=1)\n",
    "        y_train = df_train[target]\n",
    "        X_test = df_test.drop(target, axis=1)\n",
    "        y_test = df_test[target]\n",
    "        \n",
    "        model = KernelRidge(kernel=kernel, alpha=alpha, gamma=gamma, degree=degree)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred.append(model.predict(X_test)[0])\n",
    "        \n",
    "    outcome_dictionary = {}\n",
    "    outcome_dictionary['actuals'] = df[target].values.tolist()\n",
    "    outcome_dictionary['predictions'] = y_pred\n",
    "    try:\n",
    "        outcome_dictionary['loocv_prediction_r'], outcome_dictionary['loocv_prediction_p'] = pearsonr(outcome_dictionary['actuals'], outcome_dictionary['predictions'])\n",
    "        outcome_dictionary['loocv_prediction_r2'] = outcome_dictionary['loocv_prediction_r']**2\n",
    "        outcome_dictionary['loocv_mean_squared_error'] = np.sum( np.square( (outcome_dictionary['actuals'] - outcome_dictionary['predictions']))) / len(outcome_dictionary['predictions'])\n",
    "        outcome_dictionary['loocv_root_mean_squared_error'] = np.sqrt(outcome_dictionary['loocv_mean_squared_error'])\n",
    "        outcome_dictionary['lootcv_mean_absolute_error'] = np.sum(np.abs((outcome_dictionary['predictions'] - outcome_dictionary['actuals']))) / len(outcome_dictionary['predictions'])    \n",
    "    except:\n",
    "        print('Error generating outcome metrics')\n",
    "    outcome_df = pd.DataFrame(outcome_dictionary)\n",
    "    \n",
    "    return outcome_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = ['additive_chi2', 'polynomial', 'poly', 'rbf', 'cosine', 'laplacian', 'precomputed', 'sigmoid', 'linear', 'chi2']\n",
    "kernel = 'polynomial'\n",
    "loo_results = kernel_ridge_loo(df=data_df, target='percent_change_adascog11', kernel=kernel, alpha=.01, gamma=.0001, degree=2)\n",
    "# loo_df = pd.DataFrame(loo_results)\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "#Calculate metrics\n",
    "loo_results.dropna(inplace=True)\n",
    "loo_results['loocv_pearson_r'], loo_results['loocv_pearson_p'] = pearsonr(loo_results['predictions'], loo_results['actuals'], alternative='greater')\n",
    "loo_results['loocv_r_squared'] = np.square(loo_results['loocv_pearson_r'])\n",
    "_, loo_results['loocv_pearson_p_greater'] = pearsonr(loo_results['predictions'], loo_results['actuals'], alternative='greater')\n",
    "_, loo_results['loocv_pearson_p_lesser'] = pearsonr(loo_results['predictions'], loo_results['actuals'], alternative='less')\n",
    "_, loo_results['loocv_pearson_p_two-sided'] = pearsonr(loo_results['predictions'], loo_results['actuals'], alternative='two-sided')\n",
    "loo_results['loocv_mse'] = (np.sum(np.square((loo_results['actuals']-loo_results['predictions'])))) / len(loo_results['actuals'])\n",
    "loo_results['loocv_rmse'] = np.sqrt(loo_results['loocv_mse'])\n",
    "loo_results['mean_absolute_error'] = np.sum(np.absolute(loo_results['predictions']-loo_results['actuals']))/len(loo_results['predictions'])\n",
    "\n",
    "display(loo_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save if desired\n",
    "save=True\n",
    "if save:\n",
    "    if os.path.isdir(out_dir) != True:\n",
    "        os.makedirs(out_dir)\n",
    "        print('Made directory')\n",
    "    try:\n",
    "        loo_results.to_csv(os.path.join(out_dir, f'loocv_{kernel}_kernel_ridge_regression_{data_df.columns.values.tolist()[1:]}_statistically_significant_{loo_results[\"mean_absolute_error\"].values.tolist[1]}.csv'))\n",
    "    except:\n",
    "        loo_results.to_csv(os.path.join(out_dir, f'ols_leave_one_out_full_formula.csv'))\n",
    "\n",
    "\n",
    "print('Saved to: ' + out_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call a Custom Kernel, Run a Ridge Regression, and Get Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of kernel functions\n",
    "def linear_kernel(X1, X2, **kwargs):\n",
    "    \"\"\"Linear kernel function\"\"\"\n",
    "    return np.matmul(X1, X2.transpose())\n",
    "\n",
    "def polynomial_kernel(x1, x2, degree, c=1, **kwargs):\n",
    "    return (np.dot(x1, x2) + c)**degree\n",
    "\n",
    "def rbf_kernel(x1, x2, gamma, **kwargs):\n",
    "    return np.exp(-gamma * np.power(np.linalg.norm(x1 - x2), 2))\n",
    "\n",
    "def gaussian_kernel(x1, x2, sigma, **kwargs):\n",
    "    return np.exp(-np.power(np.linalg.norm(x1 - x2), 2) / (2 * sigma ** 2))\n",
    "\n",
    "def sigmoid_kernel(x1, x2, k=1, c=1, **kwargs):\n",
    "    return np.tanh(k * np.dot(x1, x2) + c)\n",
    "\n",
    "def laplacian_kernel(x1, x2, gamma, **kwargs):\n",
    "    return np.exp(-gamma * np.linalg.norm(x1 - x2))\n",
    "\n",
    "def exponential_kernel(x1, x2, gamma, **kwargs):\n",
    "    return np.exp(-gamma * np.linalg.norm(x1 - x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from scipy.stats import pearsonr\n",
    "kernel_list = [\"linear_kernel\", \"polynomial_kernel\", \"rbf_kernel\", \"gaussian_kernel\", \"sigmoid_kernel\", \"laplacian_kernel\", \"exponential_kernel\"] #, \"exp\", \"log\", \"tanh\"]\n",
    "#Iterate over the kernels of interest\n",
    "\n",
    "result_list_kernel = []; results_list_r2 = []; results_list_r = []; results_list_p = []; results_list_mse = []; results_list_rmse = []; results_list_mae = []\n",
    "for kernel_string in kernel_list:\n",
    "\n",
    "    #Generate Kernelized data\n",
    "    n = data_df.shape[0]\n",
    "    kernel = np.zeros((n,n))\n",
    "    Y = data_df['percent_change_adascog11']\n",
    "    X = data_df.drop('percent_change_adascog11', axis=1)\n",
    "    sigma = 1000\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            kernel[i,j] = eval(kernel_string)(X.iloc[i], X.iloc[j], gamma=1, sigma=1, k=1, degree=2)#, sigma=1)# degree=1)\n",
    "            \n",
    "    #Train a ridge regression on kernelized data\n",
    "    model = KernelRidge(kernel='precomputed')\n",
    "    results = model.fit(kernel[:, :], Y[:])\n",
    "\n",
    "    results_dict = {}\n",
    "    # results_dict['predictions'] = np.dot(kernel,model.dual_coef_)\n",
    "    # results_dict['observations'] = Y[:]\n",
    "    result_list_kernel.append(kernel_string)\n",
    "    results_list_r2.append(results.score(kernel[:, :], Y[:]))\n",
    "    r, p = pearsonr(np.dot(kernel,model.dual_coef_), Y[:])\n",
    "    results_list_r.append(r); results_list_p.append(p)\n",
    "    results_list_mse.append((np.sum(np.square((Y[:]-np.dot(kernel,model.dual_coef_))))) / len(Y[:]))\n",
    "    results_list_rmse.append(np.sqrt((np.sum(np.square((Y[:]-np.dot(kernel,model.dual_coef_))))) / len(Y[:])))\n",
    "    results_list_mae.append(np.sum(np.absolute(np.dot(kernel,model.dual_coef_)-Y[:]))/len(np.dot(kernel,model.dual_coef_)))\n",
    "results_dict['kernel'] = result_list_kernel\n",
    "results_dict['r2'] = results_list_r2; results_dict['r'] = results_list_r; results_dict['p'] = results_list_p\n",
    "results_dict['mse'] = results_list_mse; results_dict['rmse'] = results_list_rmse; results_dict['mae'] = results_list_mae\n",
    "\n",
    "kernel_comparison_kernel_ridge_results = pd.DataFrame(results_dict)\n",
    "display(kernel_comparison_kernel_ridge_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Results if desired\n",
    "save=True\n",
    "if save:\n",
    "    if os.path.isdir(out_dir) != True:\n",
    "        os.makedirs(out_dir)\n",
    "        print('Made directory')\n",
    "    kernel_comparison_kernel_ridge_results.to_csv(os.path.join(out_dir, 'kernel_comparison_kernel_ridge_results.csv'))\n",
    "\n",
    "\n",
    "print('Saved to: ' + out_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Kernels Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = data_df.shape[0]\n",
    "kernel = np.zeros((n,n))\n",
    "Y = data_df['percent_change_adascog11']\n",
    "X = data_df.drop('percent_change_adascog11', axis=1)\n",
    "sigma = 1000\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        kernel[i,j] = exponential_kernel(X.iloc[i], X.iloc[j], gamma=1, k=1, degree=1)#, sigma=1)# degree=1)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Kernelized data\n",
    "n = data_df.shape[0]\n",
    "kernel = np.zeros((n,n))\n",
    "Y = data_df['percent_change_adascog11']\n",
    "X = data_df.drop('percent_change_adascog11', axis=1)\n",
    "sigma = 1000\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        kernel[i,j] = exponential_kernel(X.iloc[i], X.iloc[j], gamma=1, k=1, degree=1)#, sigma=1)# degree=1)\n",
    "        \n",
    "#Train a ridge regression on kernelized data\n",
    "model = KernelRidge(kernel='precomputed')\n",
    "results = model.fit(kernel[:, :], Y[:])\n",
    "\n",
    "results_dict = {}\n",
    "results_dict['predictions'] = np.dot(kernel,model.dual_coef_)\n",
    "results_dict['observations'] = Y[:]\n",
    "results_dict['r2'] = results.score(kernel[:, :], Y[:])\n",
    "results_dict['pearson_r'], results_dict['pearson_p'] = pearsonr(results_dict['predictions'], results_dict['observations'])\n",
    "results_dict['mse'] = (np.sum(np.square((results_dict['observations']-results_dict['predictions'])))) / len(results_dict['observations'])\n",
    "results_dict['rmse'] = np.sqrt(results_dict['mse'])\n",
    "results_dict['mae'] = np.sum(np.absolute(results_dict['predictions']-results_dict['observations']))/len(results_dict['predictions'])\n",
    "\n",
    "manual_kernel_ridge_results = pd.DataFrame(results_dict)\n",
    "display(manual_kernel_ridge_results)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Ridge Regression, K-Folds Cross Validation, Default Gaussian Kernel/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "def kernel_ridge_kfold(df:pd.DataFrame, target:str, k:int, sigma:float):\n",
    "    kf = KFold(n_splits=k, shuffle=True)\n",
    "    y_pred = []\n",
    "    y_test_all = []\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        df_train, df_test = df.iloc[train_index], df.iloc[test_index]\n",
    "        X_train = df_train.drop(target, axis=1)\n",
    "        y_train = df_train[target]\n",
    "        X_test = df_test.drop(target, axis=1)\n",
    "        y_test = df_test[target]\n",
    "        model = KernelRidge(kernel='rbf', gamma=1/(2*sigma**2))\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred.append(model.predict(X_test))\n",
    "        y_test_all.append(y_test)\n",
    "    y_test_all = np.concatenate(y_test_all)\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    R, P = pearsonr(y_pred, y_test_all)\n",
    "    return R, P\n",
    "\n",
    "R, P = kernel_ridge_kfold(df=data_df, target='percent_change_adascog11', k=2, sigma=100)#(data_df.shape[0]-1)/6)\n",
    "results_df = pd.DataFrame({'R': R, 'P': P}, index=[0])\n",
    "display(results_df)\n",
    "\n",
    "save=False\n",
    "if save:\n",
    "    if os.path.isdir(out_dir) == False:\n",
    "        os.mkdir(out_dir)\n",
    "    results_df.to_csv(os.path.join(out_dir, 'kernel_ridge_regression_k_folds_results.csv'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Coefficients from Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_ridge(df:pd.DataFrame, target:str, sigma:float):\n",
    "    y_pred = []\n",
    "    y_test_all = []\n",
    "    df_train = df.iloc[:, :]\n",
    "    X_train = df_train.drop(target, axis=1)\n",
    "    y_train = df_train[target]\n",
    "    model = KernelRidge(kernel='rbf', gamma=1/(2*sigma**2))\n",
    "    model.fit(X_train, y_train)\n",
    "    print(model.predict(X_train))\n",
    "    \n",
    "    #Extract the coefficients\n",
    "    kernel_space_coefficients = model.dual_coef_\n",
    "    normal_coefficients = np.dot(X_train.transpose(), kernel_space_coefficients)\n",
    "    return normal_coefficients, kernel_space_coefficients\n",
    "\n",
    "coefficients, kernel_space_coefficients = kernel_ridge(df=data_df, target='percent_change_adascog11', sigma=(data_df.shape[0]-1)/6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients_df = pd.DataFrame({'Coefficient Name': data_df.columns.to_list()[1:], 'Values': coefficients})\n",
    "display(coefficients_df)\n",
    "\n",
    "save=True\n",
    "if save:\n",
    "    if os.path.isdir(out_dir) == False:\n",
    "        os.mkdir(out_dir)\n",
    "    results_df.to_csv(os.path.join(out_dir, 'kernel_ridge_regression_coefficient_weight_results.csv'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run initial model on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataframe into response and independent variables\n",
    "X = data_df.iloc[:,1:].astype('float32')\n",
    "y = data_df.iloc[:,0].astype('float32')\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a list of kernel functions\n",
    "kernels = [tf.exp(-tf.reduce_sum(tf.square(X_train - X_train), axis=-1) / (2 * tf.square(0.1))),\n",
    "           tf.matmul(X_train,tf.transpose(X_train)),\n",
    "           tf.pow(tf.matmul(X_train,tf.transpose(X_train)),2),\n",
    "           tf.pow(tf.matmul(X_train,tf.transpose(X_train)),3),\n",
    "           tf.exp(tf.reduce_sum(X_train * X_train, axis=1)),\n",
    "        #    tf.log(1+tf.reduce_sum(X_train * X_train, axis=1)),\n",
    "           tf.tanh(tf.reduce_sum(X_train * X_train, axis=1))]\n",
    "kernel_names = [\"RBF-0.1\", \"Linear\", \"2nd degree polynomial\", \"3rd degree polynomial\", \"Exponential\", \"Logarithmic\", \"Hyperbolic tangent\"]\n",
    "\n",
    "# Create placeholders for the input data\n",
    "X_ph = tf.compat.v1.placeholder(tf.float32, shape=(None, 2))\n",
    "y_ph = tf.compat.v1.placeholder(tf.float32, shape=(None,))\n",
    "\n",
    "# Create a dense layer\n",
    "dense = tf.layers.Dense(units=1)\n",
    "\n",
    "for kernel, kernel_name in zip(kernels, kernel_names):\n",
    "    # Compute pairwise distances using the kernel trick\n",
    "    kernel_output = kernel(X_ph, X_ph)\n",
    "    kernel_output_train = kernel(X_ph, X_train)\n",
    "    kernel_output_test = kernel(X_ph, X_test)\n",
    "\n",
    "    # Pass the kernel output through the dense layer\n",
    "    output = dense(kernel_output)\n",
    "    output_train = dense(kernel_output_train)\n",
    "    output_test = dense(kernel_output_test)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    loss = tf.losses.MeanAbsoluteError(y_ph, output)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    train_op = optimizer.minimize(loss)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for _ in range(1000):\n",
    "            _, train_loss = sess.run([train_op, loss], feed_dict={X_ph: X_train, y_ph: y_train})\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        test_output = sess.run(output_test, feed_dict={X_ph: X_test})\n",
    "        test_mse = tf.losses.mean_squared_error(y_test, test_output)\n",
    "        print(f\"Kernel: {kernel_name}, Test MSE: {test_mse}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run LOOCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Kernels\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "\n",
    "def leave_one_out_cross_validation(df, kernels, kernel_names):\n",
    "    # Split dataframe into response and independent variables\n",
    "    X = df.iloc[:,1:].astype('float32')\n",
    "    y = df.iloc[:,0].astype('float32')\n",
    "    n = len(X)\n",
    "    mae_list = []\n",
    "    for i in range(n):\n",
    "        X_test = X.iloc[i].values.reshape(1,-1)\n",
    "        y_test = y.iloc[i]\n",
    "        X_train = X.drop(i)\n",
    "        y_train = y.drop(i)\n",
    "\n",
    "        for kernel, kernel_name in zip(kernels, kernel_names):\n",
    "            # Compute pairwise distances using the kernel trick\n",
    "            if kernel_name == 'polynomial2':\n",
    "                kernel_output = kernel(X_train, X_train, degree=2)\n",
    "                kernel_output_test = kernel(X_test, X_train, degree=2)            \n",
    "            if kernel_name == 'polynomial3':\n",
    "                kernel_output = kernel(X_train, X_train, degree=3)\n",
    "                kernel_output_test = kernel(X_test, X_train, degree=3)\n",
    "            elif kernel_name == 'rbf':\n",
    "                kernel_output = kernel(X_train, X_train, gamma=1/X_train.shape[1])\n",
    "                kernel_output_test = kernel(X_test, X_train, gamma=1/X_train.shape[1])\n",
    "            elif kernel_name == 'exp':\n",
    "                kernel_output = kernel(X_train, X_train, gamma=1.0)\n",
    "                kernel_output_test = kernel(X_test, X_train, gamma=1.0)\n",
    "            elif kernel_name == 'log':\n",
    "                kernel_output = kernel(X_train, X_train, alpha=1.0)\n",
    "                kernel_output_test = kernel(X_test, X_train, alpha=1.0)\n",
    "            elif kernel_name == 'tanh':\n",
    "                kernel_output = kernel(X_train, X_train, alpha=1.0, beta=1.0)\n",
    "                kernel_output_test = kernel(X_test, X_train, alpha=1.0, beta=1.0)\n",
    "            else:\n",
    "                kernel_output = kernel(X_train, X_train)\n",
    "                kernel_output_test = kernel(X_test, X_train)\n",
    "\n",
    "            print(kernel_output.shape, kernel_output_test.shape)\n",
    "\n",
    "            # Define the model, regularization parameters, and optimizer\n",
    "            dense = tf.keras.layers.Dense(units=1, kernel_regularizer=regularizers.l1(0.1))\n",
    "            # loss = tf.losses.mean_absolute_error(y_train, output)\n",
    "            optimizer = tf.optimizers.Adam()\n",
    "\n",
    "            # training loop\n",
    "            for epoch in range(1000):\n",
    "                with tf.GradientTape() as tape:\n",
    "                    logits = dense(tf.reshape(kernel_output, (-1, kernel_output.shape[1]))) #logits are just the output of dense layer, generally prior to activation layer\n",
    "                    loss_value = tf.losses.mean_absolute_error(y_train, logits)\n",
    "                grads = tape.gradient(loss_value, dense.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(grads, dense.trainable_variables))\n",
    "\n",
    "            # Evaluate the model on the test set\n",
    "            test_output = dense(kernel_output_test) #Runs the now trained dense model on the test set\n",
    "            print(test_output, kernel_name, np.sum(np.isnan(test_output)))\n",
    "            test_mae = tf.losses.mean_absolute_error(y_test, test_output)\n",
    "            mae_list.append(test_mae)\n",
    "\n",
    "    return mae_list\n",
    "\n",
    "mae_list = leave_one_out_cross_validation(data_df, kernels, kernel_names)\n",
    "print(\"MAE: \", mae_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE: \", mae_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define RBF kernel function\n",
    "def rbf_kernel(X1, X2, gamma=1):\n",
    "    \"\"\"RBF (Radial Basis Function) kernel function\"\"\"\n",
    "    sq_dists = tf.reduce_sum(X1**2, 1, keepdims=True) + tf.reduce_sum(X2**2, 1, keepdims=True) - 2 * tf.matmul(X1, X2, transpose_b=True)\n",
    "    return tf.exp(-gamma * sq_dists)\n",
    "\n",
    "# Define input data\n",
    "X1 = tf.constant([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]], dtype=tf.float32)\n",
    "X2 = tf.constant([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18],\n",
    "                [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
    "                [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
    "                [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21],\n",
    "                [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
    "                ], dtype=tf.float32)\n",
    "\n",
    "# Pass input data through RBF kernel\n",
    "kernel_output = rbf_kernel(X1, X2, gamma=0.0001)\n",
    "\n",
    "# Pass kernel output through dense layer\n",
    "dense = tf.keras.layers.Dense(units=1)\n",
    "output = dense(kernel_output)\n",
    "\n",
    "# Print prediction\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimlab_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:27:35) [Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "62880161f19d28ddb8a8f59c63374d84ace356c39e36cc839cb3fb3bb03fb010"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
