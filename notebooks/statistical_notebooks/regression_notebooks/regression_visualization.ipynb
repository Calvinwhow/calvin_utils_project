{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Analysis on Results of A Regression\n",
    "\n",
    "### Authors: Calvin Howard.\n",
    "\n",
    "#### Last updated: July 6, 2023\n",
    "\n",
    "We do some fancy stuff in here. Many miscellaneous methods ensue. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 - Import CSV with All Data\n",
    "**The CSV is expected to be in this format**\n",
    "- ID and absolute paths to niftis are critical\n",
    "```\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "| ID  | Nifti_File_Path            | Covariate_1  | Covariate_2  | Covariate_3  |\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "| 1   | /path/to/file1.nii.gz      | 0.5          | 1.2          | 3.4          |\n",
    "| 2   | /path/to/file2.nii.gz      | 0.7          | 1.4          | 3.1          |\n",
    "| 3   | /path/to/file3.nii.gz      | 0.6          | 1.5          | 3.5          |\n",
    "| 4   | /path/to/file4.nii.gz      | 0.9          | 1.1          | 3.2          |\n",
    "| ... | ...                        | ...          | ...          | ...          |\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your CSV file containing data for regression\n",
    "input_csv_path = '/Users/cu135/Partners HealthCare Dropbox/Calvin Howard/studies/cognition_2023/metadata/master_list_proper_subjects.xlsx'\n",
    "sheet = 'master_list_proper_subjects'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify where you want to save your results to\n",
    "out_dir = '/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Research/2023/subiculum_cognition_and_age/figures/Figures/age_effect_figure/pd_validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.permutation_analysis_utils.statsmodels_palm import CalvinStatsmodelsPalm\n",
    "# Instantiate the PalmPrepararation class\n",
    "cal_palm = CalvinStatsmodelsPalm(input_csv_path=input_csv_path, output_dir=out_dir, sheet=sheet)\n",
    "# Call the process_nifti_paths method\n",
    "data_df = cal_palm.read_and_display_data()\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Preprocess Your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop Row Based on Value of Column**\n",
    "\n",
    "Define the column, condition, and value for dropping rows\n",
    "- column = 'your_column_name'\n",
    "- condition = 'above'  # Options: 'equal', 'above', 'below'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the parameters for dropping rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'City'  # The column you'd like to evaluate\n",
    "condition = 'not'  # Thecondition to check ('equal', 'above', 'below', 'not')\n",
    "value = 'Boston'  # The value to compare against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df, other_df = cal_palm.drop_rows_based_on_value(column, condition, value)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handle NANs**\n",
    "- Set drop_nans=True is you would like to remove NaNs from data\n",
    "- Provide a column name or a list of column names to remove NaNs from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['Age', 'Percent_Cognitive_Improvement', 'Subiculum_Connectivity_T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = cal_palm.drop_nans_from_columns(columns_to_drop_from=drop_list)\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standardize Data**\n",
    "- Enter Columns you Don't want to standardize into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove anything you don't want to standardize\n",
    "cols_not_to_standardize = ['Z_Scored_Percent_Cognitive_Improvement', 'Z_Scored_Subiculum_Connectivity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = cal_palm.standardize_columns(cols_not_to_standardize)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Statsmodel Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "formula = \"Percent_Cognitive_Improvement ~ Age * Subiculum_Connectivity_T\"\n",
    "#----------------------------------------------------------------DO NOT TOUCH\n",
    "results = smf.ols(formula, data=data_df).fit()\n",
    "print(results.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Diagnostics on the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.statistical_utils.statistical_measurements import model_diagnostics\n",
    "model_diagnostics(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structural Equation Modelling - Structural Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels\n",
    "def structural_coefficients(model: statsmodels.regression.linear_model.RegressionResultsWrapper, \n",
    "                            data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function calculates the structural coefficients of a linear regression model, along with their \n",
    "    associated model coefficients (beta weights). It also computes a 'suppressor index' which indicates \n",
    "    the likelihood of a variable being a suppressor variable (high beta weight, near-zero structural coefficient).\n",
    "    A suppressor index over 10 is a good heuristic for identifying a suppressor variable\n",
    "    \n",
    "    Parameters:\n",
    "    model (statsmodels.regression.linear_model.RegressionResultsWrapper): The fitted linear regression model.\n",
    "    data (pd.DataFrame): The dataset used in the model.\n",
    "    \n",
    "    Returns:\n",
    "    structural_coefs_df (pd.DataFrame): A dataframe containing the predictors, their structural coefficients,\n",
    "                                        model coefficients (beta weights), and suppressor index.\n",
    "                                        \n",
    "                                        If the sum of the structure coefficients is higher than 1, they are correlated (multicollinear)\n",
    "    \"\"\"\n",
    "    # Calculating the predicted values\n",
    "    y_predicted = model.predict(data)\n",
    "\n",
    "    # Creating a temporary dataframe to store interaction terms\n",
    "    temp_df = pd.DataFrame()\n",
    "    \n",
    "    # Calculating the structural coefficients\n",
    "    structural_coefs = {}\n",
    "    for pred in model.params.index:\n",
    "        if pred == 'Intercept':\n",
    "            continue\n",
    "\n",
    "        # Check if the predictor is an interaction term\n",
    "        if ':' in pred:\n",
    "            # Split the interaction term into its components\n",
    "            components = pred.split(':')\n",
    "            # Multiply the components and store the result in the temporary dataframe\n",
    "            temp_product = data[components[0]]\n",
    "            for component in components[1:]:\n",
    "                temp_product *= data[component]\n",
    "            temp_df[pred] = temp_product\n",
    "        else:\n",
    "            temp_df[pred] = data[pred]\n",
    "        \n",
    "        coef, _ = pearsonr(temp_df[pred], y_predicted)\n",
    "        structural_coefs[pred] = np.square(coef)\n",
    "\n",
    "    # Calculating the model coefficients\n",
    "    model_coefs = model.params.drop('Intercept')\n",
    "\n",
    "    # Creating a dataframe to store the results\n",
    "    structural_coefs_df = pd.DataFrame(list(zip(structural_coefs.keys(), structural_coefs.values(), model_coefs.values)), \n",
    "                                       columns=['predictor', 'structural_coefficient', 'model_coefficient'])\n",
    "\n",
    "    # Adding suppressor index column\n",
    "    structural_coefs_df['suppressor_index'] = structural_coefs_df['model_coefficient'].abs() / structural_coefs_df['structural_coefficient']\n",
    "\n",
    "    # Sorting the dataframe by the structural coefficients in descending order\n",
    "    structural_coefs_df.sort_values(by='structural_coefficient', ascending=False, inplace=True)\n",
    "    structural_coefs_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return structural_coefs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_structural_coefs_df = structural_coefficients(results, data_df.copy())\n",
    "squared_structural_coefs_df.to_csv(os.path.join(out_dir, 'structural_coefficient_analysis.csv'))\n",
    "print('saved to: ', os.path.join(out_dir, 'structural_coefficient_analysis.csv'))\n",
    "display(squared_structural_coefs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sqrt, mean\n",
    "\n",
    "# Calculate the squared errors\n",
    "squared_errors = (data_df['percent_change_adascog11'] - results.fittedvalues) ** 2\n",
    "\n",
    "# Calculate the mean of the squared errors\n",
    "mse = mean(squared_errors)\n",
    "\n",
    "# Calculate the root mean squared error\n",
    "rmse = sqrt(mse)\n",
    "\n",
    "print(\"Root Mean Squared Error:\", rmse)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare Two Lienar Regressions Using F-Test (ANOVA_LM In Statsmodels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.api import anova_lm\n",
    "smaller_formula = 'Percent_Cognitive_Improvement ~ Age + Subiculum_Connectivity'\n",
    "\n",
    "larger_formula = 'Percent_Cognitive_Improvement ~ Age * Subiculum_Connectivity'\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------DO NOT TOUCH!----------------------------------------------------------------\n",
    "table1 = anova_lm(smf.ols(smaller_formula, data=data_df).fit(), smf.ols(larger_formula, data=data_df).fit())\n",
    "print(table1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marginal Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use 2D Interaction Plot to Visualize Interactions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard Interaciton Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 Variable Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List, Optional\n",
    "from statsmodels.genmod.generalized_linear_model import GLMResults\n",
    "\n",
    "def save_fig(fig, out_dir):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    fig.savefig(os.path.join(out_dir, 'create_2D_interaction_plot.png'))\n",
    "    fig.savefig(os.path.join(out_dir, 'create_2D_interaction_plot.svg'))\n",
    "    print('Saved to: ', os.path.join(out_dir, 'create_2D_interaction_plot.svg'))\n",
    "\n",
    "def permutation_test_for_interaction(data_df: pd.DataFrame, \n",
    "                                     x_one_col: str, \n",
    "                                     x_two_col: str, \n",
    "                                     outcome_col: str, \n",
    "                                     results: GLMResults, \n",
    "                                     x_values: list=None,\n",
    "                                     n_permutations: int = 2) -> float:\n",
    "    \"\"\"\n",
    "    Performs a permutation test to assess the significance of the interaction effect.\n",
    "    \n",
    "    Returns the p-value.\n",
    "    \"\"\"\n",
    "    # Generate predictions for observed data\n",
    "    if x_values is None:\n",
    "        x_two_mean = data_df[x_two_col].mean()\n",
    "        x_two_std = data_df[x_two_col].std()\n",
    "        x_two_minus_2sd = x_two_mean - 2 * x_two_std\n",
    "        x_two_plus_2sd = x_two_mean + 2 * x_two_std\n",
    "\n",
    "        X_pred_minus_2sd = pd.DataFrame({\n",
    "            x_one_col: data_df[x_one_col],\n",
    "            x_two_col: np.ones_like(data_df[x_one_col]) * x_two_minus_2sd\n",
    "        })\n",
    "        X_pred_plus_2sd = pd.DataFrame({\n",
    "            x_one_col: data_df[x_one_col],\n",
    "            x_two_col: np.ones_like(data_df[x_one_col]) * x_two_plus_2sd\n",
    "        })\n",
    "    else:\n",
    "        X_pred_minus_2sd = pd.DataFrame({\n",
    "            x_one_col: data_df[x_one_col],\n",
    "            x_two_col: np.ones_like(data_df[x_one_col]) * x_values[0]\n",
    "        })\n",
    "        X_pred_plus_2sd = pd.DataFrame({\n",
    "            x_one_col: data_df[x_one_col],\n",
    "            x_two_col: np.ones_like(data_df[x_one_col]) * x_values[1]\n",
    "        })\n",
    "    y_pred_minus_2sd = results.predict(X_pred_minus_2sd)\n",
    "    y_pred_plus_2sd = results.predict(X_pred_plus_2sd)\n",
    "    \n",
    "    observed_area_between_lines = np.abs(y_pred_minus_2sd - y_pred_plus_2sd).sum()\n",
    "    \n",
    "    # Initialize array to store areas from permutations\n",
    "    permuted_areas = np.zeros(n_permutations)\n",
    "    \n",
    "    # Perform permutations\n",
    "    for i in tqdm(range(n_permutations)):\n",
    "        # Permute the predictor variables\n",
    "        permuted_x_one = np.random.permutation(data_df[x_one_col])\n",
    "        permuted_x_two = np.random.permutation(data_df[x_two_col])\n",
    "        \n",
    "        # Recalculate mean and standard deviation for permuted x_two\n",
    "        x_two_mean_permuted = permuted_x_two.mean()\n",
    "        x_two_std_permuted = permuted_x_two.std()\n",
    "        x_two_minus_2sd_permuted = x_two_mean_permuted - 2 * x_two_std_permuted\n",
    "        x_two_plus_2sd_permuted = x_two_mean_permuted + 2 * x_two_std_permuted\n",
    "        \n",
    "        # Generate predictions for permuted data\n",
    "        X_pred_minus_2sd_permuted = pd.DataFrame({\n",
    "            x_one_col: permuted_x_one,\n",
    "            x_two_col: np.ones_like(permuted_x_one) * x_two_minus_2sd_permuted\n",
    "        })\n",
    "        X_pred_plus_2sd_permuted = pd.DataFrame({\n",
    "            x_one_col: permuted_x_one,\n",
    "            x_two_col: np.ones_like(permuted_x_one) * x_two_plus_2sd_permuted\n",
    "        })\n",
    "        \n",
    "        y_pred_minus_2sd_permuted = results.predict(X_pred_minus_2sd_permuted)\n",
    "        y_pred_plus_2sd_permuted = results.predict(X_pred_plus_2sd_permuted)\n",
    "        \n",
    "        permuted_area = np.abs(y_pred_minus_2sd_permuted - y_pred_plus_2sd_permuted).sum()\n",
    "        \n",
    "        # Store the permuted area\n",
    "        permuted_areas[i] = permuted_area\n",
    "    \n",
    "    # Calculate p-value\n",
    "    p_value = np.mean(permuted_areas >= observed_area_between_lines)\n",
    "    \n",
    "    return p_value\n",
    "\n",
    "# Modifying the function to include the visual updates\n",
    "from typing import List, Optional\n",
    "\n",
    "def create_2D_interaction_plot(data_df: pd.DataFrame, \n",
    "                               x_one: Dict[str, str], \n",
    "                               x_two: Dict[str, str], \n",
    "                               outcome: Dict[str, str], \n",
    "                               results: GLMResults, \n",
    "                               x_values: list=None,\n",
    "                               legend_labels: Optional[List[str]] = None) -> None:\n",
    "    \"\"\"\n",
    "    Creates a 2D interaction plot visualizing the effect of x_one on the outcome at two levels of x_two.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_df : pd.DataFrame\n",
    "        Dataframe containing the predictor variables and outcome.\n",
    "    x_one : Dict[str, str]\n",
    "        Dictionary with label as key and column name of the first predictor variable in the dataframe as value.\n",
    "    x_two : Dict[str, str]\n",
    "        Dictionary with label as key and column name of the second predictor variable in the dataframe as value.\n",
    "    outcome : Dict[str, str]\n",
    "        Dictionary with label as key and column name of the outcome variable in the dataframe as value.\n",
    "    results : GLMResults\n",
    "        Fitted model used for making predictions.\n",
    "    legend_labels : List[str], optional\n",
    "        Labels to be used in the legend. Default is None.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract column names from the dictionaries\n",
    "    x_one_label, x_one_col = list(x_one.keys())[0], list(x_one.values())[0]\n",
    "    x_two_label, x_two_col = list(x_two.keys())[0], list(x_two.values())[0]\n",
    "    outcome_label, outcome_col = list(outcome.keys())[0], list(outcome.values())[0]\n",
    "    \n",
    "    # Calculate p-value using permutation test\n",
    "    p_value = permutation_test_for_interaction(data_df, x_one_col, x_two_col, outcome_col, results, x_values=x_values)\n",
    "     \n",
    "    # Calculate mean and standard deviation for x_two\n",
    "    x_two_mean = data_df[x_two_col].mean()\n",
    "    x_two_std = data_df[x_two_col].std()\n",
    "    \n",
    "    # Create arrays for x_two at -2 and +2 standard deviations from the mean\n",
    "    x_two_minus_2sd = 57 #x_two_mean - 2 * x_two_std\n",
    "    x_two_plus_2sd = 68 #x_two_mean + 2 * x_two_std\n",
    "    \n",
    "    # Create DataFrames for prediction\n",
    "    X_pred_minus_2sd = pd.DataFrame({\n",
    "        x_one_col: data_df[x_one_col],\n",
    "        x_two_col: np.ones_like(data_df[x_one_col]) * x_two_minus_2sd\n",
    "    })\n",
    "    \n",
    "    X_pred_plus_2sd = pd.DataFrame({\n",
    "        x_one_col: data_df[x_one_col],\n",
    "        x_two_col: np.ones_like(data_df[x_one_col]) * x_two_plus_2sd\n",
    "    })\n",
    "    \n",
    "    # Generate predictions\n",
    "    y_pred_minus_2sd = results.predict(X_pred_minus_2sd)\n",
    "    y_pred_plus_2sd = results.predict(X_pred_plus_2sd)\n",
    "    \n",
    "    # Create the plot\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    \n",
    "    # Generate predictions (this part could be refactored)\n",
    "    if x_values is None:\n",
    "        X_pred_minus_2sd = pd.DataFrame({\n",
    "            x_one_col: data_df[x_one_col],\n",
    "            x_two_col: np.ones_like(data_df[x_one_col]) * (data_df[x_two_col].mean() - 2 * data_df[x_two_col].std())\n",
    "        })\n",
    "        X_pred_plus_2sd = pd.DataFrame({\n",
    "            x_one_col: data_df[x_one_col],\n",
    "            x_two_col: np.ones_like(data_df[x_one_col]) * (data_df[x_two_col].mean() + 2 * data_df[x_two_col].std())\n",
    "        })\n",
    "    else:\n",
    "        X_pred_minus_2sd = pd.DataFrame({\n",
    "            x_one_col: data_df[x_one_col],\n",
    "            x_two_col: np.ones_like(data_df[x_one_col]) * x_values[0]\n",
    "        })\n",
    "        X_pred_plus_2sd = pd.DataFrame({\n",
    "            x_one_col: data_df[x_one_col],\n",
    "            x_two_col: np.ones_like(data_df[x_one_col]) * x_values[1]\n",
    "        })\n",
    "        \n",
    "    y_pred_minus_2sd = results.predict(X_pred_minus_2sd)\n",
    "    y_pred_plus_2sd = results.predict(X_pred_plus_2sd)\n",
    "    \n",
    "    # Plotting\n",
    "    plt.plot(data_df[x_one_col], y_pred_minus_2sd, label=legend_labels[0] if legend_labels else f\"{x_two_label} at -2 SD\", color='blue')\n",
    "    plt.plot(data_df[x_one_col], y_pred_plus_2sd, label=legend_labels[1] if legend_labels else f\"{x_two_label} at +2 SD\", color='red')\n",
    "    \n",
    "    plt.xlabel(x_one_label)\n",
    "    plt.ylabel(outcome_label)\n",
    "    legend = plt.legend(frameon=False)\n",
    "    \n",
    "    # Add p-value to the title\n",
    "    plt.title(f\"p-value: {p_value:.4f}\")\n",
    "    \n",
    "    # Despine the plot\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    \n",
    "    plt.show()\n",
    "    return fig\n",
    "# The function can be used like this:\n",
    "# p_value = permutation_test_for_interaction(data_df, {'X1 Label': 'x1_col'}, {'X2 Label': 'x2_col'}, {'Outcome Label': 'outcome_col'}, results)\n",
    "# Then, the p-value can be set as the title in the plot function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter a list here which has the 2 values to assess the interaction of. \n",
    "If you do not have 2 values in mind, replace the list with None. \n",
    "Then, I will assess at +/- stdevs for you, which is common in generating interaction plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_to_test = [57, 69.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = create_2D_interaction_plot(data_df.copy(), \n",
    "                                 x_one={'Subiculum_Connectivity_T': 'Subiculum_Connectivity_T'}, \n",
    "                                 x_two={'Age': 'Age'}, \n",
    "                                 outcome={'% Improvement UPDRS-1': 'Percent_Cognitive_Improvement'}, \n",
    "                                 results=results,\n",
    "                                 x_values=values_to_test,\n",
    "                                 legend_labels=['57', '75'])\n",
    "save_fig(fig, out_dir)\n",
    "print('Saved to: ', out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Significance Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def permute_outcome_and_get_proportions_fixed(data_df, \n",
    "                                              x_one, x_one_under_mean, x_one_over_mean, x_one_split_point,\n",
    "                                              x_two, x_two_under_mean, x_two_over_mean, x_two_split_point,\n",
    "                                              response, binarize=True):\n",
    "    \"\"\"\n",
    "    Function to perform permutation testing on the outcome and compute the proportion of permuted means \n",
    "    greater than observed means for both x_one and x_two.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_df : pandas.DataFrame\n",
    "        The dataframe containing the data.\n",
    "    x_one, x_two : str\n",
    "        Column names of the two factors.\n",
    "    x_one_under_mean, x_two_under_mean : str\n",
    "        Labels to be used when the values of x_one and x_two are under the mean, respectively.\n",
    "    x_one_over_mean, x_two_over_mean : str\n",
    "        Labels to be used when the values of x_one and x_two are over the mean, respectively.\n",
    "    x_one_split_point, x_two_split_point: int\n",
    "        Value to split the data of x by.\n",
    "    response : str\n",
    "        Column name of the outcome variable.\n",
    "    binarize : bool\n",
    "        Whether to convert x_one and x_two into binary variables.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        Proportion of permuted means greater than observed mean for x_one and x_two.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Copy the data\n",
    "    df_copy = data_df.copy()\n",
    "    \n",
    "    # Binarize the variables to get observed values\n",
    "    if binarize:\n",
    "        if x_two_split_point is not None:\n",
    "            df_copy[x_two] = np.where(df_copy[x_two] <= x_two_split_point, 0, 1)\n",
    "        else:\n",
    "            df_copy[x_two] = np.where(df_copy[x_two] <= df_copy[x_two].mean(), 0, 1)\n",
    "        \n",
    "        if x_one_split_point is not None:\n",
    "            df_copy[x_one] = np.where(df_copy[x_one] <= x_one_split_point, 0, 1)\n",
    "        else:\n",
    "            df_copy[x_one] = np.where(df_copy[x_one] <= df_copy[x_one].mean(), 0, 1)\n",
    "    \n",
    "    #Observed Values between within a level of x_one across levels of x_two\n",
    "    delta_x_one_low = df_copy[response][(df_copy[x_one]==0) & (df_copy[x_two]==0)].mean() - df_copy[response][(df_copy[x_one]==0) & (df_copy[x_two]==1)].mean()\n",
    "    delta_x_one_high = df_copy[response][(df_copy[x_one]==1) & (df_copy[x_two]==0)].mean() - df_copy[response][(df_copy[x_one]==1) & (df_copy[x_two]==1)].mean()    \n",
    "    #Empiric Values\n",
    "    delta_x_one_low_list = []\n",
    "    delta_x_one_high_list = []\n",
    "    \n",
    "    #Observed Values between within a level of x_two across levels of x_one\n",
    "    delta_x_two_low = df_copy[response][(df_copy[x_two]==0) & (df_copy[x_one]==0)].mean() - df_copy[response][(df_copy[x_two]==0) & (df_copy[x_one]==1)].mean()\n",
    "    delta_x_two_high = df_copy[response][(df_copy[x_two]==1) & (df_copy[x_one]==0)].mean() - df_copy[response][(df_copy[x_two]==1) & (df_copy[x_one]==1)].mean()    \n",
    "    #Empiric Values\n",
    "    delta_x_two_low_list = []\n",
    "    delta_x_two_high_list = []\n",
    "    \n",
    "    \n",
    "    # Permute outcome and calculate means\n",
    "    for _ in tqdm(range(10000)):\n",
    "        permuted_data = data_df.copy()\n",
    "        permuted_data[response] = np.random.permutation(permuted_data[response].values)\n",
    "        \n",
    "            # Binarize the variables to get observed values\n",
    "        if binarize:\n",
    "            if x_two_split_point is not None:\n",
    "                permuted_data[x_two] = np.where(permuted_data[x_two] <= x_two_split_point, 0, 1)\n",
    "            else:\n",
    "                permuted_data[x_two] = np.where(permuted_data[x_two] <= permuted_data[x_two].mean(), 0, 1)\n",
    "            \n",
    "            if x_one_split_point is not None:\n",
    "                permuted_data[x_one] = np.where(permuted_data[x_one] <= x_one_split_point, 0, 1)\n",
    "            else:\n",
    "                permuted_data[x_one] = np.where(permuted_data[x_one] <= permuted_data[x_one].mean(), 0, 1)\n",
    "        \n",
    "        #Observed Values\n",
    "        delta_x_one_low_list.append(permuted_data[response][(permuted_data[x_one]==0) & (permuted_data[x_two]==0)].mean() - permuted_data[response][(permuted_data[x_one]==0) & (permuted_data[x_two]==1)].mean())\n",
    "        delta_x_one_high_list.append(permuted_data[response][(permuted_data[x_one]==1) & (permuted_data[x_two]==0)].mean() - permuted_data[response][(permuted_data[x_one]==1) & (permuted_data[x_two]==1)].mean())\n",
    "        delta_x_two_low_list.append(permuted_data[response][(permuted_data[x_two]==0) & (permuted_data[x_one]==0)].mean() - permuted_data[response][(permuted_data[x_two]==0) & (permuted_data[x_one]==1)].mean())\n",
    "        delta_x_two_high_list.append(permuted_data[response][(permuted_data[x_two]==1) & (permuted_data[x_one]==0)].mean() - permuted_data[response][(permuted_data[x_two]==1) & (permuted_data[x_one]==1)].mean())\n",
    "        \n",
    "    \n",
    "    x_one_proportion_level1 = np.mean(np.array(delta_x_one_low_list) > delta_x_one_low)\n",
    "    x_one_proportion_level2 = np.mean(np.array(delta_x_one_high_list) > delta_x_one_high)\n",
    "    x_two_proportion_level1 = np.mean(np.array(delta_x_two_low_list) > delta_x_two_low)\n",
    "    x_two_proportion_level2 = np.mean(np.array(delta_x_two_high_list) > delta_x_two_high)\n",
    "    \n",
    "    return x_one_proportion_level1, x_one_proportion_level2, x_two_proportion_level1, x_two_proportion_level2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the fixed function\n",
    "x_one='Age'; x_one_low_label='Young'; x_one_high_label='Old'\n",
    "x_one_split_point=63\n",
    "\n",
    "x_two='Subiculum_Connectivity'; x_two_low_label='Low Connectivity'; x_two_high_label='High Connectivity'\n",
    "x_two_split_point=66\n",
    "\n",
    "response='outcome'\n",
    "#----------------------------------------------------------------\n",
    "x_one_proportion_level1, x_one_proportion_level2, x_two_proportion_level1, x_two_proportion_level2 = permute_outcome_and_get_proportions_fixed(data_df.copy(), \n",
    "                 x_one=x_one, x_one_under_mean=x_one_low_label, x_one_over_mean=x_one_high_label, x_one_split_point=x_one_split_point,\n",
    "                 x_two=x_two, x_two_under_mean=x_two_low_label, x_two_over_mean=x_two_high_label, x_two_split_point=x_two_split_point,\n",
    "                 response=response)\n",
    "\n",
    "print(f'Significance of {x_one} between levels of {x_two} is: {x_one_proportion_level1} at the {x_one_low_label} {x_one} and {x_one_proportion_level2} at the {x_one_high_label} {x_one}')\n",
    "print(f'Significance of {x_two} between levels of {x_one} is: {x_two_proportion_level1} at the {x_two_low_label} {x_two} and {x_two_proportion_level2} at the {x_two_high_label} {x_two}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use response plane to visualize interaction effect\n",
    "- This models the marginal distribution of variables\n",
    "- If the model has 2 predictors and 1 response, then choose option A\n",
    "- If the model has more than 2 predictors, then choose option B. You will need to manually vary across the additional predictors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 variable method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.genmod.generalized_linear_model import GLMResults\n",
    "\n",
    "def plot_residuals(ax, data_df, x_one, x_two, outcome, results):\n",
    "    \"\"\"\n",
    "    Plots actual data points and residuals on the 3D plot.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ax : matplotlib 3D axis\n",
    "        The 3D axis object to plot on.\n",
    "    data_df : pd.DataFrame\n",
    "        Dataframe containing the predictor variables and outcome.\n",
    "    x_one : str\n",
    "        Column name of the first predictor variable in the dataframe.\n",
    "    x_two : str\n",
    "        Column name of the second predictor variable in the dataframe.\n",
    "    outcome : str\n",
    "        Column name of the outcome variable in the dataframe.\n",
    "    results : GLMResults\n",
    "        Fitted model used for making predictions.\n",
    "    \"\"\"\n",
    "    # Plot actual data points\n",
    "    ax.scatter(data_df[x_one], data_df[x_two], data_df[outcome], color='red', s=50)\n",
    "\n",
    "    # Calculate predicted values and plot residuals\n",
    "    for _, row in data_df.iterrows():\n",
    "        x1_val, x2_val, y_val = row[x_one], row[x_two], row[outcome]\n",
    "        y_pred_val = results.predict(pd.DataFrame({x_one: [x1_val], x_two: [x2_val]}))\n",
    "        ax.plot([x1_val, x1_val], [x2_val, x2_val], [y_val, y_pred_val], color='blue', linestyle='dashed', linewidth=1)\n",
    "\n",
    "def create_interaction_plot(data_df: pd.DataFrame,\n",
    "                            x_one: str,\n",
    "                            x_two: str,\n",
    "                            outcome: str,\n",
    "                            results: GLMResults,\n",
    "                            num_slices: int = 100,\n",
    "                            out_dir: str = './',\n",
    "                            labels: dict = None,\n",
    "                            residuals=False) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Creates a 3D plot visualizing the interaction of two predictor variables on the outcome.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_df : pd.DataFrame\n",
    "        Dataframe containing the predictor variables and outcome.\n",
    "    x_one : str\n",
    "        Column name of the first predictor variable in the dataframe.\n",
    "    x_two : str\n",
    "        Column name of the second predictor variable in the dataframe.\n",
    "    outcome : str\n",
    "        Column name of the outcome variable in the dataframe.\n",
    "    results : GLMResults\n",
    "        Fitted model used for making predictions.\n",
    "    num_slices : int, optional\n",
    "        Number of slices to create in the 3D grid, default is 100.\n",
    "    out_dir : str, optional\n",
    "        Directory to save the output PNG and SVG files, default is the current directory.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    plt.Figure\n",
    "        The created figure.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create grid of predictor variable values\n",
    "    x1 = np.linspace(min(data_df[x_one]), max(data_df[x_one]), num_slices)\n",
    "    x2 = np.linspace(min(data_df[x_two]), max(data_df[x_two]), num_slices)\n",
    "    x1v, x2v = np.meshgrid(x1, x2)\n",
    "\n",
    "    # Set plot style\n",
    "    sns.set_style('white')\n",
    "    sns.set_palette('Greys', 1, desat=1)\n",
    "\n",
    "    # Flattening the matrices to create a DataFrame for prediction\n",
    "    X_grid = pd.DataFrame({\n",
    "        x_one: x1v.ravel(),\n",
    "        x_two: x2v.ravel(),\n",
    "    })\n",
    "\n",
    "    # Generate response values for grid\n",
    "    y_pred = results.predict(X_grid).values.reshape(num_slices, num_slices)\n",
    "\n",
    "    # Create a new figure for plotting\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Plot the surface\n",
    "    ax.plot_surface(x1v, x2v, y_pred, cmap='Greys', alpha=1.0)\n",
    "    \n",
    "    if residuals:\n",
    "        plot_residuals(ax, data_df, x_one, x_two, outcome, results)\n",
    "\n",
    "    # Set the axes labels\n",
    "    format_label = lambda x: ' '.join(word.capitalize() for word in x.split('_'))\n",
    "    # Set the axes labels\n",
    "    if labels is not None:\n",
    "        ax.set_xlabel(labels.get('x', format_label(x_one)))\n",
    "        ax.set_ylabel(labels.get('y', format_label(x_two)))\n",
    "        ax.set_zlabel(labels.get('z', format_label(outcome)))\n",
    "    else:\n",
    "        ax.set_xlabel(format_label(x_one))\n",
    "        ax.set_ylabel(format_label(x_two))\n",
    "        ax.set_zlabel(format_label(outcome))\n",
    "\n",
    "    # Save the plot as PNG and SVG files\n",
    "    fig.savefig(os.path.join(out_dir, '2_variable.png'), dpi=300)\n",
    "    fig.savefig(os.path.join(out_dir, '2_variable.svg'), format='svg')\n",
    "    print('Saved to file', out_dir)\n",
    "\n",
    "    return fig, y_pred, np.meshgrid(x1, x2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'Age'\n",
    "y = 'Subiculum_Connectivity_T'\n",
    "z = 'Percent_Cognitive_Improvement'\n",
    "#----------------------------------------------------------------DO NOT TOUCH THIS!----------------------------------------------------------------\n",
    "fig, y_pred, X_grid = create_interaction_plot(data_df, \n",
    "                        x_one=x, \n",
    "                        x_two=y, \n",
    "                        outcome=z, \n",
    "                        results=results, \n",
    "                        out_dir=out_dir, \n",
    "                        labels={'x': x, 'y': y, 'z': z});"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 Variable Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import imageio\n",
    "import os\n",
    "from statsmodels.genmod.generalized_linear_model import GLMResults\n",
    "from typing import List\n",
    "from matplotlib import colors\n",
    "\n",
    "def create_interaction_gifs(data_df: pd.DataFrame, \n",
    "                            x_one: str, \n",
    "                            x_two: str, \n",
    "                            x_three: str, \n",
    "                            outcome: str, \n",
    "                            results: GLMResults, \n",
    "                            num_slices: int = 100,\n",
    "                            gif_duration: float = 0.3) -> List[str]:\n",
    "    \"\"\"\n",
    "    Creates gifs visualizing the interaction of predictor variables on the outcome.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_df : pd.DataFrame\n",
    "        Dataframe containing the predictor variables and outcome.\n",
    "    x_one : str\n",
    "        Column name of the first predictor variable in the dataframe.\n",
    "    x_two : str\n",
    "        Column name of the second predictor variable in the dataframe.\n",
    "    x_three : str\n",
    "        Column name of the third predictor variable in the dataframe.\n",
    "    outcome : str\n",
    "        Column name of the outcome variable in the dataframe.\n",
    "    results : GLMResults\n",
    "        Fitted model used for making predictions.\n",
    "    num_slices : int, optional\n",
    "        Number of slices to create in the gifs, default is 100.\n",
    "    gif_duration : float, optional\n",
    "        Duration of each frame in the gif in seconds, default is 0.3.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    List[str]\n",
    "        List of file paths to the created gif files.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if x_three is binary\n",
    "    unique_values = data_df[x_three].unique()\n",
    "    is_binary = len(unique_values) == 2\n",
    "\n",
    "    # Create grid of predictor variable values\n",
    "    x1 = np.linspace(min(data_df[x_one]), max(data_df[x_one]), num_slices)\n",
    "    x2 = np.linspace(min(data_df[x_two]), max(data_df[x_two]), num_slices)\n",
    "    \n",
    "    # Set plot style\n",
    "    sns.set_style('white')\n",
    "    sns.set_palette('Greys', 1, desat=1)\n",
    "\n",
    "    gif_paths = []\n",
    "\n",
    "    if is_binary:\n",
    "        for x_three_value in unique_values:\n",
    "            # Flattening the matrices to create a DataFrame for prediction\n",
    "            X_grid = pd.DataFrame({\n",
    "                x_one: np.tile(x1, len(x2)),\n",
    "                x_two: np.repeat(x2, len(x1)),\n",
    "                x_three: np.ones_like(np.tile(x1, len(x2))) * x_three_value\n",
    "            })\n",
    "\n",
    "            # Generate response values for grid\n",
    "            y_pred = results.predict(X_grid).values.reshape(len(x2), len(x1))\n",
    "\n",
    "            # Create a new figure for plotting\n",
    "            fig = plt.figure(figsize=(10, 7))\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "            # Plot the surface\n",
    "            ax.plot_surface(np.tile(x1, (len(x2), 1)), np.repeat(x2[:, np.newaxis], len(x1), axis=1), y_pred, cmap='bwr', alpha=0.8)\n",
    "\n",
    "            # Set the axes labels\n",
    "            format_label = lambda x: ' '.join(word.capitalize() for word in x.split('_'))\n",
    "            ax.set_xlabel(format_label(x_one))\n",
    "            ax.set_ylabel(format_label(x_two))\n",
    "            ax.set_zlabel(format_label(outcome))\n",
    "\n",
    "            # Set the title with the actual value of x_three\n",
    "            title = f'{x_three} = {x_three_value}'\n",
    "            ax.set_title(title)\n",
    "\n",
    "            # Save the plot as an image file\n",
    "            image_path = f'plot_{x_three}_{x_three_value}.png'\n",
    "            plt.savefig(image_path, dpi=300)\n",
    "            gif_paths.append(image_path)\n",
    "            plt.close()\n",
    "    else:\n",
    "        # Flattening the matrices to create a DataFrame for prediction\n",
    "        x3 = np.linspace(min(data_df[x_three]), max(data_df[x_three]), num_slices)\n",
    "        x1v, x2v, x3v = np.meshgrid(x1, x2, x3)\n",
    "\n",
    "        X_grid = pd.DataFrame({\n",
    "            x_one: x1v.ravel(),\n",
    "            x_two: x2v.ravel(),\n",
    "            x_three: x3v.ravel(),\n",
    "        })\n",
    "\n",
    "        # Generate response values for grid\n",
    "        y_pred = results.predict(X_grid).values.reshape(num_slices, num_slices, num_slices)\n",
    "\n",
    "        # Collect the file paths of images\n",
    "        image_paths = []\n",
    "\n",
    "        # Iterating over x3 (third predictor variable) and saving each plot as an image\n",
    "        for i in range(num_slices):\n",
    "            x3_slice = np.linspace(min(data_df[x_three]), max(data_df[x_three]), num_slices)[i]\n",
    "\n",
    "            # Create a new figure for plotting\n",
    "            fig = plt.figure(figsize=(10, 7))\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "            # Plot the surface\n",
    "            norm = colors.TwoSlopeNorm(vcenter=0)\n",
    "            ax.plot_surface(x1v[:, :, i], x2v[:, :, i], y_pred[:, :, i], cmap='Greys', alpha=0.8, norm=norm)\n",
    "\n",
    "            # Set the axes labels\n",
    "            format_label = lambda x: ' '.join(word.capitalize() for word in x.split('_'))\n",
    "            ax.set_xlabel(format_label(x_one))\n",
    "            ax.set_ylabel(format_label(x_two))\n",
    "            ax.set_zlabel(format_label(outcome))\n",
    "\n",
    "            # Set the title with the actual value of x_three\n",
    "            title = f'{x_three} = {x3_slice:.2f}'\n",
    "            ax.set_title(title)\n",
    "\n",
    "            # Save the plot as an image file\n",
    "            image_path = f'plot_slice_{i+1}.png'\n",
    "            plt.savefig(image_path, dpi=300)\n",
    "            image_paths.append(image_path)\n",
    "            plt.close()\n",
    "\n",
    "        # Create a gif from the image files\n",
    "        gif_path = f'plots.gif'\n",
    "        images = [imageio.imread(image_path) for image_path in image_paths]\n",
    "        imageio.mimsave(gif_path, images, duration=gif_duration)\n",
    "        gif_paths.append(gif_path)\n",
    "\n",
    "        # Remove the individual image files\n",
    "        for image_path in image_paths:\n",
    "            os.remove(image_path)\n",
    "\n",
    "    return gif_paths\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# gifs = create_interaction_gifs(data_df, 'x_one', 'x_two', 'x_three', 'outcome', results)\n",
    "# print(\"GIFs created:\", gifs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_one = 'Subiculum_Connectivity'\n",
    "x_two = 'Age' \n",
    "x_three = 'Anticorrelated_Memory_Atrophy'\n",
    "outcome = 'cognitive_improvement'\n",
    "#----------------------------------------------------------------DO NOT TOUCH----------------------------------------------------------------\n",
    "gifs = create_interaction_gifs(data_df, \n",
    "                               x_one, \n",
    "                               x_two, \n",
    "                               x_three, \n",
    "                               outcome, \n",
    "                               results)\n",
    "print(\"GIFs created:\", gifs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 Variable Method\n",
    "- 4th variable is expected to be 1-hot encoded here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import imageio\n",
    "import os\n",
    "from statsmodels.genmod.generalized_linear_model import GLMResults\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def create_interaction_gifs(data_df: pd.DataFrame, \n",
    "                            x_one: str, \n",
    "                            x_two: str, \n",
    "                            x_three: str, \n",
    "                            x_four: str, \n",
    "                            x_four_dict: dict,\n",
    "                            outcome: str, \n",
    "                            results: GLMResults, \n",
    "                            num_slices: int = 100,\n",
    "                            gif_duration: float = 0.3) -> List[str]:\n",
    "    \"\"\"\n",
    "    Creates gifs visualizing the interaction of predictor variables on the outcome,\n",
    "    and the effect of a one-hot encoded variable (x_four).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_df : pd.DataFrame\n",
    "        Dataframe containing the predictor variables and outcome.\n",
    "    x_one : str\n",
    "        Column name of the first predictor variable in the dataframe.\n",
    "    x_two : str\n",
    "        Column name of the second predictor variable in the dataframe.\n",
    "    x_three : str\n",
    "        Column name of the third predictor variable in the dataframe.\n",
    "    x_four : str\n",
    "        Column name of the one-hot encoded predictor variable (values should be 0 or 1) in the dataframe.\n",
    "    x_four_list : list\n",
    "        List of the x_four variables corresponding to their one hot encoded outcomes.\n",
    "    outcome : str\n",
    "        Column name of the outcome variable in the dataframe.\n",
    "    results : GLMResults\n",
    "        Fitted model used for making predictions.\n",
    "    num_slices : int, optional\n",
    "        Number of slices to create in the gifs, default is 100.\n",
    "    gif_duration : float, optional\n",
    "        Duration of each frame in the gif in seconds, default is 0.3.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    List[str]\n",
    "        List of file paths to the created gif files.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set plot style\n",
    "    sns.set_style('white')\n",
    "    sns.set_palette('Greys', 1, desat=1)\n",
    "\n",
    "    gif_paths = []\n",
    "\n",
    "    # Iterate over x_four values 0 and 1\n",
    "    for x_four_value in [0, 1]:\n",
    "        distribution_df = data_df.copy()\n",
    "        distribution_df = distribution_df[distribution_df['Disease'] == x_four_value]\n",
    "        # Create grid of predictor variable values\n",
    "        x1 = np.linspace(min(distribution_df[x_one]), max(distribution_df[x_one]), num_slices)\n",
    "        x2 = np.linspace(min(distribution_df[x_two]), max(distribution_df[x_two]), num_slices)\n",
    "        x3 = np.linspace(min(distribution_df[x_three]), max(distribution_df[x_three]), num_slices)\n",
    "        x1v, x2v, x3v = np.meshgrid(x1, x2, x3)\n",
    "        \n",
    "        # Flattening the matrices to create a DataFrame for prediction\n",
    "        X_grid = pd.DataFrame({\n",
    "            x_one: x1v.ravel(),\n",
    "            x_two: x2v.ravel(),\n",
    "            x_three: x3v.ravel(),\n",
    "            x_four: np.ones_like(x1v).ravel() * x_four_value\n",
    "        })\n",
    "\n",
    "        # Generate response values for grid\n",
    "        y_pred = results.predict(X_grid).values.reshape(num_slices, num_slices, num_slices)\n",
    "\n",
    "        # Collect the file paths of images\n",
    "        image_paths = []\n",
    "\n",
    "        # Iterating over x3 (third predictor variable) and saving each plot as an image\n",
    "        for i in range(num_slices):\n",
    "            x3_slice = np.linspace(min(data_df[x_three]), max(data_df[x_three]), num_slices)[i]\n",
    "            \n",
    "            # Create a new figure for plotting\n",
    "            fig = plt.figure(figsize=(10, 7))\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "            # Plot the surface\n",
    "            ax.plot_surface(x1v[:, :, i], x2v[:, :, i], y_pred[:, :, i], cmap='bwr', alpha=0.8)\n",
    "\n",
    "            # Set the axes labels\n",
    "            format_label = lambda x: ' '.join(word.capitalize() for word in x.split('_'))\n",
    "            ax.set_xlabel(format_label(x_one))\n",
    "            ax.set_ylabel(format_label(x_two))\n",
    "            ax.set_zlabel(format_label(outcome))\n",
    "            \n",
    "            # Set the title with the actual value of x_three and x_four\n",
    "            title = f'{x_four_dict[x_four_value]}, {x_three} = {x3_slice:.2f}'\n",
    "            ax.set_title(title)\n",
    "\n",
    "            # Save the plot as an image file\n",
    "            image_path = f'plot_{x_four}_{x_four_dict[x_four_value]}_slice_{i+1}.png'\n",
    "            plt.savefig(image_path, dpi=300)\n",
    "            image_paths.append(image_path)\n",
    "            plt.close()\n",
    "\n",
    "        # Create a gif from the image files\n",
    "        gif_path = f'{x_four}_{x_four_dict[x_four_value]}_plots.gif'\n",
    "        images = [imageio.imread(image_path) for image_path in image_paths]\n",
    "        imageio.mimsave(gif_path, images, duration=gif_duration)\n",
    "        gif_paths.append(gif_path)\n",
    "\n",
    "        # Remove the individual image files\n",
    "        for image_path in image_paths:\n",
    "            os.remove(image_path)\n",
    "\n",
    "    return gif_paths\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# gifs = create_interaction_gifs(data_df, 'Subiculum_Connectivity', 'Subiculum_Grey_Matter', 'Age', 'Disease', 'outcome', results)\n",
    "# print(\"GIFs created:\", gifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_one = 'Subiculum_Connectivity'\n",
    "x_two = 'Subiculum_Grey_Matter' \n",
    "x_three = 'Age'\n",
    "x_four = 'Disease'\n",
    "x_four_dict = {1: \"Alzheimer's\", 0: \"Parkinson's\"}\n",
    "outcome = 'cognitive_improvement'\n",
    "#----------------------------------------------------------------DO NOT TOUCH----------------------------------------------------------------\n",
    "gifs = create_interaction_gifs(data_df, \n",
    "                               x_one, \n",
    "                               x_two, \n",
    "                               x_three, \n",
    "                               x_four,\n",
    "                               x_four_dict,\n",
    "                               outcome, \n",
    "                               results)\n",
    "print(\"GIFs created:\", gifs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 Variable Method\n",
    "- This is identical to the 4 variable method, but takes the 5th variable \n",
    "and calculates is at -2 and +2 standard deviations, then plots a response plane for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import imageio\n",
    "import os\n",
    "from statsmodels.genmod.generalized_linear_model import GLMResults\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def create_interaction_gifs_with_5_variables(data_df: pd.DataFrame, \n",
    "                                             x_one: str, \n",
    "                                             x_two: str, \n",
    "                                             x_three: str, \n",
    "                                             x_four: str, \n",
    "                                             x_four_dict: dict,\n",
    "                                             x_five: str,\n",
    "                                             x_five_factor_levels: int,\n",
    "                                             outcome: str, \n",
    "                                             results: GLMResults, \n",
    "                                             num_slices: int = 100,\n",
    "                                             gif_duration: float = 0.3) -> List[str]:\n",
    "    \n",
    "    # Create grid of predictor variable values\n",
    "    x1 = np.linspace(min(data_df[x_one]), max(data_df[x_one]), num_slices)\n",
    "    x2 = np.linspace(min(data_df[x_two]), max(data_df[x_two]), num_slices)\n",
    "    x3 = np.linspace(min(data_df[x_three]), max(data_df[x_three]), num_slices)\n",
    "    x1v, x2v, x3v = np.meshgrid(x1, x2, x3)\n",
    "\n",
    "    # Set plot style\n",
    "    sns.set_style('white')\n",
    "    sns.set_palette('Greys', 1, desat=1)\n",
    "\n",
    "    gif_paths = []\n",
    "\n",
    "    # Iterate over x_four values 0 and 1\n",
    "    for x_four_value in [0, 1]:\n",
    "        \n",
    "        # Collect the file paths of images\n",
    "        image_paths = []\n",
    "\n",
    "        # Iterating over x3 (third predictor variable) and saving each plot as an image\n",
    "        for i in range(num_slices):\n",
    "            x3_slice = np.linspace(min(data_df[x_three]), max(data_df[x_three]), num_slices)[i]\n",
    "            \n",
    "            # Create a new figure for plotting\n",
    "            fig = plt.figure(figsize=(10, 7))\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "            # Choose to use x_five mean\n",
    "            x_five_mean = data_df[x_five].mean()\n",
    "            x_five_std = data_df[x_five].std()\n",
    "            if x_five_factor_levels == 1:\n",
    "                x_five_level = [x_five_mean]\n",
    "            # Choose to use x_five +/- 2 standard deviations\n",
    "            else:\n",
    "                x_five_level = [x_five_mean-(2*x_five_std), x_five_mean+(2*x_five_std)]\n",
    "            for level in range(0, len(x_five_level)):\n",
    "                \n",
    "                # Flattening the matrices to create a DataFrame for prediction\n",
    "                X_grid = pd.DataFrame({\n",
    "                    x_one: x1v.ravel(),\n",
    "                    x_two: x2v.ravel(),\n",
    "                    x_three: x3v.ravel(),\n",
    "                    x_four: np.ones_like(x1v).ravel() * x_four_value,\n",
    "                    x_five: np.ones_like(x1v).ravel() * x_five_level[level]\n",
    "                })\n",
    "\n",
    "                # Generate response values for grid\n",
    "                y_pred = results.predict(X_grid).values.reshape(num_slices, num_slices, num_slices)\n",
    "                \n",
    "                # Plot the surface\n",
    "                cmap = 'viridis' if x_five_level[level] == data_df[x_five].mean() else ('cool' if x_five_level[level] < 0 else 'magma')\n",
    "                ax.plot_surface(x1v[:, :, i], x2v[:, :, i], y_pred[:, :, i], cmap=cmap, alpha=0.5)\n",
    "\n",
    "            # Set the axes labels\n",
    "            format_label = lambda x: ' '.join(word.capitalize() for word in x.split('_'))\n",
    "            ax.set_xlabel(format_label(x_one))\n",
    "            ax.set_ylabel(format_label(x_two))\n",
    "            ax.set_zlabel(format_label(outcome))\n",
    "            \n",
    "            # Set the title with the actual value of x_three and x_four\n",
    "            title = f'{x_four_dict[x_four_value]}, {x_three} = {x3_slice:.2f}'\n",
    "            ax.set_title(title)\n",
    "\n",
    "            # Save the plot as an image file\n",
    "            image_path = f'plot_{x_four}_{x_four_dict[x_four_value]}_slice_{i+1}.png'\n",
    "            plt.savefig(image_path, dpi=300)\n",
    "            image_paths.append(image_path)\n",
    "            plt.close()\n",
    "\n",
    "        # Create a gif from the image files\n",
    "        gif_path = f'{x_four}_{x_four_dict[x_four_value]}_plots.gif'\n",
    "        images = [imageio.imread(image_path) for image_path in image_paths]\n",
    "        imageio.mimsave(gif_path, images, duration=gif_duration)\n",
    "        gif_paths.append(gif_path)\n",
    "\n",
    "        # Remove the individual image files\n",
    "        for image_path in image_paths:\n",
    "            os.remove(image_path)\n",
    "\n",
    "    return gif_paths\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_one = 'Subiculum_Connectivity'\n",
    "x_two = 'Subiculum_Grey_Matter' \n",
    "x_three = 'Age'\n",
    "x_four = 'Disease'\n",
    "x_four_dict = {1: \"Alzheimer's\", 0: \"Parkinson's\"}\n",
    "x_five = 'Subiculum_CSF'\n",
    "x_five_factor_levels = 1\n",
    "outcome = 'cognitive_improvement'\n",
    "#----------------------------------------------------------------DO NOT TOUCH----------------------------------------------------------------\n",
    "gifs = create_interaction_gifs_with_5_variables(data_df, \n",
    "                               x_one, \n",
    "                               x_two, \n",
    "                               x_three, \n",
    "                               x_four,\n",
    "                               x_four_dict,\n",
    "                               x_five,\n",
    "                               x_five_factor_levels,\n",
    "                               outcome, \n",
    "                               results)\n",
    "print(\"GIFs created:\", gifs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Inflection Point of Joint Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Local Maxima/Minima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "class SaddlePointFinderMaxMin:\n",
    "    \"\"\"\n",
    "    A class to identify saddle points in a 2D array using local maxima and minima method.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Initialize the class with the 2D array to be analyzed.\n",
    "\n",
    "        Parameters:\n",
    "        data (np.ndarray): 2D array for which the saddle points are to be identified.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        \n",
    "    def find_local_minima_maxima(self, array):\n",
    "        \"\"\"\n",
    "        Find local minima and maxima in a 1D array.\n",
    "        \n",
    "        Parameters:\n",
    "        array (np.ndarray): 1D data array\n",
    "        \n",
    "        Returns:\n",
    "        tuple: Indices of local minima and maxima in the array.\n",
    "        \"\"\"\n",
    "        local_minima = argrelextrema(array, np.less)[0]\n",
    "        local_maxima = argrelextrema(array, np.greater)[0]\n",
    "        return local_minima, local_maxima\n",
    "    \n",
    "    def find_critical_points(self):\n",
    "        \"\"\"\n",
    "        Identify the saddle points in the 2D array using local maxima and minima method.\n",
    "\n",
    "        Returns:\n",
    "        list: List of coordinates (as tuples) of the identified saddle points.\n",
    "        \"\"\"\n",
    "        row_minima_coords = []\n",
    "        row_maxima_coords = []\n",
    "        for i, row in enumerate(self.data):\n",
    "            local_minima, local_maxima = self.find_local_minima_maxima(row)\n",
    "            for coord in local_minima:\n",
    "                row_minima_coords.append((i, coord))\n",
    "            for coord in local_maxima:\n",
    "                row_maxima_coords.append((i, coord))\n",
    "                \n",
    "        col_minima_coords = []\n",
    "        col_maxima_coords = []\n",
    "        for i, col in enumerate(self.data.T):\n",
    "            local_minima, local_maxima = self.find_local_minima_maxima(col)\n",
    "            for coord in local_minima:\n",
    "                col_minima_coords.append((coord, i))\n",
    "            for coord in local_maxima:\n",
    "                col_maxima_coords.append((coord, i))\n",
    "        \n",
    "        saddle_points = list(set(row_minima_coords).intersection(col_maxima_coords) | set(row_maxima_coords).intersection(col_minima_coords))\n",
    "        \n",
    "        return saddle_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the class with the given data\n",
    "finder = SaddlePointFinderMaxMin(y_pred)\n",
    "finder.find_critical_points()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import argrelextrema\n",
    "from matplotlib import colors \n",
    "\n",
    "class GradientCriticalPointFinder:\n",
    "    \"\"\"\n",
    "    A class to identify and visualize the approximate critical points in a 2D array using gradient-based methods.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_array, out_dir=None):\n",
    "        \"\"\"\n",
    "        Initialize the GradientCriticalPointFinder with the 2D array to be analyzed.\n",
    "\n",
    "        Parameters:\n",
    "        data_array (np.ndarray): 2D array for which the critical points are to be identified.\n",
    "        \"\"\"\n",
    "        self.data_array = data_array\n",
    "        self.gradient_x = None\n",
    "        self.gradient_y = None\n",
    "        self.combined_gradient_abs = None\n",
    "        self.critical_points = None\n",
    "        self.out_dir = out_dir\n",
    "\n",
    "    def _compute_gradients(self):\n",
    "        \"\"\"\n",
    "        Computes the gradients for each dimension of the data array.\n",
    "        \"\"\"\n",
    "        self.gradient_x = np.gradient(self.data_array, axis=0)\n",
    "        self.gradient_y = np.gradient(self.data_array, axis=1)\n",
    "        combined_gradient = self.gradient_x * self.gradient_y\n",
    "        self.combined_gradient_abs = np.abs(combined_gradient)\n",
    "\n",
    "    def set_indices_to_one(self, zero_array, row_indices, col_indices):\n",
    "        for r, c in zip(row_indices, col_indices):\n",
    "            zero_array[r, c] = 1\n",
    "        return zero_array\n",
    "    \n",
    "    def _identify_critical_points(self, use_absolute_minima=False):\n",
    "        \"\"\"\n",
    "        Identify the approximate critical points by finding intersections between the minima of gradient_x and gradient_y.\n",
    "        \"\"\"\n",
    "        gradient_x_min = np.zeros_like(self.gradient_x)\n",
    "        gradient_y_min = np.zeros_like(self.gradient_y)\n",
    "\n",
    "        if use_absolute_minima:\n",
    "            # Find the index of the global minimum in each column for gradient_x\n",
    "            for i in range(0, self.gradient_x.shape[0]):\n",
    "                gradient_x_min[i, :] = np.where(self.gradient_x[i,:] == np.min(self.gradient_x[i,:]), 1, 0)\n",
    "                \n",
    "            # Find the index of the global minimum in each row for gradient_y\n",
    "            for i in range(0, self.gradient_y.shape[1]):\n",
    "                gradient_y_min[:, i] = np.where(self.gradient_y[:,i] == np.min(self.gradient_y[:,i]), 1, 0)\n",
    "\n",
    "        # Find coincident hits\n",
    "        critical_points_array = gradient_x_min * gradient_y_min\n",
    "        \n",
    "        # At the end of the method:\n",
    "        rows, cols = np.where(critical_points_array == 1)\n",
    "        self.critical_points = (rows, cols)\n",
    "        print('Critical points found at rows:', self.critical_points[0], 'cols:', self.critical_points[1])\n",
    "\n",
    "\n",
    "    def plot(self, use_absolute_minima=False):\n",
    "        \"\"\"\n",
    "        Generate the required plots.\n",
    "        \"\"\"\n",
    "        # Ensure gradients are computed\n",
    "        if self.gradient_x is None or self.gradient_y is None:\n",
    "            self._compute_gradients()\n",
    "\n",
    "        # Identify critical points\n",
    "        self._identify_critical_points(use_absolute_minima)\n",
    "\n",
    "        self.fig, axes = plt.subplots(1, 4, figsize=(24, 6))\n",
    "        norm = colors.TwoSlopeNorm(vcenter=0)\n",
    "    \n",
    "        # Plot gradients with the norm applied\n",
    "        cax1 = axes[0].imshow(self.gradient_x, cmap='bwr', origin='lower', norm=norm)\n",
    "        axes[0].set_title(\"Gradient X\")\n",
    "        plt.colorbar(cax1, ax=axes[0], orientation='vertical')\n",
    "\n",
    "        cax2 = axes[1].imshow(self.gradient_y, cmap='bwr', origin='lower', norm=norm)\n",
    "        axes[1].set_title(\"Gradient Y\")\n",
    "        plt.colorbar(cax2, ax=axes[1], orientation='vertical')\n",
    "\n",
    "        # Plot absolute value of the multiplied gradients\n",
    "        cax3 = axes[2].imshow(self.combined_gradient_abs, cmap='bwr', origin='lower', norm=norm)\n",
    "        axes[2].set_title(\"Abs(Gradient X * Gradient Y)\")\n",
    "        plt.colorbar(cax3, ax=axes[2], orientation='vertical')\n",
    "        \n",
    "        # Plot data_array with critical points and the norm applied\n",
    "        cax4 = axes[3].imshow(self.data_array, cmap='bwr', origin='lower', norm=norm)\n",
    "        if len(self.critical_points[0]) > 0:\n",
    "            axes[3].scatter(self.critical_points[1], self.critical_points[0], color='black', marker='X', label='Critical Point')\n",
    "        axes[3].set_title(\"Function with Critical Points\")\n",
    "        plt.colorbar(cax4, ax=axes[3], orientation='vertical')\n",
    "\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "            \n",
    "    def get_critical_points(self):\n",
    "        \"\"\"\n",
    "        Return the coordinates of the identified critical points.\n",
    "        \"\"\"\n",
    "        return self.critical_points\n",
    "    \n",
    "    def save_figure(self):\n",
    "        \"\"\"\n",
    "        Save the figure stored in self.figure to a file.\n",
    "\n",
    "        Parameters:\n",
    "        filename (str): The name of the file to save the figure as (e.g., 'figure.png').\n",
    "        \"\"\"\n",
    "        if self.out_dir is not None:\n",
    "            # Save the plot as PNG and SVG files\n",
    "            self.fig.savefig(os.path.join(out_dir, 'gradient.png'), dpi=300)\n",
    "            self.fig.savefig(os.path.join(out_dir, 'gradient.svg'), format='svg')\n",
    "            print('Saved to file', out_dir)\n",
    "            \n",
    "    def run(self):\n",
    "        '''\n",
    "        Run method.\n",
    "        '''\n",
    "        self.plot(use_absolute_minima=True)\n",
    "        self.get_critical_points()\n",
    "        self.save_figure()\n",
    "        \n",
    "    \n",
    "finder = GradientCriticalPointFinder(y_pred, out_dir=out_dir).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import argrelextrema\n",
    "\n",
    "class GradientCriticalPointFinder:\n",
    "    \"\"\"\n",
    "    A class to identify and visualize the approximate critical points in a 2D array using gradient-based methods.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_array):\n",
    "        \"\"\"\n",
    "        Initialize the GradientCriticalPointFinder with the 2D array to be analyzed.\n",
    "\n",
    "        Parameters:\n",
    "        data_array (np.ndarray): 2D array for which the critical points are to be identified.\n",
    "        \"\"\"\n",
    "        self.data_array = data_array\n",
    "        self.gradient_x = None\n",
    "        self.gradient_y = None\n",
    "        self.combined_gradient_abs = None\n",
    "        self.critical_points = None\n",
    "\n",
    "    def _compute_gradients(self):\n",
    "        \"\"\"\n",
    "        Computes the gradients for each dimension of the data array.\n",
    "        \"\"\"\n",
    "        self.gradient_x = np.gradient(self.data_array, axis=0)\n",
    "        self.gradient_y = np.gradient(self.data_array, axis=1)\n",
    "\n",
    "    def _identify_critical_points(self):\n",
    "        \"\"\"\n",
    "        Identify the approximate critical points using element-wise multiplication and rounding.\n",
    "        \"\"\"\n",
    "        combined_gradient = self.gradient_x * self.gradient_y\n",
    "        self.combined_gradient_abs = np.abs(combined_gradient)\n",
    "        \n",
    "        # Find local minima\n",
    "        local_minima = argrelextrema(self.combined_gradient_abs, np.less)\n",
    "        self.critical_points = local_minima\n",
    "\n",
    "    def plot(self):\n",
    "        \"\"\"\n",
    "        Generate the required plots.\n",
    "        \"\"\"\n",
    "        # Ensure gradients are computed\n",
    "        if self.gradient_x is None or self.gradient_y is None:\n",
    "            self._compute_gradients()\n",
    "\n",
    "        # Identify critical points\n",
    "        if self.critical_points is None:\n",
    "            self._identify_critical_points()\n",
    "\n",
    "        fig, axes = plt.subplots(1, 4, figsize=(24, 6))\n",
    "        norm = colors.TwoSlopeNorm(vcenter=0)\n",
    "    \n",
    "        # Plot gradients with the norm applied\n",
    "        cax1 = axes[0].imshow(self.gradient_x, cmap='bwr', origin='lower', norm=norm)\n",
    "        axes[0].set_title(\"Gradient X\")\n",
    "        plt.colorbar(cax1, ax=axes[0], orientation='vertical')\n",
    "\n",
    "        cax2 = axes[1].imshow(self.gradient_y, cmap='bwr', origin='lower', norm=norm)\n",
    "        axes[1].set_title(\"Gradient Y\")\n",
    "        plt.colorbar(cax2, ax=axes[1], orientation='vertical')\n",
    "\n",
    "        # Plot absolute value of the multiplied gradients\n",
    "        cax3 = axes[2].imshow(self.combined_gradient_abs, cmap='bwr', origin='lower', norm=norm)\n",
    "        axes[2].set_title(\"Abs(Gradient X * Gradient Y)\")\n",
    "        plt.colorbar(cax3, ax=axes[2], orientation='vertical')\n",
    "        \n",
    "        # Plot data_array with critical points and the norm applied\n",
    "        cax4 = axes[3].imshow(self.data_array, cmap='bwr', origin='lower', norm=norm)\n",
    "        axes[3].scatter(self.critical_points[1], self.critical_points[0], color='black', marker='X', label='Critical Point')\n",
    "        axes[3].set_title(\"Function with Critical Points\")\n",
    "        plt.colorbar(cax4, ax=axes[3], orientation='vertical')\n",
    "\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def get_critical_points(self):\n",
    "        \"\"\"\n",
    "        Return the coordinates of the identified critical points.\n",
    "        \"\"\"\n",
    "        if self.critical_points is None:\n",
    "            self._identify_critical_points()\n",
    "        \n",
    "        return self.critical_points\n",
    "finder = GradientCriticalPointFinder(y_pred)\n",
    "finder.plot()\n",
    "finder.get_critical_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_Grid[0] corresponds to the x-axis, and this derives the value of it at the gradient min.\n",
    "#In your experiements, this is generally age. \n",
    "print(X_grid[0][42, 58]) #<---row is the 0 value in gradient y, col is the 0 value in gradient x\n",
    "#X_Grid[1] corresponds to the z-axis, and this derives the value of it at the gradient min\n",
    "print(X_grid[1][42, 58])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Hessian discriminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HessianSaddlePointFinder:\n",
    "    \"\"\"\n",
    "    A class to identify the saddle points in a 2D array.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, y_pred):\n",
    "        \"\"\"\n",
    "        Initialize the SaddlePointFinder with the 2D array to be analyzed.\n",
    "\n",
    "        Parameters:\n",
    "        y_pred (np.ndarray): 2D array for which the saddle points are to be identified.\n",
    "        \"\"\"\n",
    "        self.y_pred = y_pred\n",
    "\n",
    "    def _compute_derivatives(self):\n",
    "        \"\"\"\n",
    "        Computes the first order partial derivatives with respect to both dimensions.\n",
    "\n",
    "        Returns:\n",
    "        tuple: First order partial derivatives with respect to x and y dimensions.\n",
    "        \"\"\"\n",
    "        dy_d1 = np.gradient(self.y_pred, axis=0)\n",
    "        dy_d2 = np.gradient(self.y_pred, axis=1)\n",
    "        \n",
    "        return dy_d1, dy_d2\n",
    "\n",
    "    def _compute_second_mixed_derivatives(self):\n",
    "        \"\"\"\n",
    "        Computes the second order partial derivatives and both mixed partial derivatives.\n",
    "\n",
    "        Returns:\n",
    "        tuple: Second order partial derivatives with respect to x and y dimensions, and both mixed partial derivatives.\n",
    "        \"\"\"\n",
    "        dy_d1, dy_d2 = self._compute_derivatives()\n",
    "        \n",
    "        # Second order partial derivative with respect to x dimension (rows)\n",
    "        d2y_d1_2 = np.gradient(dy_d1, axis=0)\n",
    "        \n",
    "        # Second order partial derivative with respect to y dimension (columns)\n",
    "        d2y_d2_2 = np.gradient(dy_d2, axis=1)\n",
    "        \n",
    "        # Mixed partial derivatives\n",
    "        d2y_d1d2 = np.gradient(dy_d1, axis=1)\n",
    "        d2y_d2d1 = np.gradient(dy_d2, axis=0)\n",
    "        \n",
    "        return d2y_d1_2, d2y_d2_2, d2y_d1d2, d2y_d2d1\n",
    "\n",
    "    def find_saddle_points(self):\n",
    "        \"\"\"\n",
    "        Identify the saddle points in the 2D array.\n",
    "\n",
    "        Returns:\n",
    "        tuple: Coordinates of the saddle point or (None, None) if no saddle point exists.\n",
    "        \"\"\"\n",
    "        second_deriv_1, second_deriv_2, mixed_deriv_1, mixed_deriv_2 = self._compute_second_mixed_derivatives()\n",
    "        \n",
    "        # Check equivalence of mixed partial derivatives\n",
    "        if not np.allclose(mixed_deriv_1, mixed_deriv_2):\n",
    "            return \"Error: Mixed partial derivatives are not equivalent.\"\n",
    "        \n",
    "        # Calculate D\n",
    "        D = second_deriv_1 * second_deriv_2 - mixed_deriv_1**2\n",
    "        \n",
    "        # Identify saddle points\n",
    "        saddle_points = np.where(D < 0)\n",
    "        \n",
    "        print('Saddle points found at coordinates:')\n",
    "        print(np.min(D))\n",
    "        if saddle_points[0].size == 0:\n",
    "            return None, None\n",
    "        else:\n",
    "            return saddle_points[0][0], saddle_points[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test proof of saddle point idenfitication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test the final class with the sample_array\n",
    "z = np.linspace(0,10,100)\n",
    "x = z \n",
    "\n",
    "# Create the grid of coordinates\n",
    "xv, zv = np.meshgrid(x,z)\n",
    "\n",
    "# Calculate y at every coordinate set\n",
    "sample_array = xv**2 - zv**2\n",
    "\n",
    "# Identify the single saddle point, which should be at 0,0\n",
    "saddle_finder_final = SaddlePointFinderFinal(sample_array)\n",
    "saddle_coordinates_final = saddle_finder_final.find_saddle_points()\n",
    "saddle_coordinates_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Saddle Point of Your Array of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saddle_finder_final = SaddlePointFinderFinal(y_pred)\n",
    "saddle_coordinates_final = saddle_finder_final.find_saddle_points()\n",
    "saddle_coordinates_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[saddle_coordinates_final[0], saddle_coordinates_final[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape\n",
    "from numpy import savetxt\n",
    "import os\n",
    "savetxt(os.path.join(out_dir,'y_pred.csv'), y_pred, delimiter=',')\n",
    "print('saved to: ', os.path.join(out_dir,'y_pred.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_grid.to_numpy().shape\n",
    "\n",
    "print(X_grid.to_numpy()[saddle_coordinates_final[0], 0])\n",
    "print(X_grid.to_numpy()[saddle_coordinates_final[1], 1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Within Joint Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "def compute_statistics_and_create_dataframe(resampled_metrics, observed_metric, test_type, test_tails='two_tailed'):\n",
    "    \"\"\"\n",
    "    Compute p-value and confidence interval and organize them in a DataFrame.\n",
    "    \n",
    "    :param resampled_metrics: List of metrics computed from the resampled or permuted data\n",
    "    :param observed_metric: Observed metric computed from the original data\n",
    "    :param comparison_method: Method for comparing responses ('correlation' or 'point_testing')\n",
    "    :param test_type: Type of test performed ('resampling' or 'permutation')\n",
    "    :param test_tails: Type of tail for p-value testing ('two_tailed', 'right_tailed', or 'left_tailed')\n",
    "    :return: DataFrame with p-value and confidence interval\n",
    "    \"\"\"\n",
    "    # Calculate p-value and confidence interval for low and high values\n",
    "    if test_type =='permutation':\n",
    "        if test_tails == 'two_tailed':\n",
    "            print('Two-tailed p-value testing')\n",
    "            p_value_low = np.mean(np.abs([x[0] for x in resampled_metrics]) >= np.abs(observed_metric[0]))\n",
    "            p_value_high = np.mean(np.abs([x[1] for x in resampled_metrics]) >= np.abs(observed_metric[1]))\n",
    "        elif test_tails == 'right_tailed':\n",
    "            print('Right-tailed p-value testing')\n",
    "            p_value_low = np.mean([x[0] for x in resampled_metrics] >= observed_metric[0])\n",
    "            p_value_high = np.mean([x[1] for x in resampled_metrics] >= observed_metric[1])\n",
    "        elif test_tails == 'left_tailed':\n",
    "            print('Left-tailed p-value testing.')\n",
    "            p_value_low = np.mean([x[0] for x in resampled_metrics] <= observed_metric[0])\n",
    "            p_value_high = np.mean([x[1] for x in resampled_metrics] <= observed_metric[1])\n",
    "        else:\n",
    "            raise ValueError(\"Invalid value for test_tails. Must be one of 'two_tailed', 'right_tailed', or 'left_tailed'.\")\n",
    "    elif test_type == 'resampling':\n",
    "        p_value_low = np.mean(np.sign(np.mean([x[0] for x in resampled_metrics])) != np.sign(observed_metric[0]))\n",
    "        p_value_high = np.mean(np.sign(np.mean([x[1] for x in resampled_metrics])) != np.sign(observed_metric[1]))\n",
    "    else:\n",
    "        raise ValueError(f\"Test type is not supported: {test_type}\")\n",
    "    \n",
    "    conf_int_low = np.percentile([x[0] for x in resampled_metrics], [2.5, 97.5])\n",
    "    conf_int_high = np.percentile([x[1] for x in resampled_metrics], [2.5, 97.5])\n",
    "\n",
    "    # Create DataFrame\n",
    "    data = {\n",
    "        'Observed Metric': [observed_metric[0], observed_metric[1]],\n",
    "        'P-value': [p_value_low, p_value_high],\n",
    "        '95% CI Lower': [conf_int_low[0], conf_int_high[0]],\n",
    "        '95% CI Upper': [conf_int_low[1], conf_int_high[1]]\n",
    "    }\n",
    "    index = ['Delta Y pred indep_var_2 +/- stdev holding indep_var_1 at -2stdev', \n",
    "                'Delta Y pred indep_var_2 +/- stdev holding indep_var_1 at +2stdev']\n",
    "\n",
    "    return pd.DataFrame(data, index=[index])\n",
    "\n",
    "\n",
    "def compare_responses(df, dependent_var, independent_var1, independent_var2, interaction=True):\n",
    "    \"\"\"\n",
    "    Compare responses of a dataset using point testing method.\n",
    "    \n",
    "    :param df: DataFrame containing the dataset\n",
    "    :param dependent_var: Name of the dependent variable\n",
    "    :param independent_var1: Name of the first independent variable\n",
    "    :param independent_var2: Name of the second independent variable\n",
    "    :param interaction: Boolean indicating if interaction between independent variables should be considered\n",
    "    :param test_tails: Type of tail for p-value testing ('two_tailed', 'right_tailed', or 'left_tailed')\n",
    "    :return: Comparison metric (absolute differences between low and high points)\n",
    "    \"\"\"\n",
    "    if interaction:\n",
    "        formula = f'{dependent_var} ~ {independent_var1} * {independent_var2}'\n",
    "    else:\n",
    "        formula = f'{dependent_var} ~ {independent_var1} + {independent_var2}'\n",
    "\n",
    "    # Fit the model\n",
    "    model = smf.ols(formula=formula, data=df).fit()\n",
    "\n",
    "    # Evaluate at specific points\n",
    "    diff_low, diff_high = evaluate_at_specific_points(df, independent_var1, independent_var2, model)\n",
    "\n",
    "    # Return the absolute differences\n",
    "    return abs(diff_low), abs(diff_high)\n",
    "\n",
    "def evaluate_at_specific_points(df, independent_var1, independent_var2, model):\n",
    "    \"\"\"\n",
    "    Evaluate the model at specific points.\n",
    "    \n",
    "    :param df: DataFrame containing the dataset\n",
    "    :param independent_var1: Name of the first independent variable\n",
    "    :param independent_var2: Name of the second independent variable\n",
    "    :param model: Fitted model\n",
    "    :return: Differences between low and high points\n",
    "    \"\"\"\n",
    "    # Determine the low and high values of the independent variables\n",
    "    iv1_sd = data_df[independent_var1].std()\n",
    "    iv2_sd = data_df[independent_var2].std()\n",
    "    iv1_mean = data_df[independent_var1].mean()\n",
    "    iv2_mean = data_df[independent_var2].mean()\n",
    "\n",
    "    # Create the dataframes for low_1 and high_1 predictions\n",
    "    low_1_df = pd.DataFrame({\n",
    "        independent_var1: iv1_mean - 2 * iv1_sd,\n",
    "        independent_var2: [iv2_mean - 2 * iv2_sd, iv2_mean + 2 * iv2_sd]\n",
    "    })\n",
    "\n",
    "    high_1_df = pd.DataFrame({\n",
    "        independent_var1: iv1_mean + 2 * iv1_sd,\n",
    "        independent_var2: [iv2_mean - 2 * iv2_sd, iv2_mean + 2 * iv2_sd]\n",
    "    })\n",
    "\n",
    "    # Perform the predictions on the dataframes\n",
    "    low_1_predictions = model.predict(low_1_df)\n",
    "    high_1_predictions = model.predict(high_1_df)\n",
    "\n",
    "    # Calculate the differences between the predictions\n",
    "    difference_low = low_1_predictions[1] - low_1_predictions[0]\n",
    "    difference_high = high_1_predictions[1] - high_1_predictions[0]\n",
    "\n",
    "    return difference_low, difference_high\n",
    "\n",
    "def resample_or_permutation_test(df, dependent_var, independent_var1, independent_var2, interaction=True, num_resamples=1000, test_type='permutation', test_tails='two_tails'):\n",
    "    \"\"\"\n",
    "    Perform resampling or permutation test to compare responses of two datasets and return results in a DataFrame.\n",
    "    \n",
    "    :param df: DataFrame containing the dataset\n",
    "    :param dependent_var: Name of the dependent variable\n",
    "    :param independent_var1: Name of the first independent variable\n",
    "    :param independent_var2: Name of the second independent variable\n",
    "    :param interaction: Boolean indicating if interaction between independent variables should be considered\n",
    "    :param comparison_method: Method for comparing responses ('correlation' or 'point_testing')\n",
    "    :param num_slices: Number of values to take for each variable to form the grid (used in correlation)\n",
    "    :param num_resamples: Number of resamples to perform\n",
    "    :param test_type: Type of test to perform ('resampling' or 'permutation')\n",
    "    :return: p-value and confidence interval\n",
    "    \"\"\"\n",
    "    # Calculate observed metric\n",
    "    observed_metric = compare_responses(df, dependent_var, independent_var1, independent_var2, interaction)\n",
    "    \n",
    "    # Initialize results\n",
    "    resampled_metrics = []\n",
    "\n",
    "    for i in tqdm(range(num_resamples)):\n",
    "        # Perform resampling or permutation\n",
    "        if test_type == 'resampling':\n",
    "            sample_df = df.sample(frac=1, replace=True)\n",
    "        elif test_type == 'permutation':\n",
    "            sample_df = df.copy()\n",
    "            sample_df[dependent_var] = np.random.permutation(sample_df[dependent_var].values)\n",
    "        else:\n",
    "            raise ValueError(\"test_type must be either 'resampling' or 'permutation'.\")\n",
    "        \n",
    "        # Calculate resampled metric\n",
    "        resampled_metric = compare_responses(sample_df, dependent_var, independent_var1, independent_var2, interaction)\n",
    "        resampled_metrics.append(resampled_metric)\n",
    "    \n",
    "    # Calculate statistics and create DataFrame\n",
    "    results_dataframe = compute_statistics_and_create_dataframe(resampled_metrics, observed_metric, test_type, test_tails=test_tails)\n",
    "    \n",
    "    return results_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define dataframe 1 and dataframe 2 for comaprison by permutation test\n",
    "df_1 = data_df[data_df['City'] == 'Boston']\n",
    "df_2 = data_df[data_df['City'] == 'Toronto']\n",
    "dependent_var = 'Z_Scored_Percent_Cognitive_Improvement'\n",
    "independent_var1 = 'Age'\n",
    "independent_var2 = 'Z_Scored_Subiculum_Connectivity_T'\n",
    "enable_interaction = True\n",
    "num_iterations = 10000\n",
    "test_tails = 'two_tailed'\n",
    "#:param test_tails: Type of tail for p-value testing ('two_tailed', 'right_tailed', or 'left_tailed')\n",
    "#----------------------------------------------------------------DO NOT TOUCH----------------------------------------------------------------\n",
    "permutation_results = resample_or_permutation_test(df = df_1,\n",
    "                                                    dependent_var = dependent_var,\n",
    "                                                    independent_var1 = independent_var1,\n",
    "                                                    independent_var2 = independent_var2,\n",
    "                                                    interaction = enable_interaction,\n",
    "                                                    num_resamples=num_iterations, \n",
    "                                                    test_type='permutation',\n",
    "                                                    test_tails=test_tails)\n",
    "permutation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------DO NOT TOUCH----------------------------------------------------------------\n",
    "bootstrap_results = resample_or_permutation_test(df = df_2,\n",
    "                                                    dependent_var = dependent_var,\n",
    "                                                    independent_var1 = independent_var1,\n",
    "                                                    independent_var2 = independent_var2,\n",
    "                                                    interaction = enable_interaction,\n",
    "                                                    num_resamples=num_iterations, \n",
    "                                                    test_type='resampling')\n",
    "bootstrap_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Between Joint Distributions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparison of 2 Joint Distributions**\n",
    "1) Joint Distributions and Multiple Regression:\n",
    "\n",
    "The concept of \"joint distributions\" refers to the combined distribution of multiple variables, taking into account their mutual relationships. In the context of multiple regression analysis, we utilize a statistical model to examine the joint distribution of the independent variables and their relationship with the dependent variable. By fitting a regression model, such as the one used in this code, we can investigate how the independent variables collectively influence the dependent variable.\n",
    "\n",
    "In the provided code, we compare the responses of two datasets based on their joint distributions. This means that we analyze the relationship between the independent variables (independent_var1 and independent_var2) as a pair and their collective influence on the dependent variable. We fit separate regression models for each dataset, considering both independent variables as predictors and the dependent variable as the response.\n",
    "\n",
    "Analyzing the joint distributions allows us to gain insights into how the independent variables interact with each other and jointly impact the dependent variable. By considering the joint relationship between the variables, we can understand how changes in one independent variable may affect the response when the other independent variable is also taken into account.\n",
    "\n",
    "2) Permutation vs Bootstrap:\n",
    "\n",
    "The code employs two different approaches for hypothesis testing: permutation testing and bootstrap resampling. Both methods aim to assess the significance of the observed metrics by generating alternative datasets.\n",
    "\n",
    "Permutation testing involves randomly permuting the values of the dependent variable while keeping the independent variables unchanged. This process breaks the relationship between the dependent and independent variables, creating new datasets under the assumption of no association. By comparing the observed metric with metrics obtained from the permuted datasets, we can estimate p-values and confidence intervals, providing a measure of the statistical significance of our results. A permuted dataset is one wherein the independent variables are unrelated to the dependent variable. They are the null distribution. \n",
    "\n",
    "Bootstrap resampling, on the other hand, involves randomly sampling data points from the original datasets with replacement. This resampling process allows us to create multiple datasets of the same size as the original datasets. By generating new datasets through resampling, we can examine the distribution of the metrics of interest and estimate their variability. This information can be used to estimate confidence intervals and assess the statistical significance of our findings. A bootstrap resampling process creates alternative datasets wherein the independent variables are still related to the dependent variable. These define significance by demonstrating the confidence intervals of the dataset do not cross a threshold, which is typically 0.\n",
    "\n",
    "3) Correlation vs Point-test:\n",
    "\n",
    "The code provides two different methods for comparing responses based on the joint distributions: correlation and point testing.\n",
    "\n",
    "The correlation analysis aims to assess the spatial correlation between the joint distributions of the two datasets. This analysis examines the overall patterns and similarities in the responses across the range of the joint distributions. By calculating the correlation coefficient between the predicted responses, we can determine if there is a consistent relationship between the joint distributions of the independent variables and the dependent variable across the datasets. Then, we compare this to bootstrapped or permuted datasets to derive significance estimates.\n",
    "\n",
    "In contrast, point testing focuses on evaluating the differences in the predicted responses at specific points of the joint distributions. Specifically, we examine the differences at +/- 2 standard deviations of the independent variables. This analysis allows us to determine if the differences between the responses at these specific points significantly vary between the two datasets. By comparing the differences in response values at these critical points, we can identify regions of the joint distributions where the relationship between the independent variables and the dependent variable differs significantly. The purpose of this is to condense a 3-dimensional joint distribution into 2-dimensions at set values which is good for generating figures. Then, we compare this to bootstrapped or permuted datasets to derive significance estimates.\n",
    "\n",
    "In summary, comparing the joint distributions enables us to analyze the combined effects of the independent variables on the dependent variable. The correlation and point testing methods offer different perspectives on the relationship between the variables, while permutation testing and bootstrap resampling provide means to assess the statistical significance of our findings.\n",
    "\n",
    "**Instructions**\n",
    "Testing: 'correlation' or 'point_testing'\n",
    "Significance Testing: 'permutation' or 'resampling'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "def compute_statistics_and_create_dataframe(resampled_metrics, observed_metric, comparison_method, test_type, test_tails='right_tailed'):\n",
    "    \"\"\"\n",
    "    Compute p-value and confidence interval and organize them in a DataFrame.\n",
    "    \n",
    "    :param resampled_metrics: List of metrics computed from the resampled or permuted data\n",
    "    :param observed_metric: Observed metric computed from the original data\n",
    "    :param comparison_method: Method for comparing responses ('correlation' or 'point_testing')\n",
    "    :return: DataFrame with p-value and confidence interval\n",
    "    \"\"\"\n",
    "    if comparison_method == 'correlation':\n",
    "        if test_tails == 'right_tailed':\n",
    "            p_value = np.mean((resampled_metrics) >= (observed_metric))\n",
    "        if test_tails == 'left_tailed':\n",
    "            p_value = np.mean((resampled_metrics) <= (observed_metric))\n",
    "        if test_tails == 'two_tailed':\n",
    "            p_value = np.mean(np.abs(resampled_metrics) >= np.abs(observed_metric))\n",
    "        conf_int = np.percentile(resampled_metrics, [2.5, 97.5])\n",
    "\n",
    "        # Create DataFrame\n",
    "        data = {\n",
    "            'Observed Metric': [observed_metric],\n",
    "            'P-value': [p_value],\n",
    "            '95% CI Lower': [conf_int[0]],\n",
    "            '95% CI Upper': [conf_int[1]]\n",
    "        }\n",
    "        index = 'Spatial correlation of the joint distributions'\n",
    "    \n",
    "    elif comparison_method == 'point_testing':\n",
    "        # Calculate p-value and confidence interval for low and high values\n",
    "        if test_type =='permutation':\n",
    "            if test_tails == 'two_tailed':\n",
    "                print('Two-tailed p-value testing')\n",
    "                p_value_low = np.mean(np.abs([x[0] for x in resampled_metrics]) >= np.abs(observed_metric[0]))\n",
    "                p_value_high = np.mean(np.abs([x[1] for x in resampled_metrics]) >= np.abs(observed_metric[1]))\n",
    "            elif test_tails == 'right_tailed':\n",
    "                print('Right-tailed p-value testing')\n",
    "                p_value_low = np.mean([x[0] for x in resampled_metrics] >= observed_metric[0])\n",
    "                p_value_high = np.mean([x[1] for x in resampled_metrics] >= observed_metric[1])\n",
    "            elif test_tails == 'left_tailed':\n",
    "                print('Left-tailed p-value testing.')\n",
    "                p_value_low = np.mean([x[0] for x in resampled_metrics] <= observed_metric[0])\n",
    "                p_value_high = np.mean([x[1] for x in resampled_metrics] <= observed_metric[1])\n",
    "            else:\n",
    "                raise ValueError(\"Invalid value for test_tails. Must be one of 'two_tailed', 'right_tailed', or 'left_tailed'.\")\n",
    "        elif test_type == 'resampling':\n",
    "            p_value_low = np.mean(np.sign(np.mean([x[0] for x in resampled_metrics])) != (np.sign(np.mean([x[0] for x in resampled_metrics]))))\n",
    "            p_value_high = np.mean(np.sign(np.mean([x[1] for x in resampled_metrics])) != (np.sign(np.mean([x[1] for x in resampled_metrics]))))\n",
    "        else:\n",
    "            raise ValueError (f'Test type is not supported {test_type}')\n",
    "        conf_int_low = np.percentile(resampled_metrics[0], [2.5, 97.5])\n",
    "        conf_int_high = np.percentile(resampled_metrics[1], [2.5, 97.5])\n",
    "\n",
    "        # Create DataFrame\n",
    "        data = {\n",
    "            'Observed Metric': [observed_metric[0], observed_metric[1]],\n",
    "            'P-value': [p_value_low, p_value_high],\n",
    "            '95% CI Lower': [conf_int_low[0], conf_int_high[0]],\n",
    "            '95% CI Upper': [conf_int_low[1], conf_int_high[1]]\n",
    "        }\n",
    "        index = ['Delta Y pred indep_var_2 +/- stdev holding indep_var_1 at -2stdev', \n",
    "                 'Delta Y pred indep_var_2 +/- stdev holding indep_var_1 at +2stdev']\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"comparison_method must be either 'correlation' or 'point_testing'.\")\n",
    "\n",
    "    return pd.DataFrame(data, index=[index])\n",
    "\n",
    "\n",
    "def calculate_predicted_response(data_df, independent_var1, independent_var2, model, num_slices=100):\n",
    "    \"\"\"\n",
    "    Calculate predicted response values for a grid of values of two independent variables.\n",
    "    \n",
    "    :param data_df: DataFrame containing data\n",
    "    :param independent_var1: Name of the first independent variable\n",
    "    :param independent_var2: Name of the second independent variable\n",
    "    :param model: Fitted model\n",
    "    :param num_slices: Number of values to take for each variable to form the grid\n",
    "    :return: Flattened array of predicted responses\n",
    "    \"\"\"\n",
    "    x1 = np.linspace(min(data_df[independent_var1]), max(data_df[independent_var1]), num_slices)\n",
    "    x2 = np.linspace(min(data_df[independent_var2]), max(data_df[independent_var2]), num_slices)\n",
    "    x1v, x2v = np.meshgrid(x1, x2)\n",
    "\n",
    "    X_grid = pd.DataFrame({\n",
    "        independent_var1: x1v.ravel(),\n",
    "        independent_var2: x2v.ravel(),\n",
    "    })\n",
    "\n",
    "    y_pred = model.predict(X_grid).values.reshape(num_slices, num_slices)\n",
    "\n",
    "    return y_pred.ravel()\n",
    "\n",
    "def evaluate_at_specific_points(data_df, independent_var1, independent_var2, model):\n",
    "    \"\"\"\n",
    "    Evaluate the model at specific points: +/- 2 standard deviations of the independent variables.\n",
    "\n",
    "    :param data_df: DataFrame containing data\n",
    "    :param independent_var1: Name of the first independent variable\n",
    "    :param independent_var2: Name of the second independent variable\n",
    "    :param model: Fitted model\n",
    "    :return: Differences between the predictions at specific points\n",
    "    \"\"\"\n",
    "    iv1_sd = data_df[independent_var1].std()\n",
    "    iv2_sd = data_df[independent_var2].std()\n",
    "    iv1_mean = data_df[independent_var1].mean()\n",
    "    iv2_mean = data_df[independent_var2].mean()\n",
    "\n",
    "    # Create the dataframes for low_1 and high_1 predictions\n",
    "    low_1_df = pd.DataFrame({\n",
    "        independent_var1: iv1_mean - 2 * iv1_sd,\n",
    "        independent_var2: [iv2_mean - 2 * iv2_sd, iv2_mean + 2 * iv2_sd]\n",
    "    })\n",
    "\n",
    "    high_1_df = pd.DataFrame({\n",
    "        independent_var1: iv1_mean + 2 * iv1_sd,\n",
    "        independent_var2: [iv2_mean - 2 * iv2_sd, iv2_mean + 2 * iv2_sd]\n",
    "    })\n",
    "\n",
    "    # Perform the predictions on the dataframes\n",
    "    low_1_predictions = model.predict(low_1_df)\n",
    "    high_1_predictions = model.predict(high_1_df)\n",
    "\n",
    "    # Calculate the differences between the predictions\n",
    "    difference_low = low_1_predictions[1] - low_1_predictions[0]\n",
    "    difference_high = high_1_predictions[1] - high_1_predictions[0]\n",
    "\n",
    "    return difference_low, difference_high\n",
    "\n",
    "def compare_responses(df1, df2, dependent_var, independent_var1, independent_var2, interaction=True, comparison_method='correlation', num_slices=100):\n",
    "    \"\"\"\n",
    "    Compare responses of two datasets using correlation or point testing method.\n",
    "    \n",
    "    :param df1: DataFrame containing first dataset\n",
    "    :param df2: DataFrame containing second dataset\n",
    "    :param dependent_var: Name of the dependent variable\n",
    "    :param independent_var1: Name of the first independent variable\n",
    "    :param independent_var2: Name of the second independent variable\n",
    "    :param interaction: Boolean indicating if interaction between independent variables should be considered\n",
    "    :param comparison_method: Method for comparing responses ('correlation' or 'point_testing')\n",
    "    :param num_slices: Number of values to take for each variable to form the grid (used in correlation)\n",
    "    :return: Comparison metric\n",
    "    \"\"\"\n",
    "    if interaction:\n",
    "        formula = f'{dependent_var} ~ {independent_var1} * {independent_var2}'\n",
    "    else:\n",
    "        formula = f'{dependent_var} ~ {independent_var1} + {independent_var2}'\n",
    "\n",
    "    # Fit the models\n",
    "    model1 = smf.ols(formula=formula, data=df1).fit()\n",
    "    model2 = smf.ols(formula=formula, data=df2).fit()\n",
    "\n",
    "    if comparison_method == 'correlation':\n",
    "        # Calculate predicted responses\n",
    "        response_1 = calculate_predicted_response(df1, independent_var1, independent_var2, model1, num_slices)\n",
    "        response_2 = calculate_predicted_response(df2, independent_var1, independent_var2, model2, num_slices)\n",
    "\n",
    "        # Calculate correlation between the predicted responses\n",
    "        return stats.pearsonr(response_1, response_2)[0]\n",
    "\n",
    "    elif comparison_method == 'point_testing':\n",
    "        # Evaluate at specific points\n",
    "        diff_low_1, diff_high_1 = evaluate_at_specific_points(df1, independent_var1, independent_var2, model1)\n",
    "        diff_low_2, diff_high_2 = evaluate_at_specific_points(df2, independent_var1, independent_var2, model2)\n",
    "        \n",
    "        # Return the absolute differences\n",
    "        return abs(diff_low_1 - diff_low_2), abs(diff_high_1 - diff_high_2)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"comparison_method must be either 'correlation' or 'point_testing'.\")\n",
    "\n",
    "# Update the resample_or_permutation_test function\n",
    "def resample_or_permutation_test(df1, df2, dependent_var, independent_var1, independent_var2, interaction=True, comparison_method='correlation', num_slices=100, num_resamples=1000, test_type='permutation'):\n",
    "    \"\"\"\n",
    "    Perform resampling or permutation test to compare responses of two datasets and return results in a DataFrame.\n",
    "    \n",
    "    :param df1: DataFrame containing first dataset\n",
    "    :param df2: DataFrame containing second dataset\n",
    "    :param dependent_var: Name of the dependent variable\n",
    "    :param independent_var1: Name of the first independent variable\n",
    "    :param independent_var2: Name of the second independent variable\n",
    "    :param interaction: Boolean indicating if interaction between independent variables should be considered\n",
    "    :param comparison_method: Method for comparing responses ('correlation' or 'point_testing')\n",
    "    :param num_slices: Number of values to take for each variable to form the grid (used in correlation)\n",
    "    :param num_resamples: Number of resamples to perform\n",
    "    :param test_type: Type of test to perform ('resampling' or 'permutation')\n",
    "    :return: p-value and confidence interval\n",
    "    \"\"\"\n",
    "    # Calculate observed metric\n",
    "    observed_metric = compare_responses(df1, df2, dependent_var, independent_var1, independent_var2, interaction, comparison_method, num_slices)\n",
    "    \n",
    "    # Initialize results\n",
    "    resampled_metrics = []\n",
    "\n",
    "    for i in tqdm(range(num_resamples)):\n",
    "        # Perform resampling or permutation\n",
    "        if test_type == 'resampling':\n",
    "            sample_df1 = df1.sample(frac=1, replace=True)\n",
    "            sample_df2 = df2.sample(frac=1, replace=True)\n",
    "        elif test_type == 'permutation':\n",
    "            sample_df1 = df1.copy()\n",
    "            sample_df2 = df2.copy()\n",
    "            sample_df1[dependent_var] = np.random.permutation(sample_df1[dependent_var].values)\n",
    "            sample_df2[dependent_var] = np.random.permutation(sample_df2[dependent_var].values)\n",
    "        else:\n",
    "            raise ValueError(\"test_type must be either 'resampling' or 'permutation'.\")\n",
    "        \n",
    "        # Calculate resampled metric\n",
    "        resampled_metric = compare_responses(sample_df1, sample_df2, dependent_var, independent_var1, independent_var2, interaction, comparison_method, num_slices)\n",
    "        resampled_metrics.append(resampled_metric)\n",
    "    \n",
    "    # Calculate statistics and create DataFrame\n",
    "    results_dataframe = compute_statistics_and_create_dataframe(resampled_metrics, observed_metric, comparison_method, test_type)\n",
    "    \n",
    "    return results_dataframe, resampled_metrics, observed_metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define dataframe 1 and dataframe 2 for comaprison by permutation test\n",
    "df_1 = data_df[data_df['City'] == 'Boston']\n",
    "df_2 = data_df[data_df['City'] == 'Toronto']\n",
    "dependent_var = 'Z_Scored_Percent_Cognitive_Improvement'\n",
    "independent_var1 = 'Z_Scored_Subiculum_Connectivity_T'\n",
    "independent_var2 = 'Age'\n",
    "enable_interaction = False\n",
    "num_iterations = 1000\n",
    "comparison_method = 'correlation' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permutation Test It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while (permutation_results.loc[:,'P-value'] > 0.05).any():\n",
    "permutation_results,  empiric_distribution, observed_metric = resample_or_permutation_test(df1 = df_1,\n",
    "                                                            df2 = df_2,\n",
    "                                                            dependent_var = dependent_var,\n",
    "                                                            independent_var1 = independent_var1,\n",
    "                                                            independent_var2 = independent_var2,\n",
    "                                                            interaction = enable_interaction,\n",
    "                                                            test_type = 'permutation',\n",
    "                                                            comparison_method = comparison_method,\n",
    "                                                            num_resamples = num_iterations)\n",
    "permutation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrap Test It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------DO NOT TOUCH----------------------------------------------------------------\n",
    "bootstrap_results, empiric_distribution, observed_metric = resample_or_permutation_test(df1 = df_1,\n",
    "                                                            df2 = df_2,\n",
    "                                                            dependent_var = dependent_var,\n",
    "                                                            independent_var1 = independent_var1,\n",
    "                                                            independent_var2 = independent_var2,\n",
    "                                                            interaction = enable_interaction,\n",
    "                                                            test_type = 'resampling',\n",
    "                                                            comparison_method = comparison_method,\n",
    "                                                            num_resamples = num_iterations)\n",
    "bootstrap_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the Histogram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class DeltaCorrelation():\n",
    "    def __init__(self, data_df):\n",
    "        self.empiric_dist = None\n",
    "        self.observed_val = None\n",
    "\n",
    "    def set_empiric_and_observed(self, empiric_dist, observed_val):\n",
    "        self.empiric_dist = empiric_dist\n",
    "        self.observed_val = observed_val\n",
    "\n",
    "    def plot_kde_histogram(self, bins=50, one_tail=False, color_palette='dark'):\n",
    "        if self.empiric_dist is None or self.observed_val is None:\n",
    "            print(\"Empiric distribution and observed value must be set before plotting.\")\n",
    "            return\n",
    "\n",
    "        if one_tail:\n",
    "            empiric_dist = np.abs(self.empiric_dist)\n",
    "            observed_val = np.abs(self.observed_val)\n",
    "        else:\n",
    "            empiric_dist = self.empiric_dist\n",
    "            observed_val = self.observed_val\n",
    "\n",
    "        p_value = np.mean(empiric_dist >= observed_val)\n",
    "\n",
    "        sns.set_palette(color_palette)\n",
    "        current_palette = sns.color_palette(color_palette)\n",
    "        chosen_color = current_palette[3]\n",
    "\n",
    "        g = sns.displot(empiric_dist, kde=True, bins=bins, label=\"Empirical Distribution\", element=\"step\", color='blue', alpha=.25)\n",
    "        g.fig.set_size_inches(6.5, 4.5)\n",
    "        plt.axvline(x=observed_val, color='red', linestyle='-', linewidth=1.5, label=f\"Observed Value\", alpha=1)\n",
    "        plt.title(f\"Spatial Correlation = {observed_val:.2f}, p = {p_value:.4f}\")\n",
    "        plt.xlabel(\"Value\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.legend()\n",
    "\n",
    "        fig = g.fig\n",
    "\n",
    "        fig.savefig(f\"{out_dir}/kde_histogram.png\", bbox_inches='tight')\n",
    "        fig.savefig(f\"{out_dir}/kde_histogram.svg\", bbox_inches='tight')\n",
    "        print(f'Saved to {out_dir}/kde_histogram.svg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = DeltaCorrelation(data_df)\n",
    "hist.set_empiric_and_observed(empiric_dist=empiric_distribution, observed_val=observed_metric)\n",
    "hist.plot_kde_histogram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find the Inflection in Arbitrary Number of Distributions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdms\n",
    "from scipy.optimize import minimize\n",
    "from statsmodels.formula.api import ols\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from calvin_utils.statistical_utils.distribution_statistics import plot_with_annotation\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "\n",
    "class SaddlePointFinder:\n",
    "    \"\"\"\n",
    "    This class finds the saddle points in a linear regression model with interaction terms.\n",
    "    It uses the coefficients of the model as the first partial derivatives of the function with respect to each variable.\n",
    "    The class identifies points in the data where these partial derivatives are minimized, which are treated as saddle points.\n",
    "    \n",
    "    Note: \n",
    "    The approach is heuristic and not rigorous. It assumes that the coefficients can serve as good approximations\n",
    "    for the first partial derivatives, which may not always be the case. Therefore, the identified saddle points \n",
    "    are approximate and should be interpreted with caution.\n",
    "    \"\"\"\n",
    "    def __init__(self, dependent_var, independent_var1, independent_var2, num_resamples=1000):\n",
    "        \"\"\"\n",
    "        Initialize the SaddlePointFinder with variable names and resampling details.\n",
    "        \n",
    "        Parameters:\n",
    "        - dependent_var (str): The dependent variable in the formula.\n",
    "        - independent_var1, independent_var2 (str): The independent variables in the formula.\n",
    "        - num_resamples (int): The number of bootstrapping samples.\n",
    "        \"\"\"\n",
    "        self.dependent_var = dependent_var\n",
    "        self.independent_var1 = independent_var1\n",
    "        self.independent_var2 = independent_var2\n",
    "        self.num_resamples = num_resamples\n",
    "\n",
    "    def find_saddle_point(self, model, sample_df):\n",
    "        \"\"\"\n",
    "        Find the values of the regressors at the saddle point in a single model.\n",
    "        \n",
    "        Parameters:\n",
    "        - model: A fitted OLS model.\n",
    "        - sample_df: The DataFrame containing the sampled data.\n",
    "        \n",
    "        Returns:\n",
    "        - A tuple containing the saddle point values for the independent variables.\n",
    "        \"\"\"\n",
    "        coef_x1 = model.params.get(self.independent_var1, 0)\n",
    "        coef_x2 = model.params.get(self.independent_var2, 0)\n",
    "        coef_interaction = model.params.get(f\"{self.independent_var1}:{self.independent_var2}\", 0)\n",
    "\n",
    "        sample_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        y2 = coef_x1 + coef_interaction * sample_df[self.independent_var2]\n",
    "        index_min_y2 = np.argmin(np.abs(y2))\n",
    "        x2 = sample_df.loc[index_min_y2, self.independent_var2]\n",
    "\n",
    "        y1 = coef_x2 + coef_interaction * sample_df[self.independent_var1]\n",
    "        index_min_y1 = np.argmin(np.abs(y1))\n",
    "        x1 = sample_df.loc[index_min_y1, self.independent_var1]\n",
    "\n",
    "        return (x1, x2)\n",
    "\n",
    "    def resample_and_find_saddle_points(self, df):\n",
    "        \"\"\"\n",
    "        Perform bootstrapping to find approximate saddle points in the model.\n",
    "        \n",
    "        Parameters:\n",
    "        - df (DataFrame): The DataFrame containing the variables.\n",
    "        \n",
    "        Returns:\n",
    "        - DataFrame containing the saddle points for the independent variables.\n",
    "        \"\"\"\n",
    "        saddle_points = []\n",
    "        for _ in tqdm(range(self.num_resamples)):\n",
    "            sample_df = df.sample(frac=1, replace=True)\n",
    "            formula = f\"{self.dependent_var} ~ {self.independent_var1} * {self.independent_var2}\"\n",
    "            model = ols(formula=formula, data=sample_df).fit()\n",
    "            saddle_point = self.find_saddle_point(model, sample_df)\n",
    "            saddle_points.append(saddle_point)\n",
    "        return pd.DataFrame(saddle_points, columns=[self.independent_var1, self.independent_var2])\n",
    "\n",
    "    def run_multiple_dfs(self, df_list):\n",
    "        \"\"\"\n",
    "        Run the saddle point finder on multiple DataFrames.\n",
    "        \n",
    "        Parameters:\n",
    "        - df_list (list): List of DataFrames.\n",
    "        \n",
    "        Returns:\n",
    "        - List of DataFrames, each containing the saddle points for the corresponding input DataFrame.\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        for df in df_list:\n",
    "            result = self.resample_and_find_saddle_points(df)\n",
    "            results.append(result)\n",
    "        return results\n",
    "    \n",
    "    def perform_t_tests_and_plots(self, df_dict, x_label='x', y_label='y', test_type='t-test_ind',  out_dir=None, colours=['red', 'blue']):\n",
    "        \"\"\"\n",
    "        Perform t-tests and generate plots for pairs of DataFrames.\n",
    "\n",
    "        Parameters:\n",
    "        - df_dict (dict): Dictionary containing DataFrame as key and its new column name as value.\n",
    "        - x_label (str): X-axis label for the plot.\n",
    "        - y_label (str): Y-axis label for the plot.\n",
    "        - test_type (str): Type of statistical test to perform.\n",
    "        - out_dir (str): Directory to save the output plots.\n",
    "        - colours (list): List of colours for the plot.\n",
    "\n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "\n",
    "        df_list = list(df_dict.values())\n",
    "        col_name_list = list(df_dict.keys())\n",
    "\n",
    "        for i, df1 in enumerate(df_list[:-1]):\n",
    "            for j, df2 in enumerate(df_list[i+1:]):\n",
    "                \n",
    "                col1_new = col_name_list[i]\n",
    "                col2_new = col_name_list[i+j+1]\n",
    "                \n",
    "                df1_renamed = df1.rename(columns={df1.columns[0]: col1_new})\n",
    "                df2_renamed = df2.rename(columns={df2.columns[0]: col2_new})\n",
    "\n",
    "                merged_df = pd.concat([df1_renamed[[col1_new]], df2_renamed[[col2_new]]], keys=[col1_new, col2_new], names=['Group', 'None']).reset_index(level=0).rename(columns={'Group': 'Group', 0: 'Value'})\n",
    "                \n",
    "                plt = plot_with_annotation(dataframe=merged_df, \n",
    "                                        col1=col1_new, \n",
    "                                        col2=col2_new,\n",
    "                                        xlabel=x_label, \n",
    "                                        ylabel=y_label, \n",
    "                                        test_type=test_type,\n",
    "                                        colours=colours)\n",
    "                if out_dir is not None:\n",
    "                    os.makedirs(os.path.join(out_dir, 'distribution_figures'), exist_ok=True)\n",
    "                    plt.savefig(os.path.join(out_dir, f'distribution_figures/{x_label}_{test_type}_{y_label}.png'))\n",
    "                    plt.savefig(os.path.join(out_dir, f'distribution_figures/{x_label}_{test_type}_{y_label}.svg'))\n",
    "                    print(f'Figure saved to: {os.path.join(out_dir, f\"distribution_figures/{x_label}_{test_type}_{y_label}\")}')\n",
    "                plt.show()\n",
    "\n",
    "def plot_95CI(df_dict, x_label='x', y_label='y', out_dir=None, colours=['red', 'blue']):\n",
    "    \"\"\"\n",
    "    Plot the 95% confidence intervals for each DataFrame using seaborn boxplot.\n",
    "\n",
    "    Parameters:\n",
    "    - df_dict (dict): Dictionary containing DataFrame as key and its new column name as value.\n",
    "    - x_label (str): X-axis label for the plot.\n",
    "    - y_label (str): Y-axis label for the plot.\n",
    "    - out_dir (str): Directory to save the output plots.\n",
    "    - colours (list): List of colours for the plot.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Prepare data for seaborn\n",
    "    aggregated_data = []\n",
    "    for label, df in df_dict.items():\n",
    "        df['label'] = label\n",
    "        aggregated_data.append(df)\n",
    "\n",
    "    concatenated_df = pd.concat(aggregated_data)\n",
    "    concatenated_df.columns = [y_label, x_label]\n",
    "\n",
    "    # Create the boxplot\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.boxplot(x=x_label, y=y_label, data=concatenated_df, ax=ax, palette=colours, whis=[2.5, 97.5])\n",
    "\n",
    "    # Labels and title\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.set_title(f'Distribution of {y_label} At Inflection Point')\n",
    "\n",
    "\n",
    "    # Save plot\n",
    "    if out_dir is not None:\n",
    "        os.makedirs(os.path.join(out_dir, '95CI_figures'), exist_ok=True)\n",
    "        plt.savefig(os.path.join(out_dir, f'95CI_figures/{x_label}_{y_label}.png'))\n",
    "        plt.savefig(os.path.join(out_dir, f'95CI_figures/{x_label}_{y_label}.svg'))\n",
    "        print(f'Figure saved to: {os.path.join(out_dir, f\"95CI_figures/{x_label}_{y_label}\")}')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def run_ks_test(df_dict):\n",
    "    \"\"\"\n",
    "    Run a Kolmogorov-Smirnov test on two datasets to determine if their distributions are significantly different.\n",
    "\n",
    "    Parameters:\n",
    "    - df_dict (dict): Dictionary containing two DataFrames as key-value pairs.\n",
    "\n",
    "    Returns:\n",
    "    - p_value (float): p-value from the KS test.\n",
    "    \"\"\"\n",
    "    if len(df_dict) != 2:\n",
    "        return \"The dictionary should contain exactly two datasets.\"\n",
    "    \n",
    "    data_1, data_2 = list(df_dict.values())\n",
    "    \n",
    "    # Extracting the single column from each DataFrame\n",
    "    data_1_column = data_1.iloc[:, 0]\n",
    "    data_2_column = data_2.iloc[:, 0]\n",
    "    \n",
    "    # Running the KS test\n",
    "    _, p_value = ks_2samp(data_1_column, data_2_column)\n",
    "    \n",
    "    return p_value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent_var = 'Z_Scored_Percent_Cognitive_Improvement'\n",
    "independent_var1 = 'Age'\n",
    "independent_var2 = 'Subiculum_Connectivity'\n",
    "num_resamples=10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saddle_finder = SaddlePointFinder(dependent_var=dependent_var, independent_var1=independent_var1, independent_var2=independent_var2, num_resamples=num_resamples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option A) Run a Single Dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = saddle_finder.resample_and_find_saddle_points(data_df)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option B) Run Multiple Dataframes**\n",
    "- Enter as many as you want into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = data_df[data_df['Cohort'] == 1]\n",
    "df_2 = data_df[data_df['Cohort'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df_1, df_2]\n",
    "result = saddle_finder.run_multiple_dfs(df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the Distributions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot 95% CI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option A) 1 Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_label = 'Boston'\n",
    "value_of_interest = 'Subiculum_Connectivity'\n",
    "y_label = 'Y'\n",
    "x_label = 'X'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {df_1_label: result.loc[:, [value_of_interest]]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option B) Multiple Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_label = 'Alzheimer'\n",
    "df_2_label = 'Parkinson'\n",
    "value_of_interest = 'Age'\n",
    "y_label = 'Age'\n",
    "x_label = 'Disease'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {df_1_label: results[0].loc[:, [value_of_interest]], df_2_label: results[1].loc[:, [value_of_interest]]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_95CI(df_dict=df_dict, x_label=x_label, y_label=y_label, out_dir='/Users/cu135/Dropbox (Partners HealthCare)/studies/cognition_2023/analyses/saddle_point', colours=['red', 'blue'])\n",
    "run_ks_test(df_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Distribution and Test Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0].loc[:, [value_of_interest]].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Mann-Whitney'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {df_1_label: results[0].loc[:, [value_of_interest]], df_2_label: results[1].loc[:, [value_of_interest]]}\n",
    "saddle_finder.perform_t_tests_and_plots(df_dict=df_dict, x_label=x_label, y_label=y_label, out_dir='/Users/cu135/Dropbox (Partners HealthCare)/studies/cognition_2023/analyses/saddle_point', colours=['red', 'blue'], test_type='t-test_ind')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See If Two Regressions Are Significantly Different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries (if you haven't already)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from tqdm import tqdm\n",
    "\n",
    "class RegressionComparison:\n",
    "    def __init__(self, df, dependent_var, independent_vars, split_var, split_value, constant_value_for_second_predictor=np.nan):\n",
    "        \"\"\"\n",
    "        Initialize the RegressionComparison object with data and variable names.\n",
    "        \"\"\"\n",
    "        self.df1 = df[df[split_var] <= split_value]\n",
    "        self.df2 = df[df[split_var] > split_value]\n",
    "        self.dependent_var = dependent_var\n",
    "        self.independent_vars = independent_vars\n",
    "        self.formula = f\"{dependent_var} ~ {' + '.join(independent_vars)}\"\n",
    "        self.constant_value_for_second_predictor=constant_value_for_second_predictor\n",
    "        if self.df1.empty or self.df2.empty:\n",
    "            raise ValueError(\"One of the datasets is empty after the split. Check your split variable and value.\")\n",
    "    \n",
    "    def fit_models(self):\n",
    "        \"\"\"\n",
    "        Fit OLS regression models for each dataset.\n",
    "        \"\"\"\n",
    "        self.model1 = smf.ols(formula=self.formula, data=self.df1).fit()\n",
    "        self.model2 = smf.ols(formula=self.formula, data=self.df2).fit()\n",
    "        \n",
    "    def create_evaluation_dataframe(self, n_points=100):\n",
    "        \"\"\"\n",
    "        Create a DataFrame for evaluation with different ranges for the first predictor\n",
    "        and a constant value for the second predictor.\n",
    "        \n",
    "        :param constant_value_for_second_predictor: The constant value to set for the second predictor.\n",
    "        :param n_points: Number of points where the model will be evaluated.\n",
    "        :return: Two DataFrames for evaluation, one for each dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        # For the first dataset\n",
    "        x_values_df1 = np.linspace(min(self.df1[self.independent_vars[0]]), \n",
    "                                max(self.df1[self.independent_vars[0]]), n_points)\n",
    "        eval_df1 = pd.DataFrame({self.independent_vars[0]: x_values_df1})\n",
    "        eval_df1[self.independent_vars[1]] = self.constant_value_for_second_predictor\n",
    "        \n",
    "        # For the second dataset\n",
    "        x_values_df2 = np.linspace(min(self.df2[self.independent_vars[0]]), \n",
    "                                max(self.df2[self.independent_vars[0]]), n_points)\n",
    "        eval_df2 = pd.DataFrame({self.independent_vars[0]: x_values_df2})\n",
    "        eval_df2[self.independent_vars[1]] = self.constant_value_for_second_predictor\n",
    "        \n",
    "        return eval_df1, eval_df2\n",
    "\n",
    "\n",
    "    def calculate_observed_delta(self, n_points=100):\n",
    "        \"\"\"\n",
    "        Calculate the observed delta between the two regression models for 100 datapoints.\n",
    "        \"\"\"\n",
    "        self.x_df1, self.x_df2 = self.create_evaluation_dataframe()\n",
    "\n",
    "        pred1 = self.model1.predict(self.x_df1)\n",
    "        pred2 = self.model2.predict(self.x_df2)\n",
    "\n",
    "        self.observed_delta = np.sum(pred1 - pred2)\n",
    "        \n",
    "\n",
    "    def permute_outcomes(self):\n",
    "        \"\"\"Permute the dependent variable in df1 and df2.\"\"\"\n",
    "        permuted_y1 = np.random.permutation(self.df1[self.dependent_var].values)\n",
    "        permuted_y2 = np.random.permutation(self.df2[self.dependent_var].values)\n",
    "\n",
    "        perm_df1 = self.df1.copy()\n",
    "        perm_df2 = self.df2.copy()\n",
    "\n",
    "        perm_df1[self.dependent_var] = permuted_y1\n",
    "        perm_df2[self.dependent_var] = permuted_y2\n",
    "\n",
    "        return perm_df1, perm_df2\n",
    "\n",
    "\n",
    "    def calculate_empirical_delta(self, n_permutations=1000, n_points=100):\n",
    "        \"\"\"Calculate the empirical delta using permuted data.\"\"\"\n",
    "        self.empirical_deltas = []\n",
    "\n",
    "        for _ in tqdm(range(n_permutations)):\n",
    "            # Step 1: Permute the outcomes\n",
    "            perm_df1, perm_df2 = self.permute_outcomes()\n",
    "\n",
    "            # Step 2: Fit models on permuted data\n",
    "            model1 = smf.ols(formula=self.formula, data=perm_df1).fit()\n",
    "            model2 = smf.ols(formula=self.formula, data=perm_df2).fit()\n",
    "\n",
    "            # Step 3: Create evaluation DataFrames for permuted data\n",
    "            x_df1, x_df2 = self.create_evaluation_dataframe(n_points)\n",
    "\n",
    "            # Step 4: Make predictions on evaluation DataFrames\n",
    "            pred1 = model1.predict(x_df1)\n",
    "            pred2 = model2.predict(x_df2)\n",
    "\n",
    "            # Step 5: Calculate and store empirical delta\n",
    "            empirical_delta = np.sum(pred1 - pred2)\n",
    "            self.empirical_deltas.append(empirical_delta)\n",
    "\n",
    "    def calculate_significance(self):\n",
    "        \"\"\"\n",
    "        Calculate the p-value based on empirical deltas.\n",
    "        \"\"\"\n",
    "        mask = self.empirical_deltas >= self.observed_delta\n",
    "        self.p_value = np.mean(mask)\n",
    "        \n",
    "        return self.p_value\n",
    "\n",
    "    def run(self, n_permutations=1000, n_points=100):\n",
    "        \"\"\"\n",
    "        Orchestrates the complete pipeline.\n",
    "        \n",
    "        :param n_permutations: Number of permutations for empirical delta calculation.\n",
    "        :param n_points: Number of points to use in observed delta calculation.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Step 1: Fit the models\n",
    "        self.fit_models()\n",
    "        \n",
    "        # Step 2: Create evaluation DataFrames\n",
    "        self.x_df1, self.x_df2 = self.create_evaluation_dataframe(n_points)\n",
    "        \n",
    "        # Step 3: Calculate observed delta\n",
    "        self.calculate_observed_delta(n_points)\n",
    "        \n",
    "        # Step 4: Calculate empirical delta\n",
    "        self.calculate_empirical_delta(n_permutations)\n",
    "        \n",
    "        # Step 5: Calculate significance\n",
    "        p_value = self.calculate_significance()\n",
    "        \n",
    "        return p_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Punch In Your Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables based on your specific case\n",
    "dependent_var = 'Z_Scored_Cognitive_Improvement_By_Group'\n",
    "independent_vars = ['Subiculum_Connectivity', 'Age']\n",
    "split_var = 'Cohort'\n",
    "split_value = 0.5\n",
    "value_to_set_to = 67"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the class with the variables\n",
    "reg_comp = RegressionComparison(df=data_df, \n",
    "                                dependent_var=dependent_var, \n",
    "                                independent_vars=independent_vars, \n",
    "                                split_var=split_var, \n",
    "                                split_value=split_value, \n",
    "                                constant_value_for_second_predictor=value_to_set_to)\n",
    "\n",
    "# Fit the models\n",
    "p = reg_comp.run()\n",
    "print(\"Significance Count:\", p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimlab_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
