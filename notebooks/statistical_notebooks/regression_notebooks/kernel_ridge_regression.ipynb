{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import platform\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_csv_path = '/Users/cu135/Dropbox (Partners HealthCare)/studies/atrophy_seeds_2023/metadata/correlation_to_baseline_scores.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '/Users/cu135/Dropbox (Partners HealthCare)/studies/atrophy_seeds_2023/Figures/correlation_to_baseline_scores/regress_to_total'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.permutation_analysis_utils.statsmodels_palm import CalvinStatsmodelsPalm\n",
    "# Instantiate the PalmPrepararation class\n",
    "cal_palm = CalvinStatsmodelsPalm(input_csv_path=input_csv_path, output_dir=out_dir, sheet=None)\n",
    "# Call the process_nifti_paths method\n",
    "data_df = cal_palm.read_and_display_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'City'  # The column you'd like to evaluate\n",
    "condition = 'not'  # The condition to check ('equal', 'above', 'below', 'not')\n",
    "value = 'Wurzburg' # The value to drop if found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df, other_df = cal_palm.drop_rows_based_on_value(column, condition, value)\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_not_to_standardize = ['Z_Scored_Percent_Cognitive_Improvement_By_Origin_Group', 'Z_Scored_Subiculum_T_By_Origin_Group_'] #['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = cal_palm.standardize_columns(cols_not_to_standardize)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Kernel Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def krr_run(df, dependent, predictors, alpha=1.0):\n",
    "    krr = KernelRidge(alpha=alpha)\n",
    "    Y = df.loc[:, [dependent]]\n",
    "    X = df.loc[:, predictors]\n",
    "    krr_model = krr.fit(X, Y)\n",
    "    y_pred = krr_model.predict(X)\n",
    "    print(\"R-squared: \", r2_score(Y, y_pred))\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent ='TOTAL11'\n",
    "predictors = ['FrontalSurface' , 'OccipitalSurface', 'ParietalSurface', 'temp_ins_surface', 'MTLSurface']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "krr_run(data_df, dependent, predictors, alpha=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Ridge Regression LOOCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "def kernel_ridge_loo(df:pd.DataFrame, target:str, alpha:float, gamma:float, degree:int, kernel:str):\n",
    "    y_pred = []\n",
    "    for i in range(0, len(df[target].values.tolist())):\n",
    "        # splitting dataframe into train and test set\n",
    "        df_test = df.loc[[i]]\n",
    "        df_train = df.drop(df.index[i])\n",
    "        \n",
    "        X_train = df_train.drop(target, axis=1)\n",
    "        y_train = df_train[target]\n",
    "        X_test = df_test.drop(target, axis=1)\n",
    "        y_test = df_test[target]\n",
    "        \n",
    "        model = KernelRidge(kernel=kernel, alpha=alpha, gamma=gamma, degree=degree)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred.append(model.predict(X_test)[0])\n",
    "        \n",
    "    outcome_dictionary = {}\n",
    "    outcome_dictionary['actuals'] = df[target].values.tolist()\n",
    "    outcome_dictionary['predictions'] = y_pred\n",
    "    try:\n",
    "        outcome_dictionary['loocv_prediction_r'], outcome_dictionary['loocv_prediction_p'] = pearsonr(outcome_dictionary['actuals'], outcome_dictionary['predictions'])\n",
    "        outcome_dictionary['loocv_prediction_r2'] = outcome_dictionary['loocv_prediction_r']**2\n",
    "        outcome_dictionary['loocv_mean_squared_error'] = np.sum( np.square( (outcome_dictionary['actuals'] - outcome_dictionary['predictions']))) / len(outcome_dictionary['predictions'])\n",
    "        outcome_dictionary['loocv_root_mean_squared_error'] = np.sqrt(outcome_dictionary['loocv_mean_squared_error'])\n",
    "        outcome_dictionary['lootcv_mean_absolute_error'] = np.sum(np.abs((outcome_dictionary['predictions'] - outcome_dictionary['actuals']))) / len(outcome_dictionary['predictions'])    \n",
    "    except:\n",
    "        print('Error generating outcome metrics')\n",
    "    outcome_df = pd.DataFrame(outcome_dictionary)\n",
    "    \n",
    "    return outcome_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.loc[:, ['TOTAL11', 'FrontalCSF' , 'OccipitalCSF', 'ParietalCSF', 'temp_ins_csf']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reminder: kernels = ['additive_chi2', 'polynomial', 'poly', 'rbf', 'cosine', 'laplacian', 'precomputed', 'sigmoid', 'linear', 'chi2']\n",
    "kernel = 'rbf'\n",
    "target = 'TOTAL11'\n",
    "#----------------------------------------------------------------USER INPUTS ABOVE----------------------------------------------------------------\n",
    "loo_results = kernel_ridge_loo(df=data_df, target=target, kernel=kernel, alpha=0.001, gamma=.0001, degree=4)\n",
    "# loo_df = pd.DataFrame(loo_results)\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "#Calculate metrics\n",
    "loo_results.dropna(inplace=True)\n",
    "loo_results['loocv_pearson_r'], loo_results['loocv_pearson_p'] = pearsonr(loo_results['predictions'], loo_results['actuals'], alternative='greater')\n",
    "loo_results['loocv_r_squared'] = np.square(loo_results['loocv_pearson_r'])\n",
    "_, loo_results['loocv_pearson_p_greater'] = pearsonr(loo_results['predictions'], loo_results['actuals'], alternative='greater')\n",
    "_, loo_results['loocv_pearson_p_lesser'] = pearsonr(loo_results['predictions'], loo_results['actuals'], alternative='less')\n",
    "_, loo_results['loocv_pearson_p_two-sided'] = pearsonr(loo_results['predictions'], loo_results['actuals'], alternative='two-sided')\n",
    "loo_results['loocv_mse'] = (np.sum(np.square((loo_results['actuals']-loo_results['predictions'])))) / len(loo_results['actuals'])\n",
    "loo_results['loocv_rmse'] = np.sqrt(loo_results['loocv_mse'])\n",
    "loo_results['mean_absolute_error'] = np.sum(np.absolute(loo_results['predictions']-loo_results['actuals']))/len(loo_results['predictions'])\n",
    "\n",
    "display(loo_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save if desired\n",
    "save=True\n",
    "if save:\n",
    "    if os.path.isdir(out_dir) != True:\n",
    "        os.makedirs(out_dir)\n",
    "        print('Made directory')\n",
    "    try:\n",
    "        loo_results.to_csv(os.path.join(out_dir, f'loocv_{kernel}_kernel_ridge_regression_{data_df.columns.values.tolist()[1:]}_statistically_significant_{loo_results[\"mean_absolute_error\"].values.tolist[1]}.csv'))\n",
    "    except:\n",
    "        loo_results.to_csv(os.path.join(out_dir, f'ols_leave_one_out_full_formula.csv'))\n",
    "\n",
    "\n",
    "print('Saved to: ' + out_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess various Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of kernel functions\n",
    "def linear_kernel(X1, X2, **kwargs):\n",
    "    \"\"\"Linear kernel function\"\"\"\n",
    "    return np.matmul(X1, X2.transpose())\n",
    "\n",
    "def polynomial_kernel(x1, x2, degree, c=1, **kwargs):\n",
    "    return (np.dot(x1, x2) + c)**degree\n",
    "\n",
    "def rbf_kernel(x1, x2, gamma, **kwargs):\n",
    "    return np.exp(-gamma * np.power(np.linalg.norm(x1 - x2), 2))\n",
    "\n",
    "def gaussian_kernel(x1, x2, sigma, **kwargs):\n",
    "    return np.exp(-np.power(np.linalg.norm(x1 - x2), 2) / (2 * sigma ** 2))\n",
    "\n",
    "def sigmoid_kernel(x1, x2, k=1, c=1, **kwargs):\n",
    "    return np.tanh(k * np.dot(x1, x2) + c)\n",
    "\n",
    "def laplacian_kernel(x1, x2, gamma, **kwargs):\n",
    "    return np.exp(-gamma * np.linalg.norm(x1 - x2))\n",
    "\n",
    "def exponential_kernel(x1, x2, gamma, **kwargs):\n",
    "    return np.exp(-gamma * np.linalg.norm(x1 - x2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Transformation of a Kernel Upon the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = new_df.shape[0]\n",
    "kernel = np.zeros((n,n))\n",
    "kernel = np.zeros((n,n))\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        kernel[i,j] = rbf_kernel(data_df.iloc[i, 1], data_df.iloc[j, 1], gamma=1)#, sigma=1)# degree=1)\n",
    "        \n",
    "plt.hist(kernel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run LOOCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "kernel_list = [\"linear_kernel\", \"polynomial_kernel\", \"rbf_kernel\", \"gaussian_kernel\", \"sigmoid_kernel\", \"laplacian_kernel\", \"exponential_kernel\"] #, \"exp\", \"log\", \"tanh\"]\n",
    "#Iterate over the kernels of interest\n",
    "\n",
    "result_list_kernel = []; results_list_r2 = []; results_list_r = []; results_list_p = []; results_list_mse = []; results_list_rmse = []; results_list_mae = []\n",
    "for kernel_string in kernel_list:\n",
    "\n",
    "    #Generate Kernelized data\n",
    "    n = data_df.shape[0]\n",
    "    kernel = np.zeros((n,n))\n",
    "    Y = data_df['percent_change_adascog11']\n",
    "    X = data_df.drop('percent_change_adascog11', axis=1)\n",
    "    sigma = 1000\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            kernel[i,j] = eval(kernel_string)(X.iloc[i], X.iloc[j], gamma=1, sigma=1, k=1, degree=2)#, sigma=1)# degree=1)\n",
    "            \n",
    "    #Train a ridge regression on kernelized data\n",
    "    model = KernelRidge(kernel='precomputed')\n",
    "    results = model.fit(kernel[:, :], Y[:])\n",
    "\n",
    "    results_dict = {}\n",
    "    # results_dict['predictions'] = np.dot(kernel,model.dual_coef_)\n",
    "    # results_dict['observations'] = Y[:]\n",
    "    result_list_kernel.append(kernel_string)\n",
    "    results_list_r2.append(results.score(kernel[:, :], Y[:]))\n",
    "    r, p = spearmanr(np.dot(kernel,model.dual_coef_), Y[:])\n",
    "    results_list_r.append(r); results_list_p.append(p)\n",
    "    results_list_mse.append((np.sum(np.square((Y[:]-np.dot(kernel,model.dual_coef_))))) / len(Y[:]))\n",
    "    results_list_rmse.append(np.sqrt((np.sum(np.square((Y[:]-np.dot(kernel,model.dual_coef_))))) / len(Y[:])))\n",
    "    results_list_mae.append(np.sum(np.absolute(np.dot(kernel,model.dual_coef_)-Y[:]))/len(np.dot(kernel,model.dual_coef_)))\n",
    "results_dict['kernel'] = result_list_kernel\n",
    "results_dict['r2'] = results_list_r2; results_dict['r'] = results_list_r; results_dict['p'] = results_list_p\n",
    "results_dict['mse'] = results_list_mse; results_dict['rmse'] = results_list_rmse; results_dict['mae'] = results_list_mae\n",
    "\n",
    "kernel_comparison_kernel_ridge_results = pd.DataFrame(results_dict)\n",
    "display(kernel_comparison_kernel_ridge_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Results if desired\n",
    "save=True\n",
    "if save:\n",
    "    if os.path.isdir(out_dir) != True:\n",
    "        os.makedirs(out_dir)\n",
    "        print('Made directory')\n",
    "    kernel_comparison_kernel_ridge_results.to_csv(os.path.join(out_dir, 'kernel_comparison_kernel_ridge_results.csv'))\n",
    "\n",
    "\n",
    "print('Saved to: ' + out_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search for Optimal Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "## Refernece\n",
    "#--- kernels = ['additive_chi2', 'polynomial', 'poly', 'rbf', 'cosine', 'laplacian', 'precomputed', 'sigmoid', 'linear', 'chi2']\n",
    "\n",
    "# Load your dataframe\n",
    "df = data_df.copy()\n",
    "\n",
    "# Assign the independent variables and dependent variable\n",
    "Y = df['TOTAL11']\n",
    "X = df.loc[:, ['FrontalCSF' , 'OccipitalCSF', 'ParietalCSF', 'temp_ins_csf']]\n",
    "\n",
    "# Define the kernel ridge model\n",
    "kr = KernelRidge()\n",
    "\n",
    "# Define evaluation metrics\n",
    "scoring = 'r2' #'r2' neg_root_mean_squared_error\n",
    "# Define the parameter grid for the grid search\n",
    "param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'kernel': ['linear', 'rbf']}\n",
    "\n",
    "# Perform leave-one-out cross-validation\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Perform a grid search using the leave-one-out cross-validation\n",
    "grid_search = GridSearchCV(kr, param_grid, scoring=scoring, cv=len(data_df))\n",
    "grid_search.fit(X, Y)\n",
    "\n",
    "# The optimal hyperparameters\n",
    "print(\"Numer of splits:\", grid_search.n_splits_)\n",
    "print(\"Optimal parameters:\", grid_search.best_params_)\n",
    "print(\"Optimal score:\", grid_search.best_score_)\n",
    "# print(\"Overall results:\", grid_search.cv_results_)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Manual Kernalization and Manual Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = data_df.shape[0]\n",
    "kernel = np.zeros((n,n))\n",
    "Y = data_df['TOTAL11']\n",
    "X = data_df.loc[:, ['FrontalCSF' , 'OccipitalCSF', 'ParietalCSF', 'temp_ins_csf']]\n",
    "sigma = 1000\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        kernel[i,j] = exponential_kernel(X.iloc[i], X.iloc[j], gamma=1, k=1, degree=1)#, sigma=1)# degree=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Kernelized data\n",
    "n = data_df.shape[0]\n",
    "kernel = np.zeros((n,n))\n",
    "Y = data_df['percent_change_adascog11']\n",
    "X = data_df.drop('percent_change_adascog11', axis=1)\n",
    "sigma = 1000\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        kernel[i,j] = exponential_kernel(X.iloc[i], X.iloc[j], gamma=1, k=1, degree=1)#, sigma=1)# degree=1)\n",
    "        \n",
    "#Train a ridge regression on kernelized data\n",
    "model = KernelRidge(kernel='precomputed')\n",
    "results = model.fit(kernel[:, :], Y[:])\n",
    "\n",
    "results_dict = {}\n",
    "results_dict['predictions'] = np.dot(kernel,model.dual_coef_)\n",
    "results_dict['observations'] = Y[:]\n",
    "results_dict['r2'] = results.score(kernel[:, :], Y[:])\n",
    "results_dict['pearson_r'], results_dict['pearson_p'] = pearsonr(results_dict['predictions'], results_dict['observations'])\n",
    "results_dict['mse'] = (np.sum(np.square((results_dict['observations']-results_dict['predictions'])))) / len(results_dict['observations'])\n",
    "results_dict['rmse'] = np.sqrt(results_dict['mse'])\n",
    "results_dict['mae'] = np.sum(np.absolute(results_dict['predictions']-results_dict['observations']))/len(results_dict['predictions'])\n",
    "\n",
    "manual_kernel_ridge_results = pd.DataFrame(results_dict)\n",
    "display(manual_kernel_ridge_results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run K-Folds on Kernel Ridge (Useful for Precomputed Kernels)\n",
    "### If using kernels, must make sure the folds are symmetric\n",
    "### The ridge regression will expect a symmetric Kernel Matrix from training to testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "def kernel_ridge_kfold(df:pd.DataFrame, target:str, k:int, sigma:float):\n",
    "    kf = KFold(n_splits=k, shuffle=True)\n",
    "    y_pred = []\n",
    "    y_test_all = []\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        df_train, df_test = df.iloc[train_index], df.iloc[test_index]\n",
    "        X_train = df_train.drop(target, axis=1)\n",
    "        y_train = df_train[target]\n",
    "        X_test = df_test.drop(target, axis=1)\n",
    "        y_test = df_test[target]\n",
    "        model = KernelRidge(kernel='rbf', gamma=1/(2*sigma**2))\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred.append(model.predict(X_test))\n",
    "        y_test_all.append(y_test)\n",
    "    y_test_all = np.concatenate(y_test_all)\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    R, P = pearsonr(y_pred, y_test_all)\n",
    "    return R, P\n",
    "\n",
    "R, P = kernel_ridge_kfold(df=data_df, target='percent_change_adascog11', k=2, sigma=1)#(data_df.shape[0]-1)/6)\n",
    "results_df = pd.DataFrame({'R': R, 'P': P}, index=[0])\n",
    "display(results_df)\n",
    "\n",
    "save=False\n",
    "if save:\n",
    "    if os.path.isdir(out_dir) == False:\n",
    "        os.mkdir(out_dir)\n",
    "    results_df.to_csv(os.path.join(out_dir, 'kernel_ridge_regression_k_folds_results.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimlab_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
