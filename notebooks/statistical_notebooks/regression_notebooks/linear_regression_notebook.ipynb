{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Any Kind of OLS Regression (ANOVA, GLM, etc.)\n",
    "\n",
    "### Authors: Calvin Howard.\n",
    "\n",
    "#### Last updated: July 6, 2023\n",
    "\n",
    "Use this to run/test a statistical model (e.g., regression or T-tests) on a spreadsheet.\n",
    "\n",
    "Notes:\n",
    "- To best use this notebook, you should be familar with GLM design and Contrast Matrix design. See this webpage to get started:\n",
    "[FSL's GLM page](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/GLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 - Import CSV with All Data\n",
    "**The CSV is expected to be in this format**\n",
    "- ID and absolute paths to niftis are critical\n",
    "```\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "| ID  | Nifti_File_Path            | Covariate_1  | Covariate_2  | Covariate_3  |\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "| 1   | /path/to/file1.nii.gz      | 0.5          | 1.2          | 3.4          |\n",
    "| 2   | /path/to/file2.nii.gz      | 0.7          | 1.4          | 3.1          |\n",
    "| 3   | /path/to/file3.nii.gz      | 0.6          | 1.5          | 3.5          |\n",
    "| 4   | /path/to/file4.nii.gz      | 0.9          | 1.1          | 3.2          |\n",
    "| ... | ...                        | ...          | ...          | ...          |\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prep Output Direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify where you want to save your results to\n",
    "out_dir = '/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Research/2023/subiculum_cognition_and_age/figures/Figures/supplements_raw_correlations'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your CSV file containing NIFTI paths\n",
    "input_csv_path = '/Users/cu135/Partners HealthCare Dropbox/Calvin Howard/studies/cognition_2023/metadata/master_list_proper_subjects.xlsx'\n",
    "sheet = 'master_list_proper_subjects'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.permutation_analysis_utils.statsmodels_palm import CalvinStatsmodelsPalm\n",
    "# Instantiate the PalmPrepararation class\n",
    "cal_palm = CalvinStatsmodelsPalm(input_csv_path=input_csv_path, output_dir=out_dir, sheet=sheet)\n",
    "# Call the process_nifti_paths method\n",
    "data_df = cal_palm.read_and_display_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 01 - Preprocess Your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handle NANs**\n",
    "- Set drop_nans=True is you would like to remove NaNs from data\n",
    "- Provide a column name or a list of column names to remove NaNs from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['Age', 'Z_Scored_Subiculum_Connectivity_T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = cal_palm.drop_nans_from_columns(columns_to_drop_from=drop_list)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop Row Based on Value of Column**\n",
    "\n",
    "Define the column, condition, and value for dropping rows\n",
    "- column = 'your_column_name'\n",
    "- condition = 'above'  # Options: 'equal', 'above', 'below'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the parameters for dropping rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'Age_Group'  # The column you'd like to evaluate\n",
    "condition = 'equal'  # The condition to check ('equal', 'above', 'below', 'not')\n",
    "value = 'old' # The value to drop if T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df, other_df = cal_palm.drop_rows_based_on_value(column, condition, value)\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standardize Data**\n",
    "- Enter Columns you Don't want to standardize into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove anything you don't want to standardize\n",
    "# cols_not_to_standardize = ['subid'] #['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df = cal_palm.standardize_columns(cols_not_to_standardize)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regress out Covariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from calvin_utils.statistical_utils.regression_utils import RegressOutCovariates\n",
    "# # use this code block to regress out covariates. Generally better to just include as covariates in a model..\n",
    "# dependent_variable_list = lis\n",
    "# regressors = ['Age', 'Sex']\n",
    "\n",
    "# data_df, adjusted_dep_vars_list = RegressOutCovariates.run(df=data_df, dependent_variable_list=dependent_variable_list, covariates_list=regressors)\n",
    "# print(adjusted_dep_vars_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit Column Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "def convert_to_ordinal(data_df, columns):\n",
    "    \"\"\"\n",
    "    Convert unique values in specified columns of a DataFrame to ordinal values and print the mapping.\n",
    "\n",
    "    Parameters:\n",
    "    - data_df (pd.DataFrame): DataFrame containing the data to be converted.\n",
    "    - columns (list): List of column names to be converted to ordinal values.\n",
    "\n",
    "    Returns:\n",
    "    - ordinal_df (pd.DataFrame): DataFrame with specified columns converted to ordinal values.\n",
    "    - mapping_dict (dict): Dictionary showing the mapping of original values to ordinal values for each column.\n",
    "    \"\"\"\n",
    "    ordinal_df = data_df.copy()\n",
    "    mapping_dict = {}\n",
    "\n",
    "    for column in columns:\n",
    "        if column in ordinal_df.columns:\n",
    "            unique_values = ordinal_df[column].unique()\n",
    "            unique_values.sort()  # Ensure the values are sorted before assigning ordinals\n",
    "            mapping_dict[column] = {value: idx for idx, value in enumerate(unique_values)}\n",
    "            ordinal_df[column] = ordinal_df[column].map(mapping_dict[column])\n",
    "\n",
    "    print(\"Mapping of unique values to ordinal values:\")\n",
    "    for column, mapping in mapping_dict.items():\n",
    "        print(f\"{column}: {mapping}\")\n",
    "\n",
    "    return ordinal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.file_utils.dataframe_utilities import convert_to_ordinal\n",
    "\n",
    "# data_df, map = convert_to_ordinal(data_df, ['City', 'StimMatch' 'Age_Group', 'Subiculum_Group_By_Inflection_Point'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df['StimMatch'] = np.where(data_df['StimMatch']=='Match', 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Define Your Formula\n",
    "\n",
    "This is the formula relating outcome to predictors, and takes the form:\n",
    "- y = B0 + B1 + B2 + B3 + . . . BN\n",
    "\n",
    "It is defined using the columns of your dataframe instead of the variables above:\n",
    "- 'Apples_Picked ~ hours_worked + owns_apple_picking_machine'\n",
    "\n",
    "____\n",
    "**ANOVA**\n",
    "- Tests differences in means for one categorical variable.\n",
    "- formula = 'Outcome ~ C(Group1)'\n",
    "\n",
    "**2-Way ANOVA**\n",
    "- Tests differences in means for two categorical variables without interaction.\n",
    "- formula = 'Outcome ~ C(Group1) + C(Group2)'\n",
    "\n",
    "**2-Way ANOVA with Interaction**\n",
    "- Tests for interaction effects between two categorical variables.\n",
    "- formula = 'Outcome ~ C(Group1) * C(Group2)'\n",
    "\n",
    "**ANCOVA**\n",
    "- Similar to ANOVA, but includes a covariate to control for its effect.\n",
    "- formula = 'Outcome ~ C(Group1) + Covariate'\n",
    "\n",
    "**2-Way ANCOVA**\n",
    "- Extends ANCOVA with two categorical variables and their interaction, controlling for a covariate.\n",
    "- formula = 'Outcome ~ C(Group1) * C(Group2) + Covariate'\n",
    "\n",
    "**Multiple Regression**\n",
    "- Assesses the impact of multiple predictors on an outcome.\n",
    "- formula = 'Outcome ~ Predictor1 + Predictor2'\n",
    "\n",
    "**Simple Linear Regression**\n",
    "- Assesses the impact of a single predictor on an outcome.\n",
    "- formula = 'Outcome ~ Predictor'\n",
    "\n",
    "**MANOVA**\n",
    "- Assesses multiple dependent variables across groups.\n",
    "- Note: Not typically set up with a formula in statsmodels. Requires specialized functions.\n",
    "\n",
    "____\n",
    "Use the printout below to design your formula. \n",
    "- Left of the \"~\" symbol is the thing to be predicted. \n",
    "- Right of the \"~\" symbol are the predictors. \n",
    "- \":\" indicates an interaction between two things. \n",
    "- \"*\" indicates and interactions AND it accounts for the simple effects too. \n",
    "- \"+\" indicates that you want to add another predictor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"Z_Scored_Percent_Cognitive_Improvement ~ Age*Z_Scored_Subiculum_Connectivity_T*Hippocampus_GM_Vol\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Visualize Your Design Matrix\n",
    "\n",
    "This is the explanatory variable half of your regression formula\n",
    "_______________________________________________________\n",
    "Create Design Matrix: Use the create_design_matrix method. You can provide a list of formula variables which correspond to column names in your dataframe.\n",
    "\n",
    "- design_matrix = palm.create_design_matrix(formula_vars=[\"var1\", \"var2\", \"var1*var2\"])\n",
    "- To include interaction terms, use * between variables, like \"var1*var2\".\n",
    "- By default, an intercept will be added unless you set intercept=False\n",
    "- **don't explicitly add the 'intercept' column. I'll do it for you.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intercept</th>\n",
       "      <th>Age</th>\n",
       "      <th>Z_Scored_Subiculum_Connectivity_T</th>\n",
       "      <th>Age:Z_Scored_Subiculum_Connectivity_T</th>\n",
       "      <th>Hippocampus_GM_Vol</th>\n",
       "      <th>Age:Hippocampus_GM_Vol</th>\n",
       "      <th>Z_Scored_Subiculum_Connectivity_T:Hippocampus_GM_Vol</th>\n",
       "      <th>Age:Z_Scored_Subiculum_Connectivity_T:Hippocampus_GM_Vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-1.282630</td>\n",
       "      <td>-79.523056</td>\n",
       "      <td>5.8883</td>\n",
       "      <td>365.0746</td>\n",
       "      <td>-7.552510</td>\n",
       "      <td>-468.255608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-1.760917</td>\n",
       "      <td>-135.590571</td>\n",
       "      <td>3.7634</td>\n",
       "      <td>289.7818</td>\n",
       "      <td>-6.627033</td>\n",
       "      <td>-510.281555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-0.595369</td>\n",
       "      <td>-45.248013</td>\n",
       "      <td>4.8575</td>\n",
       "      <td>369.1700</td>\n",
       "      <td>-2.892003</td>\n",
       "      <td>-219.792225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-0.945206</td>\n",
       "      <td>-61.438363</td>\n",
       "      <td>4.8569</td>\n",
       "      <td>315.6985</td>\n",
       "      <td>-4.590769</td>\n",
       "      <td>-298.399985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.151973</td>\n",
       "      <td>-57.598662</td>\n",
       "      <td>5.9636</td>\n",
       "      <td>298.1800</td>\n",
       "      <td>-6.869908</td>\n",
       "      <td>-343.495380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>-0.590767</td>\n",
       "      <td>-34.264510</td>\n",
       "      <td>7.1449</td>\n",
       "      <td>414.4042</td>\n",
       "      <td>-4.220974</td>\n",
       "      <td>-244.816500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-1.065220</td>\n",
       "      <td>-68.174102</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.4288</td>\n",
       "      <td>-0.007137</td>\n",
       "      <td>-0.456766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-1.108473</td>\n",
       "      <td>-66.508376</td>\n",
       "      <td>8.5035</td>\n",
       "      <td>510.2100</td>\n",
       "      <td>-9.425900</td>\n",
       "      <td>-565.553973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>-0.775406</td>\n",
       "      <td>-40.321097</td>\n",
       "      <td>8.2357</td>\n",
       "      <td>428.2564</td>\n",
       "      <td>-6.386009</td>\n",
       "      <td>-332.072461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-0.690244</td>\n",
       "      <td>-44.175639</td>\n",
       "      <td>7.0928</td>\n",
       "      <td>453.9392</td>\n",
       "      <td>-4.895765</td>\n",
       "      <td>-313.328974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Intercept   Age  Z_Scored_Subiculum_Connectivity_T  \\\n",
       "0         1.0  62.0                          -1.282630   \n",
       "1         1.0  77.0                          -1.760917   \n",
       "2         1.0  76.0                          -0.595369   \n",
       "3         1.0  65.0                          -0.945206   \n",
       "4         1.0  50.0                          -1.151973   \n",
       "..        ...   ...                                ...   \n",
       "68        1.0  58.0                          -0.590767   \n",
       "69        1.0  64.0                          -1.065220   \n",
       "70        1.0  60.0                          -1.108473   \n",
       "72        1.0  52.0                          -0.775406   \n",
       "73        1.0  64.0                          -0.690244   \n",
       "\n",
       "    Age:Z_Scored_Subiculum_Connectivity_T  Hippocampus_GM_Vol  \\\n",
       "0                              -79.523056              5.8883   \n",
       "1                             -135.590571              3.7634   \n",
       "2                              -45.248013              4.8575   \n",
       "3                              -61.438363              4.8569   \n",
       "4                              -57.598662              5.9636   \n",
       "..                                    ...                 ...   \n",
       "68                             -34.264510              7.1449   \n",
       "69                             -68.174102              0.0067   \n",
       "70                             -66.508376              8.5035   \n",
       "72                             -40.321097              8.2357   \n",
       "73                             -44.175639              7.0928   \n",
       "\n",
       "    Age:Hippocampus_GM_Vol  \\\n",
       "0                 365.0746   \n",
       "1                 289.7818   \n",
       "2                 369.1700   \n",
       "3                 315.6985   \n",
       "4                 298.1800   \n",
       "..                     ...   \n",
       "68                414.4042   \n",
       "69                  0.4288   \n",
       "70                510.2100   \n",
       "72                428.2564   \n",
       "73                453.9392   \n",
       "\n",
       "    Z_Scored_Subiculum_Connectivity_T:Hippocampus_GM_Vol  \\\n",
       "0                                           -7.552510      \n",
       "1                                           -6.627033      \n",
       "2                                           -2.892003      \n",
       "3                                           -4.590769      \n",
       "4                                           -6.869908      \n",
       "..                                                ...      \n",
       "68                                          -4.220974      \n",
       "69                                          -0.007137      \n",
       "70                                          -9.425900      \n",
       "72                                          -6.386009      \n",
       "73                                          -4.895765      \n",
       "\n",
       "    Age:Z_Scored_Subiculum_Connectivity_T:Hippocampus_GM_Vol  \n",
       "0                                         -468.255608         \n",
       "1                                         -510.281555         \n",
       "2                                         -219.792225         \n",
       "3                                         -298.399985         \n",
       "4                                         -343.495380         \n",
       "..                                                ...         \n",
       "68                                        -244.816500         \n",
       "69                                          -0.456766         \n",
       "70                                        -565.553973         \n",
       "72                                        -332.072461         \n",
       "73                                        -313.328974         \n",
       "\n",
       "[72 rows x 8 columns]"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the design matrix\n",
    "outcome_matrix, design_matrix = cal_palm.define_design_matrix(formula, data_df)\n",
    "design_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Visualize Your Dependent Variable\n",
    "\n",
    "I have generated this for you based on the formula you provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Z_Scored_Percent_Cognitive_Improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.314066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.841572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.855477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.533109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.106772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1.086636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.103418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>-0.379443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>-0.158855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Z_Scored_Percent_Cognitive_Improvement\n",
       "0                                 0.314066\n",
       "1                                 0.013999\n",
       "2                                -0.841572\n",
       "3                                -1.855477\n",
       "4                                 0.533109\n",
       "..                                     ...\n",
       "68                                0.106772\n",
       "69                                1.086636\n",
       "70                                0.103418\n",
       "72                               -0.379443\n",
       "73                               -0.158855\n",
       "\n",
       "[72 rows x 1 columns]"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Generate Contrasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a Contrast Matrix\n",
    "- This is different from the contrast matrices used in cell-means regressions such as in PALM, but it is much more powerful. \n",
    "\n",
    "\n",
    "\n",
    "For more information on contrast matrices, please refer to this: https://cran.r-project.org/web/packages/codingMatrices/vignettes/codingMatrices.pdf\n",
    "\n",
    "Generally, these drastically effect the results of ANOVA. However, they are mereley a nuisance for a regression.\n",
    "In essence, they assess the coefficients of a given\n",
    "\n",
    "________________________________________________________________\n",
    "A coding matrix (a contrast matrix if it sums to zero) is simply a way of defining what coefficients to evaluate and how to evaluate them. \n",
    "If a coefficient is set to 1 and everything else is set to zero, we are taking the mean of the coefficient's means and assessing if they significantly\n",
    "deviate from zero--IE we are checking if it had a significant impact on the ability to predict the depdendent variable.\n",
    "If a coefficient is set to 1, another is -1, and others are 0, we are assessing how the means of the two coefficients deviate from eachother. \n",
    "If several coefficients are 1 and several others are -1, we are assessing how the group-level means of the two coefficients deviate from eachother.\n",
    "If a group of coefficients are 1, a group is -1, and a group is 0, we are only assessing how the groups +1 and -1 have differing means. \n",
    "\n",
    "1: This value indicates that the corresponding variable's coefficient in the model is included in the contrast. It means you are interested in estimating the effect of that variable.\n",
    "\n",
    "0: This value indicates that the corresponding variable's coefficient in the model is not included in the contrast. It means you are not interested in estimating the effect of that variable.\n",
    "\n",
    "-1: This value indicates that the corresponding variable's coefficient in the model is included in the contrast, but with an opposite sign. It means you are interested in estimating the negative effect of that variable.\n",
    "\n",
    "----------------------------------------------------------------\n",
    "The contrast matrix is typically a matrix with dimensions (number of contrasts) x (number of regression coefficients). Each row of the contrast matrix represents a contrast or comparison you want to test.\n",
    "\n",
    "For example, let's say you have the following regression coefficients in your model:\n",
    "\n",
    "Intercept, Age, connectivity, Age_interaction_connectivity\n",
    "A contrast matric has dimensions of [n_predictors, n_experiments] where each experiment is a contrast\n",
    "\n",
    "If you want to test the hypothesis that the effect of Age is significant, you can set up a contrast matrix with a row that specifies this contrast (actually an averaging vector):\n",
    "```\n",
    "[0,1,0,0]. This is an averaging vector because it sums to 1\n",
    "```\n",
    "This contrast will test the coefficient corresponding to the Age variable against zero.\n",
    "\n",
    "\n",
    "If you want to test the hypothesis that the effect of Age is different from the effect of connectivity, you can set up a contrast matrix with two rows:\n",
    "```\n",
    "[0,1,−1,0]. This is a contrast because it sums to 0\n",
    "```\n",
    "\n",
    "Thus, if you want to see if any given effect is significant compared to the intercept (average), you can use the following contrast matrix:\n",
    "```\n",
    "[1,0,0,0]\n",
    "[-1,1,0,0]\n",
    "[-1,0,1,0]\n",
    "[-1,0,0,1] actually a coding matrix of averaging vectors\n",
    "```\n",
    "\n",
    "The first row tests the coefficient for Age against zero, and the second row tests the coefficient for connectivity against zero. The difference between the two coefficients can then be assessed.\n",
    "_____\n",
    "You can define any number of contrasts in the contrast matrix to test different hypotheses or comparisons of interest in your regression analysis.\n",
    "\n",
    "It's important to note that the specific contrasts you choose depend on your research questions and hypotheses. You should carefully consider the comparisons you want to make and design the contrast matrix accordingly.\n",
    "\n",
    "- Examples:\n",
    "    - [Two Sample T-Test](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/GLM#Two-Group_Difference_.28Two-Sample_Unpaired_T-Test.29)\n",
    "    - [One Sample with Covariate](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/GLM#Single-Group_Average_with_Additional_Covariate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a basic contrast matrix set up to evaluate the significance of each variable.\n",
      "Here is an example of what your contrast matrix looks like as a dataframe: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intercept</th>\n",
       "      <th>Age</th>\n",
       "      <th>Z_Scored_Subiculum_Connectivity_T</th>\n",
       "      <th>Age:Z_Scored_Subiculum_Connectivity_T</th>\n",
       "      <th>Hippocampus_GM_Vol</th>\n",
       "      <th>Age:Hippocampus_GM_Vol</th>\n",
       "      <th>Z_Scored_Subiculum_Connectivity_T:Hippocampus_GM_Vol</th>\n",
       "      <th>Age:Z_Scored_Subiculum_Connectivity_T:Hippocampus_GM_Vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Intercept  Age  Z_Scored_Subiculum_Connectivity_T  \\\n",
       "0          1    0                                  0   \n",
       "1          0    1                                  0   \n",
       "2          0    0                                  1   \n",
       "3          0    0                                  0   \n",
       "4          0    0                                  0   \n",
       "5          0    0                                  0   \n",
       "6          0    0                                  0   \n",
       "7          0    0                                  0   \n",
       "\n",
       "   Age:Z_Scored_Subiculum_Connectivity_T  Hippocampus_GM_Vol  \\\n",
       "0                                      0                   0   \n",
       "1                                      0                   0   \n",
       "2                                      0                   0   \n",
       "3                                      1                   0   \n",
       "4                                      0                   1   \n",
       "5                                      0                   0   \n",
       "6                                      0                   0   \n",
       "7                                      0                   0   \n",
       "\n",
       "   Age:Hippocampus_GM_Vol  \\\n",
       "0                       0   \n",
       "1                       0   \n",
       "2                       0   \n",
       "3                       0   \n",
       "4                       0   \n",
       "5                       1   \n",
       "6                       0   \n",
       "7                       0   \n",
       "\n",
       "   Z_Scored_Subiculum_Connectivity_T:Hippocampus_GM_Vol  \\\n",
       "0                                                  0      \n",
       "1                                                  0      \n",
       "2                                                  0      \n",
       "3                                                  0      \n",
       "4                                                  0      \n",
       "5                                                  0      \n",
       "6                                                  1      \n",
       "7                                                  0      \n",
       "\n",
       "   Age:Z_Scored_Subiculum_Connectivity_T:Hippocampus_GM_Vol  \n",
       "0                                                  0         \n",
       "1                                                  0         \n",
       "2                                                  0         \n",
       "3                                                  0         \n",
       "4                                                  0         \n",
       "5                                                  0         \n",
       "6                                                  0         \n",
       "7                                                  1         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is the same contrast matrix, but as an array.\n",
      "Copy it into a cell below and edit it for more control over your analysis.\n",
      "[\n",
      "    [1, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 1, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 1, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 1, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 1, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 1, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 1, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 1],\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "contrast_matrix = cal_palm.generate_basic_contrast_matrix(design_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit Contrast Matrix Here\n",
    "- The generic contrast matrix will simply check if your Betas are significantly different from the intercept (average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ptrn = oldhigh oldlow younghigh younglow\n",
    "# contrast_matrix = [\n",
    "#     [0, 0, 0, 0],\n",
    "#     [0, 1, 0, 0],\n",
    "#     [0, 0, 1, 0],\n",
    "#     [0, 0, 0, 1],\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalize Contrast Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intercept</th>\n",
       "      <th>Age</th>\n",
       "      <th>Z_Scored_Subiculum_Connectivity_T</th>\n",
       "      <th>Age:Z_Scored_Subiculum_Connectivity_T</th>\n",
       "      <th>Hippocampus_GM_Vol</th>\n",
       "      <th>Age:Hippocampus_GM_Vol</th>\n",
       "      <th>Z_Scored_Subiculum_Connectivity_T:Hippocampus_GM_Vol</th>\n",
       "      <th>Age:Z_Scored_Subiculum_Connectivity_T:Hippocampus_GM_Vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Intercept  Age  Z_Scored_Subiculum_Connectivity_T  \\\n",
       "0          1    0                                  0   \n",
       "1          0    1                                  0   \n",
       "2          0    0                                  1   \n",
       "3          0    0                                  0   \n",
       "4          0    0                                  0   \n",
       "5          0    0                                  0   \n",
       "6          0    0                                  0   \n",
       "7          0    0                                  0   \n",
       "\n",
       "   Age:Z_Scored_Subiculum_Connectivity_T  Hippocampus_GM_Vol  \\\n",
       "0                                      0                   0   \n",
       "1                                      0                   0   \n",
       "2                                      0                   0   \n",
       "3                                      1                   0   \n",
       "4                                      0                   1   \n",
       "5                                      0                   0   \n",
       "6                                      0                   0   \n",
       "7                                      0                   0   \n",
       "\n",
       "   Age:Hippocampus_GM_Vol  \\\n",
       "0                       0   \n",
       "1                       0   \n",
       "2                       0   \n",
       "3                       0   \n",
       "4                       0   \n",
       "5                       1   \n",
       "6                       0   \n",
       "7                       0   \n",
       "\n",
       "   Z_Scored_Subiculum_Connectivity_T:Hippocampus_GM_Vol  \\\n",
       "0                                                  0      \n",
       "1                                                  0      \n",
       "2                                                  0      \n",
       "3                                                  0      \n",
       "4                                                  0      \n",
       "5                                                  0      \n",
       "6                                                  1      \n",
       "7                                                  0      \n",
       "\n",
       "   Age:Z_Scored_Subiculum_Connectivity_T:Hippocampus_GM_Vol  \n",
       "0                                                  0         \n",
       "1                                                  0         \n",
       "2                                                  0         \n",
       "3                                                  0         \n",
       "4                                                  0         \n",
       "5                                                  0         \n",
       "6                                                  0         \n",
       "7                                                  1         "
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contrast_matrix_df = cal_palm.finalize_contrast_matrix(design_matrix=design_matrix, \n",
    "                                                    contrast_matrix=contrast_matrix) \n",
    "contrast_matrix_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 - Define Exchangeability Blocks (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional - Exchangability Blocks\n",
    "- This is optional and for when you are doing a meta-analysis\n",
    "- Not yet implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is just an example, you will have to edit to adapt to your data, \n",
    "### but it should be integers, starting with 1,2,3....\n",
    "\n",
    "# coding_key = {\"Prosopagnosia_w_Yeo1000\": 1,\n",
    "#              \"Corbetta_Lesions\": 1,\n",
    "#              \"DBS_dataset\": 2\n",
    "#              }\n",
    "\n",
    "# eb_matrix = pd.DataFrame()\n",
    "# eb_matrix = clean_df['dataset'].replace(coding_key)\n",
    "# display(eb_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 - Run the Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression Results Are Displayed Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5744562646538028"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.sqrt(.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Results: Ordinary least squares\n",
      "========================================================================================================\n",
      "Model:                     OLS                                         Adj. R-squared:          0.119   \n",
      "Dependent Variable:        Z_Scored_Percent_Cognitive_Improvement      AIC:                     198.9500\n",
      "Date:                      2024-11-10 13:47                            BIC:                     217.1633\n",
      "No. Observations:          72                                          Log-Likelihood:          -91.475 \n",
      "Df Model:                  7                                           F-statistic:             2.372   \n",
      "Df Residuals:              64                                          Prob (F-statistic):      0.0321  \n",
      "R-squared:                 0.206                                       Scale:                   0.83600 \n",
      "--------------------------------------------------------------------------------------------------------\n",
      "                                                          Coef.  Std.Err.    t    P>|t|   [0.025  0.975]\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Intercept                                                -6.5377   3.7286 -1.7534 0.0843 -13.9864 0.9110\n",
      "Age                                                       0.1037   0.0572  1.8124 0.0746  -0.0106 0.2180\n",
      "Z_Scored_Subiculum_Connectivity_T                        -5.8500   4.0195 -1.4554 0.1504 -13.8799 2.1799\n",
      "Age:Z_Scored_Subiculum_Connectivity_T                     0.0854   0.0615  1.3888 0.1697  -0.0374 0.2082\n",
      "Hippocampus_GM_Vol                                        1.0542   0.5833  1.8074 0.0754  -0.1110 2.2195\n",
      "Age:Hippocampus_GM_Vol                                   -0.0170   0.0093 -1.8348 0.0712  -0.0355 0.0015\n",
      "Z_Scored_Subiculum_Connectivity_T:Hippocampus_GM_Vol      0.5214   0.6561  0.7947 0.4297  -0.7893 1.8321\n",
      "Age:Z_Scored_Subiculum_Connectivity_T:Hippocampus_GM_Vol -0.0072   0.0103 -0.7024 0.4849  -0.0279 0.0134\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Omnibus:                           14.777                    Durbin-Watson:                       2.192 \n",
      "Prob(Omnibus):                     0.001                     Jarque-Bera (JB):                    18.330\n",
      "Skew:                              -0.907                    Prob(JB):                            0.000 \n",
      "Kurtosis:                          4.679                     Condition No.:                       15173 \n",
      "========================================================================================================\n",
      "* The condition number is large (2e+04). This might indicate             strong multicollinearity or\n",
      "other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "# Fit the regression model\n",
    "model = sm.OLS(outcome_matrix, design_matrix)\n",
    "results = model.fit()\n",
    "print(results.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the Regression as a Plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import plotly.graph_objects as go\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.genmod.generalized_linear_model import GLMResults\n",
    "\n",
    "class GLMPlot:\n",
    "    def __init__(self, model_results: GLMResults, data_df: pd.DataFrame, formula: str = None):\n",
    "        \"\"\"\n",
    "        Initialize the InteractionPlot class with model results, data, and an optional formula.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model_results : GLMResults\n",
    "            The fitted model from statsmodels.\n",
    "        data_df : pd.DataFrame\n",
    "            The dataframe containing the predictor variables and outcome.\n",
    "        formula : str, optional\n",
    "            A custom formula provided by the user. If None, the model's formula will be used.\n",
    "        \"\"\"\n",
    "        self.model_results = model_results\n",
    "        self.data_df = data_df\n",
    "        self.formula = formula\n",
    "        self.outcome, self.independent_vars = None, None\n",
    "        self.outcome, self.independent_vars = self._parse_formula()\n",
    "\n",
    "    def _parse_formula(self):\n",
    "        \"\"\"\n",
    "        Parse the formula (either user-provided or from the fitted model) to extract the outcome and independent variables.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        outcome : str\n",
    "            The name of the dependent variable (outcome).\n",
    "        independent_vars : list\n",
    "            List of unique independent variables (excluding interactions).\n",
    "        \"\"\"\n",
    "        # Use the custom formula if provided, otherwise use the model's formula\n",
    "        formula = self.formula if self.formula is not None else self.model_results.model.formula\n",
    "        \n",
    "        # Split by '~' to separate outcome from predictors\n",
    "        outcome, predictors = formula.split('~')\n",
    "        outcome = outcome.strip()\n",
    "\n",
    "        # Split the predictors by *, :, and +, and strip each\n",
    "        predictors_list = predictors.replace('*', '+').replace(':', '+').split('+')\n",
    "        predictors_list_stripped = [var.strip() for var in predictors_list]\n",
    "        independent_vars = list(set(predictors_list_stripped))  # Get unique variables\n",
    "        \n",
    "        final_independent_vars_list = []\n",
    "        for i, var in enumerate(predictors_list_stripped): \n",
    "            if var in independent_vars:\n",
    "                final_independent_vars_list.append(var)\n",
    "        return outcome, final_independent_vars_list\n",
    "    \n",
    "    def _create_labels(self):\n",
    "        \"\"\"\n",
    "        Creates a dictionary of labels for each variable extracted from the formula.\n",
    "        Labels are generated by capitalizing each word and replacing underscores with spaces.\n",
    "\n",
    "        This method sets self.labels, which can be used in subsequent plotting functions.\n",
    "        \"\"\"\n",
    "        # Ensure that independent variables and outcome are parsed\n",
    "        if not hasattr(self, 'independent_vars') or not hasattr(self, 'outcome'):\n",
    "            self.outcome, self.independent_vars = self._parse_formula()\n",
    "\n",
    "        # Initialize the labels dictionary\n",
    "        labels = {}\n",
    "\n",
    "        # Format labels for independent variables and outcome\n",
    "        for var in self.independent_vars + [self.outcome]:\n",
    "            formatted_label = ' '.join([word.capitalize() for word in var.split('_')])\n",
    "            labels[var] = formatted_label\n",
    "        return labels\n",
    "\n",
    "\n",
    "    def _get_predictions(self, X_grid, num_slices):\n",
    "        try:\n",
    "            Y_HAT = self.model_results.predict(X_grid).values.reshape(num_slices, num_slices)\n",
    "        except ValueError as e: \n",
    "            if self.formula is not None:\n",
    "                self.model_results = smf.ols(self.formula, data=self.data_df).fit()\n",
    "                Y_HAT = self.model_results.predict(X_grid).values.reshape(num_slices, num_slices)\n",
    "            else:\n",
    "                raise ValueError(f\"\\n Value Error--to solve, pass the formula used for the original model to the init. \\n Traceback: {e}\")\n",
    "        return Y_HAT\n",
    "            \n",
    "    def create_interaction_plot(self, num_slices: int = 100, labels: dict = None, out_dir: str = None, plot_residuals: bool = False):\n",
    "        \"\"\"\n",
    "        Create a 3D plot visualizing the interaction of two predictor variables on the outcome with sliders for additional variables.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        num_slices : int, optional\n",
    "            Number of slices to create in the 3D grid, default is 100.\n",
    "        labels : dict, optional\n",
    "            Custom labels for the axes, default is None.\n",
    "        out_dir : str, optional\n",
    "            Directory to save the output HTML file, default is the current directory.\n",
    "        plot_residuals : bool, optional\n",
    "            If True, plots the data points and residuals, default is False.\n",
    "        \"\"\"\n",
    "        # Function to update the points and residuals on the plot\n",
    "        def plot_points_and_residuals(fig, slider_vals):\n",
    "            # Plot actual data points\n",
    "            fig.add_trace(go.Scatter3d(\n",
    "                x=self.data_df[x1], y=self.data_df[x2], z=self.data_df[self.outcome],\n",
    "                mode='markers', marker=dict(color='red', size=5), name='Actual Points'))\n",
    "\n",
    "            # Calculate and plot residuals (lines from actual to predicted values)\n",
    "            for _, row in self.data_df.iterrows():\n",
    "                x1_val, x2_val, y_val = row[x1], row[x2], row[self.outcome]\n",
    "                slider_data = {var: slider_vals[i] for i, var in enumerate(slider_vars)}\n",
    "                pred_val = self.model_results.predict(pd.DataFrame({**{x1: [x1_val], x2: [x2_val]}, **slider_data})).values[0]\n",
    "                \n",
    "                # Add residual line without showing it in the legend\n",
    "                fig.add_trace(go.Scatter3d(\n",
    "                    x=[x1_val, x1_val], y=[x2_val, x2_val], z=[y_val, pred_val],\n",
    "                    mode='lines', line=dict(color='blue', dash='dash'), name='Residual', showlegend=False))  # Hide residuals from legend\n",
    "        # Internal function to create sliders and position them correctly\n",
    "        def create_sliders(slider_vars, initial_slider_vals):\n",
    "            sliders = []\n",
    "            \n",
    "            # Calculate total padding area\n",
    "            total_padding_space = 0.2  # Reserve 20% of the figure height for sliders\n",
    "            \n",
    "            # Calculate the start position for the first slider and the step\n",
    "            slider_height_start = total_padding_space * 0.01  # Start at 10% of the padding area\n",
    "            slider_height_step = total_padding_space / len(slider_vars)  # Evenly distribute sliders\n",
    "\n",
    "            for i, slider_var in enumerate(slider_vars):\n",
    "                # Define the steps for the slider (using min, max, and median as initial)\n",
    "                slider_steps = [\n",
    "                    dict(method='restyle',\n",
    "                        args=[{'z': [update_grid_with_slider_values([val if j == i else initial_slider_vals[j] for j, _ in enumerate(slider_vars)])]}],\n",
    "                        label=str(round(val, 2)))\n",
    "                    for val in np.linspace(min(self.data_df[slider_var]), max(self.data_df[slider_var]), num=10)\n",
    "                ]\n",
    "\n",
    "                # Add the slider for the variable\n",
    "                sliders.append({\n",
    "                    'active': 5,\n",
    "                    'currentvalue': {\"prefix\": f\"{slider_var}: \"},\n",
    "                    'pad': {\"t\": 0},\n",
    "                    'y': slider_height_start + i * slider_height_step,  # Increment position for each slider relative to the padding area\n",
    "                    'len': 0.9,  # Length of the slider (0 to 1)\n",
    "                    'steps': slider_steps\n",
    "                })\n",
    "            return sliders, total_padding_space\n",
    "        def _add_sliders(fig, sliders, total_padding_space):\n",
    "            # Update the layout with sliders\n",
    "            fig.update_layout(\n",
    "                scene=dict(\n",
    "                    xaxis_title=labels.get('x', x1) if labels else x1,\n",
    "                    yaxis_title=labels.get('y', x2) if labels else x2,\n",
    "                    zaxis_title=labels.get('z', self.outcome) if labels else self.outcome,\n",
    "                    domain=dict(y=[total_padding_space, 1.0])  # Shrink the plot to leave space for sliders\n",
    "                ),\n",
    "                sliders=sliders\n",
    "            )\n",
    "\n",
    "            # Adjust figure height based on the number of sliders\n",
    "            fig.update_layout(\n",
    "                width=1200,\n",
    "                height=800 + len(slider_vars) * 100,  # Adjust height to account for padding and slider count\n",
    "                margin=dict(l=20, r=20, t=20, b=20 + len(slider_vars) * 30)  # Add bottom margin to hold sliders\n",
    "            )\n",
    "            return fig\n",
    "        # The first two variables are plotted on x and y axes, the rest will have sliders\n",
    "        x_vars = self.independent_vars\n",
    "        x1, x2 = x_vars[:2]\n",
    "        slider_vars = x_vars[2:]  # Remaining variables will be controlled via sliders\n",
    "\n",
    "        # Create a grid of values for x1 and x2\n",
    "        x1_vals = np.linspace(min(self.data_df[x1]), max(self.data_df[x1]), num_slices)\n",
    "        x2_vals = np.linspace(min(self.data_df[x2]), max(self.data_df[x2]), num_slices)\n",
    "        x1v, x2v = np.meshgrid(x1_vals, x2_vals)\n",
    "\n",
    "        # Set up the base grid of predictors\n",
    "        X_grid = pd.DataFrame({\n",
    "            x1: x1v.ravel(),\n",
    "            x2: x2v.ravel()\n",
    "        })\n",
    "\n",
    "        # Create the figure\n",
    "        fig = go.Figure()\n",
    "\n",
    "        # Helper function to update the grid with slider values and predict outcomes\n",
    "        def update_grid_with_slider_values(slider_vals):\n",
    "            # Update grid with slider values for the remaining variables\n",
    "            for i, slider_var in enumerate(slider_vars):\n",
    "                X_grid[slider_var] = slider_vals[i]\n",
    "\n",
    "            # Predict outcomes\n",
    "            y_pred = self._get_predictions(X_grid, num_slices)\n",
    "            return y_pred\n",
    "\n",
    "        # Initialize the plot with the default slider values (median of each variable)\n",
    "        initial_slider_vals = [self.data_df[var].median() for var in slider_vars]\n",
    "        y_pred_initial = update_grid_with_slider_values(initial_slider_vals)\n",
    "\n",
    "        # Add the surface plot with initial data\n",
    "        fig.add_trace(go.Surface(z=y_pred_initial, x=x1_vals, y=x2_vals, colorscale='Greys', opacity=0.7))\n",
    "\n",
    "        \n",
    "        # Plot the initial points and residuals if the boolean flag is set\n",
    "        if plot_residuals:\n",
    "            plot_points_and_residuals(fig, initial_slider_vals)\n",
    "\n",
    "        # Create and position sliders\n",
    "        if slider_vars != []:\n",
    "            sliders, total_padding_space = create_sliders(slider_vars, initial_slider_vals)\n",
    "            fig = _add_sliders(fig, sliders, total_padding_space)\n",
    "        else:\n",
    "            fig.update_layout(\n",
    "                scene=dict(\n",
    "                    xaxis_title=labels.get('x', x1) if labels else x1,\n",
    "                    yaxis_title=labels.get('y', x2) if labels else x2,\n",
    "                    zaxis_title=labels.get('z', self.outcome) if labels else self.outcome\n",
    "                )\n",
    "            )\n",
    "            fig.update_layout(width=1200,height=800)\n",
    "\n",
    "        # Save as HTML for interaction\n",
    "        if out_dir is not None:\n",
    "            fig.write_html(os.path.join(out_dir, 'interactive_plot_with_residuals.html'))\n",
    "            print('Saved to file', out_dir)\n",
    "\n",
    "        return fig\n",
    "\n",
    "    def run(self, num_slices: int = 100, out_dir: str = None, plot_residuals: bool = True):\n",
    "        \"\"\"\n",
    "        Orchestrates the entire process: parses the formula, extracts variables, and creates the plot.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        num_slices : int, optional\n",
    "            Number of slices to create in the 3D grid, default is 100.\n",
    "        out_dir : str, optional\n",
    "            Directory to save the output HTML file, default is the current directory.\n",
    "        plot_residuals : bool, optional\n",
    "            If True, plots the data points and residuals, default is False.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'labels'):\n",
    "            labels = self._create_labels()\n",
    "        \n",
    "        # Create the interaction plot\n",
    "        return self.create_interaction_plot(num_slices=num_slices, labels=labels, out_dir=out_dir, plot_residuals=plot_residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from calvin_utils.statistical_utils.regression_visualization import GLMPlot\n",
    "ip = GLMPlot(model_results=results, data_df=data_df, formula=formula)\n",
    "ip.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the Regression as a Forest Plot\n",
    "- This will probably look poor if you ran a regression without standardizing your data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.statistical_utils.statistical_measurements import ForestPlot\n",
    "forest = ForestPlot(model=results, sig_digits=2, out_dir=out_dir, table=False)\n",
    "forest.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize The Model's Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.statistical_utils.statistical_measurements import model_diagnostics\n",
    "model_diagnostics(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the Partial Regression Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.statistical_utils.statistical_measurements import PartialRegressionPlot\n",
    "partial_plot = PartialRegressionPlot(model=results, design_matrix=design_matrix, out_dir=out_dir, palette='Reds')\n",
    "partial_plot = partial_plot.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07 - Run the Contrasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrast Results Are Displayed Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_results = results.t_test(contrast_matrix_df)\n",
    "print(contrast_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08 - Compare the Coefficient Between 2 Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_column = 'Age_Group'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.permutation_analysis_utils.statsmodels_palm import RegressionAnalysis\n",
    "regression_test = RegressionAnalysis(outcome_df=outcome_matrix, design_df=design_matrix, groups_df=data_df[[groups_column]], N=10000, metric='similarity', two_tail=False, out_dir=out_dir)\n",
    "regression_test.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09 - Compare Distribution of T Values Between Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_together=False\n",
    "groups_column = 'Age_Group'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.permutation_analysis_utils.statsmodels_palm import BootstrappedRegressionAnalysis\n",
    "\n",
    "# Create an instance of BootstrappedRegressionAnalysis\n",
    "bootstrapped_regression_test = BootstrappedRegressionAnalysis(outcome_df=outcome_matrix, design_df=design_matrix, groups_df=data_df[[groups_column]], N=10000, out_dir=out_dir, plot_together=plot_together)\n",
    "\n",
    "# Run the bootstrapped regression analysis\n",
    "df1 = bootstrapped_regression_test.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 - Predict Another Dataframe\n",
    "- Can use this to predict data from a second group, such as the 'other_df' defined in \"Step 01, Drop Rows Based on Value of a Column\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "\n",
    "def calculate_ssr(observations, predictions):\n",
    "    \"\"\"\n",
    "    Calculate the regression sum of squares.\n",
    "    This is the sum of squared deviations, with deviation being Y_hat_i - Y_bar\n",
    "    \n",
    "    SSR is a measure used to quantify the variance in the observed data that is not explained by the model. \n",
    "    It is calculated as the sum of the squares of the differences between the observed values and the model's predictions. \n",
    "    The more the 'mean' predicts \n",
    "    A lower SSR indicates a better model fit, meaning the model's predictions are closer to the actual observations.\n",
    "    \n",
    "    SSR = Σ(y_hat - y_bar)^2 \n",
    "    \n",
    "    Parameters:\n",
    "    - observations (array-like): The actual observed outcomes.\n",
    "    - predictions (array-like): The outcomes predicted by the model.\n",
    "    \n",
    "    Returns:\n",
    "    - float: The calculated SSR.\n",
    "    \"\"\"\n",
    "    y_hat = observations\n",
    "    y_bar = np.mean(predictions)\n",
    "    ssr = np.sum((y_hat - y_bar) ** 2)\n",
    "    return ssr\n",
    "\n",
    "def calculate_sse(observations, predictions):\n",
    "    \"\"\"\n",
    "    Calculate the sum of squares due to error (SSE).\n",
    "    \n",
    "    SSE is a measure of the total deviation of the response values from the fit to the response values. \n",
    "    It is calculated as the sum of the squares of the differences between the predicted values and the observed values. \n",
    "    A lower SSE indicates a model that more accurately fits the data.\n",
    "    \n",
    "    SSE = Σ(y - y_hat)^2\n",
    "    \n",
    "    Parameters:\n",
    "    - observations (array-like): The actual observed outcomes.\n",
    "    - predictions (array-like): The outcomes predicted by the model.\n",
    "    \n",
    "    Returns:\n",
    "    - float: The calculated SSE.\n",
    "    \"\"\"\n",
    "    y = observations\n",
    "    y_hat = predictions\n",
    "    sse = np.sum((y - y_hat) ** 2)\n",
    "    return sse\n",
    "\n",
    "def calculate_ssto(observations):\n",
    "    \"\"\"\n",
    "    Calculate the total sum of squares (SSTO).\n",
    "    \n",
    "    SSTO is a measure of the total variance in the observed data and is used as a comparative tool for model evaluation. \n",
    "    It is calculated as the sum of the squares of the differences between the observed values and their overall mean. \n",
    "    SSTO is used in the denominator of the coefficient of determination, R^2, which assesses the fit of the model.\n",
    "    \n",
    "    SSTO = Σ(y - y_bar)^2\n",
    "    \n",
    "    Parameters:\n",
    "    - observations (array-like): The actual observed outcomes.\n",
    "    \n",
    "    Returns:\n",
    "    - float: The calculated SSTO.\n",
    "    \"\"\"\n",
    "    y = observations\n",
    "    y_bar = np.mean(y)\n",
    "    ssto = np.sum((y - y_bar) ** 2)\n",
    "    return ssto\n",
    "\n",
    "\n",
    "def calculate_msr(ssr, num_regressors):\n",
    "    \"\"\"\n",
    "    Calculate the mean square due to regression (MSR).\n",
    "    \n",
    "    MSR is a measure of the variation explained by the independent variables in the model. It is calculated as the \n",
    "    sum of squared residuals (SSR) divided by the degrees of freedom, which is the number of independent variables (regressors) minus one.\n",
    "    A higher MSR indicates that the model explains a greater amount of variation in the outcome variable.\n",
    "    \n",
    "    MSR = SSR / (number of regressors - 1)\n",
    "    \n",
    "    Parameters:\n",
    "    - ssr (float): The sum of squared residuals from the regression model.\n",
    "    - num_regressors (int): The number of independent variables in the model.\n",
    "    \n",
    "    Returns:\n",
    "    - float: The calculated MSR.\n",
    "    \"\"\"\n",
    "    return ssr / (num_regressors - 1)\n",
    "\n",
    "def calculate_mse(sse, num_regressors, num_observations):\n",
    "    \"\"\"\n",
    "    Calculate the mean square error (MSE).\n",
    "    \n",
    "    MSE is a measure of the average of the squares of the errors, that is, the average squared difference between the observed actual outcomes and the outcomes predicted by the model. It is calculated as the sum of squared errors (SSE) divided by the degrees of freedom, which is the number of observations minus the number of regressors.\n",
    "    A lower MSE indicates a better fit of the model to the data.\n",
    "    \n",
    "    MSE = SSE / (number of observations - number of regressors)\n",
    "    \n",
    "    Parameters:\n",
    "    - sse (float): The sum of squared errors from the regression model.\n",
    "    - num_regressors (int): The number of independent variables in the model.\n",
    "    - num_observations (int): The number of observations in the data set.\n",
    "    \n",
    "    Returns:\n",
    "    - float: The calculated MSE.\n",
    "    \"\"\"\n",
    "    return sse / (num_observations - num_regressors)\n",
    "\n",
    "def calculate_f_stat(msr, mse, num_regressors, num_observations):\n",
    "    \"\"\"\n",
    "    Calculate the F-statistic.\n",
    "    \n",
    "    The F-statistic is used to compare statistical models that have been fitted to a data set in order to identify the model that best fits the population from which the data were sampled. It is the ratio of the mean square due to regression (MSR) to the mean square error (MSE).\n",
    "    \n",
    "    The F-statistic follows the F-distribution under the null hypothesis that the model with no independent variables fits the data as well as your model. A higher F-statistic implies that the null hypothesis is false, and your model adds value in explaining the variation in the data.\n",
    "    \n",
    "    F = MSR / MSE\n",
    "    \n",
    "    Parameters:\n",
    "    - msr (float): The mean square due to regression.\n",
    "    - mse (float): The mean square error.\n",
    "    \n",
    "    Returns:\n",
    "    - float: The calculated F-statistic.\n",
    "    - float: The p-value from the F-distribution.\n",
    "    \"\"\"\n",
    "    f_stat = msr / mse\n",
    "    # The degrees of freedom for the numerator (dfn) is the number of independent variables (regressors).\n",
    "    # The degrees of freedom for the denominator (dfd) is the total number of observations minus the number of independent variables minus 1.\n",
    "    # These values need to be defined or calculated outside of this function.\n",
    "    dfn = num_regressors - 1\n",
    "    dfd = num_observations - num_regressors \n",
    "    p_value = f.sf(f_stat, dfn, dfd)\n",
    "    return f_stat, p_value\n",
    "\n",
    "def run_goodness_of_fit(target_outcome_matrix, predictions, target_design_matrix):\n",
    "    \"\"\"\n",
    "    Calculate the F-statistic and p-value for a linear regression model.\n",
    "\n",
    "    Parameters:\n",
    "    - target_outcome_matrix (array-like): The actual observed outcomes (Y_actual).\n",
    "    - predictions (array-like): The outcomes predicted by the model (Y_hat).\n",
    "\n",
    "    Returns:\n",
    "    - float: The calculated F-statistic.\n",
    "    - float: The p-value from the F-distribution.\n",
    "    \"\"\"\n",
    "    # Calculate the regression sum of squares (SSR).\n",
    "    ssr = calculate_ssr(target_outcome_matrix, predictions)\n",
    "\n",
    "    # Calculate the sum of squares due to error (SSE).\n",
    "    sse = calculate_sse(target_outcome_matrix, predictions)\n",
    "\n",
    "    # Calculate the number of regressors and observations.\n",
    "    num_regressors = target_design_matrix.shape[1]\n",
    "    num_observations = len(target_outcome_matrix)\n",
    "\n",
    "    # Calculate the mean square due to regression (MSR).\n",
    "    msr = calculate_msr(ssr, num_regressors)\n",
    "\n",
    "    # Calculate the mean square error (MSE).\n",
    "    mse = calculate_mse(sse, num_regressors, num_observations)\n",
    "\n",
    "    # Calculate the F-statistic and p-value.\n",
    "    f_stat, p_value = calculate_f_stat(msr, mse, num_regressors, num_observations)\n",
    "\n",
    "    return f_stat, p_value\n",
    "\n",
    "def calculate_r_squared(observations, predictions):\n",
    "    \"\"\"\n",
    "    Calculate the R-squared (coefficient of determination) value.\n",
    "\n",
    "    R-squared measures the proportion of the variance in the observed outcomes that is explained by the predictions.\n",
    "\n",
    "    R-squared = 1 - (SSE / SSTO)\n",
    "\n",
    "    Parameters:\n",
    "    - observations (array-like): The actual observed outcomes.\n",
    "    - predictions (array-like): The outcomes predicted by the model.\n",
    "\n",
    "    Returns:\n",
    "    - float: The calculated R-squared value.\n",
    "    \"\"\"\n",
    "    # Calculate SSE (Sum of Squares of Errors)\n",
    "    sse = np.sum((observations - predictions) ** 2)\n",
    "\n",
    "    # Calculate SSTO (Total Sum of Squares)\n",
    "    y_mean = np.mean(observations)\n",
    "    ssto = np.sum((observations - y_mean) ** 2)\n",
    "\n",
    "    # Calculate R-squared\n",
    "    r_squared = 1 - (sse / ssto)\n",
    "    \n",
    "    return r_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a new Dataframe to predict upon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.permutation_analysis_utils.statsmodels_palm import CalvinStatsmodelsPalm\n",
    "# Instantiate the PalmPrepararation class\n",
    "cal_palm = CalvinStatsmodelsPalm(input_csv_path=input_csv_path, output_dir=out_dir, sheet=sheet)\n",
    "# Call the process_nifti_paths method\n",
    "data_df = cal_palm.read_and_display_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'Cohort'  # The column you'd like to evaluate\n",
    "condition = 'not'  # The condition to check ('equal', 'above', 'below', 'not')\n",
    "value = 0 # The value to drop if T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df, other_df = cal_palm.drop_rows_based_on_value(column, condition, value)\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the design matrix\n",
    "target_outcome_matrix, target_design_matrix = cal_palm.define_design_matrix(formula, data_df)\n",
    "predictions = results.predict(target_design_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract F-Test for Goodness of Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_stat, p_value = run_goodness_of_fit(target_outcome_matrix=target_outcome_matrix.to_numpy().flatten(), \n",
    "                    predictions=predictions.to_numpy().flatten(), \n",
    "                    target_design_matrix=target_design_matrix)\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract R-Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "r_squared = calculate_r_squared(target_outcome_matrix.to_numpy().flatten(), predictions.to_numpy().flatten())\n",
    "print(f\"R-squared: {r_squared:.4f}\")\n",
    "r, p = pearsonr(target_outcome_matrix.to_numpy().flatten(), predictions.to_numpy().flatten())\n",
    "print(f\"PearsonR R-squared: {r*r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(target_outcome_matrix, predictions)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(target_outcome_matrix, predictions)\n",
    "\n",
    "# Print the results\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot The Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_scatter_with_f_stat_in_title(target_outcome_matrix, predictions, f_stat, p_value, out_dir=None):\n",
    "    \"\"\"\n",
    "    Create a scatterplot of predicted vs. observed values with F-statistic and p-value in the title.\n",
    "\n",
    "    Parameters:\n",
    "    - target_outcome_matrix (array-like): The actual observed outcomes.\n",
    "    - predictions (array-like): The outcomes predicted by the model.\n",
    "    - f_stat (float): The F-statistic value.\n",
    "    - p_value (float): The p-value.\n",
    "\n",
    "    Returns:\n",
    "    - None (displays the plot)\n",
    "    \"\"\"\n",
    "    # Create a scatterplot using Seaborn\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=predictions,\n",
    "                    y=target_outcome_matrix,\n",
    "                    label='Predicted vs. Observed')\n",
    "\n",
    "    # Add a diagonal line\n",
    "    xlim = plt.xlim()  # Get current X-axis limits\n",
    "    ylim = plt.ylim()  # Get current Y-axis limits\n",
    "    min_limit = min(xlim[0], ylim[0])\n",
    "    max_limit = max(xlim[1], ylim[1])\n",
    "    plt.plot([min_limit, max_limit], [min_limit, max_limit], linestyle='--', color='gray', label='Perfect Fit')\n",
    "\n",
    "    # Add labels and title with F-statistic and p-value\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Observed Values')\n",
    "    plt.title(f'Scatterplot of Predicted vs. Observed Values\\nF-statistic: {f_stat:.2f}, p-value: {p_value:.4f}')\n",
    "\n",
    "    # Set axis limits\n",
    "    plt.xlim(min_limit, max_limit)\n",
    "    plt.ylim(min_limit, max_limit)\n",
    "\n",
    "    # Show legend\n",
    "    plt.legend()\n",
    "    \n",
    "    if out_dir:\n",
    "        # Save the figure\n",
    "        plt.savefig(f\"{out_dir}/predicted_plot.png\", bbox_inches='tight')\n",
    "        plt.savefig(f\"{out_dir}/predicted_plot.svg\", bbox_inches='tight')\n",
    "        print(f'Saved to {out_dir}/predicted_plot.svg')\n",
    "\n",
    "    # Display the plot\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "def plot_residuals(target_outcome_matrix, predictions, f_stat, p_value, out_dir=None):\n",
    "    \"\"\"\n",
    "    Create a scatterplot of residuals with F-statistic and p-value in the title and save it.\n",
    "\n",
    "    Parameters:\n",
    "    - target_outcome_matrix (array-like): The actual observed outcomes.\n",
    "    - predictions (array-like): The outcomes predicted by the model.\n",
    "    - f_stat (float): The F-statistic value.\n",
    "    - p_value (float): The p-value.\n",
    "    - out_dir (str, optional): The directory to save the plot. If None, the plot won't be saved.\n",
    "\n",
    "    Returns:\n",
    "    - None (displays the plot)\n",
    "    \"\"\"\n",
    "    # Calculate residuals\n",
    "    residuals = target_outcome_matrix - predictions\n",
    "\n",
    "    # Create a scatterplot of residuals\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=predictions,\n",
    "                    y=residuals,\n",
    "                    label='Residuals vs. Predicted')\n",
    "\n",
    "    # Calculate y-axis limits\n",
    "    y_lim_min = min(-3, np.min(residuals) - 0.5)\n",
    "    y_lim_max = max(3, np.max(residuals) + 0.5)\n",
    "\n",
    "    # Set y-axis limits\n",
    "    plt.ylim(y_lim_min, y_lim_max)\n",
    "\n",
    "    # Add a horizontal line at y=0\n",
    "    plt.axhline(0, color='gray', linestyle='--', label='Zero Residual')\n",
    "\n",
    "    # Add labels and title with F-statistic and p-value\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.title(f'Scatterplot of Residuals vs. Predicted Values\\nF-statistic: {f_stat:.2f}, p-value: {p_value:.4f}')\n",
    "\n",
    "    # Show legend\n",
    "    plt.legend()\n",
    "\n",
    "    if out_dir:\n",
    "        # Save the figure\n",
    "        plt.savefig(f\"{out_dir}/residuals_plot.png\", bbox_inches='tight')\n",
    "        plt.savefig(f\"{out_dir}/residuals_plot.svg\", bbox_inches='tight')\n",
    "        print(f'Saved to {out_dir}/residuals_plot.svg')\n",
    "\n",
    "    # Display the plot\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residuals Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_residuals(target_outcome_matrix.to_numpy().flatten(), predictions.to_numpy().flatten(), f_stat, p_value, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter_with_f_stat_in_title(target_outcome_matrix.to_numpy().flatten(), predictions.to_numpy().flatten(), f_stat, p_value, out_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11 - Visualize 2-Way ANOVA (Model-Free)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate an Interaction Plot Based on the Raw Data (Model-Free)\n",
    "- data_df (pd.DataFrame): DataFrame containing the data.\n",
    "- group1_column (str): Name of the first grouping column (categorical).\n",
    "- group2_column (str): Name of the second grouping column (categorical).\n",
    "- outcome_column (str): Name of the outcome column (continuous)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df=data_df\n",
    "group_1='Age_Group'\n",
    "group_2='Subiculum_Group_By_24'\n",
    "outcome_column='City'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.statistical_utils.anova_visualization import ModelFreeInteractionPlot\n",
    "summary_df = ModelFreeInteractionPlot.calculate_means_and_sem(data_df, group_1, group_2, outcome_column)\n",
    "# Ensure Data is Okay\n",
    "ModelFreeInteractionPlot.diagnose_data(data_df, group_1, group_2, outcome_column)\n",
    "# Plot\n",
    "ModelFreeInteractionPlot.plot_interaction_error_bar(summary_df, group_1, group_2, out_dir=out_dir)\n",
    "# Test for differences in group_1 at each level of group_2. \n",
    "print(ModelFreeInteractionPlot.perform_kruskal_wallis_test(data_df, group_1, group_2, outcome_column))\n",
    "# Test for significant differences \n",
    "print(ModelFreeInteractionPlot.perform_contrast(data_df, contrast_column=group_1, outcome_column=outcome_column))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize a Modelled ANOVA (Predictions upon Existing Data Points)\n",
    "- The class expects the a dataframe containing all of the columns with your regressors (or more columns)\n",
    "- fit a formula onto a model\n",
    "    - Example: 'Z_Scored_Percent_Cognitive_Improvement ~ Age_Group*Subiculum_Group_By_24 + City'\n",
    "- Then, you must plot model's predictions of the observed data\n",
    "    - Mandatory:\n",
    "        - x_var: the factors\n",
    "        - hue_var: the levels\n",
    "    - Optional:\n",
    "        - cohort_var: additional traces for cohorts\n",
    "        - y: defaults to 'predictions', and sets the y-axis to the estimated marginal means of the model. Can set to another column in data_df. \n",
    "- Bars represent 95%CI\n",
    "- note: you do not need the input variables to be part of the dataframe. You can model predictions then split by other variables!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.statistical_utils.anova_visualization import QuickANOVAPlot\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "model = smf.ols(formula, data=data_df).fit()\n",
    "\n",
    "quick_plot = QuickANOVAPlot(model, data_df, out_dir=out_dir)\n",
    "quick_plot.make_predictions()\n",
    "quick_plot.plot_predictions(x_var='CTh_MTL', hue_var='CTh_MTL', cohort_var=None, y='TOTAL11', error_bar='se')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize as a Bar Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_plot.plot_bar(x_var='Subiculum_Group_By_Inflection_Point', hue_var='City', cohort_var=None, y='predictions', error_bar=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the Regression Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 - Visualize a GLM's Predictions Across a Range of Potential Data (AKA Profile Plot or Marginal Plot)\n",
    "- **this is pretty complex stuff, so be sure to read up on Marginals**\n",
    "- This is a plot which generates an estimated marginal estimate across a set number of categories/factors\n",
    "    - This is similar to a marginal mean, but a marginal mean provides the \n",
    "- Do **not** set any values to a list of strings. If you want to use categorical data, encode the categories as ordinal values and re-run the model. Then set the categories in the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marginal_scenarios_dict = {'Age_Group': [0, 1],'City':[0, 1], 'Z_Scored_Subiculum_Connectivity_T':['continuous']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.statistical_utils.statistical_measurements import GLMMarginalsPlot\n",
    "factor_plot = GLMMarginalsPlot(formula, data_df, model=results, data_range=None, marginal_scenarios_dict=marginal_scenarios_dict, variance_bars=None, out_dir=out_dir)\n",
    "factor_plot.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize a GLM's Predictions at Points in Data (Estimated Marginal Means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interaction Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the column names used to generate the original formula. The order of the list determines how variables are categorized in the following interaction plot. \n",
    "- This expects the formula to have defined categorical variables, like:\n",
    "    - Z_Scored_Percent_Cognitive_Improvement ~ C(Subiculum_Group_By_24)*Age + C(City)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interaction_plot_dynamic(emm_df, categorical_vars, out_dir=None):\n",
    "    \"\"\"\n",
    "    Create an interaction plot for 2 or 3 categorical variables in emm_df.\n",
    "\n",
    "    Parameters:\n",
    "    - emm_df: DataFrame containing the data\n",
    "    - categorical_vars: List of strings specifying the categorical variables\n",
    "    - ms: Marker size for the plot (default is 10)\n",
    "    \"\"\"\n",
    "    # Check if we have 2 or 3 categorical variables\n",
    "    if len(categorical_vars) == 2:\n",
    "        plot_interaction_2_vars(emm_df, categorical_vars, out_dir)\n",
    "    elif len(categorical_vars) == 3:\n",
    "        self.plot_interaction_3_vars(emm_df, categorical_vars,out_dir)\n",
    "    else:\n",
    "        print(\"This function supports only 2 or 3 categorical variables.\")\n",
    "        \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_interaction_2_vars(emm_df, categorical_vars, output_directory=None, color_list = None):\n",
    "    \"\"\"\n",
    "    Plots an interaction bar plot for two categorical variables in an ANOVA setup.\n",
    "\n",
    "    Parameters:\n",
    "        emm_df (DataFrame): The DataFrame containing the data.\n",
    "        categorical_vars (list): A list of two categorical variable names to plot.\n",
    "        color_list (list, optional): List of colors for the bars. If None, defaults to tab10 colormap.\n",
    "        output_directory (str, optional): Directory to save the plot. If None, plot is not saved.\n",
    "    \"\"\"\n",
    "    # Set up the color palette\n",
    "    if color_list is None:\n",
    "        color_palette = sns.color_palette(\"tab10\", len(emm_df[categorical_vars[1]].unique()))\n",
    "    else:\n",
    "        color_palette = sns.color_palette(color_list, len(emm_df[categorical_vars[1]].unique()))\n",
    "\n",
    "    # color_palette = sns.color_palette(\"tab10\")\n",
    "    \n",
    "    # Initialize the plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Create the bar plot\n",
    "    sns.barplot(\n",
    "        data=emm_df,\n",
    "        x=categorical_vars[0],\n",
    "        y='predictions',\n",
    "        hue=categorical_vars[1],\n",
    "        palette=color_palette\n",
    "    )\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.xlabel(categorical_vars[0])\n",
    "    plt.ylabel('Predictions')\n",
    "    plt.title(f'Interaction Bar Plot of Predicted EMMs ({categorical_vars[1]})')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot if output_directory is provided\n",
    "    if output_directory:\n",
    "        plt.savefig(f\"{output_directory}/interaction_bar_plot.png\", bbox_inches='tight')\n",
    "        plt.savefig(f\"{output_directory}/interaction_bar_plot.svg\", bbox_inches='tight')\n",
    "        print(f'Saved to {output_directory}/interaction_bar_plot.png and {output_directory}/interaction_bar_plot.svg')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.statistical_utils.statistical_measurements import EstimatedMarginalMean\n",
    "\n",
    "interaction_plot = EstimatedMarginalMean(formula, data_df, model=results)\n",
    "interaction_plot.extract_unique_variables()\n",
    "interaction_plot.create_emm_df(plus_2_stdev=True, minus_2_stdev=False)\n",
    "interaction_plot.define_design_matrix()\n",
    "interaction_plot.predict_emm_design_df()\n",
    "categorical_columns = interaction_plot.variables_df[interaction_plot.variables_df['Type'] == 'categorical']['Variable'].tolist()\n",
    "\n",
    "create_interaction_plot_dynamic(emm_df=interaction_plot.emm_df.dropna(), categorical_vars=categorical_columns, out_dir=out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_plot.emm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 - Get Zero Points of Each Coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The zero point is the point where the coefficient cross zero.\n",
    "When the response topology has a saddle point, the zero point indicates where the saddle is. \n",
    "Technically, the linear regression's formula does not have a saddle point. \n",
    "However, if you rotate the response topology which exhibits a saddle point by 45 degrees, you will observe a saddle point in orientation with the Cartesian plane. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.statistical_utils.calculus_utils import find_zero_point_of_coefficients\n",
    "find_zero_point_of_coefficients(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13 - Compare 2 Different Sets of Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Nested Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.api import anova_lm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "smaller_formula = 'TOTALMOD ~ CSFGM_MTL + CSFGM_Frontal + CSFGM_Occipital + CSFGM_Parietal + CSFGM_Temporal'\n",
    "\n",
    "larger_formula = 'TOTALMOD ~ CSF_MTL + CSF_Frontal + CSF_Occipital + CSF_Parietal + CSF_Temporal'\n",
    "\n",
    "#----------------------------------------------------------------DO NOT TOUCH!----------------------------------------------------------------\n",
    "table1 = anova_lm(smf.ols(smaller_formula, data=data_df).fit(), smf.ols(larger_formula, data=data_df).fit())\n",
    "print(table1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Un-nested Models\n",
    "- Need to employ permutation because there is no existing method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula1 = 'TOTALMOD ~ CSFGM_MTL + CSFGM_Frontal + CSFGM_Occipital + CSFGM_Parietal + CSFGM_Temporal'\n",
    "formula2 = 'TOTALMOD ~ CSF_MTL + CSF_Frontal + CSF_Occipital + CSF_Parietal + CSF_Temporal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Original R^2 values from the models\n",
    "r2_model1 = smf.ols(formula1, data=data_df).fit().rsquared\n",
    "r2_model2 = smf.ols(formula2, data=data_df).fit().rsquared\n",
    "\n",
    "# Difference in R of original models\n",
    "original_diff = r2_model1 - r2_model2\n",
    "\n",
    "# Number of permutations\n",
    "n_permutations = 1000\n",
    "\n",
    "# Store differences from permutations\n",
    "perm_diffs = []\n",
    "for i in tqdm(range(n_permutations)):\n",
    "    # Permute the outcome variable\n",
    "    data_df_permuted = data_df.copy()\n",
    "    data_df_permuted['TOTALMOD'] = np.random.permutation(data_df_permuted['TOTALMOD'].values)\n",
    "    \n",
    "    # Fit the models to the permuted dataset and calculate R^2\n",
    "    perm_model1 = smf.ols(formula1, data=data_df_permuted).fit()\n",
    "    perm_model2 = smf.ols(formula2, data=data_df_permuted).fit()\n",
    "    \n",
    "    # Difference in R^2 for the permuted models\n",
    "    perm_diff = perm_model1.rsquared - perm_model2.rsquared\n",
    "    \n",
    "    # Store the difference\n",
    "    perm_diffs.append(perm_diff)\n",
    "\n",
    "# Calculate the p-value as the proportion of permuted differences\n",
    "# that are greater than or equal to the observed difference\n",
    "p_value = np.mean([abs(diff) >= abs(original_diff)for diff in perm_diffs])\n",
    "print(f\"Original R Difference: {original_diff}\")\n",
    "print(f\"P-value from permutation test: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate Uncertainty Around a Regression Metric with Bootstrapping\n",
    "- R-squared approach visualized below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import statsmodels.api as sm\n",
    "from sklearn.utils import resample\n",
    "\n",
    "def bootstrap_r_squared(data: pd.DataFrame, formula: str, n_bootstraps: int = 1000):\n",
    "    \"\"\"\n",
    "    Perform bootstrap resampling to calculate the 95% confidence interval for R-squared.\n",
    "\n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The primary dataframe containing the data.\n",
    "    - formula (str): The formula specifying the model (e.g., 'Y ~ X1 + X2').\n",
    "    - n_bootstraps (int): The number of bootstrap samples (default is 10,000).\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary containing the original R-squared, the mean R-squared, the 95% confidence interval,\n",
    "            the standard deviation, and the standard error of R-squared.\n",
    "    \"\"\"\n",
    "    # Original model\n",
    "    model = sm.OLS.from_formula(formula, data)\n",
    "    original_results = model.fit()\n",
    "    print(\"Original R^2:\", original_results.rsquared)\n",
    "\n",
    "    # Bootstrapping\n",
    "    r_squared_values = []\n",
    "    for _ in tqdm(range(n_bootstraps)):\n",
    "        # Resample the dataframe with replacement\n",
    "        boot_data = resample(data, replace=True, n_samples=len(data))\n",
    "        \n",
    "        # Fit the model to the bootstrapped sample\n",
    "        boot_model = sm.OLS.from_formula(formula, boot_data)\n",
    "        boot_results = boot_model.fit()\n",
    "        \n",
    "        # Store the R-squared\n",
    "        r_squared_values.append(boot_results.rsquared)\n",
    "\n",
    "    # Calculate the 95% confidence interval for R^2\n",
    "    r_squared_lower = np.percentile(r_squared_values, 2.5)\n",
    "    r_squared_upper = np.percentile(r_squared_values, 97.5)\n",
    "\n",
    "    result = {\n",
    "        \"Original R^2\": original_results.rsquared,\n",
    "        \"Mean R^2\": np.mean(r_squared_values),\n",
    "        \"95% CI\": (r_squared_lower, r_squared_upper),\n",
    "        \"Stdev\": np.std(r_squared_values),\n",
    "        \"StdErr R^2\": np.std(r_squared_values) / np.sqrt(len(r_squared_values))\n",
    "    }\n",
    "\n",
    "    print(f\"95% CI for R^2: ({r_squared_lower:.4f}, {r_squared_upper:.4f})\")\n",
    "    print(f\"Mean R^2: {np.mean(r_squared_values)} | Stdev: {np.std(r_squared_values)} | StdErr R^2: {np.std(r_squared_values)/np.sqrt(len(r_squared_values))}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "bootstrap_r_squared(data_df, formula5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Number of bootstrap samples\n",
    "n_bootstraps = 10000\n",
    "r_squared_values = []\n",
    "\n",
    "# Original model\n",
    "model = sm.OLS(outcome_matrix, design_matrix)\n",
    "original_results = model.fit()\n",
    "print(\"Original R^2:\", original_results.rsquared)\n",
    "\n",
    "# Bootstrapping\n",
    "for _ in range(n_bootstraps):\n",
    "    # Resample the indices with replacement\n",
    "    boot_indices = np.random.choice(len(outcome_matrix), size=len(outcome_matrix), replace=True)\n",
    "    if isinstance(outcome_matrix, pd.DataFrame):\n",
    "        boot_outcome = outcome_matrix.iloc[boot_indices]\n",
    "    else:\n",
    "        boot_outcome = outcome_matrix[boot_indices]\n",
    "    \n",
    "    if isinstance(design_matrix, pd.DataFrame):\n",
    "        boot_design = design_matrix.iloc[boot_indices]\n",
    "    else:\n",
    "        boot_design = design_matrix[boot_indices]\n",
    "\n",
    "    # Fit the model to the bootstrapped sample\n",
    "    boot_model = sm.OLS(boot_outcome, boot_design)\n",
    "    boot_results = boot_model.fit()\n",
    "    \n",
    "    # Store the R-squared\n",
    "    r_squared_values.append(boot_results.rsquared)\n",
    "\n",
    "# Calculate the 95% confidence interval for R^2\n",
    "r_squared_lower = np.percentile(r_squared_values, 2.5)\n",
    "r_squared_upper = np.percentile(r_squared_values, 97.5)\n",
    "\n",
    "print(f\"95% CI for R^2: ({r_squared_lower:.4f}, {r_squared_upper:.4f})\")\n",
    "print(f\"Mean R^2: {np.mean(r_squared_values)} | Stdev: {np.std(r_squared_values)} | StdErr R^2: {np.std(r_squared_values)/len(r_squared_values)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import t\n",
    "\n",
    "def two_sample_t_test(n1, n2, mean1, mean2, stdev1, stdev2):\n",
    "    t_stat = (mean1 - mean2) / np.sqrt((stdev1**2/n1 + stdev2**2/n2))\n",
    "    \n",
    "    dof = n1 + n2 - 2\n",
    "    p_value = 2 * (1 - t.cdf(np.abs(t_stat), dof))\n",
    "    return t_stat, p_value\n",
    "\n",
    "t_stat, p_value = two_sample_t_test(n1=10, n2=10, mean1=0.16, mean2=0.23, stdev1=0.09, stdev2=0.09)\n",
    "print(\"t-statistic:\", t_stat)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(.11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimlab_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
