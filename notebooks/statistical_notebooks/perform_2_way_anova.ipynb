{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import platform\n",
    "import pathlib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Paths Input Here\n",
    "analysis = '2_way_anova'\n",
    "if platform.uname().system == 'Darwin': #------------------------------Mac OS X---------------------------------------------------------------\n",
    "    conn_path = r'/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Work/KiTH_Solutions/Research/Clinical Trial/study_metadata/all_performances.xlsx'\n",
    "    # out_dir = os.path.join(os.path.dirname(conn_path), f'{analysis}')\n",
    "    out_dir = '/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Work/KiTH_Solutions/Research/Clinical Trial/final_results'\n",
    "    print('I will save to:', out_dir)\n",
    "    print('I have set pathnames in the Mac style')\n",
    "else: #----------------------------------------------------------------Windows----------------------------------------------------------------\n",
    "    conn_path = r'C:\\Users\\calvin.howard\\Dropbox (Partners HealthCare)\\memory\\analyses\\roi-roi_correl\\matrix_corrMx_AvgR.csv'\n",
    "    clin_path = r'C:\\Users\\calvin.howard\\Dropbox (Partners HealthCare)\\memory\\patient_data\\AD_Clinical_Data_CDR_ADAS_COG_13.xlsx'\n",
    "    # clin_path = 'path to clinical values'\n",
    "    out_dir = r'C:\\Users\\calvin.howard\\Dropbox (Partners HealthCare)\\memory\\analyses\\roi-roi_correl\\stats'\n",
    "    #out_dir = r'path to out dir here'\n",
    "    x_roi_names = r'C:\\Users\\calvin.howard\\Dropbox (Partners HealthCare)\\memory\\analyses\\roi-roi_correl\\matrix_corrMx_names.csv'\n",
    "    #roi_names = '<path to roi name location>'\n",
    "    print('I have set pathnames in the Windows style')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#----------------------------------------------------------------user input above----------------------------------------------------------------\n",
    "sheet_name = 'study_results'\n",
    "\n",
    "if os.path.basename(conn_path).split('.')[1] == 'csv':\n",
    "    data_df = pd.read_csv(conn_path)\n",
    "else:\n",
    "    data_df = pd.read_excel(conn_path, sheet_name=sheet_name)\n",
    "\n",
    "#Prepare the dataframe for statsmodels\n",
    "data_df = data_df.reset_index(drop=True)\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Rows to Assess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df[data_df['Cohort'] != 3]\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Columns to Assess -- Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df = data_df.loc[:, ['Total', 'Total.1', 'Completed']]\n",
    "# data_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove any subjects which should not be included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier_index=[11, 47, 48, 49]\n",
    "# data_df = data_df.drop(index=outlier_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the Data -- Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data_df.columns.to_list():\n",
    "    try:\n",
    "        data_df[col] = (data_df[col])/(data_df[col].max())\n",
    "    except:\n",
    "        print(f'Cannot normalize {col}')\n",
    "data_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the Data -- Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize you data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler() \n",
    "data_df.iloc[:,:] = scaler.fit_transform(data_df.iloc[:,:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop NANs\n",
    "if data_df.isna().any().any():\n",
    "    print('We have found NaNs in your data.')\n",
    "    print('You should handle the NaNs in your dataframe with this code: \\n \"data_df.dropna(inplace=True)\"')\n",
    "else:\n",
    "    print('No NaNs found in dataframe')\n",
    "# data_df.dropna(inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulation, Creation, and Binzarization of Variables \n",
    "- This is mandatory data pre-processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename a column to 'outcome' -- mandatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set continuous variable of interest the name 'outcome'\n",
    "outcome = '% Change from baseline (ADAS-Cog11)'\n",
    "rename = data_df.pop(outcome)\n",
    "data_df['outcome'] = rename\n",
    "data_df.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new column -- optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manually Create a new variable\n",
    "new_column = 'Stimulation_Atrophy_Match'\n",
    "col1 = 'Subiculum Connectivity'\n",
    "col2 = 'Subiculum Grey Matter'\n",
    "\n",
    "#If you want to binarize the new variable, enter here\n",
    "binarize_new_column = True\n",
    "binarizing_threshold_choices = ['0', 'np.mean(data_df[new_column])'] #don't touch this. \n",
    "binarizing_choice = binarizing_threshold_choices[0] #Choice between zero and mean\n",
    "under_mean = 'Mismatch'\n",
    "over_mean = 'Match'\n",
    "\n",
    "#----------------------------------------------------------------DO NOT TOUCH\n",
    "\n",
    "data_df[new_column] = data_df[col1] * data_df[col2]\n",
    "if binarize_new_column:\n",
    "    data_df[new_column] = np.where(data_df[new_column] < eval(binarizing_choice), under_mean, over_mean)\n",
    "data_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binarize columns as needed -- optional\n",
    "This will walk you through it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manually Create a new variable\n",
    "col_to_binarize = 'Age'\n",
    "custom_binarizing_string = 'Alzheimer'\n",
    "\n",
    "#Choose byy what operator to binarize\n",
    "binarizing_operator_list = ['<', '>', '<=', '>=', '==', '!='] #don't touch this\n",
    "operator_choice = binarizing_operator_list[3]\n",
    "\n",
    "#Choose how to binarize\n",
    "binarizing_threshold_choice = ['0', 'np.mean(data_df[col_to_binarize])', f'{custom_binarizing_string}'] #don't touch this. \n",
    "binarizing_choice = binarizing_threshold_choices[1] #Choice between zero and mean\n",
    "\n",
    "#Choose how to label your binarization data\n",
    "under_mean = 'Young'\n",
    "over_mean = 'Old'\n",
    "\n",
    "#----------------------------------------------------------------DO NOT TOUCH\n",
    "data_df[col_to_binarize] = np.where(data_df['Age'] < 0, under_mean, over_mean)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statannotations.Annotator import Annotator\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def plot_distribution_tests(dataframe, comparisons_dict, test_type, correction_method, key_label, value_label, x_label, y_label, display='split_pairs', full_legend_patches=False):\n",
    "    valid_tests = ['t-test_ind', 't-test_paired', 'Mann-Whitney', 'Wilcoxon']\n",
    "    valid_corrections = ['bonferroni', 'holm', 'fdr_bh']\n",
    "    if test_type not in valid_tests:\n",
    "        raise ValueError(f\"Invalid test type. Choose from: {', '.join(valid_tests)}\")\n",
    "    if correction_method not in valid_corrections:\n",
    "        raise ValueError(f\"Invalid correction method. Choose from: {', '.join(valid_corrections)}\")\n",
    "\n",
    "    # Create a color palette with enough unique colors\n",
    "    colors = sns.color_palette(\"tab10\", len(comparisons_dict))\n",
    "\n",
    "    # Create a new DataFrame to hold the data for plotting\n",
    "    data = pd.DataFrame(columns=['GroupType', 'Metric', 'Value'])\n",
    "    pairs = []\n",
    "    # Create legend patches\n",
    "    legend_patches = []\n",
    "\n",
    "    # Iterate through comparisons_dict\n",
    "    for idx, (key, value) in enumerate(comparisons_dict.items()):\n",
    "        key_series = dataframe[key]\n",
    "        value_series = dataframe[value]\n",
    "        color = colors[idx]\n",
    "        temp_data = pd.DataFrame({\n",
    "            'GroupType': [f'Key'] * len(key_series) + [f'Value'] * len(value_series),\n",
    "            'Metric': [key] * len(key_series) + [value] * len(value_series),\n",
    "            'Value': key_series.tolist() + value_series.tolist(),\n",
    "            'Color': [color] * (len(key_series) + len(value_series))\n",
    "        })\n",
    "        data = pd.concat([data, temp_data], axis=0)\n",
    "        pairs.append(((key, 'Key'), (value, 'Value')))\n",
    "        \n",
    "        if full_legend_patches:\n",
    "            legend_patches.append(mpatches.Patch(color=colors[idx], label=f'{key} vs {value}'))\n",
    "        else:\n",
    "            legend_patches.append(mpatches.Patch(color=colors[idx], label=f'{key}'))\n",
    "\n",
    "    # Map colour\n",
    "    palette_mapping = {row['Metric']: row['Color'] for _, row in data.iterrows()}\n",
    "\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(len(comparisons_dict)*2, 5))\n",
    "    # Add annotations\n",
    "    if display=='group_pairs':\n",
    "        # Plot with seaborn (split image)\n",
    "        ax = sns.boxplot(x='Metric', y='Value', hue='GroupType', data=data, ax=ax, palette='husl')\n",
    "        # Add annotations\n",
    "        annotator = Annotator(ax=ax,\n",
    "                              data=data,\n",
    "                              x='Metric',\n",
    "                              y='Value',\n",
    "                              hue='GroupType',\n",
    "                              pairs=pairs,\n",
    "                              test=test_type,\n",
    "                              text_format='full',\n",
    "                              loc='inside',\n",
    "                              verbose=2)\n",
    "    elif display=='split_pairs':\n",
    "        # Plot with seaborn (side-by-side)\n",
    "        ax = sns.boxplot(x='GroupType', y='Value', hue='Metric', data=data, ax=ax, palette={row['Metric']: row['Color'] for _, row in data.iterrows()})\n",
    "        # Adjust pairs for side-by-side\n",
    "        pairs = [(('Key', col1), ('Value', col2)) for col1, col2 in comparisons_dict.items()]\n",
    "        # Add annotations\n",
    "        annotator = Annotator(ax=ax,\n",
    "                              data=data,\n",
    "                              x='GroupType',\n",
    "                              y='Value',\n",
    "                              hue='Metric',\n",
    "                              pairs=pairs,\n",
    "                              test=test_type,\n",
    "                              text_format='full',\n",
    "                              loc='outside',\n",
    "                              verbose=1)\n",
    "        x_labels = [key_label] + [value_label]\n",
    "        print(x_labels)\n",
    "        plt.xticks(ticks=range(len(x_labels)), labels=x_labels)\n",
    "    else:\n",
    "        raise ValueError(f'display {display} not supported please choose \"split_pairs\" or \"group_pairs\"')\n",
    "\n",
    "    # Configure and annotate\n",
    "    _, corrected_results = annotator.configure(test=test_type, comparisons_correction=correction_method).apply_and_annotate()\n",
    "\n",
    "    # Label and show plot\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    plt.title(f'Distribution Test: {test_type} with {correction_method} correction')\n",
    "    plt.legend(title='Groups', handles=legend_patches, frameon=False, loc=(0.025, 0.05))\n",
    "\n",
    "    return plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons_dict = {\n",
    "    'Attention': 'Attention.1',\n",
    "    'Memory': 'Memory.1',\n",
    "    'Language': 'Language.1', \n",
    "    'Fluency': 'Fluency.1',\n",
    "    'Visuospatial': 'Visuospatial.1',\n",
    "}\n",
    "test_type = 'Mann-Whitney'\n",
    "correction_method = 'bonferroni'\n",
    "key_label = 'Autonomous'\n",
    "value_label = 'Paper'\n",
    "x_label = 'Test Type'\n",
    "y_label = 'Score'\n",
    "\n",
    "#----------------------------------------------------------------\n",
    "plt = plot_distribution_tests(dataframe=data_df,\n",
    "                        comparisons_dict=comparisons_dict, \n",
    "                        test_type=test_type, \n",
    "                        correction_method=correction_method,\n",
    "                        key_label=key_label, \n",
    "                        value_label=value_label, \n",
    "                        x_label=x_label, \n",
    "                        y_label=y_label)\n",
    "plt\n",
    "# os.makedirs(os.path.join(out_dir, 'distribution_figures'), exist_ok=True)\n",
    "# figure.savefig(os.path.join(out_dir, f'distribution_figures/{test_type}_{correction_method}_multiple_comparison_barplot.png'))\n",
    "# figure.savefig(os.path.join(out_dir, f'distribution_figures/{test_type}_{correction_method}_multiple_comparison_barplot_barplot.svg'))\n",
    "# print('Figure saved to: ', (os.path.join(out_dir, f'icc_figures/{test_type}_{correction_method}_multiple_comparison_barplot')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_var_column = 'Completed'\n",
    "dependent_var_column_list = ['Total', 'Total.1']\n",
    "\n",
    "#Just a name for the sake of figure labels\n",
    "dependent_var_column_labels = 'Test Type'\n",
    "\n",
    "#A name for the value of the melted column\n",
    "measurement_category = 'Score'\n",
    "\n",
    "#-------------------------------------------------------------------    \n",
    "\n",
    "\n",
    "# Copy the dataframe to avoid changing the original data\n",
    "df_to_melt = data_df.copy()\n",
    "index_column=independent_var_column\n",
    "dep_var_type=dependent_var_column_list\n",
    "dep_var_category=dependent_var_column_labels\n",
    "\n",
    "# Melt dataframe\n",
    "melted_df = pd.melt(df_to_melt, id_vars=index_column, value_vars=dep_var_type, var_name=dep_var_category, value_name=measurement_category)\n",
    "melted_df\n",
    "\n",
    "display(melted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Info\n",
    "df_to_melt_info = df_to_melt.describe().transpose()\n",
    "display(df_to_melt_info)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option A - Generate a Boxplot with Tukey HSD Post Hoc for a given effect"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a Tukey HSD Post Hoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statsmodels Tukey\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "\n",
    "# Step 1: Two-way ANOVA\n",
    "formula = f'Q(\"{measurement_category}\") ~ C(Q(\"{index_column}\")) + C(Q(\"{dep_var_category}\")) + C(Q(\"{index_column}\")):C(Q(\"{dep_var_category}\"))'\n",
    "model = ols(formula, data=melted_df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print ANOVA table to see the indices\n",
    "display(anova_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#----------------------------------------------------------------DO NOT CHANGE BELOW\n",
    "\n",
    "# Step 2: Post-hoc tests if interaction is significant\n",
    "# First, check the ANOVA table indices and then access the appropriate index.\n",
    "# For example, if the index is 'Age:Network' use that to access the p-value\n",
    "interaction_index = f'C(Q(\"{index_column}\")):C(Q(\"{dep_var_category}\"))'  # change this based on the printed ANOVA table\n",
    "\n",
    "\n",
    "\n",
    "# Perform Tukey's HSD test\n",
    "# tukey = pairwise_tukeyhsd(endog=df['Damage Score'],\n",
    "#                           groups=df['Cohort_Lobe'],\n",
    "#                           alpha=0.05)\n",
    "\n",
    "# Step 2: Post-hoc tests if interaction is significant\n",
    "if anova_table.loc[interaction_index, 'PR(>F)'] < 0.05:\n",
    "    \n",
    "    pre_tukey_df = melted_df.copy()\n",
    "    # Create a new column combining Cohort and Lobe information\n",
    "    pre_tukey_df['Combined_Column'] = pre_tukey_df[index_column] + '_' + pre_tukey_df[dep_var_category]\n",
    "    \n",
    "    # Perform Tukey's test\n",
    "    tukey = pairwise_tukeyhsd(endog=pre_tukey_df[measurement_category],\n",
    "                              groups=pre_tukey_df['Combined_Column'],\n",
    "                              alpha=0.05)\n",
    "    \n",
    "    # Create a DataFrame from the Tukey's test summary\n",
    "    tukey_df = pd.DataFrame(data=tukey.summary()[1:], columns=tukey.summary()[0])\n",
    "    \n",
    "    # Display the results of the Tukey's test\n",
    "    display(tukey_df)\n",
    "else:\n",
    "    print(\"The interaction was not significant\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tukey_df.columns[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------DO NOT TOUCH\n",
    "group1_column = tukey_df.columns[0]\n",
    "group2_column = tukey_df.columns[1]\n",
    "\n",
    "\n",
    "# Convert columns to string type\n",
    "tukey_df[group1_column] = tukey_df[group1_column].astype(str)\n",
    "tukey_df[group2_column] = tukey_df[group2_column].astype(str)\n",
    "\n",
    "# Function to extract the lobe part from the combined column\n",
    "def extract_lobe(group):\n",
    "    return '_'.join(group.split('_')[1:])\n",
    "\n",
    "# Filter the rows where the lobe part is the same, but the cohort part is different\n",
    "filtered_df = tukey_df[\n",
    "    (tukey_df[group1_column].map(extract_lobe) == tukey_df[group2_column].map(extract_lobe)) &\n",
    "    (tukey_df[group1_column].map(lambda x: x.split('_')[0]) != tukey_df[group2_column].map(lambda x: x.split('_')[0]))\n",
    "]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "display(filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize interaction plot\n",
    "from statsmodels.graphics.factorplots import interaction_plot\n",
    "import matplotlib.pyplot as plt\n",
    "intrxn_plot = interaction_plot(x=melted_df[index_column], trace=melted_df[dep_var_category], response=melted_df[measurement_category])#, colors=colors)\n",
    "intrxn_plot.set_size_inches(5, 7, forward=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statannotations.Annotator import Annotator\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "x_label = 'Lobe'\n",
    "y_label = 'Damage Score'\n",
    "#----------------------------------------------------------------DO NOT TOUCH----------------------------------------------------------------\n",
    "# Assuming filtered_df is already defined with your data\n",
    "# Extract pairs and p-values from filtered_df\n",
    "pairs = [(f\"{row[filtered_df.columns[0]]}\", \n",
    "          f\"{row[filtered_df.columns[1]]}\") \n",
    "          for _, row in filtered_df.iterrows()]\n",
    "\n",
    "# pairs = [(f\"{row[filtered_df[filtered_df.columns[0]]]}\", \n",
    "#           f\"{row[filtered_df[filtered_df.columns[1]]]}\") \n",
    "#           for _, row in filtered_df.iterrows()]\n",
    "\n",
    "# pairs = [(f\"{row[filtered_df[filtered_df.columns[0]]]}_{row[dep_var_category]}\", \n",
    "#           f\"{row[filtered_df[filtered_df.columns[1]]]}_{row[dep_var_category]}\") \n",
    "#           for _, row in filtered_df.iterrows()]\n",
    "\n",
    "# Convert p-values to float\n",
    "p_values = [float(str(row[filtered_df.columns[3]])) for _, row in filtered_df.iterrows()]\n",
    "\n",
    "# Create figure and axis\n",
    "fig, ax = plt.subplots(figsize=(30, 20))\n",
    "\n",
    "# Plot with seaborn, using 'hue' to differentiate between Alzheimer's and Parkinson's within each Lobe\n",
    "sns.boxplot(data=melted_df, x=dep_var_category, y=measurement_category, hue=index_column, ax=ax)\n",
    "\n",
    "# Add annotations using statannotations\n",
    "annotator = Annotator(ax, pairs=pairs, data=melted_df, x=dep_var_category, y=measurement_category, hue=index_column)\n",
    "annotator.configure(test=None, text_format=\"star\", loc=\"inside\", verbose=2)\n",
    "annotator.set_pvalues(p_values)\n",
    "annotator.annotate()\n",
    "\n",
    "# Label and show\n",
    "ax.set_xlabel(x_label)\n",
    "ax.set_ylabel(y_label)\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=index_column, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statannotations.Annotator import Annotator\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "x_label = 'Lobe'\n",
    "y_label = 'Damage Score'\n",
    "#----------------------------------------------------------------DO NOT MODIFY----------------------------------------------------------------\n",
    "# Assuming melted_df is already defined with your data\n",
    "melted_df['combined_group'] = melted_df[index_column] + '_' + melted_df[dep_var_category]\n",
    "\n",
    "# Assuming filtered_df is already defined with your data\n",
    "# Extract pairs and p-values from filtered_df\n",
    "pairs = [(row[filtered_df.columns[0]], row[filtered_df.columns[1]]) for _, row in filtered_df.iterrows()]\n",
    "\n",
    "# Convert p-values to float\n",
    "p_values = [float(str(row[filtered_df.columns[3]])) for _, row in filtered_df.iterrows()]\n",
    "\n",
    "# Create figure and axis\n",
    "fig, ax = plt.subplots(figsize=(30, 20))\n",
    "\n",
    "# Plot with seaborn\n",
    "sns.boxplot(data=melted_df, x='combined_group', y=measurement_category, ax=ax)\n",
    "\n",
    "# Add annotations using statannotations\n",
    "annotator = Annotator(ax, pairs=pairs, data=melted_df, x='combined_group', y=measurement_category)\n",
    "annotator.configure(test=None, text_format=\"star\", loc=\"inside\", verbose=2)\n",
    "annotator.set_pvalues(p_values)\n",
    "annotator.annotate()\n",
    "\n",
    "# Label and show\n",
    "ax.set_xlabel(x_label)\n",
    "ax.set_ylabel(y_label)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option B - This is more like distribution testing (T-tests, wilcoxon tests, etc) \n",
    "- run normality testing to help choose a main test\n",
    "- choose main test\n",
    "- choose multiple corrections test\n",
    "- generate a box plot\n",
    "- annotate it"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess Normality to Determine what Test to Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Assuming melted_df is your DataFrame, and you have columns named dependent_var_column and index_column\n",
    "\n",
    "# Getting unique values from dependent_var_column\n",
    "unique_dependent_vars = melted_df[dep_var_category].unique()\n",
    "\n",
    "# Iterating through each unique value in dependent_var_column\n",
    "for unique_var in unique_dependent_vars:\n",
    "    # Filtering data for current unique dependent_var\n",
    "    sub_df = melted_df[melted_df[dep_var_category] == unique_var]\n",
    "    \n",
    "    # Finding distinct index_column groups\n",
    "    index_groups = sub_df[index_column].unique()\n",
    "    \n",
    "    # Checking normality for each group\n",
    "    for index_group in index_groups:\n",
    "        group_data = sub_df[sub_df[index_column] == index_group][measurement_category]\n",
    "        \n",
    "        # Shapiro-Wilk test\n",
    "        shapiro_stat, shapiro_p = stats.shapiro(group_data)\n",
    "        \n",
    "        # Anderson-Darling test\n",
    "        anderson_result = stats.anderson(group_data)\n",
    "        \n",
    "        print(f'For {unique_var}, {index_group}:')\n",
    "        print(f'Shapiro-Wilk: statistic={shapiro_stat}, p-value={shapiro_p}')\n",
    "        print(f'Anderson-Darling: statistic={anderson_result.statistic}, critical values={anderson_result.critical_values}, significance_levels={anderson_result.significance_level}')\n",
    "        print('--------------------------')\n",
    "\n",
    "# After checking for normality, you can decide whether to use Mann-Whitney U test or t-test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "normality_results = pd.DataFrame(columns=['dependent_var', 'index_group', 'shapiro_stat', 'shapiro_p', 'anderson_stat', 'anderson_critical_values', 'anderson_significance_levels'])\n",
    "\n",
    "# Getting unique values from dependent_var_column\n",
    "unique_dependent_vars = melted_df[dep_var_category].unique()\n",
    "\n",
    "# Iterating through each unique value in dependent_var_column\n",
    "for unique_var in unique_dependent_vars:\n",
    "    # Filtering data for current unique dependent_var\n",
    "    sub_df = melted_df[melted_df[dep_var_category] == unique_var]\n",
    "    \n",
    "    # Finding distinct index_column groups\n",
    "    index_groups = sub_df[index_column].unique()\n",
    "    \n",
    "    # Checking normality for each group\n",
    "    for index_group in index_groups:\n",
    "        group_data = sub_df[sub_df[index_column] == index_group][measurement_category]\n",
    "        \n",
    "        # Shapiro-Wilk test\n",
    "        shapiro_stat, shapiro_p = stats.shapiro(group_data)\n",
    "        \n",
    "        # Anderson-Darling test\n",
    "        anderson_result = stats.anderson(group_data)\n",
    "        \n",
    "        # Append the results to the DataFrame\n",
    "        normality_results = normality_results.append({\n",
    "            'dependent_var': unique_var,\n",
    "            'index_group': index_group,\n",
    "            'shapiro_stat': shapiro_stat,\n",
    "            'shapiro_p': shapiro_p,\n",
    "            'anderson_stat': anderson_result.statistic,\n",
    "            'anderson_critical_values': anderson_result.critical_values,\n",
    "            'anderson_significance_levels': anderson_result.significance_level\n",
    "        }, ignore_index=True)\n",
    "\n",
    "normality_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_df['Completed'] = np.where(melted_df['Test Type'] == 'Total', 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "# Assuming melted_df is your DataFrame, and you have columns named dependent_var_column and index_column\n",
    "\n",
    "pairs = []\n",
    "\n",
    "# Getting unique values from dependent_var_column\n",
    "unique_dep_vars = melted_df[dep_var_category].unique()\n",
    "\n",
    "# Getting unique values from index_column\n",
    "unique_index_vars = melted_df[index_column].unique()\n",
    "\n",
    "# Iterating through each unique value in dependent_var_column\n",
    "for dep_var in unique_dep_vars:\n",
    "    # Generating pairs among index_column groups for the current dependent_var\n",
    "    for index_group1, index_group2 in combinations(unique_index_vars, 2):\n",
    "        current_pair = ((index_group1, dep_var), (index_group2, dep_var))\n",
    "        \n",
    "        # Adding these pairs to the main list\n",
    "        pairs.append(current_pair)\n",
    "\n",
    "# Now pairs will have the desired pairs for plotting\n",
    "print(pairs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statannotations.Annotator import Annotator\n",
    "from statannotations import utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# A few helper functions:\n",
    "import numpy as np\n",
    "from scipy.stats import mannwhitneyu, normaltest, tukey_hsd, ttest_ind, kruskal, levene, brunnermunzel, wilcoxon\n",
    "fig2, ax = plt.subplots(1,1, figsize=(30, 20))\n",
    "\n",
    "main_tests = ['t-test_ind', 't-test_welch', 't-test_paired', 'Mann-Whitney', 'Mann-Whitney-gt', 'Mann-Whitney-ls', 'Levene', 'Wilcoxon', 'Kruskal', 'Brunner-Munzel']\n",
    "post_hoc_tests = ['bonferroni', 'bonf', 'Bonferroni', 'holm-bonferroni', 'HB', 'Holm-Bonferroni', 'holm', 'benjamini-hochberg', 'BH', 'fdr_bh', 'Benjamini-Hochberg', 'fdr_by', 'Benjamini-Yekutieli', 'BY', None]\n",
    "\n",
    "##----------------------------------------------------------------USER INPUT BELOW----------------------------------------------------------------\n",
    "main_test = 'Mann-Whitney'# #main_tests[0]\n",
    "post_hoc_test = 'bonferroni' #post_hoc_tests[3]\n",
    "x_label = 'Tissue Segments'\n",
    "y_label = 'Z Score Mean Volume'\n",
    "num_categories_tested = 1\n",
    "##----------------------------------------------------------------USER INPUT ABOVE----------------------------------------------------------------\n",
    "\n",
    "#Manipulate the pairs generated from stats annotation\n",
    "grey_colors = ['#F0F0F0', '#D9D9D9', '#B3B3B3', '#A6A6A6', '#999999', '#7F7F7F', '#666666', '#4D4D4D', '#333333', '#1A1A1A']\n",
    "customPalette = sns.set_palette(sns.color_palette(grey_colors))\n",
    "hue_plot_params = {\n",
    "    'data': melted_df,\n",
    "    'x': index_column,\n",
    "    'y': measurement_category,\n",
    "    \"hue\": dep_var_category,\n",
    "    \"palette\": customPalette\n",
    "}\n",
    "\n",
    "with sns.plotting_context(\"notebook\", font_scale=1.4):\n",
    "        # Plot with seaborn\n",
    "        ax = sns.boxplot(ax=ax, **hue_plot_params)\n",
    "\n",
    "        # Add annotations\n",
    "        annotator = Annotator(ax, **hue_plot_params,\n",
    "                            pairs=pairs,\n",
    "                        test=main_test, text_format='full', loc='inside', verbose=2)\n",
    "\n",
    "        #Specific post-hoc test\n",
    "        # annotator.configure(test=\"Mann-Whitney\", comparisons_correction=\"bonferroni\")\n",
    "        _, corrected_results = annotator.configure(test=main_test, comparisons_correction=post_hoc_test).apply_and_annotate()\n",
    "\n",
    "        # Label and show\n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.set_ylabel(y_label)\n",
    "        plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For t-testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statannotations.Annotator import Annotator\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "main_test = 'Mann-Whitney'# #main_tests[0]\n",
    "post_hoc_test = 'bonferroni' #post_hoc_tests[3]\n",
    "x_label = 'Disease'\n",
    "y_label = 'Subiculum Connectivity'\n",
    "\n",
    "\n",
    "sns.boxplot(x=index_column, y=measurement_category, data=melted_df, ax=ax)\n",
    "\n",
    "# Define the pairs for comparison, test type, and post-hoc correction\n",
    "pairs = [((1, 'Total'), (0, 'Total')), ((1, 'Total.1'), (0, 'Total.1'))]\n",
    "main_test = 'Mann-Whitney'\n",
    "post_hoc_test = 'bonferroni'\n",
    "\n",
    "# Add annotations using the Annotator class\n",
    "annotator = Annotator(ax=ax,\n",
    "                      data=melted_df,\n",
    "                      x=index_column,\n",
    "                      y=measurement_category,\n",
    "                      pairs=pairs,\n",
    "                      test=main_test,\n",
    "                      text_format='full',\n",
    "                      loc='inside',\n",
    "                      verbose=2)\n",
    "\n",
    "# Configure and annotate\n",
    "_, corrected_results = annotator.configure(test=main_test, comparisons_correction=post_hoc_test).apply_and_annotate()\n",
    "\n",
    "# Label and show the plot\n",
    "plt.xlabel('Test Type (1=Experimental, 0=Basic)')\n",
    "plt.ylabel('Score')\n",
    "plt.show()\n",
    "\n",
    "##----------------------------------------------------------------USER INPUT ABOVE----------------------------------------------------------------\n",
    "# Set style and color palette\n",
    "sns.set_style('white')\n",
    "sns.set_palette('Greys', len(melted_df[index_column].unique()), desat=1)\n",
    "\n",
    "# Pairs for comparison\n",
    "pairs = [(\"Parkinson\", \"Alzheimer\")]\n",
    "\n",
    "# Plot parameters\n",
    "plot_params = {\n",
    "    'data': melted_df,\n",
    "    'x': dep_var_type,\n",
    "    'y': measurement_category,\n",
    "}\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot with seaborn\n",
    "sns.boxplot(ax=ax, **plot_params)\n",
    "\n",
    "# Add annotations\n",
    "annotator = Annotator(ax=ax,\n",
    "                      data=melted_df,\n",
    "                      x=index_column,\n",
    "                      y=measurement_category,\n",
    "                      pairs=pairs,\n",
    "                      test=main_test,\n",
    "                      text_format='full',\n",
    "                      loc='inside',\n",
    "                      verbose=2)\n",
    "\n",
    "# Configure and annotate\n",
    "_, corrected_results = annotator.configure(test=main_test, comparisons_correction=post_hoc_test).apply_and_annotate()\n",
    "\n",
    "# Label and show plot\n",
    "ax.set_xlabel(x_label)\n",
    "ax.set_ylabel(y_label)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract values from statannotations into a saveable DF\n",
    "comparison_1 = []\n",
    "comparison_2 = []\n",
    "p_values = []\n",
    "test = []\n",
    "for corrected_result in corrected_results:\n",
    "    comparison_1.append(corrected_result.structs[0]['group'])\n",
    "    comparison_2.append(corrected_result.structs[1]['group'])\n",
    "    p_values.append(corrected_result.data.pvalue)\n",
    "    test.append(corrected_result.data.test_description)\n",
    "    \n",
    "post_hoc_df = pd.DataFrame({'comparison_1': comparison_1, 'comparison_2': comparison_2, 'p_values': p_values, 'post_hoc_test': test})\n",
    "display(post_hoc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finalize and save\n",
    "\n",
    "if os.path.exists(out_dir) != True:\n",
    "    os.makedirs(out_dir)\n",
    "anova_table.to_csv(out_dir + '2_way_anova_results.csv')\n",
    "post_hoc_df.to_csv(out_dir + f'post_hoc_results_{test[1]}.csv')\n",
    "fig1.savefig(out_dir + '2_way_anova_boxplot_tukey_hsd_results.png')\n",
    "fig2.savefig(out_dir + f'boxplot_{test[1]}.png')\n",
    "intrxn_plot.savefig(out_dir + f'2_way_anova_interaction_plot.png')\n",
    "normality_results.to_csv(out_dir + 'normality_test_results.csv', index=False)\n",
    "print(\"saved to: \", out_dir)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Modified Method\n",
    "- This will print the labels of the columns for you to choose how to interact your model\n",
    "- You will select the title of the column with the continuous variable and assign it to the variable 'continuous'.\n",
    "- You will select the title of the column with the categorical variable and assign it to the variable 'categorical_1'\n",
    "- You will select the title of the column with the categorical variable and assign it to the variable 'categorical_2'\n",
    "\n",
    "- If you want to create an interaction between variables, you will need to manually create a new column multiplying them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get column names for copy paste below\n",
    "print(data_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous = 'outcome'\n",
    "categorical_1 = 'Stimulation_Atrophy_Match' #This is the categorical variable which will compose the lines\n",
    "categorical_2 = 'Age' #this is the categorical variable which will compose the x axis bins\n",
    "#----------------------------------------------------------------DO NOT TOUCH\n",
    "# Fit the model\n",
    "model = ols(f'{continuous} ~ C({categorical_1}) + C({categorical_2}) + C({categorical_1}):C({categorical_2})', data=data_df).fit()\n",
    "\n",
    "# Perform the two-way ANOVA\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "display(anova_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create an interaction plot using Seaborn\n",
    "sns.set(style=\"ticks\") # Set style\n",
    "plt.figure(figsize=(8, 6)) # Set figure size\n",
    "\n",
    "# Point plot\n",
    "sns.pointplot(x=f\"{categorical_1}\", y=f\"{continuous}\", hue=f\"{categorical_2}\", data=data_df, markers=[\"o\", \"x\"], linestyles=[\"-\", \"--\"])\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel(f\"{categorical_1}\")\n",
    "plt.ylabel(f\"{continuous}\")\n",
    "plt.title(\"Interaction Plot\")\n",
    "plt.legend(title=f\"{categorical_2}\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy.stats import wilcoxon\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to annotate the significance\n",
    "def annotate_significance(ax, p_value, x1, x2, y):\n",
    "    significance = \"\"\n",
    "    if p_value < 0.05:\n",
    "        significance = \"*\"\n",
    "    if p_value < 0.01:\n",
    "        significance = \"**\"\n",
    "    if p_value < 0.001:\n",
    "        significance = \"***\"\n",
    "    ax.annotate(\"\", xy=(x1, y), xycoords='data', xytext=(x2, y), textcoords='data',\n",
    "                arrowprops=dict(arrowstyle=\"-\", lw=1.5))\n",
    "    ax.text((x1 + x2) * .5, y, significance, ha='center', va='bottom', color=\"black\")\n",
    "\n",
    "# Separate the data into two groups\n",
    "group1 = melted_df[melted_df['Completed'] == 1]['Score']\n",
    "group2 = melted_df[melted_df['Completed'] == 0]['Score']\n",
    "\n",
    "# Perform the Wilcoxon signed-rank test\n",
    "statistic, p_value = wilcoxon(group1, group2)\n",
    "sns.set_palette('Greys', len(melted_df[index_column].unique()), desat=1)\n",
    "# Plot the data using Seaborn's boxplot\n",
    "ax = sns.boxplot(x='Completed', y='Score', data=melted_df)\n",
    "# ax = sns.swarmplot(x='Completed', y='Score', data=melted_df, color=\".25\") # Optional: add data points\n",
    "\n",
    "# Find the y position for the annotation\n",
    "y_max = melted_df['Score'].max() + 0.05 # You can adjust this value as needed\n",
    "\n",
    "# Annotate the plot with the significance stars\n",
    "annotate_significance(ax, p_value, 0, 1, y_max)\n",
    "\n",
    "plt.xlabel('Test Type (1=Experimental, 0=Basic)')\n",
    "plt.ylabel('Score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimlab_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
