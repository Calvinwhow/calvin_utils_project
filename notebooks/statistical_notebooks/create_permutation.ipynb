{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Paths Input Here\n",
    "if platform.uname().system == 'Darwin': #------------------------------Mac OS X---------------------------------------------------------------\n",
    "    conn_path = r'/Users/cu135/Dropbox (Partners HealthCare)/memory/analyses/roi-roi_correl/matrix_corrMx_AvgR.csv'\n",
    "    clin_path = r'/Users/cu135/Dropbox (Partners HealthCare)/memory/patient_data/AD_Clinical_Data_CDR_ADAS_COG_13.xlsx'\n",
    "    # clin_path = 'path to clinical values'\n",
    "    out_dir = r'/Users/cu135/Dropbox (Partners HealthCare)/memory/analyses/AD_to_memory_net/permutations'\n",
    "    #out_dir = r'path to out dir here'\n",
    "    x_roi_names = r'/Users/cu135/Dropbox (Partners HealthCare)/memory/analyses/roi-roi_correl/matrix_corrMx_names.csv'\n",
    "    #roi_names = '<path to roi name location>'\n",
    "    print('I have set pathnames in the Mac style')\n",
    "else: #----------------------------------------------------------------Windows----------------------------------------------------------------\n",
    "    conn_path = r'C:\\Users\\calvin.howard\\Dropbox (Partners HealthCare)\\memory\\analyses\\roi-roi_correl\\matrix_corrMx_AvgR.csv'\n",
    "    clin_path = r'C:\\Users\\calvin.howard\\Dropbox (Partners HealthCare)\\memory\\patient_data\\AD_Clinical_Data_CDR_ADAS_COG_13.xlsx'\n",
    "    # clin_path = 'path to clinical values'\n",
    "    print(pathlib.Path(os.path.join(base,conn_path)))\n",
    "    #out_dir = r'path to out dir here'\n",
    "    x_roi_names = r'C:\\Users\\calvin.howard\\Dropbox (Partners HealthCare)\\memory\\analyses\\roi-roi_correl\\matrix_corrMx_names.csv'\n",
    "    #roi_names = '<path to roi name location>'\n",
    "    print('I have set pathnames in the Windows style')\n",
    "    out_dir = r'C:\\Users\\calvin.howard\\Dropbox (Partners HealthCare)\\memory\\analyses\\AD_to_memory_net\\permutations'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import X Vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    name_df = pd.read_csv(x_roi_names, names=['arb'], header=None)\n",
    "    # name_df.tail(5)\n",
    "    colnames = name_df.arb.values.tolist()\n",
    "    newname = []\n",
    "    for name in colnames:\n",
    "        arb = os.path.basename(name).split('.nii')[0]\n",
    "        arb = arb[0:8]\n",
    "        newname.append(arb)\n",
    "    # print('NAMES: ',newname)\n",
    "\n",
    "    x_df = pd.read_csv(conn_path, names=newname, header=None)#, ignore_index=True)\n",
    "    x_df.index = newname\n",
    "    x_df = x_df.iloc[8:,:8]\n",
    "    x_df = x_df.reset_index(drop=True)\n",
    "except:\n",
    "    print('excepted')\n",
    "    x_df = pd.read_csv(conn_path)\n",
    "    colnames = x_df.columns.values\n",
    "    newname = []\n",
    "    for name in colnames:\n",
    "        arb = os.path.basename(name).split('.nii')[0]\n",
    "        arb = arb[0:8]\n",
    "        newname.append(arb)\n",
    "    x_df = x_df.set_axis(newname, axis=1, inplace=False)\n",
    "    try:\n",
    "        x_df.pop('Unnamed:')\n",
    "    except:\n",
    "        print('no x_df.pop(<name>) column to pop')\n",
    "\n",
    "corr_df = x_df\n",
    "display(corr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assess connectivity values fundamentally\n",
    "corr_description = corr_df.describe().transpose()\n",
    "display(corr_description)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Y Vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_name = 'AD_Clinical_Scores'\n",
    "alphab_cols = 'C, D, E, F, G, J, V'\n",
    "clin_df = pd.read_excel(clin_path, sheet_name=sheet_name, usecols=alphab_cols, nrows=50)\n",
    "print('Num NaNs: ', clin_df.isna().sum().sum())\n",
    "# clin_df.tail(5)\n",
    "display(clin_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Organize the clinical dataframe\n",
    "# clin_df = clin_df.sort_values(by=['Patient # CDR, ADAS'], kind='quicksort', axis=0, ascending=True, ignore_index=True)\n",
    "# clin_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##One-hot-encode the dataframe | sham=0 stim=1 \n",
    "shams = (clin_df['Randomization Arm'] == 'sham-stim')\n",
    "clin_df.loc[shams, 'Randomization Arm'] = 0\n",
    "stims = (clin_df['Randomization Arm'] == 'stim-sham')\n",
    "clin_df.loc[stims, 'Randomization Arm'] = 1\n",
    "clin_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop Understanding of the Clinical Data\n",
    "try:\n",
    "    clin_description = clin_df.describe().transpose()\n",
    "    display(clin_description)\n",
    "except:\n",
    "    print('Failed to describe clinical dataframe, unknown cause')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrd_df = corr_df.reset_index()\n",
    "total_df = pd.concat([clin_df, corr_df], axis=1)\n",
    "display(total_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handle NaNs\n",
    "total_df = total_df.fillna(method='ffill')\n",
    "print('Num NaNs: ', total_df.isna().sum().sum())\n",
    "\n",
    "#Generate metrics for understanding\n",
    "try:\n",
    "    total_desc = total_df.describe().transpose()\n",
    "    total_desc\n",
    "except:\n",
    "    print('Failed to generate total metrics, unkown cause')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Split Vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subgrouping by age\n",
    "metric = '% Change from baseline (ADAS-Cog11)'\n",
    "metric_val = np.mean(total_df[metric])\n",
    "print(f'{metric} = {metric_val}')\n",
    "\n",
    "## Choose variables of interest.\n",
    "x_name = '00_memor'\n",
    "z_name = '% Change from baseline (ADAS-Cog11)'\n",
    "\n",
    "#----------------------------------------------------------------User Inpuots Above\n",
    "\n",
    "index_one = (total_df[metric] > metric_val) #example, all individuals over 65\n",
    "index_two = (total_df[metric] <= metric_val) #example, all individuals under/equal to 65\n",
    "\n",
    "##Example of how to use these indices to manipulate data:\n",
    "#### clin_df.loc[index_one, '<names of relevant columns>'] = 0 ## can use iloc too. \n",
    "\n",
    "\n",
    "#----------------------------------------------------------------User Inpouts below\n",
    "#set pos?\n",
    "set_pos=True\n",
    "if set_pos==True:\n",
    "    total_df[z_name] = total_df[z_name]+abs(np.mean(total_df[z_name]))\n",
    "    total_df[x_name] = np.abs(total_df[x_name])\n",
    "    pos_val='absval'\n",
    "    print('I will set all z values positive')\n",
    "else:\n",
    "    pos_val='nonabsval'\n",
    "    print('I will set all vals positive')\n",
    "\n",
    "#permute x and y together (sngl_perm), or separately (dbl perm)?\n",
    "dbl_perm = False\n",
    "if dbl_perm == True:\n",
    "    perm_no='dbl_perm'\n",
    "    print('I will double perm')\n",
    "else:\n",
    "    perm_no='sngl_perm'\n",
    "    print('I will single perm')\n",
    "    \n",
    "total_df.tail(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "x_vals = total_df[x_name]\n",
    "z_vals = total_df[z_name]\n",
    "# print(len(x_vals[index_one]))\n",
    "# print(len(x_vals[index_two]))\n",
    "\n",
    "r_over, p_over = pearsonr(x_vals[index_one], z_vals[index_one])\n",
    "r_under, p_under = pearsonr(x_vals[index_two], z_vals[index_two])\n",
    "outcomes_df = pd.DataFrame({'r_over': r_over, 'p_over': p_over, 'r_under': r_under, 'p_under': p_under, 'index':[0]})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Permutation for Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = total_df.index.tolist()\n",
    "num_perms = 10000\n",
    "perm_indices = np.zeros(np.shape([len(indices), num_perms]))\n",
    "\n",
    "r_over_perm = []; p_over_perm = []\n",
    "r_under_perm = []; p_under_perm = []\n",
    "\n",
    "for i in range(0, num_perms):\n",
    "    if dbl_perm==False:\n",
    "        perm_indices = np.random.permutation(indices)\n",
    "        r_over_arb, p_over_arb = pearsonr(total_df[x_name].loc[perm_indices[0:16]], total_df[z_name].loc[perm_indices[0:16]])\n",
    "        r_over_perm.append(r_over_arb); p_over_perm.append(p_over_arb)\n",
    "        \n",
    "        r_under_arb, p_under_arb = pearsonr(total_df[x_name].loc[perm_indices[16:]], total_df[z_name].loc[perm_indices[16:]])\n",
    "        r_under_perm.append(r_under_arb); p_under_perm.append(p_under_arb)\n",
    "    elif dbl_perm==True:\n",
    "        x_perm_indices = np.random.permutation(indices)\n",
    "        z_perm_indices = np.random.permutation(indices)\n",
    "        r_over_arb, p_over_arb = pearsonr(total_df[x_name].loc[x_perm_indices[0:16]], total_df[z_name].loc[z_perm_indices[0:16]])\n",
    "        r_over_perm.append(r_over_arb); p_over_perm.append(p_over_arb)\n",
    "        \n",
    "        r_under_arb, p_under_arb = pearsonr(total_df[x_name].loc[x_perm_indices[16:]], total_df[z_name].loc[z_perm_indices[16:]])\n",
    "        r_under_perm.append(r_under_arb); p_under_perm.append(p_under_arb)\n",
    "    else:\n",
    "        print('failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_df = pd.DataFrame({'r_over_perm': r_over_perm, 'p_over_perm': p_over_perm, 'r_under_perm': r_under_perm, 'p_under_perm': p_under_perm})\n",
    "print(f'Running {num_perms} permutations over {len(indices)} incidences \\n outcome: {z_name} \\n based on: {x_name} \\n split by: {metric}')\n",
    "perm_df['delta_r'] = perm_df['r_over_perm'] - perm_df['r_under_perm']\n",
    "perm_df.tail(5)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There were {len(perm_df)} permutations identified')\n",
    "\n",
    "counts_over = np.count_nonzero(perm_df.r_over_perm[r_over_perm < r_over])#/len(perm_df[:])\n",
    "counts_under = np.count_nonzero(perm_df.r_under_perm[r_under_perm < r_under])#/len(indices)\n",
    "\n",
    "print(f'The were {counts_over} permuted observations >{metric} occuring below the experiminary value of {r_over}')\n",
    "print(f'The were {counts_under} permuted observations <={metric} occuring below the experiminary threshold of {r_under}')\n",
    "\n",
    "prop_over = counts_over/len(perm_df)\n",
    "prop_under = counts_under/len(perm_df)\n",
    "print('prop perm r under exptl r (>metric): ', prop_over)\n",
    "print('prop perm r under exptl r (<=metric): ', prop_under)\n",
    "\n",
    "fig = plt.figure();\n",
    "ax1 = fig.add_subplot(121);\n",
    "ax1.set_title(f'Hist {metric}>{metric_val}')\n",
    "ax1.set_xlabel('R Value'); ax1.set_ylabel('counts')\n",
    "\n",
    "ax2 = fig.add_subplot(122);\n",
    "ax2.set_title(f'Hist {metric}<={metric_val}')\n",
    "ax2.set_xlabel('R Value'); ax2.set_ylabel('counts')\n",
    "\n",
    "\n",
    "ax1.hist(perm_df.r_over_perm);\n",
    "ax2.hist(perm_df.r_under_perm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure(figsize= (15,5));\n",
    "ax1 = fig2.add_subplot(131);\n",
    "ax1.set_title(f'Hist+KDE {metric}>{metric_val}');\n",
    "sns.distplot(perm_df.r_over_perm, kde=True, bins=100,\n",
    "                 color='skyblue', hist_kws={'linewidth': 15, 'alpha':0.65});\n",
    "\n",
    "ax2 = fig2.add_subplot(132);\n",
    "ax2.set_title(f'Hist+KDE {metric}<={metric_val}');\n",
    "sns.distplot(perm_df.r_under_perm, kde=True, bins=100,\n",
    "                 color='skyblue', hist_kws={'linewidth': 15, 'alpha':.65});\n",
    "\n",
    "ax3 = fig2.add_subplot(133);\n",
    "ax3.set_title(f'Hist+KDE Delta');\n",
    "sns.distplot(perm_df.delta_r, kde=True, bins=100,\n",
    "             color='skyblue', hist_kws={'linewidth': 15, 'alpha':.65});"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Z&P Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "#Calc Z vals\n",
    "ovr_avg = np.mean(perm_df.r_over_perm)\n",
    "und_avg = np.mean(perm_df.r_under_perm)\n",
    "ovr_std = np.std(perm_df.r_over_perm)\n",
    "und_std = np.std(perm_df.r_under_perm)\n",
    "\n",
    "dlt_avg = np.mean(perm_df.delta_r)\n",
    "dlt_std = np.std(perm_df.delta_r)\n",
    "\n",
    "ovr_z = (r_over - ovr_avg)/ovr_std\n",
    "und_z = (r_under - und_avg)/und_std\n",
    "r_delta = r_over - r_under\n",
    "dlt_z = (r_delta - dlt_avg)/dlt_std\n",
    "\n",
    "# Calc P Vals\n",
    "ovr_p = scipy.stats.norm.sf(abs(ovr_z))\n",
    "und_p = scipy.stats.norm.sf(abs(und_z))\n",
    "dlt_p = scipy.stats.norm.sf(abs(dlt_z))\n",
    "print('#----------------------------------------------------------------')\n",
    "print(f'p value {metric}>{metric_val}: {ovr_p}')\n",
    "print(f'p value {metric}<={metric_val}: {und_p}')\n",
    "print(f'p value delta metric: {dlt_p}')\n",
    "print('#----------------------------------------------------------------')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Vals over metric')\n",
    "display(perm_df.r_over_perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the results\n",
    "final_df = pd.DataFrame({f'{metric}>{metric_val}': [r_over, p_over, num_perms, counts_over, prop_over,\n",
    "                                                    ovr_z, ovr_p], \n",
    "                         f'{metric}<={metric_val}': [r_under, p_under, num_perms, counts_under, prop_under,\n",
    "                                                     und_z, und_p],\n",
    "                         f'delta_vals': [r_delta, None, num_perms, None, None,\n",
    "                                         dlt_z, dlt_p]}, \n",
    "                        index= ['exptl_r', 'exptl_p', 'num_perms', \n",
    "                                'prop_r_obvs_under_r_exptl', 'prop_perm_occurs_under_exptl_r',\n",
    "                                'z_val', 'p_val'])\n",
    "display(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(out_dir)!=True:\n",
    "    os.mkdir(out_dir)\n",
    "\n",
    "analysis = f'abs_{z_name}_by_{x_name}_split_by_{metric}_{pos_val}_{perm_no}'\n",
    "\n",
    "try:\n",
    "    final_df.to_csv(os.path.join(out_dir, analysis+'.csv'))\n",
    "    print(f'{analysis} saved to: \\n {out_dir}')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    fig2.savefig(os.path.join(out_dir, analysis+'.png'))\n",
    "    print(f'{analysis} saved to: \\n {out_dir}')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----\n",
    "#Final notes; in order to compare the difference of the r values, run this again, but with all Y values +np.min()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.10 (nimlab)",
   "language": "python",
   "name": "nimlab_py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:27:35) [Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "40c01ebd234e7f6bf72e95bdb8c5fad4871868daaad76374490b1ab5db2adc6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
