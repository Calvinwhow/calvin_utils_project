{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60030f1c",
   "metadata": {},
   "source": [
    "# 01 - Find Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f052c410",
   "metadata": {},
   "source": [
    "**Search for the Files**\n",
    "_______\n",
    "Formatting the Directory-Pattern Dictionary\n",
    "The function glob_multiple_file_paths expects a dictionary where each key-value pair corresponds to a root directory and a file pattern to search within that directory. The keys are the root directories where you want to start the search, and the values are the file patterns to match against.\n",
    "\n",
    "Example Dictionary Format:\n",
    "\n",
    ">dir_pattern_dict = {\n",
    ">    '/path/to/first/root_dir': '*.nii',\n",
    ">\n",
    ">    '/path/to/second/root_dir': '*.nii.gz',\n",
    ">\n",
    ">    '/another/path': '*_label.nii'\n",
    ">     Add more key-value pairs as needed\n",
    ">}\n",
    "\n",
    "Using Wildcards:\n",
    "\n",
    "The file patterns can include wildcards to match multiple files:\n",
    "- *: Matches zero or more characters\n",
    "- **: Searches all directories recursively\n",
    "- *.nii will match all files ending with .nii\n",
    "- ?: Matches any single character\n",
    "- file?.nii will match file1.nii, file2.nii, etc.\n",
    "- [seq]: Matches any character in seq\n",
    "- file[1-3].nii will match file1.nii, file2.nii, file3.nii\n",
    "- [!seq]: Matches any character NOT in seq\n",
    "- file[!1-3].nii will match any file that doesn't have 1, 2, or 3 in that position, like file4.nii, file5.nii, etc.\n",
    "\n",
    "Feel free to combine these wildcards to create complex file patterns. For example, *_??.nii will match files like file_01.nii, file_02.nii, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46a2f08",
   "metadata": {},
   "source": [
    "Where to Save to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2674a7-934d-4144-8ad8-820a6ee76c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dictionary with root directories and file patterns\n",
    "dir_pattern_dict = {\n",
    "    '/Volumes/HowExp/datasets/05c_Howard_MetaAlzheimerReview_DBS-TMS_Coordinates/derivatives/roi/sub-*/ses-01/roi/': 'sub-*5.0mm_sphere_roi_composite.nii.gz'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea8081a-82d6-4333-ab48-2cefd6eda18d",
   "metadata": {},
   "source": [
    "## Glob the files and check to see if acceptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cae19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_files = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f2a3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.file_utils.file_path_collector import glob_multiple_file_paths\n",
    "import os\n",
    "# Validate Directory\n",
    "# os.mkdir(os.path.dirname(csv_path))\n",
    "# Call the function and save the returned DataFrame to a CSV file\n",
    "path_df = glob_multiple_file_paths(dir_pattern_dict, save=save_files, save_path=None)\n",
    "\n",
    "# Display the saved path and the DataFrame\n",
    "display(path_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa505b6a",
   "metadata": {},
   "source": [
    "# Option 2 - Extract Subject IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a677c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preceding and proceeding strings\n",
    "preceding = 'sub-'\n",
    "proceeding = '/'\n",
    "\n",
    "# Extract the substring and add it to a new column 'subject'\n",
    "path_df['subject'] = path_df['paths'].str.extract(f'{preceding}(.*?){proceeding}')\n",
    "\n",
    "# Display the updated DataFrame\n",
    "display(path_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd308e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df['Subject'] = path_df['subject'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadba37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0cfe65",
   "metadata": {},
   "source": [
    "# 03 Option A - Import Another CSV and Add the Paths to It\n",
    "**The CSV is expected to be in this format**\n",
    "- ID and absolute paths to niftis are critical\n",
    "```\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "| ID  | Nifti_File_Path            | Covariate_1  | Covariate_2  | Covariate_3  |\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "| 1   | /path/to/file1.nii.gz      | 0.5          | 1.2          | 3.4          |\n",
    "| 2   | /path/to/file2.nii.gz      | 0.7          | 1.4          | 3.1          |\n",
    "| 3   | /path/to/file3.nii.gz      | 0.6          | 1.5          | 3.5          |\n",
    "| 4   | /path/to/file4.nii.gz      | 0.9          | 1.1          | 3.2          |\n",
    "| ... | ...                        | ...          | ...          | ...          |\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8c61cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "spreadsheet_path = '/Volumes/HowExp/datasets/05c_Howard_MetaAlzheimerReview_DBS-TMS_Coordinates/metadata/master_list.xlsx'\n",
    "sheet = 'Sheet1' #If using Excel, enter a string here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2cf254",
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.permutation_analysis_utils.statsmodels_palm import CalvinStatsmodelsPalm\n",
    "# Instantiate the PalmPrepararation class\n",
    "cal_palm = CalvinStatsmodelsPalm(input_csv_path=spreadsheet_path, output_dir=os.path.dirname(spreadsheet_path), sheet=sheet)\n",
    "# Call the process_nifti_paths method\n",
    "data_df = cal_palm.read_and_display_data()\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663c36cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = data_df.merge(path_df, on='Subject', how='outer', suffixes=('', '_pathdf'))\n",
    "display(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4b980c",
   "metadata": {},
   "source": [
    "Rename Paths Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7989468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.rename(columns={'paths': 'roi_path_old'})\n",
    "display(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42f56d9",
   "metadata": {},
   "source": [
    "Save the merged df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dab809",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_excel(spreadsheet_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e79473",
   "metadata": {},
   "source": [
    "# 03 Option B - Save Path DF To Its Own CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586502e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.makedirs(out_dir, exist_ok=True)\n",
    "# path_df.to_csv(os.path.join(out_dir, filename), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed7d5da",
   "metadata": {},
   "source": [
    "Hope this was helpful\n",
    "\n",
    "--Calvin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ac637d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_calvin (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
