{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "\n",
    "def upsample_nifti_simple(source_path, target_path, output_path, debug=True):\n",
    "    \"\"\"\n",
    "    Upsamples the source NIfTI file to match the target shape by embedding\n",
    "    voxel values into a higher-resolution grid based on index space scaling.\n",
    "    \n",
    "    Parameters:\n",
    "    - source_path: Path to the lower-resolution NIfTI file.\n",
    "    - target_path: Tuple representing the shape of the higher-resolution NIfTI (e.g., (x, y, z)).\n",
    "    - output_path: Path where the upsampled NIfTI file will be saved.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. \n",
    "    # Load the source NIfTI file\n",
    "    source_img = nib.load(source_path)\n",
    "    source_data = source_img.get_fdata()\n",
    "    source_shape = source_data.shape\n",
    "    # Load the target NIFTI fiel\n",
    "    target_img = nib.load(target_path)\n",
    "    target_data = target_img.get_fdata()\n",
    "    target_shape = target_data.shape\n",
    "    \n",
    "    # 2. Verify shape is valid\n",
    "    if len(source_shape) != 3:\n",
    "        raise ValueError(\"Source NIfTI must be 3D.\")\n",
    "    if len(target_shape) != 3:\n",
    "        raise ValueError(\"Target shape must be 3D.\")\n",
    "    \n",
    "    # 3. Calculate scaling factors\n",
    "    source_res = np.array(source_img.header.get_zooms()[:3])\n",
    "    target_res = np.array(target_img.header.get_zooms()[:3])\n",
    "    \n",
    "    # 4. Get MNI coordinates at every voxel\n",
    "    source_i = np.arange(source_data.shape[0])\n",
    "    source_j = np.arange(source_data.shape[1])\n",
    "    source_k = np.arange(source_data.shape[2])    \n",
    "    si, sj, sk = np.meshgrid(source_i, source_j, source_k, indexing='ij')\n",
    "    \n",
    "    \n",
    "    target_i = np.arange(target_data.shape[0])\n",
    "    target_j = np.arange(target_data.shape[1])\n",
    "    target_k = np.arange(target_data.shape[2])\n",
    "    ti, tj, tk = np.meshgrid(target_i, target_j, target_k, indexing='ij')\n",
    "    \n",
    "    # 5. Stack into a 4d tensor\n",
    "    sijk = np.stack((si, sj, sk), axis=-1) #stacks along last dimension\n",
    "    tijk = np.stack((ti, tj, tk), axis=-1)\n",
    "    \n",
    "    # 6. Convert IJK Matrices to XYZ Matrices using hamadard product([x y z] = [pi jq kr]= [p q r].T * [i j k].T)\n",
    "    sxyz = sijk * source_res\n",
    "    txyz = tijk * target_res\n",
    "    if debug: \n",
    "        print(\"At the i=40,j=40,k=40, these are the xyz coordinates of the source\")\n",
    "        print(sxyz.shape, sijk[40,40,40], sxyz[40,40,40])\n",
    "        print(\"At the coordinates above, these are the ijk and xyz coordinates of the target\")\n",
    "        distances = np.sqrt(((txyz - sxyz[40,40,40]) ** 2).sum(axis=-1)) # this is distance of EVERY VOXEL IN TARGET COMPARED TO OUR POINT AT 40,40,40\n",
    "        nearest_index = np.argmin(distances) # argmin flattens it into 1d\n",
    "        closest_index = np.unravel_index(nearest_index, distances.shape) # reshape into 3d (txyz results in shape of target)\n",
    "        print(closest_index)\n",
    "        print('xyz shape: ', txyz.shape, 'closest index ijk :',  tijk[closest_index], ' xyz: ', txyz[closest_index])\n",
    "        \n",
    "    # 7. Create a new array, ready to hold the values of source in resolution of target\n",
    "    resampled_values_flat = np.zeros_like(target_data).flatten() # Shape (target len,)\n",
    "    \n",
    "    # # 8. For each ijk index in the target xyz tensor, find the euclidean distances to the source xyz for each source ijk\n",
    "    # Prepare data for easy comparison\n",
    "    sxyz_flat = sxyz.reshape(-1, 3) # shape (source len, 3)\n",
    "    txyz_flat = txyz.reshape(-1, 3) # shape (target len, 3)\n",
    "    source_flat = source_data.flatten() # shape (source len, )\n",
    "    \n",
    "    # Only work on a section at a time\n",
    "    n_chunks = 10000 # split operation up\n",
    "    chunk_step  = txyz_flat.shape[0] // n_chunks\n",
    "    for i in tqdm(range(0,n_chunks)):\n",
    "        start_idx = i * chunk_step\n",
    "        end_idx = (i + 1) * chunk_step if i < n_chunks - 1 else txyz_flat.shape[0]\n",
    "            \n",
    "        tchunk = txyz_flat[start_idx:end_idx, :] # Shape (chunk_len, 3)\n",
    "        A = sxyz_flat[:, None, :]   # shape (source len, 1, 3)\n",
    "        B = tchunk[None, :, :]      # shape (1, chunk_len,  3)\n",
    "        C = A-B                     # shape (source len, chunk_len, 3) \n",
    "        pairwise_euc_dist = np.linalg.norm(C, axis=-1)  # shape (source len, chunk_len)\n",
    "        closest_indices = np.argmin(pairwise_euc_dist, axis=0)  # shape (chunk_len,) | minimum index along each row (corresponding to closest chunk)\n",
    "        resampled_values_flat[start_idx:end_idx] = source_flat[closest_indices]  # Shape: (source len,)\n",
    "        \n",
    "    # 9. Reshape and Insert back into Mask \n",
    "    resampled_data = np.zeros(target_shape)\n",
    "    resampled_data[target_mask] = resampled_values_flat \n",
    "    \n",
    "    ## This is an easily understood example of what we are doing. \n",
    "    # for i in tqdm(range(0, txyz.shape[0])):         # move over rows\n",
    "    #     for j in range(0, txyz.shape[1]):           # move over cols\n",
    "    #         for k in range(0, txyz.shape[2]):       # move over slices\n",
    "    #             euc_dist = np.sqrt((sxyz[:,:,:] - txyz[i,j,k])** 2).sum(axis=-1)     # xyz distance OF SOURCE at IJK to TARGET at ijk\n",
    "    #             closest_index = np.argmin(euc_dist)              #this is flat index due to argmin.\n",
    "    #             closest_source_ijk = np.unravel_index(closest_index, euc_dist.shape) # reshape into source space (was distance of source to target xyz, so is definitionally shaped as source)\n",
    "    #             empty_array[i,j,k] = source_data[closest_source_ijk[:3]]        # get the actual value of the source image at this index, but don't take the \n",
    "    \n",
    "    # 9. Verify the upsampled data matches target shape\n",
    "    if resampled_data.shape != target_shape:\n",
    "        raise ValueError(f\"Upsampled data shape {resampled_data.shape} does not match target shape {target_shape}.\")\n",
    "    \n",
    "    # 6. Create new NIfTI image\n",
    "    # Use an identity affine since we're ignoring the original affine\n",
    "    new_affine = target_img.affine\n",
    "    upsampled_img = nib.Nifti1Image(resampled_data, affine=new_affine)\n",
    "    \n",
    "    # 7. Save the upsampled NIfTI\n",
    "    nib.save(upsampled_img, output_path)\n",
    "    print(f\"Upsampled NIfTI saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def optimized_resampling(source_path, target_path, output_path):\n",
    "    # Load NIfTI files\n",
    "    source_img = nib.load(source_path)\n",
    "    source_data = source_img.get_fdata()\n",
    "    source_shape = source_data.shape\n",
    "\n",
    "    target_img = nib.load(target_path)\n",
    "    target_data = target_img.get_fdata()\n",
    "    target_shape = target_data.shape\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "def upsample_nifti_simple(source_path, target_path, output_path, debug=True):\n",
    "    \"\"\"\n",
    "    Upsamples the source NIfTI file to match the target shape by embedding\n",
    "    voxel values into a higher-resolution grid based on index space scaling.\n",
    "    \n",
    "    Parameters:\n",
    "    - source_path: Path to the lower-resolution NIfTI file.\n",
    "    - target_path: Tuple representing the shape of the higher-resolution NIfTI (e.g., (x, y, z)).\n",
    "    - output_path: Path where the upsampled NIfTI file will be saved.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Load source and target NIfTI files\n",
    "    source_img = nib.load(source_path)\n",
    "    source_data = source_img.get_fdata()\n",
    "    source_shape = source_data.shape\n",
    "    \n",
    "    target_img = nib.load(target_path)\n",
    "    target_data = target_img.get_fdata()\n",
    "    target_shape = target_data.shape\n",
    "    \n",
    "    # 2. Verify shape is valid\n",
    "    if len(source_shape) != 3:\n",
    "        raise ValueError(\"Source NIfTI must be 3D.\")\n",
    "    if len(target_shape) != 3:\n",
    "        raise ValueError(\"Target shape must be 3D.\")\n",
    "    \n",
    "    # 3. Calculate scaling factors\n",
    "    source_res = np.array(source_img.header.get_zooms()[:3])\n",
    "    target_res = np.array(target_img.header.get_zooms()[:3])\n",
    "    \n",
    "    # 4. Get MNI coordinates at every voxel\n",
    "    source_i = np.arange(source_data.shape[0])\n",
    "    source_j = np.arange(source_data.shape[1])\n",
    "    source_k = np.arange(source_data.shape[2])    \n",
    "    si, sj, sk = np.meshgrid(source_i, source_j, source_k, indexing='ij')\n",
    "    \n",
    "    target_i = np.arange(target_data.shape[0])\n",
    "    target_j = np.arange(target_data.shape[1])\n",
    "    target_k = np.arange(target_data.shape[2])\n",
    "    ti, tj, tk = np.meshgrid(target_i, target_j, target_k, indexing='ij')\n",
    "    \n",
    "    # 5. Stack into 4D tensors\n",
    "    sijk = np.stack((si, sj, sk), axis=-1)  # Source grid indices\n",
    "    tijk = np.stack((ti, tj, tk), axis=-1)  # Target grid indices\n",
    "    \n",
    "    # 6. Convert IJK to XYZ coordinates\n",
    "    sxyz = sijk * source_res  # Source XYZ coordinates\n",
    "    txyz = tijk * target_res  # Target XYZ coordinates\n",
    "    \n",
    "    # Build KD-Tree for efficient nearest-neighbor search\n",
    "    sxyz_flat = sxyz.reshape(-1, 3)\n",
    "    source_flat = source_data.flatten()\n",
    "    source_tree = cKDTree(sxyz_flat)\n",
    "    \n",
    "    # Flatten target XYZ coordinates for processing\n",
    "    txyz_flat = txyz.reshape(-1, 3)\n",
    "    \n",
    "    # 7. Chunk-based processing\n",
    "    n_chunks = 10000  # Number of chunks\n",
    "    chunk_step = txyz_flat.shape[0] // n_chunks\n",
    "    resampled_values_flat = np.zeros_like(txyz_flat[:, 0])  # Preallocate output\n",
    "    \n",
    "    for i in tqdm(range(n_chunks)):\n",
    "        # Define chunk\n",
    "        start_idx = i * chunk_step\n",
    "        end_idx = (i + 1) * chunk_step if i < n_chunks - 1 else txyz_flat.shape[0]\n",
    "        tchunk = txyz_flat[start_idx:end_idx, :]\n",
    "        \n",
    "        # Use KD-Tree to find nearest neighbors efficiently\n",
    "        _, closest_indices = source_tree.query(tchunk)\n",
    "        \n",
    "        # Assign resampled values\n",
    "        resampled_values_flat[start_idx:end_idx] = source_flat[closest_indices]\n",
    "    \n",
    "    # Reshape resampled values into target shape\n",
    "    resampled_data = resampled_values_flat.reshape(target_shape)\n",
    "    \n",
    "    # Debugging output (optional)\n",
    "    if debug:\n",
    "        print(\"Source shape:\", source_shape)\n",
    "        print(\"Target shape:\", target_shape)\n",
    "        print(\"Resampled data shape:\", resampled_data.shape)\n",
    "    \n",
    "    # 8. Save the resampled NIfTI file\n",
    "    new_affine = target_img.affine  # Preserve the affine of the target\n",
    "    upsampled_img = nib.Nifti1Image(resampled_data, affine=new_affine)\n",
    "    nib.save(upsampled_img, output_path)\n",
    "    print(f\"Upsampled NIfTI saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_to_upsample = '/Users/cu135/Partners HealthCare Dropbox/Calvin Howard/studies/rimlf/data/test/sub-TeKe_cerebrospinal_fluid_generated_nifti.nii'\n",
    "out_path ='/Users/cu135/Partners HealthCare Dropbox/Calvin Howard/studies/rimlf/data/test/sub-TeKe_cerebrospinal_fluid_generated_nifti_resamp.nii'\n",
    "img_to_target = '/Users/cu135/Partners HealthCare Dropbox/Calvin Howard/studies/rimlf/data/test/wmTeKe_T1_native.nii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsample_nifti_simple(img_to_upsample,img_to_target,out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "def optimize_translation(original_path, resampled_path):\n",
    "    \"\"\"\n",
    "    Optimizes the translation of the resampled NIfTI file to align its centroid\n",
    "    with the centroid of the original NIfTI file.\n",
    "\n",
    "    Parameters:\n",
    "    - original_path: Path to the original NIfTI file.\n",
    "    - resampled_path: Path to the resampled NIfTI file.\n",
    "\n",
    "    Returns:\n",
    "    - optimized_affine: Adjusted affine matrix for the resampled image.\n",
    "    - translation_vector: Computed translation vector applied to the resampled image.\n",
    "    \"\"\"\n",
    "    # Load NIfTI files\n",
    "    original_img = nib.load(original_path)\n",
    "    resampled_img = nib.load(resampled_path)\n",
    "\n",
    "    # Get affine matrices and data shapes\n",
    "    original_affine = original_img.affine\n",
    "    resampled_affine = resampled_img.affine\n",
    "\n",
    "    original_shape = original_img.shape\n",
    "    resampled_shape = resampled_img.shape\n",
    "\n",
    "    # Compute world coordinates for original and resampled\n",
    "    original_ijk = np.array(np.meshgrid(\n",
    "        np.arange(original_shape[0]),\n",
    "        np.arange(original_shape[1]),\n",
    "        np.arange(original_shape[2]),\n",
    "        indexing='ij'\n",
    "    )).reshape(3, -1).T\n",
    "\n",
    "    resampled_ijk = np.array(np.meshgrid(\n",
    "        np.arange(resampled_shape[0]),\n",
    "        np.arange(resampled_shape[1]),\n",
    "        np.arange(resampled_shape[2]),\n",
    "        indexing='ij'\n",
    "    )).reshape(3, -1).T\n",
    "\n",
    "    original_xyz = np.dot(original_affine, np.c_[original_ijk, np.ones(original_ijk.shape[0])].T).T[:, :3]\n",
    "    resampled_xyz = np.dot(resampled_affine, np.c_[resampled_ijk, np.ones(resampled_ijk.shape[0])].T).T[:, :3]\n",
    "\n",
    "    # Compute centroids\n",
    "    original_centroid = np.mean(original_xyz, axis=0)\n",
    "    resampled_centroid = np.mean(resampled_xyz, axis=0)\n",
    "\n",
    "    # Compute translation vector\n",
    "    translation_vector = original_centroid - resampled_centroid\n",
    "\n",
    "    # Apply translation to the affine\n",
    "    optimized_affine = resampled_affine.copy()\n",
    "    translation_vector = [4, -5.5, 0]\n",
    "    optimized_affine[:3, 3] += translation_vector\n",
    "\n",
    "    return optimized_affine, translation_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize translation\n",
    "optimized_affine, translation_vector = optimize_translation('/Users/cu135/Partners HealthCare Dropbox/Calvin Howard/studies/rimlf/data/test/wmTeKe_T1_native.nii', out_path)\n",
    "# Save the resampled NIfTI with the optimized affine\n",
    "resampled_img= nib.load(out_path)\n",
    "optimized_img = nib.Nifti1Image(resampled_img.get_fdata(), affine=optimized_affine)\n",
    "nib.save(optimized_img, '/Users/cu135/Partners HealthCare Dropbox/Calvin Howard/studies/rimlf/data/test/sub-TeKe_cerebrospinal_fluid_generated_nifti_resamp_t.nii')\n",
    "# Debug translation vector\n",
    "print(\"Translation vector applied:\", translation_vector)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.10 (nimlab)",
   "language": "python",
   "name": "nimlab_py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
