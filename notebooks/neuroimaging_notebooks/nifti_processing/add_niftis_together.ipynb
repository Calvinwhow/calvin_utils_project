{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV\n",
    "df = pd.read_csv('/Volumes/AP_ExHD/CalvinsAtrophyMapping_PINES_SCHIZOPHRENIA_ECT/metadata/files_to_subtract.csv')\n",
    "\n",
    "# Pivot the data\n",
    "pivoted_df = df.pivot(columns='order', values='paths')\n",
    "\n",
    "# Rename columns for clarity\n",
    "pivoted_df.columns = ['Group1Col' if col == 1 else 'Group2Col' for col in pivoted_df.columns]\n",
    "\n",
    "# Reset index to make it a standard dataframe\n",
    "pivoted_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Save to a new CSV (optional)\n",
    "pivoted_df.to_csv('/Volumes/AP_ExHD/CalvinsAtrophyMapping_PINES_SCHIZOPHRENIA_ECT/metadata/files_to_subtract_p.csv', index=False)\n",
    "\n",
    "display(pivoted_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV\n",
    "df = pd.read_csv('/Volumes/AP_ExHD/CalvinsAtrophyMapping_PINES_SCHIZOPHRENIA_ECT/metadata/files_to_subtract_p.csv')\n",
    "\n",
    "# Separate groups into lists and drop NaN values\n",
    "group1 = df['Group1Col'].dropna().reset_index(drop=True)\n",
    "group2 = df['Group2Col'].dropna().reset_index(drop=True)\n",
    "\n",
    "# Align the lists into a new DataFrame\n",
    "aligned_df = pd.DataFrame({'Group1Col': group1, 'Group2Col': group2})\n",
    "\n",
    "# Save to a new CSV (optional)\n",
    "aligned_df.to_csv('/Volumes/AP_ExHD/CalvinsAtrophyMapping_PINES_SCHIZOPHRENIA_ECT/metadata/files_to_subtract_p_a.csv', index=False)\n",
    "\n",
    "print(aligned_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional - Discover Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Files to Add Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "def find_files(root_dir, target_str):\n",
    "    \"\"\"\n",
    "    Return a list of files globbed using a root directory and a target string.\n",
    "\n",
    "    Args:\n",
    "        root_dir (str): The root directory to start the search.\n",
    "        target_str (str): The target string to match in file names.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of file paths matching the target string.\n",
    "    \n",
    "    # Example usage:\n",
    "    root_directory = '/path/to/root/directory'\n",
    "    target_string = 'example'\n",
    "\n",
    "    files_matching_target = find_files(root_directory, target_string)\n",
    "    print(files_matching_target)\n",
    "    \"\"\"\n",
    "    search_pattern = f\"{root_dir}/**/*{target_str}*\"\n",
    "    files = glob.glob(search_pattern, recursive=True)\n",
    "    return files\n",
    "\n",
    "def create_dataframe_and_save(paths, output_path):\n",
    "    \"\"\"\n",
    "    Creates a pandas DataFrame from a list of file paths with a single column 'paths'.\n",
    "    The DataFrame is saved to a specified output path without an index.\n",
    "\n",
    "    Parameters:\n",
    "    - paths (list): A list of file paths to include in the DataFrame.\n",
    "    - output_path (str): The file path where the DataFrame should be saved as a CSV.\n",
    "\n",
    "    Prints messages indicating the progress and completion of the DataFrame creation and saving process.\n",
    "    Includes error handling for potential issues during the DataFrame creation and saving process.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Creating the DataFrame\n",
    "        df = pd.DataFrame(paths, columns=['paths'])\n",
    "        print(\"DataFrame created successfully.\")\n",
    "\n",
    "        # Saving the DataFrame to the specified output path\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"DataFrame saved successfully to {output_path}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Root Directory and Target String of Files to Add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/cu135/Partners HealthCare Dropbox/Calvin Howard/resources/datasets/Nilakantan_TMS/derivatives'\n",
    "target = 'sub-*/ses-01/roi/*tms_sphere_roi.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = find_files(path, target)\n",
    "file_list = list(set(file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit the Files Above to Select the Specific Files you Want to Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_list = [\n",
    "#  '/Volumes/Expansion/datasets/SANTE_Epilepsy_DBS_ANT/derivatives/conn/_averaged_summed_binarized_connectivity.nii',\n",
    "#  '/Volumes/Expansion/datasets/Queensland_PD_DBS_STN/derivatives/conn/_summary_maps/_averaged_summed_binarized_connectivity.nii',\n",
    "#  '/Volumes/Expansion/datasets/Kahana_Epilepsy_iEEG/derivatives/_averaged_summed_binarized_connectivity.nii',\n",
    "#  '/Volumes/Expansion/datasets/GRAFMAN_TBI_MULTIFOCAL/grafman_fc/_averaged_summed_binarized_connectivity.nii',\n",
    "#  '/Volumes/Expansion/datasets/Episodic_Memory_Lesions/_averaged_summed_binarized_connectivity.nii',\n",
    "#  '/Volumes/Expansion/datasets/CORBETTA_STROKE_MULTIFOCAL/BIDS_Dataset/_averaged_summed_binarized_connectivity.nii',\n",
    "#  '/Volumes/Expansion/datasets/ADVANCE_AD_DBS_FORNIX/connectivity_data/vta_published_t_connectivity/connectivity_summary/_averaged_summed_binarized_connectivity.nii',\n",
    "#  '/Volumes/Expansion/datasets/Manitoba_PET/_averaged_summed_binarized_connectivity.nii',\n",
    "#  '/Volumes/Expansion/datasets/adni/neuroimaging/true_ad_randomized/connectivity/_averaged_summed_binarized_connectivity.nii'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define CSV Output Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/cu135/Partners HealthCare Dropbox/Calvin Howard/resources/datasets/Nilakantan_TMS/metadata/added.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_dataframe_and_save(paths=file_list, output_path=path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To import from CSV:\n",
    "- import_path = 'files_to_import.csv'\n",
    "- file_column = None\n",
    "- file_pattern = None\n",
    "\n",
    "To import from Folder\n",
    "- \n",
    "- \n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/cu135/Partners HealthCare Dropbox/Calvin Howard/resources/datasets/Nilakantan_TMS/derivatives'\n",
    "file_column = None\n",
    "file_pattern = 'sub-*/ses-01/roi/*tms_sphere_roi.nii.gz' #'*_T.nii*'\n",
    "\n",
    "output_directory = '/Users/cu135/Partners HealthCare Dropbox/Calvin Howard/resources/datasets/Nilakantan_TMS' #'path'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.file_utils.import_functions import GiiNiiFileImport\n",
    "matrix_df1 = GiiNiiFileImport(import_path=path, file_column=file_column, file_pattern=file_pattern).run()\n",
    "matrix_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.file_utils.import_functions import GiiNiiFileImport\n",
    "file_column = 'ses2'\n",
    "matrix_df2 = GiiNiiFileImport(import_path=path, file_column=file_column, file_pattern=file_pattern).run()\n",
    "matrix_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = matrix_df1 - matrix_df2\n",
    "from calvin_utils.nifti_utils.generate_nifti import view_and_save_nifti\n",
    "df3['sum'] = \n",
    "for col in df3:\n",
    "    view_and_save_nifti(df3[col], out_dir='/Volumes/AP_ExHD/CalvinsAtrophyMapping_PINES_SCHIZOPHRENIA_ECT/analyses/subtraction', output_name=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add and save nifits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN values with 0\n",
    "import numpy as np\n",
    "\n",
    "# matrix_df1.values[:] = np.where((matrix_df1.values > -7) & (matrix_df1.values < 7), 0, matrix_df1.values)\n",
    "# nifti_name = '_summed_connectivity'\n",
    "\n",
    "# matrix_df1.values[:] = np.where(matrix_df1.values < -7, 1, np.where(matrix_df1.values > 7, 1, 0))\n",
    "matrix_df1.values[:] = np.where(matrix_df1.values == 1.0, 1, 0)\n",
    "nifti_name = '_summed_binarized_connectivity'\n",
    "\n",
    "matrix_df1.fillna(0, inplace=True)\n",
    "matrix_df1\n",
    "# drop some lesions\n",
    "# Drop every third column (0-indexed, so 2, 5, 8, ...)\n",
    "# matrix_df1.drop(matrix_df1.columns[1::2], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_df1['avg'] = matrix_df1.mean(axis=1)\n",
    "matrix_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nifti_name = 'binary_summed_connectivity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.nifti_utils.generate_nifti import view_and_save_nifti\n",
    "view_and_save_nifti(matrix_df1['avg'], out_dir=output_directory, output_name='avg_difference.nii', ref_file='/Users/cu135/hires_backdrops/MNI152_T1_2mm_brain.nii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_df1['averaged'] = matrix_df1['summed']/(matrix_df1.shape[1]-1)\n",
    "# matrix_df1['averaged'] = matrix_df1['averaged']/np.max(np.abs(matrix_df1['averaged']))\n",
    "\n",
    "from calvin_utils.nifti_utils.generate_nifti import view_and_save_nifti\n",
    "view_and_save_nifti(matrix_df1['averaged'], out_dir=output_directory, output_name=('_averaged'+nifti_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Using MNI152 2mm Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "# Load the two NIFTI files\n",
    "nifti_file1 = nib.load('/Users/cu135/Partners HealthCare Dropbox/Calvin Howard/studies/atrophy_seeds_2023/Figures/riMLF_localization/rIMLF_L_refined-from-Friedrich2022_MF-HF_075-MNI152.nii.gz')\n",
    "nifti_file2 = nib.load('/Users/cu135/Partners HealthCare Dropbox/Calvin Howard/studies/atrophy_seeds_2023/Figures/riMLF_localization/rIMLF_R_refined-from-Friedrich2022_MF-HF_075-MNI152.nii.gz')\n",
    "\n",
    "# Get the data arrays\n",
    "data1 = nifti_file1.get_fdata()\n",
    "data2 = nifti_file2.get_fdata()\n",
    "\n",
    "# Ensure the dimensions of both data arrays match\n",
    "if data1.shape != data2.shape:\n",
    "    raise ValueError(\"The dimensions of the input NIFTI files do not match.\")\n",
    "\n",
    "# Add the data arrays\n",
    "added_data = data1 + data2\n",
    "\n",
    "# Create a new NIFTI image\n",
    "added_img = nib.Nifti1Image(added_data, nifti_file1.affine, nifti_file1.header)\n",
    "\n",
    "# Save the resulting image\n",
    "nib.save(added_img, '/Users/cu135/Partners HealthCare Dropbox/Calvin Howard/studies/atrophy_seeds_2023/Figures/riMLF_localization/rIMLF_BL_refined-from-Friedrich2022_MF-HF_075-MNI152.nii.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_3.7.7_nimlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
