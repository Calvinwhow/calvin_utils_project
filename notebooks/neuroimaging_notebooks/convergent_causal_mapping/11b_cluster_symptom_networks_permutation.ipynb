{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Any Kind of OLS Regression (ANOVA, GLM, Logit, etc.)\n",
    "\n",
    "### Authors: Calvin Howard.\n",
    "\n",
    "#### Last updated: May 5, 2024\n",
    "\n",
    "Use this to run/test a statistical model (e.g., regression or T-tests) on a spreadsheet containing covariates and brain image (nii/gii) paths. \n",
    "\n",
    "Notes:\n",
    "- For this to work, it must be installed onto wherever you want to run it. You must run:\n",
    "```\n",
    "> git clone https://github.com/Calvinwhow/Research.git\n",
    "> cd into wherever you installed it. \n",
    "> pip install -e .\n",
    "```\n",
    "- To best use this notebook, you should be familar with GLM design and Contrast Matrix design. See this webpage to get started:\n",
    "[FSL's GLM page](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/GLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 - Import CSV with All Data\n",
    "**The CSV is expected to be in this format**\n",
    "- ID and absolute paths to niftis are critical\n",
    "```\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "| ID  | Nifti_File_Path            | Covariate_1  | Covariate_2  | Covariate_3  |\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "| 1   | /path/to/file1.nii.gz      | 0.5          | 1.2          | 3.4          |\n",
    "| 2   | /path/to/file2.nii.gz      | 0.7          | 1.4          | 3.1          |\n",
    "| 3   | /path/to/file3.nii.gz      | 0.6          | 1.5          | 3.5          |\n",
    "| 4   | /path/to/file4.nii.gz      | 0.9          | 1.1          | 3.2          |\n",
    "| ... | ...                        | ...          | ...          | ...          |\n",
    "+-----+----------------------------+--------------+--------------+--------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prep Output Direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify where you want to save your results to\n",
    "out_dir = '/Users/cu135/Partners HealthCare Dropbox/Calvin Howard/studies/raynor_network_mapping/results/corbetta_cluster/umapsV2/cluster_maps'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your CSV file containing NIFTI paths\n",
    "input_csv_path = '/Users/cu135/Partners HealthCare Dropbox/Calvin Howard/studies/raynor_network_mapping/metadata/mergedNotCerebellumExtensive_CLEAN.csv'\n",
    "sheet = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MotorL_acute</th>\n",
       "      <th>MotorR_acute</th>\n",
       "      <th>Motor_IC_acute</th>\n",
       "      <th>MotorL_3month</th>\n",
       "      <th>MotorR_3month</th>\n",
       "      <th>Motor_IC_3month</th>\n",
       "      <th>MotorL_1year</th>\n",
       "      <th>MotorR_1year</th>\n",
       "      <th>Motor_IC_1year</th>\n",
       "      <th>motorl_f_acute</th>\n",
       "      <th>...</th>\n",
       "      <th>gdss_12_1year</th>\n",
       "      <th>gdss_13_1year</th>\n",
       "      <th>gdss_14_1year</th>\n",
       "      <th>gdss_15_1year</th>\n",
       "      <th>gdss_score_1year</th>\n",
       "      <th>clock_acute</th>\n",
       "      <th>mes_tot_miss_acute</th>\n",
       "      <th>conn_path</th>\n",
       "      <th>roi_path</th>\n",
       "      <th>focal_cerebellum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.3652</td>\n",
       "      <td>0.5878</td>\n",
       "      <td>-0.7725</td>\n",
       "      <td>-1.0227</td>\n",
       "      <td>0.2821</td>\n",
       "      <td>-0.5117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>/Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...</td>\n",
       "      <td>/Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...</td>\n",
       "      <td>/Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6425</td>\n",
       "      <td>-0.5805</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.7433</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.7515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...</td>\n",
       "      <td>/Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...</td>\n",
       "      <td>/Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3583</td>\n",
       "      <td>0.5973</td>\n",
       "      <td>0.7771</td>\n",
       "      <td>-0.1659</td>\n",
       "      <td>0.6261</td>\n",
       "      <td>0.2651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>/Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...</td>\n",
       "      <td>/Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.7975</td>\n",
       "      <td>0.5861</td>\n",
       "      <td>0.8521</td>\n",
       "      <td>0.7416</td>\n",
       "      <td>0.4959</td>\n",
       "      <td>0.9150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...</td>\n",
       "      <td>/Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...</td>\n",
       "      <td>/Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...</td>\n",
       "      <td>/Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>-2.3491</td>\n",
       "      <td>0.0868</td>\n",
       "      <td>-1.7040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.333489</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>/Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...</td>\n",
       "      <td>/Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.4334</td>\n",
       "      <td>-0.4434</td>\n",
       "      <td>0.3529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.425266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...</td>\n",
       "      <td>/Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows × 196 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MotorL_acute  MotorR_acute  Motor_IC_acute  MotorL_3month  MotorR_3month  \\\n",
       "0             NaN           NaN             NaN        -1.3652         0.5878   \n",
       "1             NaN           NaN             NaN            NaN            NaN   \n",
       "2             NaN           NaN             NaN         0.6425        -0.5805   \n",
       "3             NaN           NaN             NaN            NaN            NaN   \n",
       "4             NaN           NaN             NaN         0.3583         0.5973   \n",
       "..            ...           ...             ...            ...            ...   \n",
       "130        0.7975        0.5861          0.8521         0.7416         0.4959   \n",
       "131           NaN           NaN             NaN            NaN            NaN   \n",
       "132           NaN           NaN             NaN            NaN            NaN   \n",
       "133       -2.3491        0.0868         -1.7040            NaN            NaN   \n",
       "134        0.4334       -0.4434          0.3529            NaN            NaN   \n",
       "\n",
       "     Motor_IC_3month  MotorL_1year  MotorR_1year  Motor_IC_1year  \\\n",
       "0            -0.7725       -1.0227        0.2821         -0.5117   \n",
       "1                NaN           NaN           NaN             NaN   \n",
       "2             0.0808        0.7433        0.3375          0.7515   \n",
       "3                NaN           NaN           NaN             NaN   \n",
       "4             0.7771       -0.1659        0.6261          0.2651   \n",
       "..               ...           ...           ...             ...   \n",
       "130           0.9150           NaN           NaN             NaN   \n",
       "131              NaN           NaN           NaN             NaN   \n",
       "132              NaN           NaN           NaN             NaN   \n",
       "133              NaN           NaN           NaN             NaN   \n",
       "134              NaN           NaN           NaN             NaN   \n",
       "\n",
       "     motorl_f_acute  ...  gdss_12_1year  gdss_13_1year  gdss_14_1year  \\\n",
       "0               NaN  ...            1.0            0.0            0.0   \n",
       "1               NaN  ...            NaN            NaN            NaN   \n",
       "2               NaN  ...            0.0            0.0            0.0   \n",
       "3               NaN  ...            NaN            NaN            NaN   \n",
       "4               NaN  ...            1.0            1.0            0.0   \n",
       "..              ...  ...            ...            ...            ...   \n",
       "130        0.794393  ...            NaN            NaN            NaN   \n",
       "131             NaN  ...            NaN            NaN            NaN   \n",
       "132             NaN  ...            NaN            NaN            NaN   \n",
       "133       -2.333489  ...            NaN            NaN            NaN   \n",
       "134        0.425266  ...            0.0            1.0            0.0   \n",
       "\n",
       "     gdss_15_1year  gdss_score_1year  clock_acute  mes_tot_miss_acute  \\\n",
       "0              0.0               3.0          6.0                45.0   \n",
       "1              NaN               NaN          NaN                 NaN   \n",
       "2              0.0               0.0         12.0                 2.0   \n",
       "3              NaN               NaN         13.0                 2.0   \n",
       "4              1.0              13.0         12.0                31.0   \n",
       "..             ...               ...          ...                 ...   \n",
       "130            NaN               NaN          3.0                 NaN   \n",
       "131            NaN               NaN          NaN                 NaN   \n",
       "132            NaN               NaN          NaN                 NaN   \n",
       "133            NaN               NaN         10.0                38.0   \n",
       "134            0.0               1.0         14.0                 0.0   \n",
       "\n",
       "                                             conn_path  \\\n",
       "0    /Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...   \n",
       "1    /Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...   \n",
       "2    /Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...   \n",
       "3    /Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...   \n",
       "4    /Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...   \n",
       "..                                                 ...   \n",
       "130  /Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...   \n",
       "131  /Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...   \n",
       "132  /Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...   \n",
       "133  /Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...   \n",
       "134  /Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...   \n",
       "\n",
       "                                              roi_path  focal_cerebellum  \n",
       "0    /Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...                 0  \n",
       "1    /Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...                 1  \n",
       "2    /Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...                 0  \n",
       "3    /Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...                 0  \n",
       "4    /Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...                 0  \n",
       "..                                                 ...               ...  \n",
       "130  /Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...                 0  \n",
       "131  /Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...                 1  \n",
       "132  /Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...                 0  \n",
       "133  /Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...                 0  \n",
       "134  /Volumes/HowExp/datasets/02a_Corbetta_Stroke_L...                 0  \n",
       "\n",
       "[135 rows x 196 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from calvin_utils.permutation_analysis_utils.statsmodels_palm import CalvinStatsmodelsPalm\n",
    "# Instantiate the PalmPrepararation class\n",
    "cal_palm = CalvinStatsmodelsPalm(input_csv_path=input_csv_path, output_dir=out_dir, sheet=sheet)\n",
    "# Call the process_nifti_paths method\n",
    "data_df = cal_palm.read_and_display_data()\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 01 - Preprocess Your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handle NANs**\n",
    "- Set drop_nans=True is you would like to remove NaNs from data\n",
    "- Provide a column name or a list of column names to remove NaNs from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MotorL_acute', 'MotorR_acute', 'Motor_IC_acute', 'MotorL_3month',\n",
       "       'MotorR_3month', 'Motor_IC_3month', 'MotorL_1year', 'MotorR_1year',\n",
       "       'Motor_IC_1year', 'motorl_f_acute',\n",
       "       ...\n",
       "       'gdss_12_1year', 'gdss_13_1year', 'gdss_14_1year', 'gdss_15_1year',\n",
       "       'gdss_score_1year', 'clock_acute', 'mes_tot_miss_acute', 'conn_path',\n",
       "       'roi_path', 'focal_cerebellum'],\n",
       "      dtype='object', length=196)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['conn_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = cal_palm.drop_nans_from_columns(columns_to_drop_from=drop_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop Row Based on Value of Column**\n",
    "\n",
    "Define the column, condition, and value for dropping rows\n",
    "- column = 'your_column_name'\n",
    "- condition = 'above'  # Options: 'equal', 'above', 'below'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the parameters for dropping rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'focal_cerebellum'  # The column you'd like to evaluate\n",
    "condition = 'not'  # The condition to check ('equal', 'above', 'below', 'not')\n",
    "value = 0 # The value to drop if found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df, other_df = cal_palm.drop_rows_based_on_value(column, condition, value)\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.bfill()\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Define Your Formula\n",
    "\n",
    "This is the formula relating outcome to predictors, and takes the form:\n",
    "- y = B0 + B1 + B2 + B3 + . . . BN\n",
    "\n",
    "It is defined using the columns of your dataframe instead of the variables above:\n",
    "- 'Apples_Picked ~ hours_worked + owns_apple_picking_machine'\n",
    "\n",
    "____\n",
    "**ANOVA**\n",
    "- Tests differences in means for one categorical variable.\n",
    "- formula = 'Outcome ~ C(Group1)'\n",
    "\n",
    "**2-Way ANOVA**\n",
    "- Tests differences in means for two categorical variables without interaction.\n",
    "- formula = 'Outcome ~ C(Group1) + C(Group2)'\n",
    "\n",
    "**2-Way ANOVA with Interaction**\n",
    "- Tests for interaction effects between two categorical variables.\n",
    "- formula = 'Outcome ~ C(Group1) * C(Group2)'\n",
    "\n",
    "**ANCOVA**\n",
    "- Similar to ANOVA, but includes a covariate to control for its effect.\n",
    "- formula = 'Outcome ~ C(Group1) + Covariate'\n",
    "\n",
    "**2-Way ANCOVA**\n",
    "- Extends ANCOVA with two categorical variables and their interaction, controlling for a covariate.\n",
    "- formula = 'Outcome ~ C(Group1) * C(Group2) + Covariate'\n",
    "\n",
    "**Multiple Regression**\n",
    "- Assesses the impact of multiple predictors on an outcome.\n",
    "- formula = 'Outcome ~ Predictor1 + Predictor2'\n",
    "\n",
    "**Simple Linear Regression**\n",
    "- Assesses the impact of a single predictor on an outcome.\n",
    "- formula = 'Outcome ~ Predictor'\n",
    "\n",
    "**MANOVA**\n",
    "- Assesses multiple dependent variables across groups.\n",
    "- Note: Not typically set up with a formula in statsmodels. Requires specialized functions.\n",
    "\n",
    "____\n",
    "Use the printout below to design your formula. \n",
    "- Left of the \"~\" symbol is the thing to be predicted. \n",
    "- Right of the \"~\" symbol are the predictors. \n",
    "- \":\" indicates an interaction between two things. \n",
    "- \"*\" indicates and interactions AND it accounts for the simple effects too. \n",
    "- \"+\" indicates that you want to add another predictor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ' + '.join(str(c) for c in data_df.columns)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = x.split(' + ')\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"MotorL_acute + MotorR_acute + Motor_IC_acute + MotorL_3month + MotorR_3month + Motor_IC_3month + MotorL_1year + MotorR_1year + Motor_IC_1year + motorl_f_acute + motorr_f_acute + motoric_within_acute + motoryn_acute + motor_battery_complete_acute + motoryn_3month + motor_battery_complete_3month + fim_motor_3month + motoryn_1year + motor_battery_complete_1year + fim_motor_1year + nihss_hospital_basic + nihssyn_acute + nih1a_acute + nih1b_acute + nih1c_acute + nih2_acute + nih3_acute + nih4_acute + nih5a_acute + nih5b_acute + nih6a_acute + nih6b_acute + nih7_acute + nih8_acute + nih9_acute + nih10_acute + nih11_acute + nih_total_acute + nih_stroke_scale_complete_acute + nihssyn_3month + nih1a_3month + nih1b_3month + nih1c_3month + nih2_3month + nih3_3month + nih4_3month + nih5a_3month + nih5b_3month + nih6a_3month + nih6b_3month + nih7_3month + nih8_3month + nih9_3month + nih10_3month + nih11_3month + nih_total_3month + nih_stroke_scale_complete_3month + nihssyn_1year + nih1a_1year + nih1b_1year + nih1c_1year + nih2_1year + nih3_1year + nih4_1year + nih5a_1year + nih5b_1year + nih6a_1year + nih6b_1year + nih7_1year + nih8_1year + nih9_1year + nih10_1year + nih11_1year + nih_total_1year + nih_stroke_scale_complete_1year + animal_raw_acute + nonword_acute + bvmt_im_acute + bvmt_learn_acute + bvmt_delay_acute + bvmt_perc_acute + bvmt_hit_acute + bvmt_fa_acute + bvmt_discrim_acute + bvmt_bias_acute + bvmt_imt_acute + bvmt_delayt_acute + bvmt_index_ile_acute + bvmt_im_3month + bvmt_learn_3month + bvmt_delay_3month + bvmt_perc_3month + bvmt_hit_3month + bvmt_fa_3month + bvmt_discrim_3month + bvmt_bias_3month + bvmt_imt_3month + bvmt_delayt_3month + bvmt_im_1year + bvmt_learn_1year + bvmt_delay_1year + bvmt_perc_1year + bvmt_hit_1year + bvmt_fa_1year + bvmt_discrim_1year + bvmt_bias_1year + bvmt_imt_1year + bvmt_delayt_1year + hvlt_im_acute + hvlt_learn_acute + hvlt_delay_acute + hvlt_perc_acute + hvlt_hit_acute + hvlt_fa1_acute + hvlt_fa2_acute + hvlt_fa3_acute + hvlt_discrim_acute + hvlt_imt_acute + hvlt_delayt_acute + hvlt_discrimt_acute + hvlt_im_3month + hvlt_learn_3month + hvlt_delay_3month + hvlt_perc_3month + hvlt_hit_3month + hvlt_fa1_3month + hvlt_fa2_3month + hvlt_fa3_3month + hvlt_discrim_3month + hvlt_imt_3month + hvlt_delayt_3month + hvlt_discrimt_3month + hvlt_im_1year + hvlt_learn_1year + hvlt_delay_1year + hvlt_perc_1year + hvlt_hit_1year + hvlt_fa1_1year + hvlt_fa2_1year + hvlt_fa3_1year + hvlt_discrim_1year + hvlt_imt_1year + hvlt_delayt_1year + hvlt_discrimt_1year + gds_1_acute + gds_2_acute + gds_3_acute + gds_4_acute + gds_5_acute + gds_6_acute + gds_7_acute + gds_8_acute + gds_9_acute + gds_10_acute + gds_11_acute + gds_12_acute + gds_13_acute + gds_14_acute + gds_15_acute + gdss_1_3month + gdss_2_3month + gdss_3_3month + gdss_4_3month + gdss_5_3month + gdss_6_3month + gdss_7_3month + gdss_8_3month + gdss_9_3month + gdss_10_3month + gdss_11_3month + gdss_12_3month + gdss_13_3month + gdss_14_3month + gdss_15_3month + gdss_score_3month + gdss_1_1year + gdss_2_1year + gdss_3_1year + gdss_4_1year + gdss_5_1year + gdss_6_1year + gdss_7_1year + gdss_8_1year + gdss_9_1year + gdss_10_1year + gdss_11_1year + gdss_12_1year + gdss_13_1year + gdss_14_1year + gdss_15_1year + gdss_score_1year + clock_acute + mes_tot_miss_acute ~ conn_path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formula = \"MotorL_acute + MotorR_acute + gdss_1_3month + gdss_2_3month + gdss_3_3month + gdss_4_3month + gdss_5_3month + gdss_6_3month + gdss_7_3month + gdss_8_3month + gdss_9_3month + gdss_10_3month + gdss_11_3month + gdss_12_3month + gdss_13_3month + gdss_14_3month + gdss_15_3month + gdss_score_3month + gdss_1_1year ~ conn_path\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Visualize Your Design Matrix\n",
    "\n",
    "This is the explanatory variable half of your regression formula\n",
    "_______________________________________________________\n",
    "Create Design Matrix: Use the create_design_matrix method. You can provide a list of formula variables which correspond to column names in your dataframe.\n",
    "\n",
    "- voxelwise_variable_list = A list containing the names of each variable that has voxelwise variables. Plainly, the variables that represent niftis. \n",
    "- By default, an intercept will be added unless you set intercept=False\n",
    "- **don't explicitly add the 'intercept' column. I'll do it for you.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxelwise_variable_list=['conn_path']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to run voxelwise INTERACTIONS, then you should specify the exact terms, exactly as specified in your above formula, here. \n",
    "- For example, if Formula is outcome ~ voxelwise_var1 * age + dog_number, then voxelwise_interaction_terms are ['voxelwise_var1 * age]\n",
    "- Set voxelwise_interaction_terms = None if you do not want to specify any interaction terms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxelwise_interaction_terms = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure ANY voxelwise variables are in formula. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the design matrix\n",
    "outcome_df, design_matrix = cal_palm.define_design_matrix(formula, data_df, add_intercept=False,\n",
    "                                                          voxelwise_variable_list=voxelwise_variable_list, \n",
    "                                                          voxelwise_interaction_terms=voxelwise_interaction_terms)\n",
    "design_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Visualize Your Dependent Variable\n",
    "\n",
    "I have generated this for you based on the formula you provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Generate Contrasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a Contrast Matrix\n",
    "- This is different from the contrast matrices used in cell-means regressions such as in PALM, but it is much more powerful. \n",
    "\n",
    "\n",
    "\n",
    "For more information on contrast matrices, please refer to this: https://cran.r-project.org/web/packages/codingMatrices/vignettes/codingMatrices.pdf\n",
    "\n",
    "Generally, these drastically effect the results of ANOVA. However, they are mereley a nuisance for a regression.\n",
    "In essence, they assess if coefficients are significantly different\n",
    "\n",
    "________________________________________________________________\n",
    "A coding matrix (a contrast matrix if it sums to zero) is simply a way of defining what coefficients to evaluate and how to evaluate them. \n",
    "If a coefficient is set to 1 and everything else is set to zero, we are taking the mean of the coefficient's means and assessing if they significantly\n",
    "deviate from zero--IE we are checking if it had a significant impact on the ability to predict the depdendent variable.\n",
    "If a coefficient is set to 1, another is -1, and others are 0, we are assessing how the means of the two coefficients deviate from eachother. \n",
    "If several coefficients are 1 and several others are -1, we are assessing how the group-level means of the two coefficients deviate from eachother.\n",
    "If a group of coefficients are 1, a group is -1, and a group is 0, we are only assessing how the groups +1 and -1 have differing means. \n",
    "\n",
    "1: This value indicates that the corresponding variable's coefficient in the model is included in the contrast. It means you are interested in estimating the effect of that variable.\n",
    "\n",
    "0: This value indicates that the corresponding variable's coefficient in the model is not included in the contrast. It means you are not interested in estimating the effect of that variable.\n",
    "\n",
    "-1: This value indicates that the corresponding variable's coefficient in the model is included in the contrast, but with an opposite sign. It means you are interested in estimating the negative effect of that variable.\n",
    "\n",
    "----------------------------------------------------------------\n",
    "The contrast matrix is typically a matrix with dimensions (number of contrasts) x (number of regression coefficients). Each row of the contrast matrix represents a contrast or comparison you want to test.\n",
    "\n",
    "For example, let's say you have the following regression coefficients in your model:\n",
    "\n",
    "Intercept, Age, connectivity, Age_interaction_connectivity\n",
    "A contrast matric has dimensions of [n_predictors, n_experiments] where each experiment is a contrast\n",
    "\n",
    "If you want to test the hypothesis that the effect of Age is significant, you can set up a contrast matrix with a row that specifies this contrast (actually an averaging vector):\n",
    "```\n",
    "[0,1,0,0]. This is an averaging vector because it sums to 1\n",
    "```\n",
    "This contrast will test the coefficient corresponding to the Age variable against zero.\n",
    "\n",
    "\n",
    "If you want to test the hypothesis that the effect of Age is different from the effect of connectivity, you can set up a contrast matrix with two rows:\n",
    "```\n",
    "[0,1,−1,0]. This is a contrast because it sums to 0\n",
    "```\n",
    "\n",
    "Thus, if you want to see if any given effect is significant compared to the intercept (average), you can use the following contrast matrix:\n",
    "```\n",
    "[1,0,0,0]\n",
    "[-1,1,0,0]\n",
    "[-1,0,1,0]\n",
    "[-1,0,0,1] actually a coding matrix of averaging vectors\n",
    "```\n",
    "\n",
    "The first row tests the coefficient for Age against zero, and the second row tests the coefficient for connectivity against zero. The difference between the two coefficients can then be assessed.\n",
    "_____\n",
    "You can define any number of contrasts in the contrast matrix to test different hypotheses or comparisons of interest in your regression analysis.\n",
    "\n",
    "It's important to note that the specific contrasts you choose depend on your research questions and hypotheses. You should carefully consider the comparisons you want to make and design the contrast matrix accordingly.\n",
    "\n",
    "- Examples:\n",
    "    - [Two Sample T-Test](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/GLM#Two-Group_Difference_.28Two-Sample_Unpaired_T-Test.29)\n",
    "    - [One Sample with Covariate](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/GLM#Single-Group_Average_with_Additional_Covariate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_matrix = cal_palm.generate_basic_contrast_matrix(design_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_matrix = [\n",
    "    [1]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_matrix_df = cal_palm.finalize_contrast_matrix(design_matrix=design_matrix, \n",
    "                                                    contrast_matrix=contrast_matrix) \n",
    "contrast_matrix_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 - Generate Files\n",
    "Standardization during regression is critical. \n",
    "- data_transform_method='standardize' will ensure the voxelwise values are standardized\n",
    "    - if you design matrix has a column called 'Dataset', the standardization will standardize values within each dataset individually, which is as should be done normally.\n",
    "    - If you call data_transform_method='standardize' without having a 'Dataset' column in your design matrix, the entire collection of images will be standardized. This is potentially dangerous and misleading. Be careful, and consider not standardizing at all, or going back and adding a 'Dataset' column. \n",
    "\n",
    "Mask Path\n",
    "- set mask_path to the path of your local brain mask which matches the resolution of the files you have collected. Typically this is an MNI 152 brain mask. \n",
    "    - download one here: https://nilearn.github.io/dev/modules/generated/nilearn.datasets.load_mni152_brain_mask.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_path = '/Users/cu135/hires_backdrops/MNI/MNI152_T1_2mm_brain_mask.nii'\n",
    "data_transform_method=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define exchangeability block\n",
    "- Set to none if you don't know\n",
    "- If you are running multiple cohorts, set exchangeability block to be the column which has each group in it, with groups being indicated by integers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exchangeability_col = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.permutation_analysis_utils.voxelwise_regression_prep import RegressionPrep\n",
    "preparer = RegressionPrep(design_matrix=design_matrix, \n",
    "                          contrast_matrix=contrast_matrix_df, \n",
    "                          outcome_df=outcome_df, \n",
    "                          out_dir=out_dir,\n",
    "                          voxelwise_variables=voxelwise_variable_list, \n",
    "                          voxelwise_interactions=voxelwise_interaction_terms,\n",
    "                          mask_path=mask_path, \n",
    "                          exchangeability_block=None, \n",
    "                          data_transform_method='standardize',\n",
    "                          weights=None)\n",
    "dataset_dict, json_path = preparer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 - Map and Cluster the Brains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils_project.calvin_utils.ml_utils.umap_regression import UmapRegression\n",
    "umr = UmapRegression(json_path, mask_path, formula, out_dir)\n",
    "umr.run(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all\n",
    "\n",
    "-Calvin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_calvin (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
