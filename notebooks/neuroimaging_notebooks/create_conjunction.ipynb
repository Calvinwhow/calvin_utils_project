{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nimlab import datasets as nimds\n",
    "import numpy as np\n",
    "from nilearn import image, plotting, maskers\n",
    "import nibabel as nib\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Paths Input Here\n",
    "analysis = \"r_map_and_memory_map_conjunction\"\n",
    "if platform.uname().system == 'Darwin': #------------------------------Mac OS X---------------------------------------------------------------\n",
    "    conn_path1 = r'/Users/cu135/Dropbox (Partners HealthCare)/memory/functional_networks/published_composite_networks/0Fx-DBS-Network_N46.nii'\n",
    "    conn_path2 = r'/Users/cu135/Dropbox (Partners HealthCare)/memory/functional_networks/published_composite_networks/0memory_network_T_map.nii'\n",
    "    out_dir = os.path.join(os.path.dirname(conn_path2), f'{analysis}')\n",
    "    #out_dir = r'path to out dir here'\n",
    "    print('I have set pathnames in the Mac style')\n",
    "else: #----------------------------------------------------------------Windows----------------------------------------------------------------\n",
    "    conn_path = r'C:\\Users\\calvin.howard\\Dropbox (Partners HealthCare)\\memory\\analyses\\roi-roi_correl\\matrix_corrMx_AvgR.csv'\n",
    "    clin_path = r'C:\\Users\\calvin.howard\\Dropbox (Partners HealthCare)\\memory\\patient_data\\AD_Clinical_Data_CDR_ADAS_COG_13.xlsx'\n",
    "    # clin_path = 'path to clinical values'\n",
    "    out_dir = r'C:\\Users\\calvin.howard\\Dropbox (Partners HealthCare)\\memory\\analyses\\roi-roi_correl\\stats'\n",
    "    #out_dir = r'path to out dir here'\n",
    "    x_roi_names = r'C:\\Users\\calvin.howard\\Dropbox (Partners HealthCare)\\memory\\analyses\\roi-roi_correl\\matrix_corrMx_names.csv'\n",
    "    #roi_names = '<path to roi name location>'\n",
    "    print('I have set pathnames in the Windows style')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Perform Conjunction Analysios\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from calvin_utils.fisher_z_transform import fisher_z_transform\n",
    "from scipy.ndimage import measurements\n",
    "def conjunction_analysis(file1, file2, f1='t', f2='t', absval=True, binarize=True, thresh_by_stdev=True, thresh_by_quantile=False, threshold_stdevs=2, threshold_quantile=0, threshold_voxels=10, conjunction_type='minimum', flip_matrix=False):\n",
    "    # Load the NIFTI files using nibabel\n",
    "    img1 = nib.load(file1)\n",
    "    img2 = nib.load(file2)\n",
    "\n",
    "    # Extract the data arrays from the NIFTI objects\n",
    "    data1 = img1.get_fdata(); data1 = np.nan_to_num(data1, nan=0, posinf=10, neginf=-10)\n",
    "    data2 = img2.get_fdata(); data2 = np.nan_to_num(data2, nan=0, posinf=10, neginf=-10)\n",
    "    \n",
    "    if flip_matrix:\n",
    "        data1 = data1*(-1)\n",
    "        print('I will flip matrix 1, multiplying by -1')\n",
    "        \n",
    "    #Fisher Z transform R values \n",
    "    if f1 == 'r':\n",
    "        data1 = fisher_z_transform(data1)\n",
    "        data1 = data1\n",
    "        print('I will Fisher Z transform Data 1')\n",
    "    if f2 =='r':\n",
    "        print('I will Fisher Z transform Data 2')\n",
    "        data2 = fisher_z_transform(data2)\n",
    "\n",
    "    # Calculate the threshold as 2 standard deviations for each data array\n",
    "    if thresh_by_stdev:\n",
    "        threshold1 = threshold_stdevs * np.std(data1)\n",
    "        print('I will threshold data1 by ', str(threshold1), f' which is {threshold_stdevs} standard deviations)')\n",
    "        threshold2 = threshold_stdevs * np.std(data2)\n",
    "        print('I will threshold data2 by ', str(threshold2), f' which is {threshold_stdevs} standard deviations)')\n",
    "            #Convert the matrices to their absolute values (do this if you don't know the effect of one on the other)\n",
    "        if absval:\n",
    "            print('I will take the absolute values of the data')\n",
    "            data1 = np.abs(data1)\n",
    "            data2 = np.abs(data2)\n",
    "        data1[data1 < threshold1] = 0\n",
    "        data2[data2 < threshold2] = 0\n",
    "        \n",
    "    if thresh_by_quantile:\n",
    "        #Convert the matrices to their absolute values (do this if you don't know the effect of one on the other)\n",
    "        if absval:\n",
    "            print('I will take the absolute values of the data')\n",
    "            data1 = np.abs(data1)\n",
    "            data2 = np.abs(data2)\n",
    "        threshold1 = np.quantile(data1, threshold_quantile)\n",
    "        threshold2 = np.quantile(data2, threshold_quantile)\n",
    "        data1[data1 < threshold1] = 0\n",
    "        data2[data2 < threshold2] = 0\n",
    "\n",
    "    # Perform the conjunction analysis using the specified type\n",
    "    if conjunction_type == 'minimum':\n",
    "        conjunction_data = np.minimum(data1, data2)\n",
    "    elif conjunction_type == 'product':\n",
    "        conjunction_data = data1 * data2\n",
    "        print('I have conjoined by product')\n",
    "    else:\n",
    "        raise ValueError(\"Invalid conjunction type\")\n",
    "\n",
    "    if binarize:\n",
    "        conjunction_data = np.where(conjunction_data > 0, 1, 0)\n",
    "        print('I will binarize the data')\n",
    "    # Create a new NIFTI object for the conjunction data\n",
    "        \n",
    "    #Eliminate voxels of insufficient volume\n",
    "    if threshold_voxels is not None:\n",
    "        #Set the dimensions of the convoluting kernel\n",
    "        kernel = np.ones((3,3,3))\n",
    "        binary_mask = conjunction_data\n",
    "        convolution = []\n",
    "        for x in range(0, binary_mask.shape[0]): #iterate through all the x xalues\n",
    "            for y in range(0, binary_mask.shape[1]): #iterate through all the y values\n",
    "                for z in range(0, binary_mask.shape[2]): #iterate through all the z values\n",
    "                    try: #If there are 9 voxels, do this\n",
    "                        # Perform convolution with the binary mask and the kernel, appending to array.\n",
    "                        convolution.append(np.squeeze(np.array([\n",
    "                            np.sum(np.multiply(binary_mask[x:x+3, y:y+3, z:z+3], kernel))\n",
    "                        ])))\n",
    "                    except: # if there are <9 voxels, do this. \n",
    "                        convolution.append(0)\n",
    "        # Reshape the convolved array to match the shape of the original data\n",
    "        convolution = np.array(convolution)\n",
    "        convolution = convolution.reshape(binary_mask.shape[0], binary_mask.shape[1], binary_mask.shape[2])\n",
    "        # Set regions equal to less than 10 to 0\n",
    "        binary_mask[convolution < threshold_voxels] = 0    \n",
    "        conjunction_data = binary_mask\n",
    "        print('Data threshold to voxel volume of : ', threshold_voxels)\n",
    "    \n",
    "    print('num voxels d1: ', np.count_nonzero(data1), 'percent survivors: ', np.count_nonzero(conjunction_data)/np.count_nonzero(data1))\n",
    "    print('num voxels d2: ', np.count_nonzero(data2), 'percent survivors: ', np.count_nonzero(conjunction_data)/np.count_nonzero(data2))\n",
    "    print('Surviving voxels: ', np.count_nonzero(conjunction_data))\n",
    "    print('Dice coefficient is: ', np.count_nonzero(conjunction_data)*2 / )\n",
    "    conjunction_matrix = conjunction_data #nib.Nifti1Image(conjunction_data, img1.affine, img1.header)\n",
    "\n",
    "    # Return the conjunction image\n",
    "    return np.reshape(conjunction_matrix, data1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype1 = 'r'; dtype2 = 't'\n",
    "threshold_quantile = 0.96; thresh_by_quantile=True\n",
    "stdev_thresh = 3; thresh_by_stdev=False\n",
    "vox_thresh = None\n",
    "absval = False #take positive and negative values\n",
    "flip_matrix=False #make one matrix negative\n",
    "\n",
    "#-----------------USER INPUT----------------\n",
    "conjunction_matrix = conjunction_analysis(conn_path1, conn_path2, f1=dtype1, f2=dtype2, absval=absval, \n",
    "                                         threshold_stdevs=stdev_thresh, thresh_by_stdev=thresh_by_stdev,\n",
    "                                         threshold_quantile=threshold_quantile, thresh_by_quantile=thresh_by_quantile,\n",
    "                                         threshold_voxels=vox_thresh, \n",
    "                                         conjunction_type='product', binarize=False, flip_matrix=flip_matrix)\n",
    "if type(stdev_thresh) == float:\n",
    "    stdev_name = str(stdev_thresh).split('.')[0]\n",
    "    stdev_name = stdev_name + '-point-' + str(stdev_thresh).split('.')[1]\n",
    "else:\n",
    "    stdev_name = stdev_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = nimds.get_img(\"mni_icbm152\")\n",
    "print(type(conjunction_matrix), type(conjunction_matrix[1][1]))\n",
    "ovr_img1 = image.new_img_like(mask, conjunction_matrix)\n",
    "ovr_html1 = plotting.view_img(ovr_img1, cut_coords=(0,0,0), title=(f'conjunction'), black_bg=False, opacity=.75, cmap='ocean_hot')\n",
    "ovr_html1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify the clusters using convolution\n",
    "import scipy.ndimage as ndimage \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#----------------------------------------------------------------user input----------------------------------------------------------------\n",
    "def convolve_extract_clusters(nifti_image, save_clusters=False):\n",
    "    conjunction_data = nifti_image.get_fdata()\n",
    "\n",
    "    kernel = np.ones((3,3,3))\n",
    "    binary_mask = conjunction_data\n",
    "    convolution = []\n",
    "    for x in range(0, binary_mask.shape[0]): #iterate through all the x xalues\n",
    "        for y in range(0, binary_mask.shape[1]): #iterate through all the y values\n",
    "            for z in range(0, binary_mask.shape[2]): #iterate through all the z values\n",
    "                try: #If there are 9 voxels, do this\n",
    "                    # Perform convolution with the binary mask and the kernel, appending to array.\n",
    "                    convolution.append(np.squeeze(np.array([\n",
    "                        np.sum(np.multiply(binary_mask[x:x+3, y:y+3, z:z+3], kernel))\n",
    "                    ])))\n",
    "                except: # if there are <9 voxels, do this. \n",
    "                    convolution.append(0)\n",
    "    # Reshape the convolved array to match the shape of the original data\n",
    "    convolution = np.array(convolution)\n",
    "    c, numc = ndimage.measurements.label(convolution)\n",
    "    convolution = convolution.reshape(binary_mask.shape[0], binary_mask.shape[1], binary_mask.shape[2])\n",
    "    c, numc = ndimage.measurements.label(convolution)\n",
    "    print('Number clusters: ', numc)\n",
    "\n",
    "    mask = nimds.get_img(\"mni_icbm152\")\n",
    "    cluster_dict = {}\n",
    "    for i in range(1, numc+1):\n",
    "        cluster_dict[i] = np.where(c == i, 1, 0)\n",
    "        print(f'Cluster {i} is size: {np.sum(cluster_dict[i])}')\n",
    "        print(cluster_dict[i].shape)\n",
    "        if save_clusters:\n",
    "            cluster_out = out_dir + f'/clustered_rois_{stdev_name}_standard_deviations'\n",
    "            analysis_name = f'{analysis}_stdevthresh_{stdev_name}_voxthresh_{vox_thresh}_absval_{absval}'\n",
    "            savename = analysis_name + '_cluster_' + str(i)\n",
    "            \n",
    "            if os.path.isdir(cluster_out) != True:\n",
    "                os.mkdir(cluster_out)\n",
    "            \n",
    "            cluster_img = image.new_img_like(mask, cluster_dict[i]);\n",
    "            cluster_html = plotting.view_img(cluster_img, cut_coords=(0,0,0), title=(f'cluster_{i}'), black_bg=False, opacity=.75, cmap='ocean_hot');\n",
    "            cluster_img.to_filename(os.path.join(cluster_out, f'{savename}'));\n",
    "            cluster_html.save_as_html(os.path.join(cluster_out, f'{savename}.html'));\n",
    "\n",
    "            print('File: ' + savename)\n",
    "            print('saved to: ', cluster_out)\n",
    "        # cluster_matrix = cluster.reshape(-1, np.prod(cluster.shape)).T\n",
    "    print(type(cluster_dict[1]))\n",
    "    return cluster_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Save your nifti and html\n",
    "if thresh_by_stdev:\n",
    "    analysis_name = f'conjunction_stdevthresh_{stdev_name}_voxthresh_{vox_thresh}_absval_{absval}'\n",
    "elif thresh_by_quantile:\n",
    "    analysis_name = f'conjunction_percthresh_{int(threshold_quantile*100)}_voxthresh_{vox_thresh}_absval_{absval}'\n",
    "else:\n",
    "    analysis_name = 'arb'\n",
    "print(analysis_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------Save if desired----------------------------------------------------------------\n",
    "if os.path.isdir(out_dir)==False:\n",
    "    os.makedirs(out_dir)\n",
    "savename = analysis_name \n",
    "#Save\n",
    "ovr_img1.to_filename(os.path.join(out_dir, f'{analysis_name}.nii'))\n",
    "ovr_html1.save_as_html(os.path.join(out_dir, f'{analysis_name}.html'))\n",
    "\n",
    "print('Title: ' + savename)\n",
    "print('saved to: ', out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the clusters\n",
    "convolve_extract_clusters(ovr_img1, save_clusters=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.10 (nimlab)",
   "language": "python",
   "name": "nimlab_py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "62880161f19d28ddb8a8f59c63374d84ace356c39e36cc839cb3fb3bb03fb010"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
