{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os\n",
    "import glob as glob\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "#Calculate Correlation\n",
    "from scipy.stats import pearsonr\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import platform\n",
    "\n",
    "from calvin_utils.nifti_utils.generate_nifti import view_and_save_nifti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '/Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/BIDS_AD_DBS_FORNIX/response_topology/voxelwise_mixed_effects/age-stim-interaction_pd-vs-ad'\n",
    "clinical_data_path = r'/Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/BIDS_AD_DBS_FORNIX/clinical_analyses/ses-01/sub-all/ad_pd_mixed_data/ad_pd_full_data.csv'\n",
    "# clin_path = 'path to clinical values'\n",
    "print('Will save to: ', out_dir)\n",
    "save = True\n",
    "if os.path.exists(out_dir):\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Clinical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------user input above----------------------------------------------------------------\n",
    "data_df = pd.read_csv(clinical_data_path)\n",
    "    \n",
    "# #Remove subjects\n",
    "outlier_index=[11, 47, 48, 49]\n",
    "data_df = data_df.drop(index=outlier_index)\n",
    "data_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "data_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get More Clinical Data As Needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_column = 'Patient # CDR, ADAS'\n",
    "clinical_information_column = ['Standardized Age', 'One Hot Disease']\n",
    "outcome_column = 'Standardized Percent Improvement'\n",
    "\n",
    "#----------------------------------------------------------------DO NOT MODIFY--------------------------------------------------------\n",
    "clinical_df_1 = pd.DataFrame()\n",
    "clinical_df_1 = data_df[clinical_information_column]\n",
    "\n",
    "clinical_df_1['subject_id'] = data_df.loc[:, [subject_column]]\n",
    "clinical_df_1['outcome'] = data_df.loc[:, [outcome_column]]\n",
    "\n",
    "# clinical_df_1['subject_id'] = [id.split('_')[0] for id in data_df[subject_column].to_list()] \n",
    "clinical_df_1.set_index('subject_id', inplace=True)\n",
    "\n",
    "# Convert the 'subject_id' column to strings for each DataFrame\n",
    "clinical_df_1.index = clinical_df_1.index.astype(str)\n",
    "display(clinical_df_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Imaging Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.file_utils.import_matrices import import_matrices_from_folder\n",
    "from calvin_utils.nifti_utils.generate_nifti import nifti_from_matrix\n",
    "from nimlab import datasets as nimds\n",
    "import numpy as np\n",
    "from nilearn import image, plotting, maskers\n",
    "\n",
    "#get conectivity values of interest\n",
    "matrix_path = '/Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/BIDS_AD_DBS_FORNIX/connectivity_data/vta_published_t_connectivity'\n",
    "matrix = import_matrices_from_folder(matrix_path, file_pattern='*_T*.nii*')\n",
    "\n",
    "#Standardize matrix via z score\n",
    "prepped_matrix = pd.DataFrame()\n",
    "from calvin_utils.statistical_utils.z_score_matrix import z_score_matrix\n",
    "for column in matrix.columns:\n",
    "    #Rename while we're at it. Needs to be an integer, as this is the type of patient ID in the clinical data\n",
    "    print(column)\n",
    "    new_name = int(column.split('_')[0]) #.split('T')[1]) #<----------------------------------THIS IS A BUG-CREATOR. MUST BE TAILORED TO PATIENT DATA\n",
    "    #Standardize column by column\n",
    "    prepped_matrix[new_name] = z_score_matrix(matrix[column])\n",
    "    #Set values outside brain back to zero\n",
    "    prepped_matrix[new_name] = np.where(matrix[column] == 0, 0, prepped_matrix[new_name])\n",
    "\n",
    "#Set patients to those in the clinical data dataframe\n",
    "prepped_matrix = prepped_matrix.transpose()\n",
    "prepped_matrix['subject_id'] = [str(col).split('_')[0] for col in prepped_matrix.index]\n",
    "prepped_matrix.set_index('subject_id', inplace=True)\n",
    "neuroimaging_df_1 = prepped_matrix\n",
    "neuroimaging_df_1.index = neuroimaging_df_1.index.astype(str)\n",
    "#Display results\n",
    "display(neuroimaging_df_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import More Imaging Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Another Dataframe if desired\n",
    "from calvin_utils.file_utils.import_matrices import import_matrices_from_folder\n",
    "from calvin_utils.nifti_utils.generate_nifti import nifti_from_matrix\n",
    "from nimlab import datasets as nimds\n",
    "import numpy as np\n",
    "from nilearn import image, plotting, maskers\n",
    "\n",
    "#get conectivity values of interest\n",
    "matrix_path = '/Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/BIDS_PD_DBS_STN_WURZBURG/vtasCompoundMNI152/subgroup_with_cognitive_scores/cog_decline_patient_connectivity'\n",
    "neuroimaging_df_2 = import_matrices_from_folder(matrix_path, file_pattern='*T.nii*')\n",
    "performed_z_score = False \n",
    "#----------------------------------------------------------------DO NOT MODIFY!----------------------------------------------------------------\n",
    "#Standardize matrix via z score\n",
    "# neuroimaging_df_2 = pd.DataFrame()\n",
    "# from calvin_utils.z_score_matrix import z_score_matrix\n",
    "# if performed_z_score:\n",
    "#     for column in matrix.columns:\n",
    "#         #Rename while we're at it. Needs to be an integer, as this is the type of patient ID in the clinical data\n",
    "#         new_name = int(column.split('_')[0])\n",
    "#         #Standardize column by column\n",
    "#         prepped_matrix[new_name] = z_score_matrix(matrix[column])\n",
    "#         #Set values outside brain back to zero\n",
    "#         prepped_matrix[new_name] = np.where(matrix[column] == 0, 0, prepped_matrix[new_name])\n",
    "\n",
    "#Set patients to those in the clinical data dataframe\n",
    "# prepped_matrix = prepped_matrix.loc[:, data_df.index]\n",
    "\n",
    "neuroimaging_df_2 = neuroimaging_df_2.transpose()\n",
    "neuroimaging_df_2['subject_id'] = [col.split('_')[0].split('MDST')[1] for col in neuroimaging_df_2.index]\n",
    "neuroimaging_df_2.set_index('subject_id', inplace=True)\n",
    "\n",
    "neuroimaging_df_2.index = neuroimaging_df_2.index.astype(str)\n",
    "\n",
    "\n",
    "#Display results\n",
    "display(neuroimaging_df_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# perform masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mask Dataframes\n",
    "mask_path = None #'/Users/cu135/Dropbox (Partners HealthCare)/resources/datasets/BIDS_AD_DBS_FORNIX/response_topology/voxelwise_glm/stim_by_age/palm_results/palm_statistic_topology/generated_nifti.nii' #None #\n",
    "masking_df = None # # \n",
    "#----------------------------------------------------------------DO NOT MODIFY\n",
    "from calvin_utils.nifti_utils.matrix_utilities import mask_matrix\n",
    "# def mask_matrix(df_1, mask_path=None, mask_threshold=0.2, mask_by='rows', dataframe_to_mask_by=None):\n",
    "\n",
    "neuroimaging_df_1 = mask_matrix(neuroimaging_df_1, mask_path=mask_path, mask_threshold=0, mask_by='columns', dataframe_to_mask_by=masking_df)\n",
    "neuroimaging_df_2 = mask_matrix(neuroimaging_df_2, mask_path=mask_path, mask_threshold=0, mask_by='columns', dataframe_to_mask_by=masking_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a lambda function for standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "neuroimaging_df_1.iloc[:, 0:] = scaler.fit_transform(neuroimaging_df_1.iloc[:, 0:])\n",
    "neuroimaging_df_2.iloc[:, 0:] = scaler.fit_transform(neuroimaging_df_2.iloc[:, 0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroimaging_df_1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Imaging Data to the Clinical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.file_utils.dataframe_utilities import preprocess_colnames_for_regression\n",
    "# Stack neuroimaging dataframes\n",
    "stacked_neuroimaging_df = pd.concat([neuroimaging_df_1, neuroimaging_df_2], axis=0)\n",
    "\n",
    "# Perform inner join with clinical_df\n",
    "merged_df = preprocess_colnames_for_regression(clinical_df_1.join(stacked_neuroimaging_df, how='inner'))\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional - Save Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(os.path.join(out_dir, \"dataframe_for_mixed_effects.csv\"))\n",
    "merged_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run The Mixed Effects Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.file_utils.print_suppression import HiddenPrints\n",
    "import gc\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import statsmodels.regression.mixed_linear_model as sm\n",
    "from patsy import dmatrices\n",
    "\n",
    "\n",
    "def extract_predictors_from_formula(formula):\n",
    "    y, X = dmatrices(formula, pd.DataFrame({'voxel': [0, 1], 'Standardized_Age': [0, 1], 'outcome': [0, 1]}), return_type='dataframe')\n",
    "    return X.columns.tolist()[0:]\n",
    "\n",
    "def initialize_results_array(num_voxels, expected_predictors, metrics):\n",
    "    num_metrics = len(expected_predictors) * len(metrics) + 1  # +1 for 'voxel'\n",
    "    return np.zeros((num_voxels, num_metrics))\n",
    "\n",
    "def voxelwise_mixed_effects_regression_updated(data_df, formula_template, random_effects_column, model_type='linear', batch_size=50000, checkpoint_path='checkpoint.parquet', use_checkpoints=False):\n",
    "    \"\"\"\n",
    "    Perform mixed-effects regression voxelwise based on the provided formula template.\n",
    "    \n",
    "    Parameters:\n",
    "        data_df (pd.DataFrame): DataFrame containing outcome, voxel values, clinical covariates, and other variables with subjects in rows.\n",
    "        formula_template (str): A string template for the regression formula with 'voxel' as a placeholder for voxel columns.\n",
    "        voxel_columns (list): List of voxel column names in data_df.\n",
    "        random_effects_column (str): The column in data_df to be used for random effects.\n",
    "        model_type (str, default='linear'): Specifies the type of regression model to use ('linear' or 'logistic').\n",
    "        batch_size (int, default=5000): Number of voxels to process before saving a checkpoint.\n",
    "        checkpoint_path (str, default='checkpoint.parquet'): Path to save the intermediate results as a checkpoint.\n",
    "        use_checkpoints (bool, default=False): whether or not to use checkpoint function\n",
    "\n",
    "    Returns:\n",
    "        results_df (pd.DataFrame): DataFrame containing p-values, coefficient values, t-values for each voxel,\n",
    "                                   along with the coefficient, t-value, and p-value for each predictor.\n",
    "    \"\"\"\n",
    "    # Extract predictors and initialize results array\n",
    "    voxel_columns = data_df.columns[data_df.columns.get_loc('outcome')+1:]\n",
    "    expected_predictors = extract_predictors_from_formula(formula_template)\n",
    "    metrics = ['_coeff', '_t_value', '_p_value']\n",
    "    num_metrics = len(expected_predictors) * len(metrics) + 1  # +1 for 'voxel'\n",
    "    num_voxels = len(voxel_columns)\n",
    "    results_array = np.zeros((num_voxels, num_metrics))\n",
    "    \n",
    "    # Existing checkpointing logic\n",
    "    try:\n",
    "        if (os.path.exists(checkpoint_path)) & (use_checkpoints):\n",
    "            results_df = pd.read_parquet(checkpoint_path)\n",
    "            start_idx = len(results_df)\n",
    "        else:\n",
    "            start_idx = 0\n",
    "    except Exception as e:\n",
    "        print(f\"Failed due to error: {e}.\")\n",
    "    \n",
    "    # Loop through each voxel column and fit the model\n",
    "    for idx, voxel in enumerate(tqdm(voxel_columns[start_idx:])):\n",
    "        formula = formula_template.replace('voxel', voxel)\n",
    "        \n",
    "        # Existing mixed-effects logic\n",
    "        try:\n",
    "            if model_type == 'linear':\n",
    "                with HiddenPrints():\n",
    "                    model = sm.MixedLM.from_formula(formula, data=data_df, groups=data_df[random_effects_column]).fit(method=\"cg\")\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported model_type: {model_type}\")\n",
    "\n",
    "            # New: Directly populate the results_array\n",
    "            col_idx = 1\n",
    "            for predictor in model.params.index:\n",
    "                results_array[idx, col_idx:col_idx + 3] = [model.params[predictor], model.tvalues[predictor], model.pvalues[predictor]]\n",
    "                col_idx += 3\n",
    "\n",
    "        except Exception as e:\n",
    "            if str(e) == \"Singular matrix\":\n",
    "                pass  # Handle singular matrix cases as needed\n",
    "            \n",
    "        # Existing checkpointing logic\n",
    "        try:\n",
    "            if ((idx + 1) % batch_size == 0) & (use_checkpoints):\n",
    "                pd.DataFrame(results_array).to_parquet(checkpoint_path)\n",
    "                gc.collect()\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to save checkpoint due to error: {e}.\")\n",
    "    \n",
    "    # Generate DataFrame from results_array\n",
    "    column_names = ['voxel'] + [f\"{pred}{met}\" for pred in expected_predictors for met in metrics]\n",
    "    results_df = pd.DataFrame(results_array, columns=column_names)\n",
    "    \n",
    "    return results_df, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'outcome ~ Standardized_Age + voxel  + Standardized_Age:voxel'\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    results_df, model = voxelwise_mixed_effects_regression_updated(merged_df.iloc[:, 0:20], \n",
    "                                                formula_template=formula, \n",
    "                                                random_effects_column = 'One_Hot_Disease', \n",
    "                                                model_type='linear', \n",
    "                                                batch_size=100000, \n",
    "                                                checkpoint_path='checkpoint.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Results to Niftis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from calvin_utils.nifti_utils.generate_nifti import view_and_save_nifti\n",
    "from calvin_utils.nifti_utils.matrix_utilities import unmask_matrix\n",
    "\n",
    "def save_results_as_nifti(results_df, out_dir, mask_path=None, mask_threshold=0.2, unmask_by='rows', dataframe_to_unmask_by=None):\n",
    "    \"\"\"\n",
    "    Save each column in the results DataFrame as a NIFTI file.\n",
    "    \n",
    "    Parameters:\n",
    "        results_df (pd.DataFrame): DataFrame containing various statistical measures for each voxel.\n",
    "        out_dir (str): Directory where NIFTI files should be saved.\n",
    "        mask_path (str, optional): Path to the NIFTI mask file to use for unmasking.\n",
    "        mask_threshold (float, optional): Mask threshold for unmasking.\n",
    "        unmask_by (str, optional): Direction for unmasking ('rows' or 'columns').\n",
    "        dataframe_to_unmask_by (pd.DataFrame, optional): DataFrame to use for unmasking.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "    \n",
    "    # Iterate over every column in results_df and generate NIFTI files\n",
    "    for colname in results_df.columns:\n",
    "        # Unmask the matrix\n",
    "        unmasked_df = unmask_matrix(results_df[colname], mask_path=mask_path, mask_threshold=mask_threshold,\n",
    "                                    unmask_by=unmask_by, dataframe_to_unmask_by=dataframe_to_unmask_by)\n",
    "        \n",
    "        # Save the unmasked matrix as a NIFTI file\n",
    "        view_and_save_nifti(unmasked_df, out_dir, output_name=colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results_as_nifti(results_df, out_dir, mask_path=None, mask_threshold=0.2, unmask_by='rows', dataframe_to_unmask_by=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enjoy\n",
    "\n",
    "-Calvin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimlab_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
